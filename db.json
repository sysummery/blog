{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"themes/ocean/source/404.html","path":"404.html","modified":1,"renderable":1},{"_id":"themes/ocean/source/favicon.ico","path":"favicon.ico","modified":1,"renderable":1},{"_id":"themes/ocean/source/robots.txt","path":"robots.txt","modified":1,"renderable":1},{"_id":"themes/ocean/source/css/404.styl","path":"css/404.styl","modified":1,"renderable":1},{"_id":"themes/ocean/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/ocean/source/fancybox/jquery.fancybox.min.css","path":"fancybox/jquery.fancybox.min.css","modified":1,"renderable":1},{"_id":"themes/ocean/source/images/hexo.svg","path":"images/hexo.svg","modified":1,"renderable":1},{"_id":"themes/ocean/source/images/shark-inverted.svg","path":"images/shark-inverted.svg","modified":1,"renderable":1},{"_id":"themes/ocean/source/images/shark.svg","path":"images/shark.svg","modified":1,"renderable":1},{"_id":"themes/ocean/source/js/busuanzi-2.3.pure.min.js","path":"js/busuanzi-2.3.pure.min.js","modified":1,"renderable":1},{"_id":"themes/ocean/source/js/jquery.justifiedGallery.min.js","path":"js/jquery.justifiedGallery.min.js","modified":1,"renderable":1},{"_id":"themes/ocean/source/js/lazyload.min.js","path":"js/lazyload.min.js","modified":1,"renderable":1},{"_id":"themes/ocean/source/js/ocean.js","path":"js/ocean.js","modified":1,"renderable":1},{"_id":"themes/ocean/source/js/pace.min.js","path":"js/pace.min.js","modified":1,"renderable":1},{"_id":"themes/ocean/source/js/search.js","path":"js/search.js","modified":1,"renderable":1},{"_id":"themes/ocean/source/js/tocbot.min.js","path":"js/tocbot.min.js","modified":1,"renderable":1},{"_id":"themes/ocean/source/fancybox/jquery.fancybox.min.js","path":"fancybox/jquery.fancybox.min.js","modified":1,"renderable":1},{"_id":"themes/ocean/source/js/jquery-2.0.3.min.js","path":"js/jquery-2.0.3.min.js","modified":1,"renderable":1},{"_id":"themes/ocean/source/css/feathericon/feathericon.eot","path":"css/feathericon/feathericon.eot","modified":1,"renderable":1},{"_id":"themes/ocean/source/css/feathericon/feathericon.ttf","path":"css/feathericon/feathericon.ttf","modified":1,"renderable":1},{"_id":"themes/ocean/source/css/feathericon/feathericon.woff","path":"css/feathericon/feathericon.woff","modified":1,"renderable":1},{"_id":"themes/ocean/source/css/feathericon/feathericon.woff2","path":"css/feathericon/feathericon.woff2","modified":1,"renderable":1},{"_id":"themes/ocean/source/images/ocean/overlay-hero.png","path":"images/ocean/overlay-hero.png","modified":1,"renderable":1},{"_id":"themes/ocean/source/css/feathericon/feathericon.svg","path":"css/feathericon/feathericon.svg","modified":1,"renderable":1},{"_id":"themes/ocean/source/images/forrestgump.png","path":"images/forrestgump.png","modified":1,"renderable":1},{"_id":"themes/ocean/source/images/ocean/ocean.ogv","path":"images/ocean/ocean.ogv","modified":1,"renderable":1},{"_id":"themes/ocean/source/images/ocean/ocean.png","path":"images/ocean/ocean.png","modified":1,"renderable":1},{"_id":"themes/ocean/source/images/ocean/ocean.webm","path":"images/ocean/ocean.webm","modified":1,"renderable":1},{"_id":"themes/ocean/source/images/ocean/ocean.mp4","path":"images/ocean/ocean.mp4","modified":1,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"29ca48e0007f57a88befb896f2b9667c543fd340","modified":1574336930471},{"_id":"source/._.DS_Store","hash":"0bed7e90c2bade9763fa18f1fb4441d31f91c87c","modified":1574336930000},{"_id":"source/CNAME","hash":"8208eba922834e71f79fb91228e282bb2afc48fc","modified":1571478270000},{"_id":"themes/ocean/.DS_Store","hash":"ec3d2d9926ac365180bed2ca8666b32eda0bd179","modified":1584188440072},{"_id":"themes/ocean/._.DS_Store","hash":"0bed7e90c2bade9763fa18f1fb4441d31f91c87c","modified":1584188440000},{"_id":"themes/ocean/.__config.yml","hash":"a32259b1ad80eb8e25330ad48dc7f439cefc6ecc","modified":1574054480000},{"_id":"themes/ocean/README.md","hash":"00819412fe8753136eccbc4802ebcb2609c355df","modified":1571468967000},{"_id":"themes/ocean/_config.yml","hash":"41884321efe63d7c561867389422d5490d597dac","modified":1574054480323},{"_id":"themes/ocean/package.json","hash":"b993176f8c35bc3ab9dbd8642ec6cd125fcb447e","modified":1571468967000},{"_id":"source/_posts/.DS_Store","hash":"806243f29518634855dc4f0a2b1de7fc93055634","modified":1606144749004},{"_id":"source/_posts/._.DS_Store","hash":"0bed7e90c2bade9763fa18f1fb4441d31f91c87c","modified":1606144749004},{"_id":"source/_posts/._btree-height.md","hash":"1fae85250f3aaa4fb294b40469336f81d7c1fb4a","modified":1606144749004},{"_id":"source/_posts/._the-log-files-in-mysql.md","hash":"769eab3fcef55a5c7f22a55a9e56db5142452475","modified":1606144749004},{"_id":"source/_posts/btree-height.md","hash":"4544530928fcdc1b953c2f0904ebac9ed809a43a","modified":1606145027775},{"_id":"source/_posts/cookie-oauth2-jwt.md","hash":"436beb864ce1e68867d79c036b0797c17cf56604","modified":1606145027775},{"_id":"source/_posts/git-advance.md","hash":"c19875c74bd2418d2cbd8d7c5f8fe3898d9433c7","modified":1606145027776},{"_id":"source/_posts/go-array-str-slice.md","hash":"da77301f9f4330306f193b5352191cbd3c681f7f","modified":1606145027777},{"_id":"source/_posts/go-gc.md","hash":"15cafd9fbcf687de1f5081f1ef0e56aa54646f2d","modified":1606145027777},{"_id":"source/_posts/go-lock.md","hash":"a0283cf9be2d299348cbb1d9c72185c4fd8224ec","modified":1606145027777},{"_id":"source/_posts/https.md","hash":"259f0192db7e23f141ac131e67bada157813b29c","modified":1606145027778},{"_id":"source/_posts/innodb-locks.md","hash":"08a410062fc5bec997530dd60854b5ac40fb318e","modified":1606145027778},{"_id":"source/_posts/innodb.md","hash":"0591530f5f65b198f16493fad3ffb042197aefed","modified":1606145027778},{"_id":"source/_posts/nginx-notes.md","hash":"7248e7ed1f8ef856615d97388e567d98763edd44","modified":1606145027779},{"_id":"source/_posts/paxos.md","hash":"4ea7a94ba977e3990dbdeb7f66ecd752de50f531","modified":1606145027779},{"_id":"source/_posts/raft-note.md","hash":"2b6742395de04953bd54ed4fa4ac262202c52e61","modified":1606145027779},{"_id":"source/_posts/the-log-files-in-mysql.md","hash":"c7a72ca33c019bca8fd26a5f5639adfd5a7ed514","modified":1606145027780},{"_id":"source/_posts/zk-first-exploration.md","hash":"910b6f5803f3ad389611086714ebb842e4f09f46","modified":1606145027780},{"_id":"source/categories/index.md","hash":"79fdb28cee9916fc647217342db181bb71d536b4","modified":1571468964000},{"_id":"source/posts/.DS_Store","hash":"806243f29518634855dc4f0a2b1de7fc93055634","modified":1606144808939},{"_id":"source/posts/._.DS_Store","hash":"0bed7e90c2bade9763fa18f1fb4441d31f91c87c","modified":1606144808940},{"_id":"source/posts/._btree-height.md","hash":"1fae85250f3aaa4fb294b40469336f81d7c1fb4a","modified":1606144808940},{"_id":"source/posts/._the-log-files-in-mysql.md","hash":"769eab3fcef55a5c7f22a55a9e56db5142452475","modified":1606144808940},{"_id":"source/posts/btree-height.md","hash":"6c6e56fc04cba6366484630fc1b1a1ec267a8f31","modified":1606144808940},{"_id":"source/posts/cookie-oauth2-jwt.md","hash":"d2c15aaf8441cd5cbf9a1495f39177000b301c3c","modified":1606144808940},{"_id":"source/posts/git-advance.md","hash":"b09afef321b49406dae4ec2b04ee6cc56275930d","modified":1606144808940},{"_id":"source/posts/go-array-str-slice.md","hash":"8d945617a28cf0977fc09d2265bbb937503de6ad","modified":1606144808940},{"_id":"source/posts/go-gc.md","hash":"92b5f7d5b6062fa796f54e1ca5318b024db33d0c","modified":1606144808939},{"_id":"source/posts/go-lock.md","hash":"9b67a31deeb1041d4a2f81245efa8428bca591ed","modified":1606144808940},{"_id":"source/posts/https.md","hash":"6c861be271ada0ef846ee5636e84c4100cc0c33c","modified":1606144808940},{"_id":"source/posts/innodb-locks.md","hash":"562086f975de84d02ae56aa018495df071193a56","modified":1606144808940},{"_id":"source/posts/innodb.md","hash":"f81a996029086ae38c76531c883a8f20cbe8eded","modified":1606144808939},{"_id":"source/posts/nginx-notes.md","hash":"3d69cb8fb1b076d022dd99d14ce0e33f451b7827","modified":1606144808939},{"_id":"source/posts/paxos.md","hash":"63bacd350143f87bb028d0cef34213b72ffbe9f1","modified":1606144808940},{"_id":"source/posts/raft-note.md","hash":"e3f29afb22d88bb92b8db6dbd53d7d5cd28dcebf","modified":1606144808939},{"_id":"source/posts/the-log-files-in-mysql.md","hash":"86635b97311eba6b9e308eef1be2825633d77b6d","modified":1606144808940},{"_id":"source/posts/zk-first-exploration.md","hash":"faed7fe3029536b9d8eb97801c5d8519d615752a","modified":1606144808940},{"_id":"source/tags/._index.md","hash":"888815c10b2c87bd50be945b5a6b084605f66671","modified":1573988193000},{"_id":"source/tags/index.md","hash":"0dbd878a2eae645e7ec5ad1666eb7e65743df88d","modified":1573988193879},{"_id":"themes/ocean/.git/FETCH_HEAD","hash":"26b6bdbd6c84123087ed49ab1fa21097672f79db","modified":1571468967000},{"_id":"themes/ocean/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1571468967000},{"_id":"themes/ocean/.git/ORIG_HEAD","hash":"77b13c47e9c38a7cf440256f20cf446eef180931","modified":1571468967000},{"_id":"themes/ocean/.git/config","hash":"686588db57bb2d68a492446ce94aa90be25c28fa","modified":1571468967000},{"_id":"themes/ocean/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1571468967000},{"_id":"themes/ocean/.git/index","hash":"eb92508e108207e9e568ab01e188436c35189a0e","modified":1584196118000},{"_id":"themes/ocean/.git/packed-refs","hash":"23a3a838571501ccde569e40126353e6903ccdb4","modified":1571468967000},{"_id":"themes/ocean/languages/de.yml","hash":"3ebf0775abbee928c8d7bda943c191d166ded0d3","modified":1571468967000},{"_id":"themes/ocean/languages/default.yml","hash":"3083f319b352d21d80fc5e20113ddf27889c9d11","modified":1571468967000},{"_id":"themes/ocean/languages/es.yml","hash":"76edb1171b86532ef12cfd15f5f2c1ac3949f061","modified":1571468967000},{"_id":"themes/ocean/languages/fr.yml","hash":"415e1c580ced8e4ce20b3b0aeedc3610341c76fb","modified":1571468967000},{"_id":"themes/ocean/languages/ja.yml","hash":"a73e1b9c80fd6e930e2628b393bfe3fb716a21a9","modified":1571468967000},{"_id":"themes/ocean/languages/ko.yml","hash":"881d6a0a101706e0452af81c580218e0bfddd9cf","modified":1571468967000},{"_id":"themes/ocean/languages/nl.yml","hash":"12ed59faba1fc4e8cdd1d42ab55ef518dde8039c","modified":1571468967000},{"_id":"themes/ocean/languages/no.yml","hash":"965a171e70347215ec726952e63f5b47930931ef","modified":1571468967000},{"_id":"themes/ocean/languages/pt.yml","hash":"57d07b75d434fbfc33b0ddb543021cb5f53318a8","modified":1571468967000},{"_id":"themes/ocean/languages/ru.yml","hash":"4fda301bbd8b39f2c714e2c934eccc4b27c0a2b0","modified":1571468967000},{"_id":"themes/ocean/languages/zh-CN.yml","hash":"1ef52d096f074d88399ef1fa80d2f78a81d4b83c","modified":1571468967000},{"_id":"themes/ocean/languages/zh-TW.yml","hash":"53ce3000c5f767759c7d2c4efcaa9049788599c3","modified":1571468967000},{"_id":"themes/ocean/layout/.DS_Store","hash":"8a0497cbc993d967552e80f8b09ac8e4dc493e4a","modified":1584188459572},{"_id":"themes/ocean/layout/._.DS_Store","hash":"0bed7e90c2bade9763fa18f1fb4441d31f91c87c","modified":1584188459000},{"_id":"themes/ocean/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1571468967000},{"_id":"themes/ocean/layout/categories.ejs","hash":"5c341e56c38f30e610ab25c9026b4a21fe1127c8","modified":1571468967000},{"_id":"themes/ocean/layout/index.ejs","hash":"dead30ea8014348cef977dcb44eea0ae0f0601c5","modified":1571468967000},{"_id":"themes/ocean/layout/layout.ejs","hash":"280514f9a3d5ba1f571062ec899627dbc06c7298","modified":1571468967000},{"_id":"themes/ocean/layout/page.ejs","hash":"a9a48ae63f5d68a36382951166fdd6e482b901f1","modified":1571468967000},{"_id":"themes/ocean/layout/post.ejs","hash":"a9a48ae63f5d68a36382951166fdd6e482b901f1","modified":1571468967000},{"_id":"themes/ocean/layout/tags.ejs","hash":"88b34dd8d7b1e64fa27aa6ed72af996cf6700809","modified":1571468967000},{"_id":"themes/ocean/source/.DS_Store","hash":"9e946254b724eafb3caf694d23fde1f78d13ca5c","modified":1584186454278},{"_id":"themes/ocean/source/._.DS_Store","hash":"0bed7e90c2bade9763fa18f1fb4441d31f91c87c","modified":1584186454000},{"_id":"themes/ocean/source/404.html","hash":"788929fab7b99dd74575399f41cddae6f63ce1f4","modified":1571468967000},{"_id":"themes/ocean/source/favicon.ico","hash":"0f20298a6a4d1ebd7a7ae7b87d7a3ae9afec0623","modified":1571468967000},{"_id":"themes/ocean/source/robots.txt","hash":"0a017f05351c30d5fcff0206cf19e85fd5c6a6e9","modified":1571468967000},{"_id":"themes/ocean/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1571468967000},{"_id":"themes/ocean/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1571468967000},{"_id":"themes/ocean/.git/hooks/fsmonitor-watchman.sample","hash":"f7c0aa40cb0d620ff0bca3efe3521ec79e5d7156","modified":1571468967000},{"_id":"themes/ocean/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1571468967000},{"_id":"themes/ocean/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1571468967000},{"_id":"themes/ocean/.git/hooks/pre-commit.sample","hash":"33729ad4ce51acda35094e581e4088f3167a0af8","modified":1571468967000},{"_id":"themes/ocean/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1571468967000},{"_id":"themes/ocean/.git/hooks/pre-rebase.sample","hash":"288efdc0027db4cfd8b7c47c4aeddba09b6ded12","modified":1571468967000},{"_id":"themes/ocean/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1571468967000},{"_id":"themes/ocean/.git/hooks/prepare-commit-msg.sample","hash":"2584806ba147152ae005cb675aa4f01d5d068456","modified":1571468967000},{"_id":"themes/ocean/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1571468967000},{"_id":"themes/ocean/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1571468967000},{"_id":"themes/ocean/.git/logs/HEAD","hash":"6e07b0b11a6d913e612b4d970ad8d862ab5985c6","modified":1571468967000},{"_id":"themes/ocean/layout/_partial/.DS_Store","hash":"54002dcc34393cf9831a1f250cd5bcfff8937033","modified":1584188448065},{"_id":"themes/ocean/layout/_partial/._.DS_Store","hash":"0bed7e90c2bade9763fa18f1fb4441d31f91c87c","modified":1584188448000},{"_id":"themes/ocean/layout/_partial/._footer.ejs","hash":"607adf3e5a8293762f6c93a776568a08a7d3bbc1","modified":1581345884000},{"_id":"themes/ocean/layout/_partial/._head.ejs","hash":"dfd920e8135733ad7595f9529c231cca5e83465c","modified":1571468967000},{"_id":"themes/ocean/layout/_partial/._ocean.ejs","hash":"7de333882eae85261f3c93110af3b0b9740fb4ea","modified":1584272553000},{"_id":"themes/ocean/layout/_partial/after-footer.ejs","hash":"35d62fa94858538d23304c112a0d9df58ff36223","modified":1571468967000},{"_id":"themes/ocean/layout/_partial/archive-post.ejs","hash":"9be7173badcca6582c1136204adb3aa432aada21","modified":1571468967000},{"_id":"themes/ocean/layout/_partial/archive.ejs","hash":"d7221ce7a6f5989ded47f7d9b0f40778f897deb6","modified":1571468967000},{"_id":"themes/ocean/layout/_partial/article.ejs","hash":"db02c3113601cd70cf3d0f23449144115fb902b4","modified":1571468967000},{"_id":"themes/ocean/layout/_partial/footer.ejs","hash":"0ca2877f747e71294bb23c71773644bbb8c25c13","modified":1606143515099},{"_id":"themes/ocean/layout/_partial/head.ejs","hash":"498b4cf5e94c50576d9362effe8d581e63142a62","modified":1571468967340},{"_id":"themes/ocean/layout/_partial/ocean.ejs","hash":"a07052b9a72314bfd5e96fecfd21e76c148481f8","modified":1606143598746},{"_id":"themes/ocean/layout/_partial/sidebar.ejs","hash":"ad2a7db738cc2b4a9ab99b2ba81d90390616ffb3","modified":1571468967000},{"_id":"themes/ocean/layout/_partial/totop.ejs","hash":"72b960315983ee95363fa9cabe82f52916ac9ae3","modified":1571468967000},{"_id":"themes/ocean/screenshots/hexo-theme-ocean.jpg","hash":"13b5045d2120cac2f68849757f5e0af08938b7c6","modified":1571468967000},{"_id":"themes/ocean/source/css/.DS_Store","hash":"00cc4275145a4077a9bab6020f176c25852fb0ff","modified":1584186469003},{"_id":"themes/ocean/source/css/._.DS_Store","hash":"0bed7e90c2bade9763fa18f1fb4441d31f91c87c","modified":1584186469000},{"_id":"themes/ocean/source/css/404.styl","hash":"14b2fec2da86081f0545732552aa5f07b545c19a","modified":1571468967000},{"_id":"themes/ocean/source/css/_extend.styl","hash":"deb6aca91c40516f5d638008a72f9def42e5d081","modified":1571468967000},{"_id":"themes/ocean/source/css/_feathericon.styl","hash":"8494f0e869411781264868f08eda62fd838e0cee","modified":1571468967000},{"_id":"themes/ocean/source/css/_mixins.styl","hash":"6959409df2dd0a1ca05be0c0e9b2a884efdfb82d","modified":1571468967000},{"_id":"themes/ocean/source/css/_normalize.styl","hash":"b3337320133b7a336db7033aa6bbe94b054c0b21","modified":1571468967000},{"_id":"themes/ocean/source/css/_variables.styl","hash":"68470eee12d812fcc51c1bd7a4578acae4613fa0","modified":1571468967000},{"_id":"themes/ocean/source/css/style.styl","hash":"b15d434deff447dc22601f325e66dee78a2d80f8","modified":1571468967000},{"_id":"themes/ocean/source/fancybox/jquery.fancybox.min.css","hash":"2e6a66987dbc7a57bbfd2655bce166739b4ba426","modified":1571468967000},{"_id":"themes/ocean/source/images/.DS_Store","hash":"671f8fce95aa48c6f78fd035517194a1081ff62f","modified":1584185876500},{"_id":"themes/ocean/source/images/._.DS_Store","hash":"0bed7e90c2bade9763fa18f1fb4441d31f91c87c","modified":1584185876000},{"_id":"themes/ocean/source/images/._shark-inverted.svg","hash":"ff71355055528d4e3c4bf7e93de14d290a4c3355","modified":1571468967000},{"_id":"themes/ocean/source/images/._shark.svg","hash":"eb17c89bca3fa46a1a813011223df8d9e4b5b6a2","modified":1571468967000},{"_id":"themes/ocean/source/images/hexo.svg","hash":"71e7204d04ccfe260f06ea5873484791cd5f404a","modified":1571468967000},{"_id":"themes/ocean/source/images/shark-inverted.svg","hash":"53140244b49bc7d166c85ce2b9ccec5df01c4de0","modified":1571468967363},{"_id":"themes/ocean/source/images/shark.svg","hash":"1e01df6c601300d7c9d2a5e6e16e32d286fe409f","modified":1571468967362},{"_id":"themes/ocean/source/js/busuanzi-2.3.pure.min.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1571468967000},{"_id":"themes/ocean/source/js/jquery.justifiedGallery.min.js","hash":"73b9373cd80bdbf77e711818095f3f120a019547","modified":1571468967000},{"_id":"themes/ocean/source/js/lazyload.min.js","hash":"b801b3946fb9b72e03512c0663458e140e1fa77b","modified":1571468967000},{"_id":"themes/ocean/source/js/ocean.js","hash":"acac20176cf22a84f889894d7482dc9207076f12","modified":1571468967000},{"_id":"themes/ocean/source/js/pace.min.js","hash":"d32ab818e0f97d3b0c80f5631fc23d8a0cb52795","modified":1571468967000},{"_id":"themes/ocean/source/js/search.js","hash":"118be0e0918532ac1225f62e1a0a6f0673e0b173","modified":1571468967000},{"_id":"themes/ocean/source/js/tocbot.min.js","hash":"bae97e8a24a05a99335f8e725641c8ca9c50502a","modified":1571468967000},{"_id":"themes/ocean/source/fancybox/jquery.fancybox.min.js","hash":"b2b093d8f5ffeee250c8d0d3a2285a213318e4ea","modified":1571468967000},{"_id":"themes/ocean/source/js/jquery-2.0.3.min.js","hash":"800edb7787c30f4982bf38f2cb8f4f6fb61340e9","modified":1571468967000},{"_id":"themes/ocean/.git/objects/pack/pack-91a241f34a42bf5b544ce7bcba628c5cd5a2d6a4.idx","hash":"3e532b7a4b090c4211b214c068b8fd20523f1b7a","modified":1571468967000},{"_id":"themes/ocean/.git/refs/heads/master","hash":"77b13c47e9c38a7cf440256f20cf446eef180931","modified":1571468967000},{"_id":"themes/ocean/layout/_partial/post/._gitalk.ejs","hash":"f38e48afb0c7591e8218542bfdd547581a8e1569","modified":1571468967000},{"_id":"themes/ocean/layout/_partial/post/albums.ejs","hash":"acb6d9628b7a2de4f32a84c6f652ac7207d14517","modified":1571468967000},{"_id":"themes/ocean/layout/_partial/post/busuanzi.ejs","hash":"88462d160479cc3f0cc58efcd888fbaf22b0d4d8","modified":1571468967000},{"_id":"themes/ocean/layout/_partial/post/category.ejs","hash":"85f0ebeceee1c32623bfa1e4170dbe1e34442fea","modified":1571468967000},{"_id":"themes/ocean/layout/_partial/post/date.ejs","hash":"6197802873157656e3077c5099a7dda3d3b01c29","modified":1571468967000},{"_id":"themes/ocean/layout/_partial/post/gallery.ejs","hash":"5f8487fe7bed9a09001c6655244ff35f583cf1eb","modified":1571468967000},{"_id":"themes/ocean/layout/_partial/post/gitalk.ejs","hash":"e36d149ad83c3a52562dbef61a0083957eb24578","modified":1571468967335},{"_id":"themes/ocean/layout/_partial/post/justifiedGallery.ejs","hash":"17ccb9fc394d11412619a153997bb87650799c6e","modified":1571468967000},{"_id":"themes/ocean/layout/_partial/post/nav.ejs","hash":"e59198918e92ef92156aeefbf6023584ac1cae64","modified":1571468967000},{"_id":"themes/ocean/layout/_partial/post/search.ejs","hash":"2c9d19d1685e834aa2020998da2a2d259ce9b9ff","modified":1571468967000},{"_id":"themes/ocean/layout/_partial/post/tag.ejs","hash":"2fcb0bf9c8847a644167a27824c9bb19ac74dd14","modified":1571468967000},{"_id":"themes/ocean/layout/_partial/post/title.ejs","hash":"53ccbfc6f1c424fb4dd609c1a61ffb69841403cc","modified":1571468967000},{"_id":"themes/ocean/layout/_partial/post/tocbot.ejs","hash":"9898b0dd9237e21908ba40292a8a9f947bed44d2","modified":1571468967000},{"_id":"themes/ocean/layout/_partial/post/topping.ejs","hash":"bacd7e1d09397cfb32d97b5f3296f3ac538e57ea","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/._navbar.styl","hash":"00b6838cbd36af2a1c29f6ecb42a98347ed22a27","modified":1573984557000},{"_id":"themes/ocean/source/css/_partial/albums.styl","hash":"0659d5f7469f24a415354ff767d949926465d515","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/apple.styl","hash":"e06dce604cc58ec39d677e4e59910c2725684901","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/archive.styl","hash":"8aefdcf2d542ad839018c2c58511e3318a38490d","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/article.styl","hash":"89be74d7c23366cad7ae1acf0db38bf0e7687a46","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/articles.styl","hash":"7bf289013d304505984b251be725b49165a694fd","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/categories.styl","hash":"f0c898823a5ddc37ae6bf76cc34ce8e50dd30885","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/float.styl","hash":"d888df89a172e4c8119cb8740fc1eae1a9539157","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/footer.styl","hash":"24779cbce1012d4f35ffc6b3ec0830cbc2ea3b3f","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/gallery.styl","hash":"7bdc2c9fb4971dbd7511c5cbb69bd611f20db591","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/gitalk.styl","hash":"3706eef2e0541493f1679a30241d279e29dfdc17","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/highlight.styl","hash":"c6e99fd23056fb01177aeefbc5dd4a8e88cf8f81","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/justifiedGallery.styl","hash":"e7b5784ffd501f98216a717f876f2adb23fa5cd9","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/layou.styl","hash":"afe74f664f413d48a18739e908b6768f59eb5443","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/lists.styl","hash":"6fd213c53027d42164bfc9f0e3b4ea02317bfb89","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/mobile.styl","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/navbar.styl","hash":"6248092d2f333380b7afe569a3a55e3da4935a0c","modified":1573984557549},{"_id":"themes/ocean/source/css/_partial/ocean.styl","hash":"69ba351909c73eb1e04510facc9b35dd584198e0","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/pace.styl","hash":"e326918ba276ee332d0598d8193ccd8353e7d916","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/search.styl","hash":"011aaf21942dfff514ed4e98ce20142efbdd1b71","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/sidebar.styl","hash":"600c70f1de82da5223af290d47a583f9c379d188","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/tag.styl","hash":"925af8beede44ab53fe3cd0a5c472d2baa03baec","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/tocbot.styl","hash":"da8560a8f9718d3afb9760956f9f8e4bb88b3dd8","modified":1571468967000},{"_id":"themes/ocean/source/css/_partial/totop.styl","hash":"4bae031b6852384666cdf36e98c6bbbba1281453","modified":1571468967000},{"_id":"themes/ocean/source/css/feathericon/feathericon.eot","hash":"e2a01ae6f849841bc7a9fd21e5b7b450f1ded19b","modified":1571468967000},{"_id":"themes/ocean/source/css/feathericon/feathericon.ttf","hash":"d0d80c3c960d7d45e6bd7fa428d8a6a8c8245b2d","modified":1571468967000},{"_id":"themes/ocean/source/css/feathericon/feathericon.woff","hash":"d22fe861e47afd92969ab46c7cbb7ea9c225aaf8","modified":1571468967000},{"_id":"themes/ocean/source/css/feathericon/feathericon.woff2","hash":"2c11c45331d914ee38ad42ccf966132a508b5596","modified":1571468967000},{"_id":"themes/ocean/source/images/ocean/._ocean.mp4","hash":"22138706294113a5106c80dc86a1d07b8db05120","modified":1571468967000},{"_id":"themes/ocean/source/images/ocean/._ocean.ogv","hash":"212cdc38d30e06f24773abda79d2de07af552e6c","modified":1571468967000},{"_id":"themes/ocean/source/images/ocean/._ocean.png","hash":"1eb7bbe0774c2fbdf65cb2e044f3662c6cc41d30","modified":1571468967000},{"_id":"themes/ocean/source/images/ocean/._ocean.webm","hash":"38dfa6ceb11441196b4e22d8a02001ad49267d41","modified":1571468967000},{"_id":"themes/ocean/source/images/ocean/._overlay-hero.png","hash":"7ef5c5d1fd8d359adb00482301fca0b1081d870d","modified":1571468967000},{"_id":"themes/ocean/source/images/ocean/overlay-hero.png","hash":"92481a1848c35be96a693af11f77265323a7c189","modified":1571468967358},{"_id":"themes/ocean/source/css/feathericon/feathericon.svg","hash":"c113006c6822451802c8457128c352c0e4934453","modified":1571468967000},{"_id":"themes/ocean/.git/logs/refs/heads/master","hash":"6e07b0b11a6d913e612b4d970ad8d862ab5985c6","modified":1571468967000},{"_id":"themes/ocean/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1571468967000},{"_id":"themes/ocean/source/images/forrestgump.png","hash":"18ad6a8ba815878e36a0d5562136dc4fb8920c12","modified":1571468967000},{"_id":"themes/ocean/.git/logs/refs/remotes/origin/HEAD","hash":"6e07b0b11a6d913e612b4d970ad8d862ab5985c6","modified":1571468967000},{"_id":"themes/ocean/source/images/ocean/ocean.ogv","hash":"9c6b5d6b0544472cee39f5eafac2d5cbba5fd86b","modified":1571468967359},{"_id":"themes/ocean/source/images/ocean/ocean.png","hash":"8245d07f812625d19b48ad2d00f8191f2aa4d304","modified":1571468967362},{"_id":"themes/ocean/source/images/ocean/ocean.webm","hash":"65aa2b6483e0151611899e31571057334c60d9e4","modified":1571468967361},{"_id":"themes/ocean/source/images/ocean/ocean.mp4","hash":"1e89cac2d652005d9dafd3ecb4dd460a8ff6d6af","modified":1571468967357},{"_id":"themes/ocean/.git/objects/pack/pack-91a241f34a42bf5b544ce7bcba628c5cd5a2d6a4.pack","hash":"355f8511ae80c5a07177f5ffe8cfa4d29a2d4647","modified":1571468967000},{"_id":"public/search.xml","hash":"c3fbf9c4904eff13c2ffc27290793dc4fea749a3","modified":1606145058813},{"_id":"public/posts/btree-height.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1606145058969},{"_id":"public/posts/cookie-oauth2-jwt.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1606145058969},{"_id":"public/posts/git-advance.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1606145058969},{"_id":"public/posts/go-array-str-slice.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1606145058969},{"_id":"public/posts/go-gc.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1606145058969},{"_id":"public/posts/go-lock.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1606145058969},{"_id":"public/posts/https.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1606145058969},{"_id":"public/posts/innodb-locks.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1606145058969},{"_id":"public/posts/innodb.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1606145058970},{"_id":"public/posts/nginx-notes.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1606145058970},{"_id":"public/posts/paxos.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1606145058970},{"_id":"public/posts/raft-note.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1606145058970},{"_id":"public/posts/the-log-files-in-mysql.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1606145058970},{"_id":"public/posts/zk-first-exploration.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1606145058970},{"_id":"public/categories/index.html","hash":"04015835f84e2f6f8b4d110c2f405cbc9734b8b9","modified":1606145058970},{"_id":"public/tags/index.html","hash":"977b9584d0cf995e62e06169ab338e1205d31286","modified":1606145058970},{"_id":"public/zk-first-exploration/index.html","hash":"af51c517a9e82462d39029190bde8610df07c0b5","modified":1606145058970},{"_id":"public/raft-note/index.html","hash":"2ea15c081fc497b2a735e50a22ae25fa7fb1e7f3","modified":1606145058970},{"_id":"public/paxos/index.html","hash":"27dbfe4ea954502fbcee6ffb9969db563b591711","modified":1606145058970},{"_id":"public/go-gc/index.html","hash":"092fd381d6f93e3203b159a024c1a71625b4bd57","modified":1606145058970},{"_id":"public/innodb/index.html","hash":"1f49a780e2050c08a03dbe758ad78a2c504ef3cb","modified":1606145058970},{"_id":"public/git-advance/index.html","hash":"cf6e95b540807cfcadbf3321abaf28da3913be09","modified":1606145058970},{"_id":"public/btree-height/index.html","hash":"f9e038ba2c318514ee766079a9b8904b65e33694","modified":1606145058970},{"_id":"public/the-log-files-in-mysql/index.html","hash":"21287c6c350cb9de26225abb06392494c6635a8a","modified":1606145058970},{"_id":"public/https/index.html","hash":"a0950bf2ee21927eae75bce665bb03508fd81078","modified":1606145058970},{"_id":"public/archives/index.html","hash":"dc1931fe306e435336671e9f69ccc4a827dbbed0","modified":1606145058971},{"_id":"public/archives/page/2/index.html","hash":"1779754ee0ad3df380112cfd5fd6305bacd74e99","modified":1606145058971},{"_id":"public/archives/2019/index.html","hash":"0a8f9a4bf6b343616d7a0dc057cc2e1962ba6e3b","modified":1606145058971},{"_id":"public/archives/2019/08/index.html","hash":"58527e80c6cf63b131a21de472514cc97cf275c1","modified":1606145058971},{"_id":"public/archives/2019/11/index.html","hash":"801f93590a015c655b03dfb05dd5adcc628c028c","modified":1606145058971},{"_id":"public/archives/2019/12/index.html","hash":"6b84262ce9a34fea8bda4bc2fcc47bad4b0e1609","modified":1606145058971},{"_id":"public/archives/2020/index.html","hash":"07ceb5e98aab6aea71540b05be8dade1e76e9521","modified":1606145058971},{"_id":"public/archives/2020/01/index.html","hash":"4a3f13284accc34a70dc2e1586963421c2c8b8b2","modified":1606145058971},{"_id":"public/archives/2020/03/index.html","hash":"0ebfaa36d7a781bda75f22c012f3eb56d467d647","modified":1606145058971},{"_id":"public/page/2/index.html","hash":"ba975d2785bcb376f8cdbe584b8051ab47ba6495","modified":1606145058971},{"_id":"public/tags/mysql/index.html","hash":"18b9a6d03dc66ef144e3901a631ae97bbc267e55","modified":1606145058971},{"_id":"public/tags/innodb/index.html","hash":"76fea9678d6c2ac7114072d1686b5634075bb16f","modified":1606145058971},{"_id":"public/tags/cookie/index.html","hash":"d066667babd0cacc79cd0a70c8316b6d74ee7ec9","modified":1606145058971},{"_id":"public/tags/oauth2/index.html","hash":"4e7514a217e4438bba7c8ae4d8dd7bfc40e0dd02","modified":1606145058971},{"_id":"public/tags/jwt/index.html","hash":"e3ef807fb7bd1f5b345e63b3e1348a0d4cd50828","modified":1606145058971},{"_id":"public/tags/git/index.html","hash":"45e2447d1f9b84f51dbf6ff32cf781d9e0a0bb59","modified":1606145058971},{"_id":"public/tags/go/index.html","hash":"9a80a3cc4f52d91ff6614f9a40ec977144c64245","modified":1606145058971},{"_id":"public/tags/https/index.html","hash":"4e69ac6480b862181e3db0496927f74e856f5b42","modified":1606145058972},{"_id":"public/tags/nginx/index.html","hash":"ce45611d1455af0c82d45a00de95ad26430a122c","modified":1606145058972},{"_id":"public/tags/分布式/index.html","hash":"0f3008cc1f126cdba7ca5f440f7ffd67978d0b28","modified":1606145058972},{"_id":"public/go-lock/index.html","hash":"cb0235ca399d127456a655dac7d7d3958dcc6714","modified":1606145058972},{"_id":"public/go-array-str-slice/index.html","hash":"ce7470a471773cfd028e716759a21b0218c8bf10","modified":1606145058972},{"_id":"public/innodb-locks/index.html","hash":"c61a27f907761d8fcc23908e2fdbdd0b3bf73831","modified":1606145058972},{"_id":"public/cookie-oauth2-jwt/index.html","hash":"2b503dd0d255347d25fb8a590140bf29c428b08e","modified":1606145058972},{"_id":"public/nginx-notes/index.html","hash":"ae3b598262a635b741c79598deaeb07dd222df04","modified":1606145058972},{"_id":"public/index.html","hash":"11b3dc0ebf561b481f863b4db7fa093c76ca779f","modified":1606145058972},{"_id":"public/CNAME","hash":"8208eba922834e71f79fb91228e282bb2afc48fc","modified":1606145058976},{"_id":"public/favicon.ico","hash":"0f20298a6a4d1ebd7a7ae7b87d7a3ae9afec0623","modified":1606145058976},{"_id":"public/robots.txt","hash":"0a017f05351c30d5fcff0206cf19e85fd5c6a6e9","modified":1606145058976},{"_id":"public/images/hexo.svg","hash":"71e7204d04ccfe260f06ea5873484791cd5f404a","modified":1606145058976},{"_id":"public/images/shark-inverted.svg","hash":"53140244b49bc7d166c85ce2b9ccec5df01c4de0","modified":1606145058976},{"_id":"public/images/shark.svg","hash":"1e01df6c601300d7c9d2a5e6e16e32d286fe409f","modified":1606145058976},{"_id":"public/css/feathericon/feathericon.eot","hash":"e2a01ae6f849841bc7a9fd21e5b7b450f1ded19b","modified":1606145058976},{"_id":"public/css/feathericon/feathericon.ttf","hash":"d0d80c3c960d7d45e6bd7fa428d8a6a8c8245b2d","modified":1606145058976},{"_id":"public/css/feathericon/feathericon.woff","hash":"d22fe861e47afd92969ab46c7cbb7ea9c225aaf8","modified":1606145058976},{"_id":"public/css/feathericon/feathericon.woff2","hash":"2c11c45331d914ee38ad42ccf966132a508b5596","modified":1606145058976},{"_id":"public/images/ocean/overlay-hero.png","hash":"92481a1848c35be96a693af11f77265323a7c189","modified":1606145058976},{"_id":"public/css/feathericon/feathericon.svg","hash":"c113006c6822451802c8457128c352c0e4934453","modified":1606145059289},{"_id":"public/css/404.css","hash":"952f9d1b869886a2940768fb7d1fd891ccea29fa","modified":1606145059295},{"_id":"public/fancybox/jquery.fancybox.min.css","hash":"2e6a66987dbc7a57bbfd2655bce166739b4ba426","modified":1606145059295},{"_id":"public/js/busuanzi-2.3.pure.min.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1606145059295},{"_id":"public/js/lazyload.min.js","hash":"b801b3946fb9b72e03512c0663458e140e1fa77b","modified":1606145059295},{"_id":"public/js/ocean.js","hash":"acac20176cf22a84f889894d7482dc9207076f12","modified":1606145059295},{"_id":"public/js/pace.min.js","hash":"d32ab818e0f97d3b0c80f5631fc23d8a0cb52795","modified":1606145059295},{"_id":"public/js/search.js","hash":"118be0e0918532ac1225f62e1a0a6f0673e0b173","modified":1606145059295},{"_id":"public/js/tocbot.min.js","hash":"bae97e8a24a05a99335f8e725641c8ca9c50502a","modified":1606145059295},{"_id":"public/404.html","hash":"fb25f79daf1b4678973fd37e3148bc4dcb64d640","modified":1606145059295},{"_id":"public/css/style.css","hash":"4991a30adf378a40f19b7d485c1a16430fe4c5f0","modified":1606145059295},{"_id":"public/js/jquery.justifiedGallery.min.js","hash":"73b9373cd80bdbf77e711818095f3f120a019547","modified":1606145059295},{"_id":"public/fancybox/jquery.fancybox.min.js","hash":"b2b093d8f5ffeee250c8d0d3a2285a213318e4ea","modified":1606145059295},{"_id":"public/js/jquery-2.0.3.min.js","hash":"800edb7787c30f4982bf38f2cb8f4f6fb61340e9","modified":1606145059295},{"_id":"public/images/forrestgump.png","hash":"18ad6a8ba815878e36a0d5562136dc4fb8920c12","modified":1606145059302},{"_id":"public/images/ocean/ocean.ogv","hash":"9c6b5d6b0544472cee39f5eafac2d5cbba5fd86b","modified":1606145059306},{"_id":"public/images/ocean/ocean.png","hash":"8245d07f812625d19b48ad2d00f8191f2aa4d304","modified":1606145059310},{"_id":"public/images/ocean/ocean.webm","hash":"65aa2b6483e0151611899e31571057334c60d9e4","modified":1606145059328},{"_id":"public/images/ocean/ocean.mp4","hash":"1e89cac2d652005d9dafd3ecb4dd460a8ff6d6af","modified":1606145059337}],"Category":[],"Data":[],"Page":[{"title":"categories","date":"2019-10-18T05:35:54.000Z","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2019-10-18 13:35:54\n---\n","updated":"2019-10-19T07:09:24.000Z","path":"categories/index.html","comments":1,"layout":"page","_id":"ckhupaq9300011no8iaryg1xh","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Innodb查看B+tree的高度","date":"2019-11-21T02:46:47.000Z","tags":["mysql","innodb"],"photos":[["http://sysummerblog.club/b-plus-tree_cover.png"]],"_content":"在innodb中无论是主键索引还是非主键索引数据结构都是B+tree。而B+tree数的高度直接决定了在不考虑缓存的情况下读取一个数据页硬盘所需的IO次数，因此B+tree的高度相当重要。生产环境下高度一般为2~3.\n<!--more-->\n## 一颗B+tree能存放多少数据？\n先回顾几个名词\n\n* 磁盘的最小存储单元是扇区，大小为512字节\n* 文件系统的最小存储单元是4kb\n* innodb中数据的最小存储单元是页，大小为16kb（16384字节，不过也可以设置的更小）可以通过以下命令获取\n```sql\nshow variables like 'innodb_page_size'\n```\n* innodb中聚簇索引（主键）的叶子节点存放的是数据，非叶子节点存放的是关键字和指向下一层的指针，如下图所示，不过实际上叶子结点之间是一个双向链表而不是单向链表\n![](http://sysummerblog.club/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%882.41.29.jpg)\n\n我们假设主键是8字节的bigint型的，B+tree中的指针是6字节，那么一对数据+指针就是14字节，一个数据页的大小时16kb,但是一个数据页中不可能全部存放数据，还会有一些元信息，关于页结构可以参考这篇[文章](https://www.cnblogs.com/bdsir/p/8745553.html)。我们假设一个数据页存放数据部分最大16282字节。那么一个数据页可以存放`16282/14=1163`对“键值与指针”。\n\n如果一个数据表的主键索引的高度是2，说明他的第一层是键值和指针，第二层就是数据页了。第一层有1163个指针，也就说明第二层有1163个数据页，总共能存放`1163*16282=18935966`比特的数据。如果一行数据的平均大小为1kb,那么高度为2的B+tree可以存放`18935966/1024=18492`条数据。下面的这个是sql是查看一张表的行数据的平均大小\n```sql\nSELECT\n\t* \nFROM\n\tinformation_schema.TABLES \nWHERE\n\tinformation_schema.TABLES.TABLE_SCHEMA = 'test' \n\tAND information_schema.TABLES.TABLE_NAME = 'insert_asc'\n```\n其中test是库名insert_asc是表名。返回结果中的'AVG_ROW_LENGTH'就是每行数据的平均长度。\n\n如果高度是3的B+tree，第一层有1163个关键字于指针对，第二层就有`1163*1163`个关键字与指针对，叶子层就可以存放`1163*1163*16282`比特的数据。还是假如平均一行的数据大小是1kb,那么高度是3的B+tree可以存放`1163*1163*16282/1024=21506375`条数据。\n\n以上的推论过程有如下的局限性\n\n1. 一个数据页可以用来存放数据的空间是多少，我们假设是16282比特，但具体是多少我查了很多资料都没找到。\n2. 当一个数据页中的数据行的某一字段太大的时候，会把一部分数据放到额外的页中，为的是保证一个数据页至少有两条数据。所以啊，实际存储数据的数据页可能大于主键B+tree的叶子节点的数目。\n\n尽管上面的论证有一些局限性，但是我们还是能够得到如下的结论\n\n1. 如果单行数据不是太大的情况下，比如1kb,那么一课高度为3的主键索引可以存储2000多万行的数据，如果单行数据为0.5kb那么可以存储4000多万行的数据。\n2. 如果数据行的字段很多，会导致行数据的平均大小变大，可能会使B+tree的高度变大\n3. 一般来说B+tree的高度为2~3的时候性能是不错的，换言之如果单行记录不大的情况下，innodb的一张表能轻松地hold住2000万级别的数据\n\n## 直接查看B+tree的高度\n在innodb的表空间文件中,约定在根页偏移量64的地方存放了B+tree的高度。高度是从0开始算的。使用sql\n```sql\nSELECT\n\tb.NAME,\n\ta.NAME,\n\tindex_id,\n\ttype,\n\ta.space,\n\ta.PAGE_NO \nFROM\n\tinformation_schema.INNODB_SYS_INDEXES a,\n\tinformation_schema.INNODB_SYS_TABLES b \nWHERE\n\ta.table_id = b.table_id \n\tAND a.space <> 0 \n\tAND b.NAME = 'test/insert_desc';\n```\n可看到test数据库insert_desc表的所有索引信息\n![](http://sysummerblog.club/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%884.44.31.jpg)\n\n可以看到第一行是主键索引，他的根页在表空间的第三页。resblock_id是一个普通的索引，他的根页在表空间的第四页。使用\n```sh\nhexdump -s 49216 -n 10 insert_asc.ibd\n```\n可以看到表insert_asc.ibd主键索引的高度。\n![](http://sysummerblog.club/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%885.00.59.jpg)\n可以看到前两个字节是2，因此高度是3因为高度是从0开始算的。\n\n`-s 49216`表示从表空间文件的49216字节的偏移量开始读取，为什么是49216？因为主键索引的是在第三页,`49216=16kb*3+64`,其中16kb是数据页的大小。同理resblock_id的索引高度读取方法是\n```\nhexdump -s 65600 -n 10 insert_asc.ibd\n```\n得到的结果是\n![](http://sysummerblog.club/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%885.04.23.jpg)\n\n也就是改索引的高度是1.\n","source":"posts/btree-height.md","raw":"---\ntitle: Innodb查看B+tree的高度\ndate: 2019-11-21 10:46:47\ntags:\n    - mysql\n    - innodb\nphotos:\n    - [\"http://sysummerblog.club/b-plus-tree_cover.png\"]\n---\n在innodb中无论是主键索引还是非主键索引数据结构都是B+tree。而B+tree数的高度直接决定了在不考虑缓存的情况下读取一个数据页硬盘所需的IO次数，因此B+tree的高度相当重要。生产环境下高度一般为2~3.\n<!--more-->\n## 一颗B+tree能存放多少数据？\n先回顾几个名词\n\n* 磁盘的最小存储单元是扇区，大小为512字节\n* 文件系统的最小存储单元是4kb\n* innodb中数据的最小存储单元是页，大小为16kb（16384字节，不过也可以设置的更小）可以通过以下命令获取\n```sql\nshow variables like 'innodb_page_size'\n```\n* innodb中聚簇索引（主键）的叶子节点存放的是数据，非叶子节点存放的是关键字和指向下一层的指针，如下图所示，不过实际上叶子结点之间是一个双向链表而不是单向链表\n![](http://sysummerblog.club/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%882.41.29.jpg)\n\n我们假设主键是8字节的bigint型的，B+tree中的指针是6字节，那么一对数据+指针就是14字节，一个数据页的大小时16kb,但是一个数据页中不可能全部存放数据，还会有一些元信息，关于页结构可以参考这篇[文章](https://www.cnblogs.com/bdsir/p/8745553.html)。我们假设一个数据页存放数据部分最大16282字节。那么一个数据页可以存放`16282/14=1163`对“键值与指针”。\n\n如果一个数据表的主键索引的高度是2，说明他的第一层是键值和指针，第二层就是数据页了。第一层有1163个指针，也就说明第二层有1163个数据页，总共能存放`1163*16282=18935966`比特的数据。如果一行数据的平均大小为1kb,那么高度为2的B+tree可以存放`18935966/1024=18492`条数据。下面的这个是sql是查看一张表的行数据的平均大小\n```sql\nSELECT\n\t* \nFROM\n\tinformation_schema.TABLES \nWHERE\n\tinformation_schema.TABLES.TABLE_SCHEMA = 'test' \n\tAND information_schema.TABLES.TABLE_NAME = 'insert_asc'\n```\n其中test是库名insert_asc是表名。返回结果中的'AVG_ROW_LENGTH'就是每行数据的平均长度。\n\n如果高度是3的B+tree，第一层有1163个关键字于指针对，第二层就有`1163*1163`个关键字与指针对，叶子层就可以存放`1163*1163*16282`比特的数据。还是假如平均一行的数据大小是1kb,那么高度是3的B+tree可以存放`1163*1163*16282/1024=21506375`条数据。\n\n以上的推论过程有如下的局限性\n\n1. 一个数据页可以用来存放数据的空间是多少，我们假设是16282比特，但具体是多少我查了很多资料都没找到。\n2. 当一个数据页中的数据行的某一字段太大的时候，会把一部分数据放到额外的页中，为的是保证一个数据页至少有两条数据。所以啊，实际存储数据的数据页可能大于主键B+tree的叶子节点的数目。\n\n尽管上面的论证有一些局限性，但是我们还是能够得到如下的结论\n\n1. 如果单行数据不是太大的情况下，比如1kb,那么一课高度为3的主键索引可以存储2000多万行的数据，如果单行数据为0.5kb那么可以存储4000多万行的数据。\n2. 如果数据行的字段很多，会导致行数据的平均大小变大，可能会使B+tree的高度变大\n3. 一般来说B+tree的高度为2~3的时候性能是不错的，换言之如果单行记录不大的情况下，innodb的一张表能轻松地hold住2000万级别的数据\n\n## 直接查看B+tree的高度\n在innodb的表空间文件中,约定在根页偏移量64的地方存放了B+tree的高度。高度是从0开始算的。使用sql\n```sql\nSELECT\n\tb.NAME,\n\ta.NAME,\n\tindex_id,\n\ttype,\n\ta.space,\n\ta.PAGE_NO \nFROM\n\tinformation_schema.INNODB_SYS_INDEXES a,\n\tinformation_schema.INNODB_SYS_TABLES b \nWHERE\n\ta.table_id = b.table_id \n\tAND a.space <> 0 \n\tAND b.NAME = 'test/insert_desc';\n```\n可看到test数据库insert_desc表的所有索引信息\n![](http://sysummerblog.club/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%884.44.31.jpg)\n\n可以看到第一行是主键索引，他的根页在表空间的第三页。resblock_id是一个普通的索引，他的根页在表空间的第四页。使用\n```sh\nhexdump -s 49216 -n 10 insert_asc.ibd\n```\n可以看到表insert_asc.ibd主键索引的高度。\n![](http://sysummerblog.club/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%885.00.59.jpg)\n可以看到前两个字节是2，因此高度是3因为高度是从0开始算的。\n\n`-s 49216`表示从表空间文件的49216字节的偏移量开始读取，为什么是49216？因为主键索引的是在第三页,`49216=16kb*3+64`,其中16kb是数据页的大小。同理resblock_id的索引高度读取方法是\n```\nhexdump -s 65600 -n 10 insert_asc.ibd\n```\n得到的结果是\n![](http://sysummerblog.club/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%885.04.23.jpg)\n\n也就是改索引的高度是1.\n","updated":"2020-11-23T15:20:08.940Z","path":"posts/btree-height.html","comments":1,"layout":"page","_id":"ckhupaq9500031no89baaly0d","content":"<p>在innodb中无论是主键索引还是非主键索引数据结构都是B+tree。而B+tree数的高度直接决定了在不考虑缓存的情况下读取一个数据页硬盘所需的IO次数，因此B+tree的高度相当重要。生产环境下高度一般为2~3.</p>\n<a id=\"more\"></a>\n<h2 id=\"一颗B-tree能存放多少数据？\"><a href=\"#一颗B-tree能存放多少数据？\" class=\"headerlink\" title=\"一颗B+tree能存放多少数据？\"></a>一颗B+tree能存放多少数据？</h2><p>先回顾几个名词</p>\n<ul>\n<li><p>磁盘的最小存储单元是扇区，大小为512字节</p>\n</li>\n<li><p>文件系统的最小存储单元是4kb</p>\n</li>\n<li><p>innodb中数据的最小存储单元是页，大小为16kb（16384字节，不过也可以设置的更小）可以通过以下命令获取</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'innodb_page_size'</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>innodb中聚簇索引（主键）的叶子节点存放的是数据，非叶子节点存放的是关键字和指向下一层的指针，如下图所示，不过实际上叶子结点之间是一个双向链表而不是单向链表<br><img src=\"http://sysummerblog.club/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%882.41.29.jpg\" alt></p>\n</li>\n</ul>\n<p>我们假设主键是8字节的bigint型的，B+tree中的指针是6字节，那么一对数据+指针就是14字节，一个数据页的大小时16kb,但是一个数据页中不可能全部存放数据，还会有一些元信息，关于页结构可以参考这篇<a href=\"https://www.cnblogs.com/bdsir/p/8745553.html\" target=\"_blank\" rel=\"noopener\">文章</a>。我们假设一个数据页存放数据部分最大16282字节。那么一个数据页可以存放<code>16282/14=1163</code>对“键值与指针”。</p>\n<p>如果一个数据表的主键索引的高度是2，说明他的第一层是键值和指针，第二层就是数据页了。第一层有1163个指针，也就说明第二层有1163个数据页，总共能存放<code>1163*16282=18935966</code>比特的数据。如果一行数据的平均大小为1kb,那么高度为2的B+tree可以存放<code>18935966/1024=18492</code>条数据。下面的这个是sql是查看一张表的行数据的平均大小</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">SELECT</span></span><br><span class=\"line\">\t* </span><br><span class=\"line\"><span class=\"keyword\">FROM</span></span><br><span class=\"line\">\tinformation_schema.TABLES </span><br><span class=\"line\"><span class=\"keyword\">WHERE</span></span><br><span class=\"line\">\tinformation_schema.TABLES.TABLE_SCHEMA = <span class=\"string\">'test'</span> </span><br><span class=\"line\">\t<span class=\"keyword\">AND</span> information_schema.TABLES.TABLE_NAME = <span class=\"string\">'insert_asc'</span></span><br></pre></td></tr></table></figure>\n\n<p>其中test是库名insert_asc是表名。返回结果中的’AVG_ROW_LENGTH’就是每行数据的平均长度。</p>\n<p>如果高度是3的B+tree，第一层有1163个关键字于指针对，第二层就有<code>1163*1163</code>个关键字与指针对，叶子层就可以存放<code>1163*1163*16282</code>比特的数据。还是假如平均一行的数据大小是1kb,那么高度是3的B+tree可以存放<code>1163*1163*16282/1024=21506375</code>条数据。</p>\n<p>以上的推论过程有如下的局限性</p>\n<ol>\n<li>一个数据页可以用来存放数据的空间是多少，我们假设是16282比特，但具体是多少我查了很多资料都没找到。</li>\n<li>当一个数据页中的数据行的某一字段太大的时候，会把一部分数据放到额外的页中，为的是保证一个数据页至少有两条数据。所以啊，实际存储数据的数据页可能大于主键B+tree的叶子节点的数目。</li>\n</ol>\n<p>尽管上面的论证有一些局限性，但是我们还是能够得到如下的结论</p>\n<ol>\n<li>如果单行数据不是太大的情况下，比如1kb,那么一课高度为3的主键索引可以存储2000多万行的数据，如果单行数据为0.5kb那么可以存储4000多万行的数据。</li>\n<li>如果数据行的字段很多，会导致行数据的平均大小变大，可能会使B+tree的高度变大</li>\n<li>一般来说B+tree的高度为2~3的时候性能是不错的，换言之如果单行记录不大的情况下，innodb的一张表能轻松地hold住2000万级别的数据</li>\n</ol>\n<h2 id=\"直接查看B-tree的高度\"><a href=\"#直接查看B-tree的高度\" class=\"headerlink\" title=\"直接查看B+tree的高度\"></a>直接查看B+tree的高度</h2><p>在innodb的表空间文件中,约定在根页偏移量64的地方存放了B+tree的高度。高度是从0开始算的。使用sql</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">SELECT</span></span><br><span class=\"line\">\tb.NAME,</span><br><span class=\"line\">\ta.NAME,</span><br><span class=\"line\">\tindex_id,</span><br><span class=\"line\">\t<span class=\"keyword\">type</span>,</span><br><span class=\"line\">\ta.space,</span><br><span class=\"line\">\ta.PAGE_NO </span><br><span class=\"line\"><span class=\"keyword\">FROM</span></span><br><span class=\"line\">\tinformation_schema.INNODB_SYS_INDEXES a,</span><br><span class=\"line\">\tinformation_schema.INNODB_SYS_TABLES b </span><br><span class=\"line\"><span class=\"keyword\">WHERE</span></span><br><span class=\"line\">\ta.table_id = b.table_id </span><br><span class=\"line\">\t<span class=\"keyword\">AND</span> a.space &lt;&gt; <span class=\"number\">0</span> </span><br><span class=\"line\">\t<span class=\"keyword\">AND</span> b.NAME = <span class=\"string\">'test/insert_desc'</span>;</span><br></pre></td></tr></table></figure>\n\n<p>可看到test数据库insert_desc表的所有索引信息<br><img src=\"http://sysummerblog.club/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%884.44.31.jpg\" alt></p>\n<p>可以看到第一行是主键索引，他的根页在表空间的第三页。resblock_id是一个普通的索引，他的根页在表空间的第四页。使用</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexdump -s 49216 -n 10 insert_asc.ibd</span><br></pre></td></tr></table></figure>\n\n<p>可以看到表insert_asc.ibd主键索引的高度。<br><img src=\"http://sysummerblog.club/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%885.00.59.jpg\" alt><br>可以看到前两个字节是2，因此高度是3因为高度是从0开始算的。</p>\n<p><code>-s 49216</code>表示从表空间文件的49216字节的偏移量开始读取，为什么是49216？因为主键索引的是在第三页,<code>49216=16kb*3+64</code>,其中16kb是数据页的大小。同理resblock_id的索引高度读取方法是</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexdump -s 65600 -n 10 insert_asc.ibd</span><br></pre></td></tr></table></figure>\n\n<p>得到的结果是<br><img src=\"http://sysummerblog.club/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%885.04.23.jpg\" alt></p>\n<p>也就是改索引的高度是1.</p>\n","site":{"data":{}},"excerpt":"<p>在innodb中无论是主键索引还是非主键索引数据结构都是B+tree。而B+tree数的高度直接决定了在不考虑缓存的情况下读取一个数据页硬盘所需的IO次数，因此B+tree的高度相当重要。生产环境下高度一般为2~3.</p>","more":"<h2 id=\"一颗B-tree能存放多少数据？\"><a href=\"#一颗B-tree能存放多少数据？\" class=\"headerlink\" title=\"一颗B+tree能存放多少数据？\"></a>一颗B+tree能存放多少数据？</h2><p>先回顾几个名词</p>\n<ul>\n<li><p>磁盘的最小存储单元是扇区，大小为512字节</p>\n</li>\n<li><p>文件系统的最小存储单元是4kb</p>\n</li>\n<li><p>innodb中数据的最小存储单元是页，大小为16kb（16384字节，不过也可以设置的更小）可以通过以下命令获取</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'innodb_page_size'</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>innodb中聚簇索引（主键）的叶子节点存放的是数据，非叶子节点存放的是关键字和指向下一层的指针，如下图所示，不过实际上叶子结点之间是一个双向链表而不是单向链表<br><img src=\"http://sysummerblog.club/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%882.41.29.jpg\" alt></p>\n</li>\n</ul>\n<p>我们假设主键是8字节的bigint型的，B+tree中的指针是6字节，那么一对数据+指针就是14字节，一个数据页的大小时16kb,但是一个数据页中不可能全部存放数据，还会有一些元信息，关于页结构可以参考这篇<a href=\"https://www.cnblogs.com/bdsir/p/8745553.html\" target=\"_blank\" rel=\"noopener\">文章</a>。我们假设一个数据页存放数据部分最大16282字节。那么一个数据页可以存放<code>16282/14=1163</code>对“键值与指针”。</p>\n<p>如果一个数据表的主键索引的高度是2，说明他的第一层是键值和指针，第二层就是数据页了。第一层有1163个指针，也就说明第二层有1163个数据页，总共能存放<code>1163*16282=18935966</code>比特的数据。如果一行数据的平均大小为1kb,那么高度为2的B+tree可以存放<code>18935966/1024=18492</code>条数据。下面的这个是sql是查看一张表的行数据的平均大小</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">SELECT</span></span><br><span class=\"line\">\t* </span><br><span class=\"line\"><span class=\"keyword\">FROM</span></span><br><span class=\"line\">\tinformation_schema.TABLES </span><br><span class=\"line\"><span class=\"keyword\">WHERE</span></span><br><span class=\"line\">\tinformation_schema.TABLES.TABLE_SCHEMA = <span class=\"string\">'test'</span> </span><br><span class=\"line\">\t<span class=\"keyword\">AND</span> information_schema.TABLES.TABLE_NAME = <span class=\"string\">'insert_asc'</span></span><br></pre></td></tr></table></figure>\n\n<p>其中test是库名insert_asc是表名。返回结果中的’AVG_ROW_LENGTH’就是每行数据的平均长度。</p>\n<p>如果高度是3的B+tree，第一层有1163个关键字于指针对，第二层就有<code>1163*1163</code>个关键字与指针对，叶子层就可以存放<code>1163*1163*16282</code>比特的数据。还是假如平均一行的数据大小是1kb,那么高度是3的B+tree可以存放<code>1163*1163*16282/1024=21506375</code>条数据。</p>\n<p>以上的推论过程有如下的局限性</p>\n<ol>\n<li>一个数据页可以用来存放数据的空间是多少，我们假设是16282比特，但具体是多少我查了很多资料都没找到。</li>\n<li>当一个数据页中的数据行的某一字段太大的时候，会把一部分数据放到额外的页中，为的是保证一个数据页至少有两条数据。所以啊，实际存储数据的数据页可能大于主键B+tree的叶子节点的数目。</li>\n</ol>\n<p>尽管上面的论证有一些局限性，但是我们还是能够得到如下的结论</p>\n<ol>\n<li>如果单行数据不是太大的情况下，比如1kb,那么一课高度为3的主键索引可以存储2000多万行的数据，如果单行数据为0.5kb那么可以存储4000多万行的数据。</li>\n<li>如果数据行的字段很多，会导致行数据的平均大小变大，可能会使B+tree的高度变大</li>\n<li>一般来说B+tree的高度为2~3的时候性能是不错的，换言之如果单行记录不大的情况下，innodb的一张表能轻松地hold住2000万级别的数据</li>\n</ol>\n<h2 id=\"直接查看B-tree的高度\"><a href=\"#直接查看B-tree的高度\" class=\"headerlink\" title=\"直接查看B+tree的高度\"></a>直接查看B+tree的高度</h2><p>在innodb的表空间文件中,约定在根页偏移量64的地方存放了B+tree的高度。高度是从0开始算的。使用sql</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">SELECT</span></span><br><span class=\"line\">\tb.NAME,</span><br><span class=\"line\">\ta.NAME,</span><br><span class=\"line\">\tindex_id,</span><br><span class=\"line\">\t<span class=\"keyword\">type</span>,</span><br><span class=\"line\">\ta.space,</span><br><span class=\"line\">\ta.PAGE_NO </span><br><span class=\"line\"><span class=\"keyword\">FROM</span></span><br><span class=\"line\">\tinformation_schema.INNODB_SYS_INDEXES a,</span><br><span class=\"line\">\tinformation_schema.INNODB_SYS_TABLES b </span><br><span class=\"line\"><span class=\"keyword\">WHERE</span></span><br><span class=\"line\">\ta.table_id = b.table_id </span><br><span class=\"line\">\t<span class=\"keyword\">AND</span> a.space &lt;&gt; <span class=\"number\">0</span> </span><br><span class=\"line\">\t<span class=\"keyword\">AND</span> b.NAME = <span class=\"string\">'test/insert_desc'</span>;</span><br></pre></td></tr></table></figure>\n\n<p>可看到test数据库insert_desc表的所有索引信息<br><img src=\"http://sysummerblog.club/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%884.44.31.jpg\" alt></p>\n<p>可以看到第一行是主键索引，他的根页在表空间的第三页。resblock_id是一个普通的索引，他的根页在表空间的第四页。使用</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexdump -s 49216 -n 10 insert_asc.ibd</span><br></pre></td></tr></table></figure>\n\n<p>可以看到表insert_asc.ibd主键索引的高度。<br><img src=\"http://sysummerblog.club/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%885.00.59.jpg\" alt><br>可以看到前两个字节是2，因此高度是3因为高度是从0开始算的。</p>\n<p><code>-s 49216</code>表示从表空间文件的49216字节的偏移量开始读取，为什么是49216？因为主键索引的是在第三页,<code>49216=16kb*3+64</code>,其中16kb是数据页的大小。同理resblock_id的索引高度读取方法是</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexdump -s 65600 -n 10 insert_asc.ibd</span><br></pre></td></tr></table></figure>\n\n<p>得到的结果是<br><img src=\"http://sysummerblog.club/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%885.04.23.jpg\" alt></p>\n<p>也就是改索引的高度是1.</p>"},{"title":"从Cookie到OAuth2再到JWT","date":"2019-08-15T09:00:39.000Z","tags":["cookie","oauth2","jwt"],"photos":[["https://sysummerblog.club/jwt.jpeg"]],"_content":"cookie加session认证是比较传统的方法，但是随着分布式系统的出现，这种认证方式局限性就渐渐显露出来了。OAuth2认证主要是用于使用公共平台的身份去登陆第三方网站。JWT是一种简单的认证方式，适合分布式系统。今天想总结一下工作几年来使用的三种认证方式\n<!--more-->\n## Cookie认证\nCookie认证是每次客户端向服务器请求的时候都会在http报文的header中传送一个字段叫Cookie，他的格式是形如这样的\n![](https://sysummerblog.club/cookie.jpg)\n以分号分隔，比如Cookie:a=b;c=d, 那么到达服务器以后以php为例会有一个全局能访问的数组$\\_COOKIE保存这两个键值对。\n```php\n$var_a = $_COOKIE['a'] //值为b\n$var_c = $_COOKIE['c'] //值为d \n```\n\nCookie并不是专门用来认证的，实时上他是用来和服务器交换数据的。因为http协议是无状态的，因此每次服务器返回给客户端的时候在返回的header里面会告诉浏览器保存哪些信息，然后再次请求这个域名的时候要带上这些信息，通过这种形式来模拟“有状态”。\n\n![](https://sysummerblog.club/setcookie.jpg)\n\n所以Cookie认证就是在发送的Cookie里面放一个用于表示认证的字段，这个字段的值就是一个凭证，这个凭证就像一把钥匙，能够与服务器上的“数据”相联系，这个数据叫做session。当服务器获得了浏览器传过来的“钥匙”的时候就会通过这把钥匙去找相应的session数据，session数据在哪？有可能在本机的文件系统，也有可能是在redis集群里面。使用redis的好处除了读取和写入的速度要快于文件之外还有一个就是对分布式系统支持良好。假如你的一个服务有a,b,c三台服务器，第一次请求负载均衡到了a机器上，理应session文件应该存储到a服务器的一个文件夹中，第二次负载到了b机器上，这时候b机器没有相应的文件，之前写到a机器上的数据就不见了。服务器获取到session数据后会加载到$\\_SESSION超全局数组中。\n\n最后说一下曾今困扰我的一个问题，就是session过期的问题。比如我的请求在10:30，服务端设立的session过期时间是30分钟，那么在11:00session应该就是过期的。但是如果我10:31再次请求的时候，服务端会认为这个session的过期时间是11:01，session的过期时间是每次请求都会更新的。\n\n## OAuth2 认证\nOAuth2的应用场景是第三方应用授权登录：在APP或者网页接入一些第三方应用时，时常会需要用户登录另一个合作平台，比如QQ，微博，微信的授权登录,第三方应用通过oauth2方式获取用户信息。\n\n他的流程图大致如下\n![](https://sysummerblog.club/oauth2.png)\n\n1. 用户访问一个网站A，并在网站的登陆页面选择使用\"微信\"登陆。\n2. 客户端扫描微信登陆的二维码，此时A网站向微信服务器发起授权请求，这个请求里面会告诉微信服务器哪个微信用户想使用微信信息登陆A网站。\n3. 微信服务器收到A网站的请求后会推送消息给用户让用户选择是否同意A网站使用用户的微信名或者微信头像等信息。网站A与微信服务器的tcp连接是一直连接着的，在http应用层面是通过不断的轮训来”保持连接“的。\n4. 用户同意\n5. 微信服务器会把网站A对微信服务器的请求转到A网站提前设定好的重定向地址中，同时还会附加一个code\n6. A网站通过code和A网站之前已经向微信服务器申请的app_id和app_secret向微信服务器申请调用微信用户信息接口的access_token和refresh_token。\n7. A网站使用access_token向微信的接口获取用户的用户名和头像\n8. 做一些用户信息处理，比如把该用户的信息存在自己的服务器\n9. 返回用户的头像和用户名给浏览器\n\n所以整个过程简单再说一下：先是用户选择微信登陆，然后网站A向微信服务器发起请求，微信服务器收到用户的确认后把请求重定向到网站A的服务器，网站A获取到用户的信息后返回给客户端，至此整个过程结束。\n\n## JWT认证\n传统的cookie与session认证在分布式系统里显得很无力很苍白。我们当然可以使用一个redis集群来整一个分布式的session。不过，还有一个方法就是使用JWT(json web token)\n\n他的原理其实很简单，每次客户端登陆成功后，服务器都会为这个用户产生一个认证的字符串，作为之后权限认证的token并放在返回的header中。之后客户端在请求的时候会在请求的header里面附上这个jwt token。服务器收到这个token后会进行一系列的验证，然后判断token的有效性。\n\n那么这个token长得啥样字呢？如下\n```\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ\n```\n\n一个jwt的token由3部分组成，分别称作header、payload、signature。header和payload原本都是json格式的数据，他们分别经过base64编码变成两段字符串。最后将这两段字符串使用\\.连接起来使用一个固定的密匙和加密算法生成第三段signature。\n\n### header\njwt的头部承载两部分信息：\n\n1. 声明类型，这里是jwt\n2. 声明加密的算法 通常直接使用 HMAC SHA256\n\n```js\n{\n  'typ': 'JWT',\n  'alg': 'HS256'\n}\n```\n然后将头部进行base64加密（该加密是可以对称解密的),构成了第一部分。\n```\neyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9\n```\n\n### payload\n载荷就是存放有效信息的地方。这个名字像是特指飞机上承载的货品，这些有效信息包含三个部分。\n\n1. 标准中注册的声明\n2. 公共的声明\n3. 私有的声明\n\n标准中注册的声明 (建议但不强制使用) ：\n\n1. iss: jwt签发者\n2. sub: jwt所面向的用户\n3. aud: 接收jwt的一方\n4. exp: jwt的过期时间，这个过期时间必须要大于签发时间\n5. nbf: 定义在什么时间之前，该jwt都是不可用的.\n6. iat: jwt的签发时间\n7. jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。\n\n公共的声明 ：\n公共的声明可以添加任何的信息，一般添加用户的相关信息或其他业务需要的必要信息.但不建议添加敏感信息，因为该部分在客户端可解密.\n\n私有的声明 ：\n私有声明是提供者和消费者所共同定义的声明，一般不建议存放敏感信息，因为base64是对称解密的，意味着该部分信息可以归类为明文信息。\n\n定义一个payload:\n```js\n{\n  \"sub\": \"1234567890\",\n  \"name\": \"John Doe\",\n  \"admin\": true\n}\n```\n然后将其进行base64加密，得到Jwt的第二部分。\n```\neyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9\n```\n### signature\n把上两步生成的字符串连接起来使用一个固定的secret和加密算法生成signature。然后把这三部分连接起来就是整个token。\n\n### 服务器验证token\n\n1. 首先先使用secret和加密算法重新对token的第一部分和第二部分加密得到signature，检查得到的signature是否与token的第三部分相同，如果不相同说明token可能是别人伪造的。\n2. 解析token的payload，检查token有没有过期等信息\n3. 应用层也要对token进行验证，比如payload中有没有user_id字段，如果有就可以通过user_id找当前登陆的用户，如果没有告诉客户端重新登陆。\n\n如果是分布式服务，那么只要每台机器的加密算法和加密secret都相同那么无论请求负载均衡到哪台机器上都是一样的。\n\n","source":"posts/cookie-oauth2-jwt.md","raw":"---\ntitle: 从Cookie到OAuth2再到JWT\ndate: 2019-08-15 17:00:39\ntags:\n    - cookie\n    - oauth2\n    - jwt\nphotos:\n    - [\"https://sysummerblog.club/jwt.jpeg\"]\n---\ncookie加session认证是比较传统的方法，但是随着分布式系统的出现，这种认证方式局限性就渐渐显露出来了。OAuth2认证主要是用于使用公共平台的身份去登陆第三方网站。JWT是一种简单的认证方式，适合分布式系统。今天想总结一下工作几年来使用的三种认证方式\n<!--more-->\n## Cookie认证\nCookie认证是每次客户端向服务器请求的时候都会在http报文的header中传送一个字段叫Cookie，他的格式是形如这样的\n![](https://sysummerblog.club/cookie.jpg)\n以分号分隔，比如Cookie:a=b;c=d, 那么到达服务器以后以php为例会有一个全局能访问的数组$\\_COOKIE保存这两个键值对。\n```php\n$var_a = $_COOKIE['a'] //值为b\n$var_c = $_COOKIE['c'] //值为d \n```\n\nCookie并不是专门用来认证的，实时上他是用来和服务器交换数据的。因为http协议是无状态的，因此每次服务器返回给客户端的时候在返回的header里面会告诉浏览器保存哪些信息，然后再次请求这个域名的时候要带上这些信息，通过这种形式来模拟“有状态”。\n\n![](https://sysummerblog.club/setcookie.jpg)\n\n所以Cookie认证就是在发送的Cookie里面放一个用于表示认证的字段，这个字段的值就是一个凭证，这个凭证就像一把钥匙，能够与服务器上的“数据”相联系，这个数据叫做session。当服务器获得了浏览器传过来的“钥匙”的时候就会通过这把钥匙去找相应的session数据，session数据在哪？有可能在本机的文件系统，也有可能是在redis集群里面。使用redis的好处除了读取和写入的速度要快于文件之外还有一个就是对分布式系统支持良好。假如你的一个服务有a,b,c三台服务器，第一次请求负载均衡到了a机器上，理应session文件应该存储到a服务器的一个文件夹中，第二次负载到了b机器上，这时候b机器没有相应的文件，之前写到a机器上的数据就不见了。服务器获取到session数据后会加载到$\\_SESSION超全局数组中。\n\n最后说一下曾今困扰我的一个问题，就是session过期的问题。比如我的请求在10:30，服务端设立的session过期时间是30分钟，那么在11:00session应该就是过期的。但是如果我10:31再次请求的时候，服务端会认为这个session的过期时间是11:01，session的过期时间是每次请求都会更新的。\n\n## OAuth2 认证\nOAuth2的应用场景是第三方应用授权登录：在APP或者网页接入一些第三方应用时，时常会需要用户登录另一个合作平台，比如QQ，微博，微信的授权登录,第三方应用通过oauth2方式获取用户信息。\n\n他的流程图大致如下\n![](https://sysummerblog.club/oauth2.png)\n\n1. 用户访问一个网站A，并在网站的登陆页面选择使用\"微信\"登陆。\n2. 客户端扫描微信登陆的二维码，此时A网站向微信服务器发起授权请求，这个请求里面会告诉微信服务器哪个微信用户想使用微信信息登陆A网站。\n3. 微信服务器收到A网站的请求后会推送消息给用户让用户选择是否同意A网站使用用户的微信名或者微信头像等信息。网站A与微信服务器的tcp连接是一直连接着的，在http应用层面是通过不断的轮训来”保持连接“的。\n4. 用户同意\n5. 微信服务器会把网站A对微信服务器的请求转到A网站提前设定好的重定向地址中，同时还会附加一个code\n6. A网站通过code和A网站之前已经向微信服务器申请的app_id和app_secret向微信服务器申请调用微信用户信息接口的access_token和refresh_token。\n7. A网站使用access_token向微信的接口获取用户的用户名和头像\n8. 做一些用户信息处理，比如把该用户的信息存在自己的服务器\n9. 返回用户的头像和用户名给浏览器\n\n所以整个过程简单再说一下：先是用户选择微信登陆，然后网站A向微信服务器发起请求，微信服务器收到用户的确认后把请求重定向到网站A的服务器，网站A获取到用户的信息后返回给客户端，至此整个过程结束。\n\n## JWT认证\n传统的cookie与session认证在分布式系统里显得很无力很苍白。我们当然可以使用一个redis集群来整一个分布式的session。不过，还有一个方法就是使用JWT(json web token)\n\n他的原理其实很简单，每次客户端登陆成功后，服务器都会为这个用户产生一个认证的字符串，作为之后权限认证的token并放在返回的header中。之后客户端在请求的时候会在请求的header里面附上这个jwt token。服务器收到这个token后会进行一系列的验证，然后判断token的有效性。\n\n那么这个token长得啥样字呢？如下\n```\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ\n```\n\n一个jwt的token由3部分组成，分别称作header、payload、signature。header和payload原本都是json格式的数据，他们分别经过base64编码变成两段字符串。最后将这两段字符串使用\\.连接起来使用一个固定的密匙和加密算法生成第三段signature。\n\n### header\njwt的头部承载两部分信息：\n\n1. 声明类型，这里是jwt\n2. 声明加密的算法 通常直接使用 HMAC SHA256\n\n```js\n{\n  'typ': 'JWT',\n  'alg': 'HS256'\n}\n```\n然后将头部进行base64加密（该加密是可以对称解密的),构成了第一部分。\n```\neyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9\n```\n\n### payload\n载荷就是存放有效信息的地方。这个名字像是特指飞机上承载的货品，这些有效信息包含三个部分。\n\n1. 标准中注册的声明\n2. 公共的声明\n3. 私有的声明\n\n标准中注册的声明 (建议但不强制使用) ：\n\n1. iss: jwt签发者\n2. sub: jwt所面向的用户\n3. aud: 接收jwt的一方\n4. exp: jwt的过期时间，这个过期时间必须要大于签发时间\n5. nbf: 定义在什么时间之前，该jwt都是不可用的.\n6. iat: jwt的签发时间\n7. jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。\n\n公共的声明 ：\n公共的声明可以添加任何的信息，一般添加用户的相关信息或其他业务需要的必要信息.但不建议添加敏感信息，因为该部分在客户端可解密.\n\n私有的声明 ：\n私有声明是提供者和消费者所共同定义的声明，一般不建议存放敏感信息，因为base64是对称解密的，意味着该部分信息可以归类为明文信息。\n\n定义一个payload:\n```js\n{\n  \"sub\": \"1234567890\",\n  \"name\": \"John Doe\",\n  \"admin\": true\n}\n```\n然后将其进行base64加密，得到Jwt的第二部分。\n```\neyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9\n```\n### signature\n把上两步生成的字符串连接起来使用一个固定的secret和加密算法生成signature。然后把这三部分连接起来就是整个token。\n\n### 服务器验证token\n\n1. 首先先使用secret和加密算法重新对token的第一部分和第二部分加密得到signature，检查得到的signature是否与token的第三部分相同，如果不相同说明token可能是别人伪造的。\n2. 解析token的payload，检查token有没有过期等信息\n3. 应用层也要对token进行验证，比如payload中有没有user_id字段，如果有就可以通过user_id找当前登陆的用户，如果没有告诉客户端重新登陆。\n\n如果是分布式服务，那么只要每台机器的加密算法和加密secret都相同那么无论请求负载均衡到哪台机器上都是一样的。\n\n","updated":"2020-11-23T15:20:08.940Z","path":"posts/cookie-oauth2-jwt.html","comments":1,"layout":"page","_id":"ckhupaq9900061no8kxvc9rrh","content":"<p>cookie加session认证是比较传统的方法，但是随着分布式系统的出现，这种认证方式局限性就渐渐显露出来了。OAuth2认证主要是用于使用公共平台的身份去登陆第三方网站。JWT是一种简单的认证方式，适合分布式系统。今天想总结一下工作几年来使用的三种认证方式</p>\n<a id=\"more\"></a>\n<h2 id=\"Cookie认证\"><a href=\"#Cookie认证\" class=\"headerlink\" title=\"Cookie认证\"></a>Cookie认证</h2><p>Cookie认证是每次客户端向服务器请求的时候都会在http报文的header中传送一个字段叫Cookie，他的格式是形如这样的<br><img src=\"https://sysummerblog.club/cookie.jpg\" alt><br>以分号分隔，比如Cookie:a=b;c=d, 那么到达服务器以后以php为例会有一个全局能访问的数组$_COOKIE保存这两个键值对。</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$var_a = $_COOKIE[<span class=\"string\">'a'</span>] <span class=\"comment\">//值为b</span></span><br><span class=\"line\">$var_c = $_COOKIE[<span class=\"string\">'c'</span>] <span class=\"comment\">//值为d</span></span><br></pre></td></tr></table></figure>\n\n<p>Cookie并不是专门用来认证的，实时上他是用来和服务器交换数据的。因为http协议是无状态的，因此每次服务器返回给客户端的时候在返回的header里面会告诉浏览器保存哪些信息，然后再次请求这个域名的时候要带上这些信息，通过这种形式来模拟“有状态”。</p>\n<p><img src=\"https://sysummerblog.club/setcookie.jpg\" alt></p>\n<p>所以Cookie认证就是在发送的Cookie里面放一个用于表示认证的字段，这个字段的值就是一个凭证，这个凭证就像一把钥匙，能够与服务器上的“数据”相联系，这个数据叫做session。当服务器获得了浏览器传过来的“钥匙”的时候就会通过这把钥匙去找相应的session数据，session数据在哪？有可能在本机的文件系统，也有可能是在redis集群里面。使用redis的好处除了读取和写入的速度要快于文件之外还有一个就是对分布式系统支持良好。假如你的一个服务有a,b,c三台服务器，第一次请求负载均衡到了a机器上，理应session文件应该存储到a服务器的一个文件夹中，第二次负载到了b机器上，这时候b机器没有相应的文件，之前写到a机器上的数据就不见了。服务器获取到session数据后会加载到$_SESSION超全局数组中。</p>\n<p>最后说一下曾今困扰我的一个问题，就是session过期的问题。比如我的请求在10:30，服务端设立的session过期时间是30分钟，那么在11:00session应该就是过期的。但是如果我10:31再次请求的时候，服务端会认为这个session的过期时间是11:01，session的过期时间是每次请求都会更新的。</p>\n<h2 id=\"OAuth2-认证\"><a href=\"#OAuth2-认证\" class=\"headerlink\" title=\"OAuth2 认证\"></a>OAuth2 认证</h2><p>OAuth2的应用场景是第三方应用授权登录：在APP或者网页接入一些第三方应用时，时常会需要用户登录另一个合作平台，比如QQ，微博，微信的授权登录,第三方应用通过oauth2方式获取用户信息。</p>\n<p>他的流程图大致如下<br><img src=\"https://sysummerblog.club/oauth2.png\" alt></p>\n<ol>\n<li>用户访问一个网站A，并在网站的登陆页面选择使用”微信”登陆。</li>\n<li>客户端扫描微信登陆的二维码，此时A网站向微信服务器发起授权请求，这个请求里面会告诉微信服务器哪个微信用户想使用微信信息登陆A网站。</li>\n<li>微信服务器收到A网站的请求后会推送消息给用户让用户选择是否同意A网站使用用户的微信名或者微信头像等信息。网站A与微信服务器的tcp连接是一直连接着的，在http应用层面是通过不断的轮训来”保持连接“的。</li>\n<li>用户同意</li>\n<li>微信服务器会把网站A对微信服务器的请求转到A网站提前设定好的重定向地址中，同时还会附加一个code</li>\n<li>A网站通过code和A网站之前已经向微信服务器申请的app_id和app_secret向微信服务器申请调用微信用户信息接口的access_token和refresh_token。</li>\n<li>A网站使用access_token向微信的接口获取用户的用户名和头像</li>\n<li>做一些用户信息处理，比如把该用户的信息存在自己的服务器</li>\n<li>返回用户的头像和用户名给浏览器</li>\n</ol>\n<p>所以整个过程简单再说一下：先是用户选择微信登陆，然后网站A向微信服务器发起请求，微信服务器收到用户的确认后把请求重定向到网站A的服务器，网站A获取到用户的信息后返回给客户端，至此整个过程结束。</p>\n<h2 id=\"JWT认证\"><a href=\"#JWT认证\" class=\"headerlink\" title=\"JWT认证\"></a>JWT认证</h2><p>传统的cookie与session认证在分布式系统里显得很无力很苍白。我们当然可以使用一个redis集群来整一个分布式的session。不过，还有一个方法就是使用JWT(json web token)</p>\n<p>他的原理其实很简单，每次客户端登陆成功后，服务器都会为这个用户产生一个认证的字符串，作为之后权限认证的token并放在返回的header中。之后客户端在请求的时候会在请求的header里面附上这个jwt token。服务器收到这个token后会进行一系列的验证，然后判断token的有效性。</p>\n<p>那么这个token长得啥样字呢？如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ</span><br></pre></td></tr></table></figure>\n\n<p>一个jwt的token由3部分组成，分别称作header、payload、signature。header和payload原本都是json格式的数据，他们分别经过base64编码变成两段字符串。最后将这两段字符串使用.连接起来使用一个固定的密匙和加密算法生成第三段signature。</p>\n<h3 id=\"header\"><a href=\"#header\" class=\"headerlink\" title=\"header\"></a>header</h3><p>jwt的头部承载两部分信息：</p>\n<ol>\n<li>声明类型，这里是jwt</li>\n<li>声明加密的算法 通常直接使用 HMAC SHA256</li>\n</ol>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">'typ'</span>: <span class=\"string\">'JWT'</span>,</span><br><span class=\"line\">  <span class=\"string\">'alg'</span>: <span class=\"string\">'HS256'</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>然后将头部进行base64加密（该加密是可以对称解密的),构成了第一部分。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"payload\"><a href=\"#payload\" class=\"headerlink\" title=\"payload\"></a>payload</h3><p>载荷就是存放有效信息的地方。这个名字像是特指飞机上承载的货品，这些有效信息包含三个部分。</p>\n<ol>\n<li>标准中注册的声明</li>\n<li>公共的声明</li>\n<li>私有的声明</li>\n</ol>\n<p>标准中注册的声明 (建议但不强制使用) ：</p>\n<ol>\n<li>iss: jwt签发者</li>\n<li>sub: jwt所面向的用户</li>\n<li>aud: 接收jwt的一方</li>\n<li>exp: jwt的过期时间，这个过期时间必须要大于签发时间</li>\n<li>nbf: 定义在什么时间之前，该jwt都是不可用的.</li>\n<li>iat: jwt的签发时间</li>\n<li>jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。</li>\n</ol>\n<p>公共的声明 ：<br>公共的声明可以添加任何的信息，一般添加用户的相关信息或其他业务需要的必要信息.但不建议添加敏感信息，因为该部分在客户端可解密.</p>\n<p>私有的声明 ：<br>私有声明是提供者和消费者所共同定义的声明，一般不建议存放敏感信息，因为base64是对称解密的，意味着该部分信息可以归类为明文信息。</p>\n<p>定义一个payload:</p>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"sub\"</span>: <span class=\"string\">\"1234567890\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"name\"</span>: <span class=\"string\">\"John Doe\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"admin\"</span>: <span class=\"literal\">true</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>然后将其进行base64加密，得到Jwt的第二部分。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"signature\"><a href=\"#signature\" class=\"headerlink\" title=\"signature\"></a>signature</h3><p>把上两步生成的字符串连接起来使用一个固定的secret和加密算法生成signature。然后把这三部分连接起来就是整个token。</p>\n<h3 id=\"服务器验证token\"><a href=\"#服务器验证token\" class=\"headerlink\" title=\"服务器验证token\"></a>服务器验证token</h3><ol>\n<li>首先先使用secret和加密算法重新对token的第一部分和第二部分加密得到signature，检查得到的signature是否与token的第三部分相同，如果不相同说明token可能是别人伪造的。</li>\n<li>解析token的payload，检查token有没有过期等信息</li>\n<li>应用层也要对token进行验证，比如payload中有没有user_id字段，如果有就可以通过user_id找当前登陆的用户，如果没有告诉客户端重新登陆。</li>\n</ol>\n<p>如果是分布式服务，那么只要每台机器的加密算法和加密secret都相同那么无论请求负载均衡到哪台机器上都是一样的。</p>\n","site":{"data":{}},"excerpt":"<p>cookie加session认证是比较传统的方法，但是随着分布式系统的出现，这种认证方式局限性就渐渐显露出来了。OAuth2认证主要是用于使用公共平台的身份去登陆第三方网站。JWT是一种简单的认证方式，适合分布式系统。今天想总结一下工作几年来使用的三种认证方式</p>","more":"<h2 id=\"Cookie认证\"><a href=\"#Cookie认证\" class=\"headerlink\" title=\"Cookie认证\"></a>Cookie认证</h2><p>Cookie认证是每次客户端向服务器请求的时候都会在http报文的header中传送一个字段叫Cookie，他的格式是形如这样的<br><img src=\"https://sysummerblog.club/cookie.jpg\" alt><br>以分号分隔，比如Cookie:a=b;c=d, 那么到达服务器以后以php为例会有一个全局能访问的数组$_COOKIE保存这两个键值对。</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$var_a = $_COOKIE[<span class=\"string\">'a'</span>] <span class=\"comment\">//值为b</span></span><br><span class=\"line\">$var_c = $_COOKIE[<span class=\"string\">'c'</span>] <span class=\"comment\">//值为d</span></span><br></pre></td></tr></table></figure>\n\n<p>Cookie并不是专门用来认证的，实时上他是用来和服务器交换数据的。因为http协议是无状态的，因此每次服务器返回给客户端的时候在返回的header里面会告诉浏览器保存哪些信息，然后再次请求这个域名的时候要带上这些信息，通过这种形式来模拟“有状态”。</p>\n<p><img src=\"https://sysummerblog.club/setcookie.jpg\" alt></p>\n<p>所以Cookie认证就是在发送的Cookie里面放一个用于表示认证的字段，这个字段的值就是一个凭证，这个凭证就像一把钥匙，能够与服务器上的“数据”相联系，这个数据叫做session。当服务器获得了浏览器传过来的“钥匙”的时候就会通过这把钥匙去找相应的session数据，session数据在哪？有可能在本机的文件系统，也有可能是在redis集群里面。使用redis的好处除了读取和写入的速度要快于文件之外还有一个就是对分布式系统支持良好。假如你的一个服务有a,b,c三台服务器，第一次请求负载均衡到了a机器上，理应session文件应该存储到a服务器的一个文件夹中，第二次负载到了b机器上，这时候b机器没有相应的文件，之前写到a机器上的数据就不见了。服务器获取到session数据后会加载到$_SESSION超全局数组中。</p>\n<p>最后说一下曾今困扰我的一个问题，就是session过期的问题。比如我的请求在10:30，服务端设立的session过期时间是30分钟，那么在11:00session应该就是过期的。但是如果我10:31再次请求的时候，服务端会认为这个session的过期时间是11:01，session的过期时间是每次请求都会更新的。</p>\n<h2 id=\"OAuth2-认证\"><a href=\"#OAuth2-认证\" class=\"headerlink\" title=\"OAuth2 认证\"></a>OAuth2 认证</h2><p>OAuth2的应用场景是第三方应用授权登录：在APP或者网页接入一些第三方应用时，时常会需要用户登录另一个合作平台，比如QQ，微博，微信的授权登录,第三方应用通过oauth2方式获取用户信息。</p>\n<p>他的流程图大致如下<br><img src=\"https://sysummerblog.club/oauth2.png\" alt></p>\n<ol>\n<li>用户访问一个网站A，并在网站的登陆页面选择使用”微信”登陆。</li>\n<li>客户端扫描微信登陆的二维码，此时A网站向微信服务器发起授权请求，这个请求里面会告诉微信服务器哪个微信用户想使用微信信息登陆A网站。</li>\n<li>微信服务器收到A网站的请求后会推送消息给用户让用户选择是否同意A网站使用用户的微信名或者微信头像等信息。网站A与微信服务器的tcp连接是一直连接着的，在http应用层面是通过不断的轮训来”保持连接“的。</li>\n<li>用户同意</li>\n<li>微信服务器会把网站A对微信服务器的请求转到A网站提前设定好的重定向地址中，同时还会附加一个code</li>\n<li>A网站通过code和A网站之前已经向微信服务器申请的app_id和app_secret向微信服务器申请调用微信用户信息接口的access_token和refresh_token。</li>\n<li>A网站使用access_token向微信的接口获取用户的用户名和头像</li>\n<li>做一些用户信息处理，比如把该用户的信息存在自己的服务器</li>\n<li>返回用户的头像和用户名给浏览器</li>\n</ol>\n<p>所以整个过程简单再说一下：先是用户选择微信登陆，然后网站A向微信服务器发起请求，微信服务器收到用户的确认后把请求重定向到网站A的服务器，网站A获取到用户的信息后返回给客户端，至此整个过程结束。</p>\n<h2 id=\"JWT认证\"><a href=\"#JWT认证\" class=\"headerlink\" title=\"JWT认证\"></a>JWT认证</h2><p>传统的cookie与session认证在分布式系统里显得很无力很苍白。我们当然可以使用一个redis集群来整一个分布式的session。不过，还有一个方法就是使用JWT(json web token)</p>\n<p>他的原理其实很简单，每次客户端登陆成功后，服务器都会为这个用户产生一个认证的字符串，作为之后权限认证的token并放在返回的header中。之后客户端在请求的时候会在请求的header里面附上这个jwt token。服务器收到这个token后会进行一系列的验证，然后判断token的有效性。</p>\n<p>那么这个token长得啥样字呢？如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ</span><br></pre></td></tr></table></figure>\n\n<p>一个jwt的token由3部分组成，分别称作header、payload、signature。header和payload原本都是json格式的数据，他们分别经过base64编码变成两段字符串。最后将这两段字符串使用.连接起来使用一个固定的密匙和加密算法生成第三段signature。</p>\n<h3 id=\"header\"><a href=\"#header\" class=\"headerlink\" title=\"header\"></a>header</h3><p>jwt的头部承载两部分信息：</p>\n<ol>\n<li>声明类型，这里是jwt</li>\n<li>声明加密的算法 通常直接使用 HMAC SHA256</li>\n</ol>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">'typ'</span>: <span class=\"string\">'JWT'</span>,</span><br><span class=\"line\">  <span class=\"string\">'alg'</span>: <span class=\"string\">'HS256'</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>然后将头部进行base64加密（该加密是可以对称解密的),构成了第一部分。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"payload\"><a href=\"#payload\" class=\"headerlink\" title=\"payload\"></a>payload</h3><p>载荷就是存放有效信息的地方。这个名字像是特指飞机上承载的货品，这些有效信息包含三个部分。</p>\n<ol>\n<li>标准中注册的声明</li>\n<li>公共的声明</li>\n<li>私有的声明</li>\n</ol>\n<p>标准中注册的声明 (建议但不强制使用) ：</p>\n<ol>\n<li>iss: jwt签发者</li>\n<li>sub: jwt所面向的用户</li>\n<li>aud: 接收jwt的一方</li>\n<li>exp: jwt的过期时间，这个过期时间必须要大于签发时间</li>\n<li>nbf: 定义在什么时间之前，该jwt都是不可用的.</li>\n<li>iat: jwt的签发时间</li>\n<li>jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。</li>\n</ol>\n<p>公共的声明 ：<br>公共的声明可以添加任何的信息，一般添加用户的相关信息或其他业务需要的必要信息.但不建议添加敏感信息，因为该部分在客户端可解密.</p>\n<p>私有的声明 ：<br>私有声明是提供者和消费者所共同定义的声明，一般不建议存放敏感信息，因为base64是对称解密的，意味着该部分信息可以归类为明文信息。</p>\n<p>定义一个payload:</p>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"sub\"</span>: <span class=\"string\">\"1234567890\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"name\"</span>: <span class=\"string\">\"John Doe\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"admin\"</span>: <span class=\"literal\">true</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>然后将其进行base64加密，得到Jwt的第二部分。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"signature\"><a href=\"#signature\" class=\"headerlink\" title=\"signature\"></a>signature</h3><p>把上两步生成的字符串连接起来使用一个固定的secret和加密算法生成signature。然后把这三部分连接起来就是整个token。</p>\n<h3 id=\"服务器验证token\"><a href=\"#服务器验证token\" class=\"headerlink\" title=\"服务器验证token\"></a>服务器验证token</h3><ol>\n<li>首先先使用secret和加密算法重新对token的第一部分和第二部分加密得到signature，检查得到的signature是否与token的第三部分相同，如果不相同说明token可能是别人伪造的。</li>\n<li>解析token的payload，检查token有没有过期等信息</li>\n<li>应用层也要对token进行验证，比如payload中有没有user_id字段，如果有就可以通过user_id找当前登陆的用户，如果没有告诉客户端重新登陆。</li>\n</ol>\n<p>如果是分布式服务，那么只要每台机器的加密算法和加密secret都相同那么无论请求负载均衡到哪台机器上都是一样的。</p>"},{"title":"Git进阶","date":"2019-12-01T04:18:22.000Z","tags":["git"],"photos":[["http://sysummerblog.club/git_cover.jpeg"]],"_content":"以下是我在工作中总结的关于git命令的一些使用方法。比较常用的那些我都不说了，主要是一些经常用但是又经常忘的命令，因此在这里总结一下，仅供参考。\n<!--more-->\n### 超看操作日志\n查看当前分支的所有的提交日志\n```sh\ngit log\n```\n查看当前分支最后n次的提交日志\n```sh\ngit log -n\n```\n在一行内显示当前分支的所有提交日志\n```sh\ngit log --oneline\n```\n\n在提交的msg里搜索当前分支的日志\n```sh\ngit log --grep='cps'\n```\n\n根据作者搜索当前分支的日志\n```sh\ngit log --author='suyang'\n```\n\n查看所有的提交日志，包括已经删除的分支的\n```sh\ngit reflog\n```\n`git reflog`与`git log`一样也可以使用`-n, --online,--grep,--author`\n\n### 操作子模块\n\n克隆项目的时候连同子模块一起克隆\n```sh\ngit clone --recursive [url][path]\n```\n如果克隆的时候没有连同子模块一起克隆那么还可以\n```sh\ngit submodule update --init --recursive\n```\n之后想更新子模块的内容\n```sh\ngit submodule update\n```\n如果想修改子模块，操作和正常的git仓库一致。\n\n### 提交\n下面的命令\n```sh\ngit commit -m'提交' -a\n```\n相当于两条命令\n```sh\ngit add .\ngit commit -m'提交'\n```\n\n修改上次提交的message\n```sh\ngit commit --amend\n```\n如果分支已经push了，那么千万不要使用该命令。因为该命令会改变commit的hash值，这样就使当前的分支与远程的分支“开叉”了。\n\n### 分支\n```sh\ngit checkout -b dev origin/dev\n```\n这个命令的初衷是新建本地的dev分支并跟踪远程的dev分支。这个命令的执行前提是本地知道远程有个dev分支，否则会报错。那么怎么才能让本地知道远程的分支呢?使用`git pull`。这个命令不仅能拉取跟踪分支的最新代码，还能拉取分支和标签信息。\n\n如果误删除了分支怎么办？像我这种不想留不再使用的东西的人，已经误删过好几次了，解决办法很简单先试用`git reflog`找到你误删除的分支的最后一次commit的hash值，然后通过下面的命令恢复\n```sh\ngit checkout -b recovery hash值\n```\n\n查看远程和本地的所有分支\n```sh\ngit branch -a\n```\n\n切换到刚才的分支\n```sh\ngit checkout -\n```\n下面说说rebase。\n1. 我的分支a是基于本地的master创建的，我的master跟踪远程的master\n2. 我在分支a上开发，有3个commit\n3. 在我开发的过程中，别人向远程的master提交了新的代码，这次提交总公有2个commit\n\n这个时候我们可以知道本地的master和现在远程最新的master都是基于之前旧版本的master的，如果我现在要向远程推送代码那么我应该\n\n1. 先checkout到我本地的master\n2. 拉取远程最新的master到我的master\n3. 在我本地merge分支a，其实在这个merge的过程就是三方合并，这三方分别是最初的master，现在远程最新的master，我的分支a\n\n上面的这种方式会让提交看起来很难看，因此还有另外一种方法\n\n1. 先checkout到我本地的master\n2. 拉取远程最新的master到我的master\n3. 切换会分支a，然后执行\n```sh\ngit rebase master\n```\n这个命令的意思是，使用现在的master的分支作为基础，重新把我在a分支上的提交依次覆盖到maste分支上作为新的a的分支。变基后a分支就在当前master分支的“直接上游”\n4. 切回master分支然后merge刚才变完基的a分支，这个过程是一个fast-forward\n\n### 撤销命令汇总\n\n撤销最后n次commit，并把撤销出来的更改放到暂存区。工作区不会受影响\n```sh\ngit reset --soft HEAD~n\n```\n\n如果想直接丢弃撤销出来的内容\n```sh\ngit reset --hard HEAD~n\n```\n将fileName从暂存区删除，这不会对此时的工作区有任何的影响，仅仅是从暂存区删除了fileName而已.但是此时git会重新对filename就行评估，如果此时filename与版本库不一致，那么filename还是会出现在工作区，但这与reset命令没有关系\n```sh\ngit reset fileName\n```\n\n用版本库里的代码强行刷新暂存区与工作区\n```sh\ngit checkout -f\n```\n\n拉区版本库的 fileName 同时替换工作区与暂存区的fileName\n```sh\ngit checkout HEAD filename\n```\n\n将工作区的fileName替换为暂存区的fileName，如果暂存区没有，那么会去版本库拉去fileName替换工作区的fileName。之后filename肯定不会出现在工作区\n```sh\ngit checkout filename\n```\n\n最后说一下git revert命令\n```\ngit revert hash值\n```\nrevert命令会撤销某一次的提交，与reset不同的是，当前的版本库不会回退,而是向前一步\n","source":"posts/git-advance.md","raw":"---\ntitle: Git进阶\ndate: 2019-12-01 12:18:22\ntags:\n   - git\nphotos:\n   - [\"http://sysummerblog.club/git_cover.jpeg\"]\n---\n以下是我在工作中总结的关于git命令的一些使用方法。比较常用的那些我都不说了，主要是一些经常用但是又经常忘的命令，因此在这里总结一下，仅供参考。\n<!--more-->\n### 超看操作日志\n查看当前分支的所有的提交日志\n```sh\ngit log\n```\n查看当前分支最后n次的提交日志\n```sh\ngit log -n\n```\n在一行内显示当前分支的所有提交日志\n```sh\ngit log --oneline\n```\n\n在提交的msg里搜索当前分支的日志\n```sh\ngit log --grep='cps'\n```\n\n根据作者搜索当前分支的日志\n```sh\ngit log --author='suyang'\n```\n\n查看所有的提交日志，包括已经删除的分支的\n```sh\ngit reflog\n```\n`git reflog`与`git log`一样也可以使用`-n, --online,--grep,--author`\n\n### 操作子模块\n\n克隆项目的时候连同子模块一起克隆\n```sh\ngit clone --recursive [url][path]\n```\n如果克隆的时候没有连同子模块一起克隆那么还可以\n```sh\ngit submodule update --init --recursive\n```\n之后想更新子模块的内容\n```sh\ngit submodule update\n```\n如果想修改子模块，操作和正常的git仓库一致。\n\n### 提交\n下面的命令\n```sh\ngit commit -m'提交' -a\n```\n相当于两条命令\n```sh\ngit add .\ngit commit -m'提交'\n```\n\n修改上次提交的message\n```sh\ngit commit --amend\n```\n如果分支已经push了，那么千万不要使用该命令。因为该命令会改变commit的hash值，这样就使当前的分支与远程的分支“开叉”了。\n\n### 分支\n```sh\ngit checkout -b dev origin/dev\n```\n这个命令的初衷是新建本地的dev分支并跟踪远程的dev分支。这个命令的执行前提是本地知道远程有个dev分支，否则会报错。那么怎么才能让本地知道远程的分支呢?使用`git pull`。这个命令不仅能拉取跟踪分支的最新代码，还能拉取分支和标签信息。\n\n如果误删除了分支怎么办？像我这种不想留不再使用的东西的人，已经误删过好几次了，解决办法很简单先试用`git reflog`找到你误删除的分支的最后一次commit的hash值，然后通过下面的命令恢复\n```sh\ngit checkout -b recovery hash值\n```\n\n查看远程和本地的所有分支\n```sh\ngit branch -a\n```\n\n切换到刚才的分支\n```sh\ngit checkout -\n```\n下面说说rebase。\n1. 我的分支a是基于本地的master创建的，我的master跟踪远程的master\n2. 我在分支a上开发，有3个commit\n3. 在我开发的过程中，别人向远程的master提交了新的代码，这次提交总公有2个commit\n\n这个时候我们可以知道本地的master和现在远程最新的master都是基于之前旧版本的master的，如果我现在要向远程推送代码那么我应该\n\n1. 先checkout到我本地的master\n2. 拉取远程最新的master到我的master\n3. 在我本地merge分支a，其实在这个merge的过程就是三方合并，这三方分别是最初的master，现在远程最新的master，我的分支a\n\n上面的这种方式会让提交看起来很难看，因此还有另外一种方法\n\n1. 先checkout到我本地的master\n2. 拉取远程最新的master到我的master\n3. 切换会分支a，然后执行\n```sh\ngit rebase master\n```\n这个命令的意思是，使用现在的master的分支作为基础，重新把我在a分支上的提交依次覆盖到maste分支上作为新的a的分支。变基后a分支就在当前master分支的“直接上游”\n4. 切回master分支然后merge刚才变完基的a分支，这个过程是一个fast-forward\n\n### 撤销命令汇总\n\n撤销最后n次commit，并把撤销出来的更改放到暂存区。工作区不会受影响\n```sh\ngit reset --soft HEAD~n\n```\n\n如果想直接丢弃撤销出来的内容\n```sh\ngit reset --hard HEAD~n\n```\n将fileName从暂存区删除，这不会对此时的工作区有任何的影响，仅仅是从暂存区删除了fileName而已.但是此时git会重新对filename就行评估，如果此时filename与版本库不一致，那么filename还是会出现在工作区，但这与reset命令没有关系\n```sh\ngit reset fileName\n```\n\n用版本库里的代码强行刷新暂存区与工作区\n```sh\ngit checkout -f\n```\n\n拉区版本库的 fileName 同时替换工作区与暂存区的fileName\n```sh\ngit checkout HEAD filename\n```\n\n将工作区的fileName替换为暂存区的fileName，如果暂存区没有，那么会去版本库拉去fileName替换工作区的fileName。之后filename肯定不会出现在工作区\n```sh\ngit checkout filename\n```\n\n最后说一下git revert命令\n```\ngit revert hash值\n```\nrevert命令会撤销某一次的提交，与reset不同的是，当前的版本库不会回退,而是向前一步\n","updated":"2020-11-23T15:20:08.940Z","path":"posts/git-advance.html","comments":1,"layout":"page","_id":"ckhupaq9c00081no875b1lrno","content":"<p>以下是我在工作中总结的关于git命令的一些使用方法。比较常用的那些我都不说了，主要是一些经常用但是又经常忘的命令，因此在这里总结一下，仅供参考。</p>\n<a id=\"more\"></a>\n<h3 id=\"超看操作日志\"><a href=\"#超看操作日志\" class=\"headerlink\" title=\"超看操作日志\"></a>超看操作日志</h3><p>查看当前分支的所有的提交日志</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">log</span></span><br></pre></td></tr></table></figure>\n\n<p>查看当前分支最后n次的提交日志</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">log</span> -n</span><br></pre></td></tr></table></figure>\n\n<p>在一行内显示当前分支的所有提交日志</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">log</span> --oneline</span><br></pre></td></tr></table></figure>\n\n<p>在提交的msg里搜索当前分支的日志</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">log</span> --grep=<span class=\"string\">'cps'</span></span><br></pre></td></tr></table></figure>\n\n<p>根据作者搜索当前分支的日志</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">log</span> --author=<span class=\"string\">'suyang'</span></span><br></pre></td></tr></table></figure>\n\n<p>查看所有的提交日志，包括已经删除的分支的</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git reflog</span><br></pre></td></tr></table></figure>\n\n<p><code>git reflog</code>与<code>git log</code>一样也可以使用<code>-n, --online,--grep,--author</code></p>\n<h3 id=\"操作子模块\"><a href=\"#操作子模块\" class=\"headerlink\" title=\"操作子模块\"></a>操作子模块</h3><p>克隆项目的时候连同子模块一起克隆</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> --recursive [url][path]</span><br></pre></td></tr></table></figure>\n\n<p>如果克隆的时候没有连同子模块一起克隆那么还可以</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git submodule update --init --recursive</span><br></pre></td></tr></table></figure>\n\n<p>之后想更新子模块的内容</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git submodule update</span><br></pre></td></tr></table></figure>\n\n<p>如果想修改子模块，操作和正常的git仓库一致。</p>\n<h3 id=\"提交\"><a href=\"#提交\" class=\"headerlink\" title=\"提交\"></a>提交</h3><p>下面的命令</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git commit -m<span class=\"string\">'提交'</span> -a</span><br></pre></td></tr></table></figure>\n\n<p>相当于两条命令</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git add .</span><br><span class=\"line\">git commit -m<span class=\"string\">'提交'</span></span><br></pre></td></tr></table></figure>\n\n<p>修改上次提交的message</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git commit --amend</span><br></pre></td></tr></table></figure>\n\n<p>如果分支已经push了，那么千万不要使用该命令。因为该命令会改变commit的hash值，这样就使当前的分支与远程的分支“开叉”了。</p>\n<h3 id=\"分支\"><a href=\"#分支\" class=\"headerlink\" title=\"分支\"></a>分支</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout -b dev origin/dev</span><br></pre></td></tr></table></figure>\n\n<p>这个命令的初衷是新建本地的dev分支并跟踪远程的dev分支。这个命令的执行前提是本地知道远程有个dev分支，否则会报错。那么怎么才能让本地知道远程的分支呢?使用<code>git pull</code>。这个命令不仅能拉取跟踪分支的最新代码，还能拉取分支和标签信息。</p>\n<p>如果误删除了分支怎么办？像我这种不想留不再使用的东西的人，已经误删过好几次了，解决办法很简单先试用<code>git reflog</code>找到你误删除的分支的最后一次commit的hash值，然后通过下面的命令恢复</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout -b recovery <span class=\"built_in\">hash</span>值</span><br></pre></td></tr></table></figure>\n\n<p>查看远程和本地的所有分支</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git branch -a</span><br></pre></td></tr></table></figure>\n\n<p>切换到刚才的分支</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout -</span><br></pre></td></tr></table></figure>\n\n<p>下面说说rebase。</p>\n<ol>\n<li>我的分支a是基于本地的master创建的，我的master跟踪远程的master</li>\n<li>我在分支a上开发，有3个commit</li>\n<li>在我开发的过程中，别人向远程的master提交了新的代码，这次提交总公有2个commit</li>\n</ol>\n<p>这个时候我们可以知道本地的master和现在远程最新的master都是基于之前旧版本的master的，如果我现在要向远程推送代码那么我应该</p>\n<ol>\n<li>先checkout到我本地的master</li>\n<li>拉取远程最新的master到我的master</li>\n<li>在我本地merge分支a，其实在这个merge的过程就是三方合并，这三方分别是最初的master，现在远程最新的master，我的分支a</li>\n</ol>\n<p>上面的这种方式会让提交看起来很难看，因此还有另外一种方法</p>\n<ol>\n<li>先checkout到我本地的master</li>\n<li>拉取远程最新的master到我的master</li>\n<li>切换会分支a，然后执行<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git rebase master</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<p>这个命令的意思是，使用现在的master的分支作为基础，重新把我在a分支上的提交依次覆盖到maste分支上作为新的a的分支。变基后a分支就在当前master分支的“直接上游”<br>4. 切回master分支然后merge刚才变完基的a分支，这个过程是一个fast-forward</p>\n<h3 id=\"撤销命令汇总\"><a href=\"#撤销命令汇总\" class=\"headerlink\" title=\"撤销命令汇总\"></a>撤销命令汇总</h3><p>撤销最后n次commit，并把撤销出来的更改放到暂存区。工作区不会受影响</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git reset --soft HEAD~n</span><br></pre></td></tr></table></figure>\n\n<p>如果想直接丢弃撤销出来的内容</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git reset --hard HEAD~n</span><br></pre></td></tr></table></figure>\n\n<p>将fileName从暂存区删除，这不会对此时的工作区有任何的影响，仅仅是从暂存区删除了fileName而已.但是此时git会重新对filename就行评估，如果此时filename与版本库不一致，那么filename还是会出现在工作区，但这与reset命令没有关系</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git reset fileName</span><br></pre></td></tr></table></figure>\n\n<p>用版本库里的代码强行刷新暂存区与工作区</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout -f</span><br></pre></td></tr></table></figure>\n\n<p>拉区版本库的 fileName 同时替换工作区与暂存区的fileName</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout HEAD filename</span><br></pre></td></tr></table></figure>\n\n<p>将工作区的fileName替换为暂存区的fileName，如果暂存区没有，那么会去版本库拉去fileName替换工作区的fileName。之后filename肯定不会出现在工作区</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout filename</span><br></pre></td></tr></table></figure>\n\n<p>最后说一下git revert命令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git revert hash值</span><br></pre></td></tr></table></figure>\n\n<p>revert命令会撤销某一次的提交，与reset不同的是，当前的版本库不会回退,而是向前一步</p>\n","site":{"data":{}},"excerpt":"<p>以下是我在工作中总结的关于git命令的一些使用方法。比较常用的那些我都不说了，主要是一些经常用但是又经常忘的命令，因此在这里总结一下，仅供参考。</p>","more":"<h3 id=\"超看操作日志\"><a href=\"#超看操作日志\" class=\"headerlink\" title=\"超看操作日志\"></a>超看操作日志</h3><p>查看当前分支的所有的提交日志</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">log</span></span><br></pre></td></tr></table></figure>\n\n<p>查看当前分支最后n次的提交日志</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">log</span> -n</span><br></pre></td></tr></table></figure>\n\n<p>在一行内显示当前分支的所有提交日志</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">log</span> --oneline</span><br></pre></td></tr></table></figure>\n\n<p>在提交的msg里搜索当前分支的日志</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">log</span> --grep=<span class=\"string\">'cps'</span></span><br></pre></td></tr></table></figure>\n\n<p>根据作者搜索当前分支的日志</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">log</span> --author=<span class=\"string\">'suyang'</span></span><br></pre></td></tr></table></figure>\n\n<p>查看所有的提交日志，包括已经删除的分支的</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git reflog</span><br></pre></td></tr></table></figure>\n\n<p><code>git reflog</code>与<code>git log</code>一样也可以使用<code>-n, --online,--grep,--author</code></p>\n<h3 id=\"操作子模块\"><a href=\"#操作子模块\" class=\"headerlink\" title=\"操作子模块\"></a>操作子模块</h3><p>克隆项目的时候连同子模块一起克隆</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> --recursive [url][path]</span><br></pre></td></tr></table></figure>\n\n<p>如果克隆的时候没有连同子模块一起克隆那么还可以</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git submodule update --init --recursive</span><br></pre></td></tr></table></figure>\n\n<p>之后想更新子模块的内容</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git submodule update</span><br></pre></td></tr></table></figure>\n\n<p>如果想修改子模块，操作和正常的git仓库一致。</p>\n<h3 id=\"提交\"><a href=\"#提交\" class=\"headerlink\" title=\"提交\"></a>提交</h3><p>下面的命令</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git commit -m<span class=\"string\">'提交'</span> -a</span><br></pre></td></tr></table></figure>\n\n<p>相当于两条命令</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git add .</span><br><span class=\"line\">git commit -m<span class=\"string\">'提交'</span></span><br></pre></td></tr></table></figure>\n\n<p>修改上次提交的message</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git commit --amend</span><br></pre></td></tr></table></figure>\n\n<p>如果分支已经push了，那么千万不要使用该命令。因为该命令会改变commit的hash值，这样就使当前的分支与远程的分支“开叉”了。</p>\n<h3 id=\"分支\"><a href=\"#分支\" class=\"headerlink\" title=\"分支\"></a>分支</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout -b dev origin/dev</span><br></pre></td></tr></table></figure>\n\n<p>这个命令的初衷是新建本地的dev分支并跟踪远程的dev分支。这个命令的执行前提是本地知道远程有个dev分支，否则会报错。那么怎么才能让本地知道远程的分支呢?使用<code>git pull</code>。这个命令不仅能拉取跟踪分支的最新代码，还能拉取分支和标签信息。</p>\n<p>如果误删除了分支怎么办？像我这种不想留不再使用的东西的人，已经误删过好几次了，解决办法很简单先试用<code>git reflog</code>找到你误删除的分支的最后一次commit的hash值，然后通过下面的命令恢复</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout -b recovery <span class=\"built_in\">hash</span>值</span><br></pre></td></tr></table></figure>\n\n<p>查看远程和本地的所有分支</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git branch -a</span><br></pre></td></tr></table></figure>\n\n<p>切换到刚才的分支</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout -</span><br></pre></td></tr></table></figure>\n\n<p>下面说说rebase。</p>\n<ol>\n<li>我的分支a是基于本地的master创建的，我的master跟踪远程的master</li>\n<li>我在分支a上开发，有3个commit</li>\n<li>在我开发的过程中，别人向远程的master提交了新的代码，这次提交总公有2个commit</li>\n</ol>\n<p>这个时候我们可以知道本地的master和现在远程最新的master都是基于之前旧版本的master的，如果我现在要向远程推送代码那么我应该</p>\n<ol>\n<li>先checkout到我本地的master</li>\n<li>拉取远程最新的master到我的master</li>\n<li>在我本地merge分支a，其实在这个merge的过程就是三方合并，这三方分别是最初的master，现在远程最新的master，我的分支a</li>\n</ol>\n<p>上面的这种方式会让提交看起来很难看，因此还有另外一种方法</p>\n<ol>\n<li>先checkout到我本地的master</li>\n<li>拉取远程最新的master到我的master</li>\n<li>切换会分支a，然后执行<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git rebase master</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<p>这个命令的意思是，使用现在的master的分支作为基础，重新把我在a分支上的提交依次覆盖到maste分支上作为新的a的分支。变基后a分支就在当前master分支的“直接上游”<br>4. 切回master分支然后merge刚才变完基的a分支，这个过程是一个fast-forward</p>\n<h3 id=\"撤销命令汇总\"><a href=\"#撤销命令汇总\" class=\"headerlink\" title=\"撤销命令汇总\"></a>撤销命令汇总</h3><p>撤销最后n次commit，并把撤销出来的更改放到暂存区。工作区不会受影响</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git reset --soft HEAD~n</span><br></pre></td></tr></table></figure>\n\n<p>如果想直接丢弃撤销出来的内容</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git reset --hard HEAD~n</span><br></pre></td></tr></table></figure>\n\n<p>将fileName从暂存区删除，这不会对此时的工作区有任何的影响，仅仅是从暂存区删除了fileName而已.但是此时git会重新对filename就行评估，如果此时filename与版本库不一致，那么filename还是会出现在工作区，但这与reset命令没有关系</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git reset fileName</span><br></pre></td></tr></table></figure>\n\n<p>用版本库里的代码强行刷新暂存区与工作区</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout -f</span><br></pre></td></tr></table></figure>\n\n<p>拉区版本库的 fileName 同时替换工作区与暂存区的fileName</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout HEAD filename</span><br></pre></td></tr></table></figure>\n\n<p>将工作区的fileName替换为暂存区的fileName，如果暂存区没有，那么会去版本库拉去fileName替换工作区的fileName。之后filename肯定不会出现在工作区</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout filename</span><br></pre></td></tr></table></figure>\n\n<p>最后说一下git revert命令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git revert hash值</span><br></pre></td></tr></table></figure>\n\n<p>revert命令会撤销某一次的提交，与reset不同的是，当前的版本库不会回退,而是向前一步</p>"},{"title":"Go语言中的数组、字符串、切片","date":"2019-12-23T04:18:35.000Z","tags":["go"],"photos":[["https://sysummerblog.club/gocover1.jpeg"]],"_content":"之所以把他们三个放一起是因为他们3个的底层的原始数据有着一样的数据结构。\n<!--more-->\n## 数组\n数组是由**固定长度的**特定类型的元素组成的序列。这些元素在内存中的存储是连续的。数组一经定义，他的长度是不能改变的，数组的长度可以是0.\n\n下面几种数组的定义方式都是正确的。在go语言中，数组就是数组，并不是指向首元素的指针。\n```go\n\n//长度为3的数组，数组的每个元素的值都是0\nvar test [3]int\n\n//与上面的一样，加了{}就得用等于号\nvar test = [3]int{}\n\n//长度为3的数组，在定义的时候也初始化了每个元素的值\nvar test = [3]int{1,2,3}\n\n//长度为3的数组，第一个元素的值为1其余的值为0\nvar test = [3]int{1}\n\n//长度为3的数组，下标为1的元素的值是2，下标为0的元素的值是3，其余的值是0\nvar test = [3]int{1:2,0:3}\n\n//长度为3的数组，下标为0的元素值是1，下标为1的元素值是2，下标为2的元素值是3\nvar test = [3]int{1,1:2,2:3}\n```\n\n当一个数组被赋值或者当做函数参数被传递的时候，会复制整个数组，如果此时数组比价大，那么开销也是很大的。可以使用数组指针替代。数组指针在使用上和数组是很相似的\n```go\nfunc main () {\n\tvar test = [3]int{1:2,0:3}\n\n\tp := &test\n\n\tfmt.Println(test[0])\n\tfmt.Println(p[0])\n\n\ttest[0] = 100\n\n\tfmt.Println(test[0])\n\tfmt.Println(p[0])\n}\n```\n结果\n```\n3\n3\n100\n100\n```\n\n空数组时不占内存的，这一点与空结构体是一样的。\n```go\n\nvar times [5][0]int\n\nfor range times {\n    fmt.Println(\"hello\")\n}\n```\n\n## 字符串\n字符串是一个连续的不可改变的字节序列。\n看一下go语言中字符串的定义其实是个结构体\n```go\ntype StringHeader struct {\n    Data uintptr\n    Len int\n}\n```\n可以看出，字符串的底层是一个非负数的字节数组，另外还有一个长度。\n所以当复制一个字符串给一个变量或者作为参数传递的时候只是复制了指向基础数据的指针和字符串的长度，并没有复制底层的数据。\n\n下面先看一段代码\n```go\nfunc main () {\n\tstr := \"Hello 世界\"\n\tfor i:= 0; i < len(str); i++ {\n\t\tch := str[i]\n\t\tfmt.Println(ch)\n\t}\n\n\tfmt.Println(\"-------unicode遍历-------\")\n\tfor _, ch := range str {\n\t\tfmt.Println(ch)\n\t}\n}\n```\n结果为\n72\n101\n108\n108\n111\n32\n228\n184\n150\n231\n149\n140\n-----------unicode遍历-------------\n72\n101\n108\n108\n111\n32\n19990\n30028\n\n从结果我们可以看出\n\n1. 两个循环输出的都是一堆数字，说明go中的字符串是以byte方式存储的\n2. for循环输出的是字节的“数值”，for range输出的是以utf-8为编码方式的unicode字符的“数值”\n\n如果我想直接输出字符而不是字符的“数值”怎么办？很简单，用强制转换就好\n\n```go\nfunc main () {\n\tstr := \"Hello 世界\"\n\tfor i:= 0; i < len(str); i++ {\n\t\tch := str[i]\n\t\tfmt.Println(string(ch))\n\t}\n\n\tfmt.Println(\"------unicode遍历--------\")\n\tfor _, ch := range str {\n\t\tfmt.Println(string(ch))\n\t}\n}\n```\n输出的结果为\nH\ne\nl\nl\no\n \nä\n¸\n\nç\n\n\n-----------unicode遍历-------------\nH\ne\nl\nl\no\n \n世\n界\n\n第一个循环用6个字节“表示”了世界，因为大部分中文字符在utf-8编码方式下使用3个字节。所以在代码中多使用for range来循环字符串\n\n再看一段代码\n```go\nfunc main () {\n\tstr := \"Hello 世界\"\n\tfmt.Println(string(str[6]))\n}\n```\n\n结果\nä\n\n这说明了字符串默认是以byte数组存放的而不是rune数组。如果字符串中包含中文字符并且要读取这个字符的时候要先转成rune类型的数组切片\n```go\nfunc main () {\n\tstr     := \"Hello 世界\"\n\tstrRune := []rune(str)\n\tfmt.Println(string(strRune[6]))\n}\n```\n结果\n世\n\n\ngo中的单引号与双引号是不同的,正常的字符串用双引号表示，单引号内只能是一个字符\n\n```go\nfunc main () {\n\tstr     := '我'\n\tfmt.Println(str)\n}\n```\n结果\n25105\n\nstr存放的其实是一个rune\n\n```go\nfunc main () {\n\tstr     := '我'\n\tfmt.Println(string(str))\n}\n```\n结果\n我\n\n最后说说go语言中的反引号(\\`)。简单地说反引号中的内容不支持任何的转义，所看即所得。\n\n## 切片\n与数组不同的是切片的大小可以变化，并且切边多了一个cap属性，意为最大数量。先看一下切片在go语言中的定义\n```go\ntype SliceHeader struct {\n    Data uintptr\n    Len int\n    Cap int\n}\n```\n这也说明了复制一个切片只是复制了指向底层数据的指针以及len和cap，并不会复制底层的数据。\n\n下面说一下切片的声明和初始化\n```go\n// 不是空切片是nil，这一点与数组是不一样的\nvar a []int\n\n//空切片\nvar b = []int{}\n\n//len和cap都为3\nvar c = []int{1,2,3}\n\n//截取c的第0个和第1个元素生成一个新的切片，len是2，因为从c的0位置开始截取，所以cap与c的cap是一样的3\nvar d = c[:2]\n\n//截取c的第1个元素生成一个新的切片，len是1，cap是2\nvar d = c[1:2]\n\n//截取c的第0个元素和第一个元素生成一个新的切片，len是2，cap是3\nvar e = c[0:2:cap(c)]\n\n//len和cap都是3，每个元素的值是0\nvar f = make([]int, 3)\n\n//len是2cap是3，每个元素都是0\nvar g = make([]int, 2, 3)\n```\n\n切片的追加。如果追加后超过了原始切片的cap，那么追加后切片的cap是追加前的两倍\n```go\nfunc main () {\n\tvar c = []int{1,2,3,4,5,6}\n\n\tfmt.Println(len(c))\n\tfmt.Println(cap(c))\n\n\tc = append(c, 7)\n\n\tfmt.Println(len(c))\n\tfmt.Println(cap(c))\n}\n```\n结果\n```\n6\n6\n7\n12\n```\n删除元素\n```go\nfunc main () {\n\ta = []int{1, 2, 3}\n    // 删除尾部1个元素\n    a = a[:len(a)-1]\n \n    // 删除尾部N个元素\n    a = a[:len(a)-N]\n}\n```\n","source":"posts/go-array-str-slice.md","raw":"---\ntitle: Go语言中的数组、字符串、切片\ndate: 2019-12-23 12:18:35\ntags:\n    - go\nphotos :\n    - [\"https://sysummerblog.club/gocover1.jpeg\"]\n---\n之所以把他们三个放一起是因为他们3个的底层的原始数据有着一样的数据结构。\n<!--more-->\n## 数组\n数组是由**固定长度的**特定类型的元素组成的序列。这些元素在内存中的存储是连续的。数组一经定义，他的长度是不能改变的，数组的长度可以是0.\n\n下面几种数组的定义方式都是正确的。在go语言中，数组就是数组，并不是指向首元素的指针。\n```go\n\n//长度为3的数组，数组的每个元素的值都是0\nvar test [3]int\n\n//与上面的一样，加了{}就得用等于号\nvar test = [3]int{}\n\n//长度为3的数组，在定义的时候也初始化了每个元素的值\nvar test = [3]int{1,2,3}\n\n//长度为3的数组，第一个元素的值为1其余的值为0\nvar test = [3]int{1}\n\n//长度为3的数组，下标为1的元素的值是2，下标为0的元素的值是3，其余的值是0\nvar test = [3]int{1:2,0:3}\n\n//长度为3的数组，下标为0的元素值是1，下标为1的元素值是2，下标为2的元素值是3\nvar test = [3]int{1,1:2,2:3}\n```\n\n当一个数组被赋值或者当做函数参数被传递的时候，会复制整个数组，如果此时数组比价大，那么开销也是很大的。可以使用数组指针替代。数组指针在使用上和数组是很相似的\n```go\nfunc main () {\n\tvar test = [3]int{1:2,0:3}\n\n\tp := &test\n\n\tfmt.Println(test[0])\n\tfmt.Println(p[0])\n\n\ttest[0] = 100\n\n\tfmt.Println(test[0])\n\tfmt.Println(p[0])\n}\n```\n结果\n```\n3\n3\n100\n100\n```\n\n空数组时不占内存的，这一点与空结构体是一样的。\n```go\n\nvar times [5][0]int\n\nfor range times {\n    fmt.Println(\"hello\")\n}\n```\n\n## 字符串\n字符串是一个连续的不可改变的字节序列。\n看一下go语言中字符串的定义其实是个结构体\n```go\ntype StringHeader struct {\n    Data uintptr\n    Len int\n}\n```\n可以看出，字符串的底层是一个非负数的字节数组，另外还有一个长度。\n所以当复制一个字符串给一个变量或者作为参数传递的时候只是复制了指向基础数据的指针和字符串的长度，并没有复制底层的数据。\n\n下面先看一段代码\n```go\nfunc main () {\n\tstr := \"Hello 世界\"\n\tfor i:= 0; i < len(str); i++ {\n\t\tch := str[i]\n\t\tfmt.Println(ch)\n\t}\n\n\tfmt.Println(\"-------unicode遍历-------\")\n\tfor _, ch := range str {\n\t\tfmt.Println(ch)\n\t}\n}\n```\n结果为\n72\n101\n108\n108\n111\n32\n228\n184\n150\n231\n149\n140\n-----------unicode遍历-------------\n72\n101\n108\n108\n111\n32\n19990\n30028\n\n从结果我们可以看出\n\n1. 两个循环输出的都是一堆数字，说明go中的字符串是以byte方式存储的\n2. for循环输出的是字节的“数值”，for range输出的是以utf-8为编码方式的unicode字符的“数值”\n\n如果我想直接输出字符而不是字符的“数值”怎么办？很简单，用强制转换就好\n\n```go\nfunc main () {\n\tstr := \"Hello 世界\"\n\tfor i:= 0; i < len(str); i++ {\n\t\tch := str[i]\n\t\tfmt.Println(string(ch))\n\t}\n\n\tfmt.Println(\"------unicode遍历--------\")\n\tfor _, ch := range str {\n\t\tfmt.Println(string(ch))\n\t}\n}\n```\n输出的结果为\nH\ne\nl\nl\no\n \nä\n¸\n\nç\n\n\n-----------unicode遍历-------------\nH\ne\nl\nl\no\n \n世\n界\n\n第一个循环用6个字节“表示”了世界，因为大部分中文字符在utf-8编码方式下使用3个字节。所以在代码中多使用for range来循环字符串\n\n再看一段代码\n```go\nfunc main () {\n\tstr := \"Hello 世界\"\n\tfmt.Println(string(str[6]))\n}\n```\n\n结果\nä\n\n这说明了字符串默认是以byte数组存放的而不是rune数组。如果字符串中包含中文字符并且要读取这个字符的时候要先转成rune类型的数组切片\n```go\nfunc main () {\n\tstr     := \"Hello 世界\"\n\tstrRune := []rune(str)\n\tfmt.Println(string(strRune[6]))\n}\n```\n结果\n世\n\n\ngo中的单引号与双引号是不同的,正常的字符串用双引号表示，单引号内只能是一个字符\n\n```go\nfunc main () {\n\tstr     := '我'\n\tfmt.Println(str)\n}\n```\n结果\n25105\n\nstr存放的其实是一个rune\n\n```go\nfunc main () {\n\tstr     := '我'\n\tfmt.Println(string(str))\n}\n```\n结果\n我\n\n最后说说go语言中的反引号(\\`)。简单地说反引号中的内容不支持任何的转义，所看即所得。\n\n## 切片\n与数组不同的是切片的大小可以变化，并且切边多了一个cap属性，意为最大数量。先看一下切片在go语言中的定义\n```go\ntype SliceHeader struct {\n    Data uintptr\n    Len int\n    Cap int\n}\n```\n这也说明了复制一个切片只是复制了指向底层数据的指针以及len和cap，并不会复制底层的数据。\n\n下面说一下切片的声明和初始化\n```go\n// 不是空切片是nil，这一点与数组是不一样的\nvar a []int\n\n//空切片\nvar b = []int{}\n\n//len和cap都为3\nvar c = []int{1,2,3}\n\n//截取c的第0个和第1个元素生成一个新的切片，len是2，因为从c的0位置开始截取，所以cap与c的cap是一样的3\nvar d = c[:2]\n\n//截取c的第1个元素生成一个新的切片，len是1，cap是2\nvar d = c[1:2]\n\n//截取c的第0个元素和第一个元素生成一个新的切片，len是2，cap是3\nvar e = c[0:2:cap(c)]\n\n//len和cap都是3，每个元素的值是0\nvar f = make([]int, 3)\n\n//len是2cap是3，每个元素都是0\nvar g = make([]int, 2, 3)\n```\n\n切片的追加。如果追加后超过了原始切片的cap，那么追加后切片的cap是追加前的两倍\n```go\nfunc main () {\n\tvar c = []int{1,2,3,4,5,6}\n\n\tfmt.Println(len(c))\n\tfmt.Println(cap(c))\n\n\tc = append(c, 7)\n\n\tfmt.Println(len(c))\n\tfmt.Println(cap(c))\n}\n```\n结果\n```\n6\n6\n7\n12\n```\n删除元素\n```go\nfunc main () {\n\ta = []int{1, 2, 3}\n    // 删除尾部1个元素\n    a = a[:len(a)-1]\n \n    // 删除尾部N个元素\n    a = a[:len(a)-N]\n}\n```\n","updated":"2020-11-23T15:20:08.940Z","path":"posts/go-array-str-slice.html","comments":1,"layout":"page","_id":"ckhupaq9f000b1no8mk53dkx8","content":"<p>之所以把他们三个放一起是因为他们3个的底层的原始数据有着一样的数据结构。</p>\n<a id=\"more\"></a>\n<h2 id=\"数组\"><a href=\"#数组\" class=\"headerlink\" title=\"数组\"></a>数组</h2><p>数组是由<strong>固定长度的</strong>特定类型的元素组成的序列。这些元素在内存中的存储是连续的。数组一经定义，他的长度是不能改变的，数组的长度可以是0.</p>\n<p>下面几种数组的定义方式都是正确的。在go语言中，数组就是数组，并不是指向首元素的指针。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//长度为3的数组，数组的每个元素的值都是0</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test [<span class=\"number\">3</span>]<span class=\"keyword\">int</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//与上面的一样，加了&#123;&#125;就得用等于号</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//长度为3的数组，在定义的时候也初始化了每个元素的值</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//长度为3的数组，第一个元素的值为1其余的值为0</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//长度为3的数组，下标为1的元素的值是2，下标为0的元素的值是3，其余的值是0</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>:<span class=\"number\">2</span>,<span class=\"number\">0</span>:<span class=\"number\">3</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//长度为3的数组，下标为0的元素值是1，下标为1的元素值是2，下标为2的元素值是3</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>,<span class=\"number\">1</span>:<span class=\"number\">2</span>,<span class=\"number\">2</span>:<span class=\"number\">3</span>&#125;</span><br></pre></td></tr></table></figure>\n\n<p>当一个数组被赋值或者当做函数参数被传递的时候，会复制整个数组，如果此时数组比价大，那么开销也是很大的。可以使用数组指针替代。数组指针在使用上和数组是很相似的</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>:<span class=\"number\">2</span>,<span class=\"number\">0</span>:<span class=\"number\">3</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tp := &amp;test</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(test[<span class=\"number\">0</span>])</span><br><span class=\"line\">\tfmt.Println(p[<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">\ttest[<span class=\"number\">0</span>] = <span class=\"number\">100</span></span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(test[<span class=\"number\">0</span>])</span><br><span class=\"line\">\tfmt.Println(p[<span class=\"number\">0</span>])</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">3</span><br><span class=\"line\">3</span><br><span class=\"line\">100</span><br><span class=\"line\">100</span><br></pre></td></tr></table></figure>\n\n<p>空数组时不占内存的，这一点与空结构体是一样的。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> times [<span class=\"number\">5</span>][<span class=\"number\">0</span>]<span class=\"keyword\">int</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> <span class=\"keyword\">range</span> times &#123;</span><br><span class=\"line\">    fmt.Println(<span class=\"string\">\"hello\"</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"字符串\"><a href=\"#字符串\" class=\"headerlink\" title=\"字符串\"></a>字符串</h2><p>字符串是一个连续的不可改变的字节序列。<br>看一下go语言中字符串的定义其实是个结构体</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> StringHeader <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">    Data <span class=\"keyword\">uintptr</span></span><br><span class=\"line\">    Len <span class=\"keyword\">int</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>可以看出，字符串的底层是一个非负数的字节数组，另外还有一个长度。<br>所以当复制一个字符串给一个变量或者作为参数传递的时候只是复制了指向基础数据的指针和字符串的长度，并没有复制底层的数据。</p>\n<p>下面先看一段代码</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr := <span class=\"string\">\"Hello 世界\"</span></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i:= <span class=\"number\">0</span>; i &lt; <span class=\"built_in\">len</span>(str); i++ &#123;</span><br><span class=\"line\">\t\tch := str[i]</span><br><span class=\"line\">\t\tfmt.Println(ch)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"-------unicode遍历-------\"</span>)</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> _, ch := <span class=\"keyword\">range</span> str &#123;</span><br><span class=\"line\">\t\tfmt.Println(ch)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果为<br>72<br>101<br>108<br>108<br>111<br>32<br>228<br>184<br>150<br>231<br>149<br>140<br>———–unicode遍历————-<br>72<br>101<br>108<br>108<br>111<br>32<br>19990<br>30028</p>\n<p>从结果我们可以看出</p>\n<ol>\n<li>两个循环输出的都是一堆数字，说明go中的字符串是以byte方式存储的</li>\n<li>for循环输出的是字节的“数值”，for range输出的是以utf-8为编码方式的unicode字符的“数值”</li>\n</ol>\n<p>如果我想直接输出字符而不是字符的“数值”怎么办？很简单，用强制转换就好</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr := <span class=\"string\">\"Hello 世界\"</span></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i:= <span class=\"number\">0</span>; i &lt; <span class=\"built_in\">len</span>(str); i++ &#123;</span><br><span class=\"line\">\t\tch := str[i]</span><br><span class=\"line\">\t\tfmt.Println(<span class=\"keyword\">string</span>(ch))</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"------unicode遍历--------\"</span>)</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> _, ch := <span class=\"keyword\">range</span> str &#123;</span><br><span class=\"line\">\t\tfmt.Println(<span class=\"keyword\">string</span>(ch))</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>输出的结果为<br>H<br>e<br>l<br>l<br>o</p>\n<p>ä<br>¸</p>\n<p>ç</p>\n<p>———–unicode遍历————-<br>H<br>e<br>l<br>l<br>o</p>\n<p>世<br>界</p>\n<p>第一个循环用6个字节“表示”了世界，因为大部分中文字符在utf-8编码方式下使用3个字节。所以在代码中多使用for range来循环字符串</p>\n<p>再看一段代码</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr := <span class=\"string\">\"Hello 世界\"</span></span><br><span class=\"line\">\tfmt.Println(<span class=\"keyword\">string</span>(str[<span class=\"number\">6</span>]))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果<br>ä</p>\n<p>这说明了字符串默认是以byte数组存放的而不是rune数组。如果字符串中包含中文字符并且要读取这个字符的时候要先转成rune类型的数组切片</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr     := <span class=\"string\">\"Hello 世界\"</span></span><br><span class=\"line\">\tstrRune := []<span class=\"keyword\">rune</span>(str)</span><br><span class=\"line\">\tfmt.Println(<span class=\"keyword\">string</span>(strRune[<span class=\"number\">6</span>]))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果<br>世</p>\n<p>go中的单引号与双引号是不同的,正常的字符串用双引号表示，单引号内只能是一个字符</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr     := <span class=\"string\">'我'</span></span><br><span class=\"line\">\tfmt.Println(str)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果<br>25105</p>\n<p>str存放的其实是一个rune</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr     := <span class=\"string\">'我'</span></span><br><span class=\"line\">\tfmt.Println(<span class=\"keyword\">string</span>(str))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果<br>我</p>\n<p>最后说说go语言中的反引号(`)。简单地说反引号中的内容不支持任何的转义，所看即所得。</p>\n<h2 id=\"切片\"><a href=\"#切片\" class=\"headerlink\" title=\"切片\"></a>切片</h2><p>与数组不同的是切片的大小可以变化，并且切边多了一个cap属性，意为最大数量。先看一下切片在go语言中的定义</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> SliceHeader <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">    Data <span class=\"keyword\">uintptr</span></span><br><span class=\"line\">    Len <span class=\"keyword\">int</span></span><br><span class=\"line\">    Cap <span class=\"keyword\">int</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>这也说明了复制一个切片只是复制了指向底层数据的指针以及len和cap，并不会复制底层的数据。</p>\n<p>下面说一下切片的声明和初始化</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 不是空切片是nil，这一点与数组是不一样的</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> a []<span class=\"keyword\">int</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//空切片</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> b = []<span class=\"keyword\">int</span>&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//len和cap都为3</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> c = []<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//截取c的第0个和第1个元素生成一个新的切片，len是2，因为从c的0位置开始截取，所以cap与c的cap是一样的3</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> d = c[:<span class=\"number\">2</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//截取c的第1个元素生成一个新的切片，len是1，cap是2</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> d = c[<span class=\"number\">1</span>:<span class=\"number\">2</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//截取c的第0个元素和第一个元素生成一个新的切片，len是2，cap是3</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> e = c[<span class=\"number\">0</span>:<span class=\"number\">2</span>:<span class=\"built_in\">cap</span>(c)]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//len和cap都是3，每个元素的值是0</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> f = <span class=\"built_in\">make</span>([]<span class=\"keyword\">int</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//len是2cap是3，每个元素都是0</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> g = <span class=\"built_in\">make</span>([]<span class=\"keyword\">int</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br></pre></td></tr></table></figure>\n\n<p>切片的追加。如果追加后超过了原始切片的cap，那么追加后切片的cap是追加前的两倍</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> c = []<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(<span class=\"built_in\">len</span>(c))</span><br><span class=\"line\">\tfmt.Println(<span class=\"built_in\">cap</span>(c))</span><br><span class=\"line\"></span><br><span class=\"line\">\tc = <span class=\"built_in\">append</span>(c, <span class=\"number\">7</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(<span class=\"built_in\">len</span>(c))</span><br><span class=\"line\">\tfmt.Println(<span class=\"built_in\">cap</span>(c))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">6</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">12</span><br></pre></td></tr></table></figure>\n\n<p>删除元素</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\ta = []<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>&#125;</span><br><span class=\"line\">    <span class=\"comment\">// 删除尾部1个元素</span></span><br><span class=\"line\">    a = a[:<span class=\"built_in\">len</span>(a)<span class=\"number\">-1</span>]</span><br><span class=\"line\"> </span><br><span class=\"line\">    <span class=\"comment\">// 删除尾部N个元素</span></span><br><span class=\"line\">    a = a[:<span class=\"built_in\">len</span>(a)-N]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"<p>之所以把他们三个放一起是因为他们3个的底层的原始数据有着一样的数据结构。</p>","more":"<h2 id=\"数组\"><a href=\"#数组\" class=\"headerlink\" title=\"数组\"></a>数组</h2><p>数组是由<strong>固定长度的</strong>特定类型的元素组成的序列。这些元素在内存中的存储是连续的。数组一经定义，他的长度是不能改变的，数组的长度可以是0.</p>\n<p>下面几种数组的定义方式都是正确的。在go语言中，数组就是数组，并不是指向首元素的指针。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//长度为3的数组，数组的每个元素的值都是0</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test [<span class=\"number\">3</span>]<span class=\"keyword\">int</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//与上面的一样，加了&#123;&#125;就得用等于号</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//长度为3的数组，在定义的时候也初始化了每个元素的值</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//长度为3的数组，第一个元素的值为1其余的值为0</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//长度为3的数组，下标为1的元素的值是2，下标为0的元素的值是3，其余的值是0</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>:<span class=\"number\">2</span>,<span class=\"number\">0</span>:<span class=\"number\">3</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//长度为3的数组，下标为0的元素值是1，下标为1的元素值是2，下标为2的元素值是3</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>,<span class=\"number\">1</span>:<span class=\"number\">2</span>,<span class=\"number\">2</span>:<span class=\"number\">3</span>&#125;</span><br></pre></td></tr></table></figure>\n\n<p>当一个数组被赋值或者当做函数参数被传递的时候，会复制整个数组，如果此时数组比价大，那么开销也是很大的。可以使用数组指针替代。数组指针在使用上和数组是很相似的</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>:<span class=\"number\">2</span>,<span class=\"number\">0</span>:<span class=\"number\">3</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tp := &amp;test</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(test[<span class=\"number\">0</span>])</span><br><span class=\"line\">\tfmt.Println(p[<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">\ttest[<span class=\"number\">0</span>] = <span class=\"number\">100</span></span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(test[<span class=\"number\">0</span>])</span><br><span class=\"line\">\tfmt.Println(p[<span class=\"number\">0</span>])</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">3</span><br><span class=\"line\">3</span><br><span class=\"line\">100</span><br><span class=\"line\">100</span><br></pre></td></tr></table></figure>\n\n<p>空数组时不占内存的，这一点与空结构体是一样的。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> times [<span class=\"number\">5</span>][<span class=\"number\">0</span>]<span class=\"keyword\">int</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> <span class=\"keyword\">range</span> times &#123;</span><br><span class=\"line\">    fmt.Println(<span class=\"string\">\"hello\"</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"字符串\"><a href=\"#字符串\" class=\"headerlink\" title=\"字符串\"></a>字符串</h2><p>字符串是一个连续的不可改变的字节序列。<br>看一下go语言中字符串的定义其实是个结构体</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> StringHeader <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">    Data <span class=\"keyword\">uintptr</span></span><br><span class=\"line\">    Len <span class=\"keyword\">int</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>可以看出，字符串的底层是一个非负数的字节数组，另外还有一个长度。<br>所以当复制一个字符串给一个变量或者作为参数传递的时候只是复制了指向基础数据的指针和字符串的长度，并没有复制底层的数据。</p>\n<p>下面先看一段代码</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr := <span class=\"string\">\"Hello 世界\"</span></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i:= <span class=\"number\">0</span>; i &lt; <span class=\"built_in\">len</span>(str); i++ &#123;</span><br><span class=\"line\">\t\tch := str[i]</span><br><span class=\"line\">\t\tfmt.Println(ch)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"-------unicode遍历-------\"</span>)</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> _, ch := <span class=\"keyword\">range</span> str &#123;</span><br><span class=\"line\">\t\tfmt.Println(ch)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果为<br>72<br>101<br>108<br>108<br>111<br>32<br>228<br>184<br>150<br>231<br>149<br>140<br>———–unicode遍历————-<br>72<br>101<br>108<br>108<br>111<br>32<br>19990<br>30028</p>\n<p>从结果我们可以看出</p>\n<ol>\n<li>两个循环输出的都是一堆数字，说明go中的字符串是以byte方式存储的</li>\n<li>for循环输出的是字节的“数值”，for range输出的是以utf-8为编码方式的unicode字符的“数值”</li>\n</ol>\n<p>如果我想直接输出字符而不是字符的“数值”怎么办？很简单，用强制转换就好</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr := <span class=\"string\">\"Hello 世界\"</span></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i:= <span class=\"number\">0</span>; i &lt; <span class=\"built_in\">len</span>(str); i++ &#123;</span><br><span class=\"line\">\t\tch := str[i]</span><br><span class=\"line\">\t\tfmt.Println(<span class=\"keyword\">string</span>(ch))</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"------unicode遍历--------\"</span>)</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> _, ch := <span class=\"keyword\">range</span> str &#123;</span><br><span class=\"line\">\t\tfmt.Println(<span class=\"keyword\">string</span>(ch))</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>输出的结果为<br>H<br>e<br>l<br>l<br>o</p>\n<p>ä<br>¸</p>\n<p>ç</p>\n<p>———–unicode遍历————-<br>H<br>e<br>l<br>l<br>o</p>\n<p>世<br>界</p>\n<p>第一个循环用6个字节“表示”了世界，因为大部分中文字符在utf-8编码方式下使用3个字节。所以在代码中多使用for range来循环字符串</p>\n<p>再看一段代码</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr := <span class=\"string\">\"Hello 世界\"</span></span><br><span class=\"line\">\tfmt.Println(<span class=\"keyword\">string</span>(str[<span class=\"number\">6</span>]))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果<br>ä</p>\n<p>这说明了字符串默认是以byte数组存放的而不是rune数组。如果字符串中包含中文字符并且要读取这个字符的时候要先转成rune类型的数组切片</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr     := <span class=\"string\">\"Hello 世界\"</span></span><br><span class=\"line\">\tstrRune := []<span class=\"keyword\">rune</span>(str)</span><br><span class=\"line\">\tfmt.Println(<span class=\"keyword\">string</span>(strRune[<span class=\"number\">6</span>]))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果<br>世</p>\n<p>go中的单引号与双引号是不同的,正常的字符串用双引号表示，单引号内只能是一个字符</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr     := <span class=\"string\">'我'</span></span><br><span class=\"line\">\tfmt.Println(str)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果<br>25105</p>\n<p>str存放的其实是一个rune</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr     := <span class=\"string\">'我'</span></span><br><span class=\"line\">\tfmt.Println(<span class=\"keyword\">string</span>(str))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果<br>我</p>\n<p>最后说说go语言中的反引号(`)。简单地说反引号中的内容不支持任何的转义，所看即所得。</p>\n<h2 id=\"切片\"><a href=\"#切片\" class=\"headerlink\" title=\"切片\"></a>切片</h2><p>与数组不同的是切片的大小可以变化，并且切边多了一个cap属性，意为最大数量。先看一下切片在go语言中的定义</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> SliceHeader <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">    Data <span class=\"keyword\">uintptr</span></span><br><span class=\"line\">    Len <span class=\"keyword\">int</span></span><br><span class=\"line\">    Cap <span class=\"keyword\">int</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>这也说明了复制一个切片只是复制了指向底层数据的指针以及len和cap，并不会复制底层的数据。</p>\n<p>下面说一下切片的声明和初始化</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 不是空切片是nil，这一点与数组是不一样的</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> a []<span class=\"keyword\">int</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//空切片</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> b = []<span class=\"keyword\">int</span>&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//len和cap都为3</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> c = []<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//截取c的第0个和第1个元素生成一个新的切片，len是2，因为从c的0位置开始截取，所以cap与c的cap是一样的3</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> d = c[:<span class=\"number\">2</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//截取c的第1个元素生成一个新的切片，len是1，cap是2</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> d = c[<span class=\"number\">1</span>:<span class=\"number\">2</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//截取c的第0个元素和第一个元素生成一个新的切片，len是2，cap是3</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> e = c[<span class=\"number\">0</span>:<span class=\"number\">2</span>:<span class=\"built_in\">cap</span>(c)]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//len和cap都是3，每个元素的值是0</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> f = <span class=\"built_in\">make</span>([]<span class=\"keyword\">int</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//len是2cap是3，每个元素都是0</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> g = <span class=\"built_in\">make</span>([]<span class=\"keyword\">int</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br></pre></td></tr></table></figure>\n\n<p>切片的追加。如果追加后超过了原始切片的cap，那么追加后切片的cap是追加前的两倍</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> c = []<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(<span class=\"built_in\">len</span>(c))</span><br><span class=\"line\">\tfmt.Println(<span class=\"built_in\">cap</span>(c))</span><br><span class=\"line\"></span><br><span class=\"line\">\tc = <span class=\"built_in\">append</span>(c, <span class=\"number\">7</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(<span class=\"built_in\">len</span>(c))</span><br><span class=\"line\">\tfmt.Println(<span class=\"built_in\">cap</span>(c))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">6</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">12</span><br></pre></td></tr></table></figure>\n\n<p>删除元素</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\ta = []<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>&#125;</span><br><span class=\"line\">    <span class=\"comment\">// 删除尾部1个元素</span></span><br><span class=\"line\">    a = a[:<span class=\"built_in\">len</span>(a)<span class=\"number\">-1</span>]</span><br><span class=\"line\"> </span><br><span class=\"line\">    <span class=\"comment\">// 删除尾部N个元素</span></span><br><span class=\"line\">    a = a[:<span class=\"built_in\">len</span>(a)-N]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"Go语言中的垃圾回收","date":"2020-01-01T09:37:50.000Z","tags":["go"],"photos":[["https://sysummerblog.club/gogc.jpg"]],"_content":"垃圾回收（英语：Garbage Collection，缩写为GC），在计算机科学中是一种自动的存储器管理机制。当一个计算机上的动态存储器不再需要时，就应该予以释放，以让出存储器，这种存储器资源管理，称为垃圾回收。垃圾回收器可以让程序员减轻许多负担，也减少程序员犯错的机会。\n<!--more-->\n## 垃圾回收算法\n### 引用计数法\n每个单元维护一个域，保存其他单元对其的引用。当引用为0时就可以回收了。PHP就是使用的这种机制。\n\n引用计数是渐进式的，内存管理与用户程序交织在一起，不会出现STW，但是这种方式解决不了互相引用的问题。比如\n```\na.b = b;\nb.a = a;\n```\na和b二者互相引用，并且没有其他的引用了，引用计数法并不会把他们当做垃圾回收。\n\n### 标记清扫法\n是一种自动内存管理基于追踪的垃圾回收算法。垃圾回收的时候首先会STW。然后从根节点开始追踪每一个可达的对象，标记完之后就去回收没有被标记的几点然后进行回收。\n\n那么标记清扫法能不能解决循环引用的问题呢？是可以的\n![](https://sysummerblog.club/biaojishanchu.jpg)\n\n虽然object4与object5互相引用，但是从根节点起是没有到达他们的路径的，因此他们两个不会被标记可达，在清扫阶段会被回收。\n\n标记清扫法最大的缺点就是GC的时候会STW。\n\n### 分代收集\n分代垃圾回收算法将对象按生命周期长短存放到堆上的两个（或者更多）区域，这些区域就是分代（generation）。对于新生代的区域的垃圾回收频率要明显高于老年代区域。\n\n分配对象的时候从新生代里面分配，如果后面发现对象的生命周期较长，则将其移到老年代，这个过程叫做 promote。随着不断 promote，最后新生代的大小在整个堆的占用比例不会特别大。收集的时候集中主要精力在新生代就会相对来说效率更高，STW 时间也会更短。\n\njava的GC就是分代收集。\n\n### 三色标记法\n![](https://sysummerblog.club/sansebiaojifa.gif)\n\n三色标记算法是对标记阶段的改进，原理如下：\n\n1. 起初所有对象都是白色。\n2. 从根出发扫描所有可达对象，标记为灰色，放入待处理队列。\n3. 从队列取出灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色。\n4. 重复 3，直到灰色对象队列为空。此时白色对象即为垃圾，进行回收。\n\n步骤1、2、3的时候需要STW, 不然会出现问题。假如不STW，如下图，灰色的B节点引用了白色的C节点。当C节点还没有变灰的时候，B和C之间的引用断了并且已经变黑的A节点又引用了C。因此C不会变成灰色的，还是白色。等到回收的时候会把C回收了，但是C明明被黑色的A引用着，就出问题。因此三色球算法在标记的过程中必须要STW。\n![](https://sysummerblog.club/3sbjfqx.jpg)\n\n\n## go语言的垃圾回收算法\ngo原因的垃圾回收算法是基于三色标记法的，并在此基础上加入了写屏障缩短了整个过程的STW时间。\n\n![](https://sysummerblog.club/gc.png)\n\n具体的过程是\n\n1. 首先从 root 开始遍历，root 包括全局指针和 goroutine 栈上的指针。\n2. 从 root 开始遍历，标记为灰色。遍历灰色队列。\n3. re-scan 全局指针和栈。因为 mark 和用户程序是并行的，所以在过程 1 的时候可能会有新的对象分配，这个时候就需要通过写屏障（write barrier）记录下来。re-scan 再完成检查一下。\n\nSWT的阶段\n\n1. 第一个是 GC 将要开始的时候，这个时候主要是一些准备工作，比如 enable write barrier。\n2. 第二个过程就是上面提到的 re-scan 过程。如果这个时候没有 stw，那么 mark 将无休止。\n\n什么时候触发gc\n\n1. 阈值：默认内存扩大一倍，启动gc\n2. 定期：默认2min触发一次\n3. 手动：runtime.gc()\n","source":"posts/go-gc.md","raw":"---\ntitle: Go语言中的垃圾回收\ndate: 2020-01-01 17:37:50\ntags:\n    - go\nphotos:\n    - [\"https://sysummerblog.club/gogc.jpg\"]\n---\n垃圾回收（英语：Garbage Collection，缩写为GC），在计算机科学中是一种自动的存储器管理机制。当一个计算机上的动态存储器不再需要时，就应该予以释放，以让出存储器，这种存储器资源管理，称为垃圾回收。垃圾回收器可以让程序员减轻许多负担，也减少程序员犯错的机会。\n<!--more-->\n## 垃圾回收算法\n### 引用计数法\n每个单元维护一个域，保存其他单元对其的引用。当引用为0时就可以回收了。PHP就是使用的这种机制。\n\n引用计数是渐进式的，内存管理与用户程序交织在一起，不会出现STW，但是这种方式解决不了互相引用的问题。比如\n```\na.b = b;\nb.a = a;\n```\na和b二者互相引用，并且没有其他的引用了，引用计数法并不会把他们当做垃圾回收。\n\n### 标记清扫法\n是一种自动内存管理基于追踪的垃圾回收算法。垃圾回收的时候首先会STW。然后从根节点开始追踪每一个可达的对象，标记完之后就去回收没有被标记的几点然后进行回收。\n\n那么标记清扫法能不能解决循环引用的问题呢？是可以的\n![](https://sysummerblog.club/biaojishanchu.jpg)\n\n虽然object4与object5互相引用，但是从根节点起是没有到达他们的路径的，因此他们两个不会被标记可达，在清扫阶段会被回收。\n\n标记清扫法最大的缺点就是GC的时候会STW。\n\n### 分代收集\n分代垃圾回收算法将对象按生命周期长短存放到堆上的两个（或者更多）区域，这些区域就是分代（generation）。对于新生代的区域的垃圾回收频率要明显高于老年代区域。\n\n分配对象的时候从新生代里面分配，如果后面发现对象的生命周期较长，则将其移到老年代，这个过程叫做 promote。随着不断 promote，最后新生代的大小在整个堆的占用比例不会特别大。收集的时候集中主要精力在新生代就会相对来说效率更高，STW 时间也会更短。\n\njava的GC就是分代收集。\n\n### 三色标记法\n![](https://sysummerblog.club/sansebiaojifa.gif)\n\n三色标记算法是对标记阶段的改进，原理如下：\n\n1. 起初所有对象都是白色。\n2. 从根出发扫描所有可达对象，标记为灰色，放入待处理队列。\n3. 从队列取出灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色。\n4. 重复 3，直到灰色对象队列为空。此时白色对象即为垃圾，进行回收。\n\n步骤1、2、3的时候需要STW, 不然会出现问题。假如不STW，如下图，灰色的B节点引用了白色的C节点。当C节点还没有变灰的时候，B和C之间的引用断了并且已经变黑的A节点又引用了C。因此C不会变成灰色的，还是白色。等到回收的时候会把C回收了，但是C明明被黑色的A引用着，就出问题。因此三色球算法在标记的过程中必须要STW。\n![](https://sysummerblog.club/3sbjfqx.jpg)\n\n\n## go语言的垃圾回收算法\ngo原因的垃圾回收算法是基于三色标记法的，并在此基础上加入了写屏障缩短了整个过程的STW时间。\n\n![](https://sysummerblog.club/gc.png)\n\n具体的过程是\n\n1. 首先从 root 开始遍历，root 包括全局指针和 goroutine 栈上的指针。\n2. 从 root 开始遍历，标记为灰色。遍历灰色队列。\n3. re-scan 全局指针和栈。因为 mark 和用户程序是并行的，所以在过程 1 的时候可能会有新的对象分配，这个时候就需要通过写屏障（write barrier）记录下来。re-scan 再完成检查一下。\n\nSWT的阶段\n\n1. 第一个是 GC 将要开始的时候，这个时候主要是一些准备工作，比如 enable write barrier。\n2. 第二个过程就是上面提到的 re-scan 过程。如果这个时候没有 stw，那么 mark 将无休止。\n\n什么时候触发gc\n\n1. 阈值：默认内存扩大一倍，启动gc\n2. 定期：默认2min触发一次\n3. 手动：runtime.gc()\n","updated":"2020-11-23T15:20:08.939Z","path":"posts/go-gc.html","comments":1,"layout":"page","_id":"ckhupaq9h000d1no8p1jm2x1c","content":"<p>垃圾回收（英语：Garbage Collection，缩写为GC），在计算机科学中是一种自动的存储器管理机制。当一个计算机上的动态存储器不再需要时，就应该予以释放，以让出存储器，这种存储器资源管理，称为垃圾回收。垃圾回收器可以让程序员减轻许多负担，也减少程序员犯错的机会。</p>\n<a id=\"more\"></a>\n<h2 id=\"垃圾回收算法\"><a href=\"#垃圾回收算法\" class=\"headerlink\" title=\"垃圾回收算法\"></a>垃圾回收算法</h2><h3 id=\"引用计数法\"><a href=\"#引用计数法\" class=\"headerlink\" title=\"引用计数法\"></a>引用计数法</h3><p>每个单元维护一个域，保存其他单元对其的引用。当引用为0时就可以回收了。PHP就是使用的这种机制。</p>\n<p>引用计数是渐进式的，内存管理与用户程序交织在一起，不会出现STW，但是这种方式解决不了互相引用的问题。比如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a.b = b;</span><br><span class=\"line\">b.a = a;</span><br></pre></td></tr></table></figure>\n\n<p>a和b二者互相引用，并且没有其他的引用了，引用计数法并不会把他们当做垃圾回收。</p>\n<h3 id=\"标记清扫法\"><a href=\"#标记清扫法\" class=\"headerlink\" title=\"标记清扫法\"></a>标记清扫法</h3><p>是一种自动内存管理基于追踪的垃圾回收算法。垃圾回收的时候首先会STW。然后从根节点开始追踪每一个可达的对象，标记完之后就去回收没有被标记的几点然后进行回收。</p>\n<p>那么标记清扫法能不能解决循环引用的问题呢？是可以的<br><img src=\"https://sysummerblog.club/biaojishanchu.jpg\" alt></p>\n<p>虽然object4与object5互相引用，但是从根节点起是没有到达他们的路径的，因此他们两个不会被标记可达，在清扫阶段会被回收。</p>\n<p>标记清扫法最大的缺点就是GC的时候会STW。</p>\n<h3 id=\"分代收集\"><a href=\"#分代收集\" class=\"headerlink\" title=\"分代收集\"></a>分代收集</h3><p>分代垃圾回收算法将对象按生命周期长短存放到堆上的两个（或者更多）区域，这些区域就是分代（generation）。对于新生代的区域的垃圾回收频率要明显高于老年代区域。</p>\n<p>分配对象的时候从新生代里面分配，如果后面发现对象的生命周期较长，则将其移到老年代，这个过程叫做 promote。随着不断 promote，最后新生代的大小在整个堆的占用比例不会特别大。收集的时候集中主要精力在新生代就会相对来说效率更高，STW 时间也会更短。</p>\n<p>java的GC就是分代收集。</p>\n<h3 id=\"三色标记法\"><a href=\"#三色标记法\" class=\"headerlink\" title=\"三色标记法\"></a>三色标记法</h3><p><img src=\"https://sysummerblog.club/sansebiaojifa.gif\" alt></p>\n<p>三色标记算法是对标记阶段的改进，原理如下：</p>\n<ol>\n<li>起初所有对象都是白色。</li>\n<li>从根出发扫描所有可达对象，标记为灰色，放入待处理队列。</li>\n<li>从队列取出灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色。</li>\n<li>重复 3，直到灰色对象队列为空。此时白色对象即为垃圾，进行回收。</li>\n</ol>\n<p>步骤1、2、3的时候需要STW, 不然会出现问题。假如不STW，如下图，灰色的B节点引用了白色的C节点。当C节点还没有变灰的时候，B和C之间的引用断了并且已经变黑的A节点又引用了C。因此C不会变成灰色的，还是白色。等到回收的时候会把C回收了，但是C明明被黑色的A引用着，就出问题。因此三色球算法在标记的过程中必须要STW。<br><img src=\"https://sysummerblog.club/3sbjfqx.jpg\" alt></p>\n<h2 id=\"go语言的垃圾回收算法\"><a href=\"#go语言的垃圾回收算法\" class=\"headerlink\" title=\"go语言的垃圾回收算法\"></a>go语言的垃圾回收算法</h2><p>go原因的垃圾回收算法是基于三色标记法的，并在此基础上加入了写屏障缩短了整个过程的STW时间。</p>\n<p><img src=\"https://sysummerblog.club/gc.png\" alt></p>\n<p>具体的过程是</p>\n<ol>\n<li>首先从 root 开始遍历，root 包括全局指针和 goroutine 栈上的指针。</li>\n<li>从 root 开始遍历，标记为灰色。遍历灰色队列。</li>\n<li>re-scan 全局指针和栈。因为 mark 和用户程序是并行的，所以在过程 1 的时候可能会有新的对象分配，这个时候就需要通过写屏障（write barrier）记录下来。re-scan 再完成检查一下。</li>\n</ol>\n<p>SWT的阶段</p>\n<ol>\n<li>第一个是 GC 将要开始的时候，这个时候主要是一些准备工作，比如 enable write barrier。</li>\n<li>第二个过程就是上面提到的 re-scan 过程。如果这个时候没有 stw，那么 mark 将无休止。</li>\n</ol>\n<p>什么时候触发gc</p>\n<ol>\n<li>阈值：默认内存扩大一倍，启动gc</li>\n<li>定期：默认2min触发一次</li>\n<li>手动：runtime.gc()</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>垃圾回收（英语：Garbage Collection，缩写为GC），在计算机科学中是一种自动的存储器管理机制。当一个计算机上的动态存储器不再需要时，就应该予以释放，以让出存储器，这种存储器资源管理，称为垃圾回收。垃圾回收器可以让程序员减轻许多负担，也减少程序员犯错的机会。</p>","more":"<h2 id=\"垃圾回收算法\"><a href=\"#垃圾回收算法\" class=\"headerlink\" title=\"垃圾回收算法\"></a>垃圾回收算法</h2><h3 id=\"引用计数法\"><a href=\"#引用计数法\" class=\"headerlink\" title=\"引用计数法\"></a>引用计数法</h3><p>每个单元维护一个域，保存其他单元对其的引用。当引用为0时就可以回收了。PHP就是使用的这种机制。</p>\n<p>引用计数是渐进式的，内存管理与用户程序交织在一起，不会出现STW，但是这种方式解决不了互相引用的问题。比如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a.b = b;</span><br><span class=\"line\">b.a = a;</span><br></pre></td></tr></table></figure>\n\n<p>a和b二者互相引用，并且没有其他的引用了，引用计数法并不会把他们当做垃圾回收。</p>\n<h3 id=\"标记清扫法\"><a href=\"#标记清扫法\" class=\"headerlink\" title=\"标记清扫法\"></a>标记清扫法</h3><p>是一种自动内存管理基于追踪的垃圾回收算法。垃圾回收的时候首先会STW。然后从根节点开始追踪每一个可达的对象，标记完之后就去回收没有被标记的几点然后进行回收。</p>\n<p>那么标记清扫法能不能解决循环引用的问题呢？是可以的<br><img src=\"https://sysummerblog.club/biaojishanchu.jpg\" alt></p>\n<p>虽然object4与object5互相引用，但是从根节点起是没有到达他们的路径的，因此他们两个不会被标记可达，在清扫阶段会被回收。</p>\n<p>标记清扫法最大的缺点就是GC的时候会STW。</p>\n<h3 id=\"分代收集\"><a href=\"#分代收集\" class=\"headerlink\" title=\"分代收集\"></a>分代收集</h3><p>分代垃圾回收算法将对象按生命周期长短存放到堆上的两个（或者更多）区域，这些区域就是分代（generation）。对于新生代的区域的垃圾回收频率要明显高于老年代区域。</p>\n<p>分配对象的时候从新生代里面分配，如果后面发现对象的生命周期较长，则将其移到老年代，这个过程叫做 promote。随着不断 promote，最后新生代的大小在整个堆的占用比例不会特别大。收集的时候集中主要精力在新生代就会相对来说效率更高，STW 时间也会更短。</p>\n<p>java的GC就是分代收集。</p>\n<h3 id=\"三色标记法\"><a href=\"#三色标记法\" class=\"headerlink\" title=\"三色标记法\"></a>三色标记法</h3><p><img src=\"https://sysummerblog.club/sansebiaojifa.gif\" alt></p>\n<p>三色标记算法是对标记阶段的改进，原理如下：</p>\n<ol>\n<li>起初所有对象都是白色。</li>\n<li>从根出发扫描所有可达对象，标记为灰色，放入待处理队列。</li>\n<li>从队列取出灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色。</li>\n<li>重复 3，直到灰色对象队列为空。此时白色对象即为垃圾，进行回收。</li>\n</ol>\n<p>步骤1、2、3的时候需要STW, 不然会出现问题。假如不STW，如下图，灰色的B节点引用了白色的C节点。当C节点还没有变灰的时候，B和C之间的引用断了并且已经变黑的A节点又引用了C。因此C不会变成灰色的，还是白色。等到回收的时候会把C回收了，但是C明明被黑色的A引用着，就出问题。因此三色球算法在标记的过程中必须要STW。<br><img src=\"https://sysummerblog.club/3sbjfqx.jpg\" alt></p>\n<h2 id=\"go语言的垃圾回收算法\"><a href=\"#go语言的垃圾回收算法\" class=\"headerlink\" title=\"go语言的垃圾回收算法\"></a>go语言的垃圾回收算法</h2><p>go原因的垃圾回收算法是基于三色标记法的，并在此基础上加入了写屏障缩短了整个过程的STW时间。</p>\n<p><img src=\"https://sysummerblog.club/gc.png\" alt></p>\n<p>具体的过程是</p>\n<ol>\n<li>首先从 root 开始遍历，root 包括全局指针和 goroutine 栈上的指针。</li>\n<li>从 root 开始遍历，标记为灰色。遍历灰色队列。</li>\n<li>re-scan 全局指针和栈。因为 mark 和用户程序是并行的，所以在过程 1 的时候可能会有新的对象分配，这个时候就需要通过写屏障（write barrier）记录下来。re-scan 再完成检查一下。</li>\n</ol>\n<p>SWT的阶段</p>\n<ol>\n<li>第一个是 GC 将要开始的时候，这个时候主要是一些准备工作，比如 enable write barrier。</li>\n<li>第二个过程就是上面提到的 re-scan 过程。如果这个时候没有 stw，那么 mark 将无休止。</li>\n</ol>\n<p>什么时候触发gc</p>\n<ol>\n<li>阈值：默认内存扩大一倍，启动gc</li>\n<li>定期：默认2min触发一次</li>\n<li>手动：runtime.gc()</li>\n</ol>"},{"title":"Go语言中的锁","date":"2020-01-15T06:57:01.000Z","tags":["go"],"photos":[["https://sysummerblog.club/golang2.jpeg"]],"_content":"总结一下这段时间学习的有关go语言中的锁的知识。\n<!--more-->\n多线程和多协程编程能够充分利用多核处理器的优势，是系统性能提升。但是有时也会给我们意外的“惊喜”，比如下面的计数器的例子\n```go\nvar count int = 0\nfunc main() {\n\twg := sync.WaitGroup{}\n\twg.Add(5)\n\n\tfor i := 1; i <= 5; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tcount++\n\t\t}()\n\t}\n\n    wg.Wait()\n\tfmt.Println(count)\n}\n```\n我们期待的结果是5，但事实上结果是不确定的。因为5个协程是并发执行的，当每个协程执行到`count += i`的时候count的值是不确定的，因此结果也是不确定的。\n\n向例子中的count变量可以成为临界资源，当多个线程或协程对临界资源进行修改的时候就必须要“上锁”。使用锁可以保证在对临界资源进行修改的这一动作上各个并行的协程是“串行修改的”。\n\n## Mutex 互斥锁\n创建一个互斥锁\n```go\nmx := new(sync.Mutex)\n```\n\n1.mx.Lock()加锁，mx.Unlock()解锁\n2. 锁是针对资源的，不是针对协程的，哪个协程加锁，就得哪个协程解锁。\n3. 一个协程获得锁后其他协程无论读写只能等待，直到占用锁的协程释放锁\n4. Lock()之前Unlock()会导致panic，还未Unlock()之后Lock()会产生死锁\n\n还是上面的例子，我们稍加修改使用互斥锁\n\n```go\nvar count int = 0\nfunc main() {\n    wg := sync.WaitGroup{}\n\twg.Add(5)\n\n\tmx := sync.Mutex{}\n\n\tfor i := 1; i <= 5; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tmx.Lock()\n\t\t\tcount++\n\t\t\tmx.Unlock()\n\t\t}()\n\t}\n\n\twg.Wait()\n\tfmt.Println(count)\n}\n```\n输出的结果恒为5。\n\n## RWMutex 读写锁\n互斥锁的优势是简单，劣势是太粗暴了。假设对于一个临界资源，有的协程想写，有的只想读。如果在某一时刻只能允许一个协程读，其他的协程必须等待的话就显得效率太低了。因此读写锁出现了。\n\n```go\nrwmx := sync.RWMutex{}\n```\n1. rwmx.Lock()加写锁，rwmx.Unlock()解写锁。写锁排斥任何读锁和写锁\n2. rwmx.RLock()加读锁，rwmx.RUnlock()解读锁。读锁排斥写锁但是不排斥读锁\n\n下面的例子，主协程上了读锁，子协程也都可以获取读锁，整个程序和没有加锁是一样的\n```go\nvar count int = 0\nfunc main() {\n\tvar wg sync.WaitGroup\n\tvar mx sync.RWMutex\n\n\tmx.RLock()\n\tfmt.Println(\"主协程获取了读锁\")\n\n\twg.Add(2)\n\n\tfor i := 1; i <= 2; i++ {\n\t\tgo func(x int) {\n\t\t\tdefer wg.Done()\n\t\t\tmx.RLock()\n\t\t\tfmt.Printf(\"协程%d获取了读锁\\n\", x)\n\t\t\tfmt.Println(count)\n\t\t\tmx.RUnlock()\n\t\t\tfmt.Printf(\"协程%d释放了读锁\\n\", x)\n\t\t}(i)\n\t}\n\n\twg.Wait()\n\tmx.RUnlock()\n\tfmt.Println(\"主协程释放了读锁\")\n}\n```\n结果为：\n```\n主协程获取了读锁\n协程2获取了读锁\n0\n协程2释放了读锁\n协程1获取了读锁\n0\n协程1释放了读锁\n主协程释放了读锁\n```\n下面的示例是主协程获取了写锁想修改count的值，子协程想获取读锁读取count的值\n```go\nvar count int = 0\nfunc PracticeCond5() {\n\tvar wg sync.WaitGroup\n\tvar mx sync.RWMutex\n\n\tmx.Lock()\n\tfmt.Println(\"主协程获取了写锁\")\n\n\twg.Add(2)\n\n\tfor i := 1; i <= 2; i++ {\n\t\tgo func(x int) {\n\t\t\tdefer wg.Done()\n\t\t\tmx.RLock()\n\t\t\tfmt.Printf(\"协程%d获取了读锁\\n\", x)\n\t\t\tfmt.Println(count)\n\t\t\tmx.RUnlock()\n\t\t\tfmt.Printf(\"协程%d释放了读锁\\n\", x)\n\t\t}(i)\n\t}\n\n\tcount++\n\tmx.Unlock()\n\tfmt.Println(\"主协程释放了写锁\")\n\twg.Wait()\n}\n```\n结果为\n```\n主协程获取了写锁\n主协程释放了写锁\n协程2获取了读锁\n1\n协程2释放了读锁\n协程1获取了读锁\n1\n协程1释放了读锁\n```\n可以看出子协程都是等到主协程将count值加一然后释放写锁后才获取的读锁。\n\n## Cond 条件变量\n条件变量适用于多个协程等待某一个资源就绪的情况。条件变量依赖于互斥锁或者读写锁。\n\n使用互斥锁创建条件变量\n```go\n    wx   := new(sync.Mutex)\n\tcond := sync.NewCond(wx)\n```\n在使用的过程中有以下几个函数\n\n* cond.Wait() 当前协程等待资源就绪，整个过程会阻塞当前协程，直到被通知资源就绪\n* cond.Signal() 通知1个等待的协程，使其能够继续工作\n* cond.Broadcast() 广播，通知所有的协程继续工作\n\n需要强调以下几点\n\n1. 调用cond.wait()之前一定要先`cond.L.Lock()`因为wait函数是\n```go\nfunc (c *Cond) Wait() {\n\tc.checker.check()\n\tt := runtime_notifyListAdd(&c.notify)\n\tc.L.Unlock()\n\truntime_notifyListWait(&c.notify, t)\n\tc.L.Lock()\n}\n```\n它是先将协程加入到监听队列然后再释放锁。等到资源就绪的时候再尝试获取互斥锁。\n\n来看一个完整的例子\n```go\nfunc main() {\n\tmx   := new(sync.Mutex)\n\tcond := sync.NewCond(mx)\n\twg   := sync.WaitGroup{}\n\twg.Add(4)\n\n\tfor i := 1; i <= 4; i++ {\n\t\tgo func(x int) {\n\t\t\tdefer wg.Done()\n\t\t\tcond.L.Lock()\n\t\t\tcond.Wait()\n\t\t\tfmt.Println(x)\n\t\t\ttime.Sleep(time.Second)\n\t\t\tfmt.Printf(\"%d准备释放锁\\n\", x)\n\t\t\tcond.L.Unlock()\n\t\t}(i)\n\t}\n\n\tfmt.Println(\"start\")\n\ttime.Sleep(time.Second * 3)\n\tfmt.Println(\"下发第一个通知\")\n\tcond.Signal()\n\ttime.Sleep(time.Second * 3)\n\tfmt.Println(\"下发第二个通知\")\n\tcond.Signal()\n\ttime.Sleep(time.Second * 3)\n\tfmt.Println(\"开始广播\")\n\tcond.Broadcast()\n\n\twg.Wait()\n\tfmt.Println(\"退出\")\n}\n```\n结果为\n```\nstart\n下发第一个通知\n1\n1准备释放锁\n下发第二个通知\n2\n2准备释放锁\n开始广播\n3\n3准备释放锁\n4\n4准备释放锁\n退出\n\n```\n","source":"posts/go-lock.md","raw":"---\ntitle: Go语言中的锁\ndate: 2020-01-15 14:57:01\ntags:\n    - go\nphotos:\n      - [\"https://sysummerblog.club/golang2.jpeg\"]\n---\n总结一下这段时间学习的有关go语言中的锁的知识。\n<!--more-->\n多线程和多协程编程能够充分利用多核处理器的优势，是系统性能提升。但是有时也会给我们意外的“惊喜”，比如下面的计数器的例子\n```go\nvar count int = 0\nfunc main() {\n\twg := sync.WaitGroup{}\n\twg.Add(5)\n\n\tfor i := 1; i <= 5; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tcount++\n\t\t}()\n\t}\n\n    wg.Wait()\n\tfmt.Println(count)\n}\n```\n我们期待的结果是5，但事实上结果是不确定的。因为5个协程是并发执行的，当每个协程执行到`count += i`的时候count的值是不确定的，因此结果也是不确定的。\n\n向例子中的count变量可以成为临界资源，当多个线程或协程对临界资源进行修改的时候就必须要“上锁”。使用锁可以保证在对临界资源进行修改的这一动作上各个并行的协程是“串行修改的”。\n\n## Mutex 互斥锁\n创建一个互斥锁\n```go\nmx := new(sync.Mutex)\n```\n\n1.mx.Lock()加锁，mx.Unlock()解锁\n2. 锁是针对资源的，不是针对协程的，哪个协程加锁，就得哪个协程解锁。\n3. 一个协程获得锁后其他协程无论读写只能等待，直到占用锁的协程释放锁\n4. Lock()之前Unlock()会导致panic，还未Unlock()之后Lock()会产生死锁\n\n还是上面的例子，我们稍加修改使用互斥锁\n\n```go\nvar count int = 0\nfunc main() {\n    wg := sync.WaitGroup{}\n\twg.Add(5)\n\n\tmx := sync.Mutex{}\n\n\tfor i := 1; i <= 5; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tmx.Lock()\n\t\t\tcount++\n\t\t\tmx.Unlock()\n\t\t}()\n\t}\n\n\twg.Wait()\n\tfmt.Println(count)\n}\n```\n输出的结果恒为5。\n\n## RWMutex 读写锁\n互斥锁的优势是简单，劣势是太粗暴了。假设对于一个临界资源，有的协程想写，有的只想读。如果在某一时刻只能允许一个协程读，其他的协程必须等待的话就显得效率太低了。因此读写锁出现了。\n\n```go\nrwmx := sync.RWMutex{}\n```\n1. rwmx.Lock()加写锁，rwmx.Unlock()解写锁。写锁排斥任何读锁和写锁\n2. rwmx.RLock()加读锁，rwmx.RUnlock()解读锁。读锁排斥写锁但是不排斥读锁\n\n下面的例子，主协程上了读锁，子协程也都可以获取读锁，整个程序和没有加锁是一样的\n```go\nvar count int = 0\nfunc main() {\n\tvar wg sync.WaitGroup\n\tvar mx sync.RWMutex\n\n\tmx.RLock()\n\tfmt.Println(\"主协程获取了读锁\")\n\n\twg.Add(2)\n\n\tfor i := 1; i <= 2; i++ {\n\t\tgo func(x int) {\n\t\t\tdefer wg.Done()\n\t\t\tmx.RLock()\n\t\t\tfmt.Printf(\"协程%d获取了读锁\\n\", x)\n\t\t\tfmt.Println(count)\n\t\t\tmx.RUnlock()\n\t\t\tfmt.Printf(\"协程%d释放了读锁\\n\", x)\n\t\t}(i)\n\t}\n\n\twg.Wait()\n\tmx.RUnlock()\n\tfmt.Println(\"主协程释放了读锁\")\n}\n```\n结果为：\n```\n主协程获取了读锁\n协程2获取了读锁\n0\n协程2释放了读锁\n协程1获取了读锁\n0\n协程1释放了读锁\n主协程释放了读锁\n```\n下面的示例是主协程获取了写锁想修改count的值，子协程想获取读锁读取count的值\n```go\nvar count int = 0\nfunc PracticeCond5() {\n\tvar wg sync.WaitGroup\n\tvar mx sync.RWMutex\n\n\tmx.Lock()\n\tfmt.Println(\"主协程获取了写锁\")\n\n\twg.Add(2)\n\n\tfor i := 1; i <= 2; i++ {\n\t\tgo func(x int) {\n\t\t\tdefer wg.Done()\n\t\t\tmx.RLock()\n\t\t\tfmt.Printf(\"协程%d获取了读锁\\n\", x)\n\t\t\tfmt.Println(count)\n\t\t\tmx.RUnlock()\n\t\t\tfmt.Printf(\"协程%d释放了读锁\\n\", x)\n\t\t}(i)\n\t}\n\n\tcount++\n\tmx.Unlock()\n\tfmt.Println(\"主协程释放了写锁\")\n\twg.Wait()\n}\n```\n结果为\n```\n主协程获取了写锁\n主协程释放了写锁\n协程2获取了读锁\n1\n协程2释放了读锁\n协程1获取了读锁\n1\n协程1释放了读锁\n```\n可以看出子协程都是等到主协程将count值加一然后释放写锁后才获取的读锁。\n\n## Cond 条件变量\n条件变量适用于多个协程等待某一个资源就绪的情况。条件变量依赖于互斥锁或者读写锁。\n\n使用互斥锁创建条件变量\n```go\n    wx   := new(sync.Mutex)\n\tcond := sync.NewCond(wx)\n```\n在使用的过程中有以下几个函数\n\n* cond.Wait() 当前协程等待资源就绪，整个过程会阻塞当前协程，直到被通知资源就绪\n* cond.Signal() 通知1个等待的协程，使其能够继续工作\n* cond.Broadcast() 广播，通知所有的协程继续工作\n\n需要强调以下几点\n\n1. 调用cond.wait()之前一定要先`cond.L.Lock()`因为wait函数是\n```go\nfunc (c *Cond) Wait() {\n\tc.checker.check()\n\tt := runtime_notifyListAdd(&c.notify)\n\tc.L.Unlock()\n\truntime_notifyListWait(&c.notify, t)\n\tc.L.Lock()\n}\n```\n它是先将协程加入到监听队列然后再释放锁。等到资源就绪的时候再尝试获取互斥锁。\n\n来看一个完整的例子\n```go\nfunc main() {\n\tmx   := new(sync.Mutex)\n\tcond := sync.NewCond(mx)\n\twg   := sync.WaitGroup{}\n\twg.Add(4)\n\n\tfor i := 1; i <= 4; i++ {\n\t\tgo func(x int) {\n\t\t\tdefer wg.Done()\n\t\t\tcond.L.Lock()\n\t\t\tcond.Wait()\n\t\t\tfmt.Println(x)\n\t\t\ttime.Sleep(time.Second)\n\t\t\tfmt.Printf(\"%d准备释放锁\\n\", x)\n\t\t\tcond.L.Unlock()\n\t\t}(i)\n\t}\n\n\tfmt.Println(\"start\")\n\ttime.Sleep(time.Second * 3)\n\tfmt.Println(\"下发第一个通知\")\n\tcond.Signal()\n\ttime.Sleep(time.Second * 3)\n\tfmt.Println(\"下发第二个通知\")\n\tcond.Signal()\n\ttime.Sleep(time.Second * 3)\n\tfmt.Println(\"开始广播\")\n\tcond.Broadcast()\n\n\twg.Wait()\n\tfmt.Println(\"退出\")\n}\n```\n结果为\n```\nstart\n下发第一个通知\n1\n1准备释放锁\n下发第二个通知\n2\n2准备释放锁\n开始广播\n3\n3准备释放锁\n4\n4准备释放锁\n退出\n\n```\n","updated":"2020-11-23T15:20:08.940Z","path":"posts/go-lock.html","comments":1,"layout":"page","_id":"ckhupaq9i000f1no8cwv6rz80","content":"<p>总结一下这段时间学习的有关go语言中的锁的知识。</p>\n<a id=\"more\"></a>\n<p>多线程和多协程编程能够充分利用多核处理器的优势，是系统性能提升。但是有时也会给我们意外的“惊喜”，比如下面的计数器的例子</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> count <span class=\"keyword\">int</span> = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\twg := sync.WaitGroup&#123;&#125;</span><br><span class=\"line\">\twg.Add(<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">1</span>; i &lt;= <span class=\"number\">5</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\tcount++</span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    wg.Wait()</span><br><span class=\"line\">\tfmt.Println(count)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>我们期待的结果是5，但事实上结果是不确定的。因为5个协程是并发执行的，当每个协程执行到<code>count += i</code>的时候count的值是不确定的，因此结果也是不确定的。</p>\n<p>向例子中的count变量可以成为临界资源，当多个线程或协程对临界资源进行修改的时候就必须要“上锁”。使用锁可以保证在对临界资源进行修改的这一动作上各个并行的协程是“串行修改的”。</p>\n<h2 id=\"Mutex-互斥锁\"><a href=\"#Mutex-互斥锁\" class=\"headerlink\" title=\"Mutex 互斥锁\"></a>Mutex 互斥锁</h2><p>创建一个互斥锁</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mx := <span class=\"built_in\">new</span>(sync.Mutex)</span><br></pre></td></tr></table></figure>\n\n<p>1.mx.Lock()加锁，mx.Unlock()解锁<br>2. 锁是针对资源的，不是针对协程的，哪个协程加锁，就得哪个协程解锁。<br>3. 一个协程获得锁后其他协程无论读写只能等待，直到占用锁的协程释放锁<br>4. Lock()之前Unlock()会导致panic，还未Unlock()之后Lock()会产生死锁</p>\n<p>还是上面的例子，我们稍加修改使用互斥锁</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> count <span class=\"keyword\">int</span> = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">    wg := sync.WaitGroup&#123;&#125;</span><br><span class=\"line\">\twg.Add(<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\tmx := sync.Mutex&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">1</span>; i &lt;= <span class=\"number\">5</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\tmx.Lock()</span><br><span class=\"line\">\t\t\tcount++</span><br><span class=\"line\">\t\t\tmx.Unlock()</span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">\tfmt.Println(count)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>输出的结果恒为5。</p>\n<h2 id=\"RWMutex-读写锁\"><a href=\"#RWMutex-读写锁\" class=\"headerlink\" title=\"RWMutex 读写锁\"></a>RWMutex 读写锁</h2><p>互斥锁的优势是简单，劣势是太粗暴了。假设对于一个临界资源，有的协程想写，有的只想读。如果在某一时刻只能允许一个协程读，其他的协程必须等待的话就显得效率太低了。因此读写锁出现了。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rwmx := sync.RWMutex&#123;&#125;</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>rwmx.Lock()加写锁，rwmx.Unlock()解写锁。写锁排斥任何读锁和写锁</li>\n<li>rwmx.RLock()加读锁，rwmx.RUnlock()解读锁。读锁排斥写锁但是不排斥读锁</li>\n</ol>\n<p>下面的例子，主协程上了读锁，子协程也都可以获取读锁，整个程序和没有加锁是一样的</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> count <span class=\"keyword\">int</span> = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> wg sync.WaitGroup</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> mx sync.RWMutex</span><br><span class=\"line\"></span><br><span class=\"line\">\tmx.RLock()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"主协程获取了读锁\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Add(<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">1</span>; i &lt;= <span class=\"number\">2</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(x <span class=\"keyword\">int</span>)</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\tmx.RLock()</span><br><span class=\"line\">\t\t\tfmt.Printf(<span class=\"string\">\"协程%d获取了读锁\\n\"</span>, x)</span><br><span class=\"line\">\t\t\tfmt.Println(count)</span><br><span class=\"line\">\t\t\tmx.RUnlock()</span><br><span class=\"line\">\t\t\tfmt.Printf(<span class=\"string\">\"协程%d释放了读锁\\n\"</span>, x)</span><br><span class=\"line\">\t\t&#125;(i)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">\tmx.RUnlock()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"主协程释放了读锁\"</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果为：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">主协程获取了读锁</span><br><span class=\"line\">协程2获取了读锁</span><br><span class=\"line\">0</span><br><span class=\"line\">协程2释放了读锁</span><br><span class=\"line\">协程1获取了读锁</span><br><span class=\"line\">0</span><br><span class=\"line\">协程1释放了读锁</span><br><span class=\"line\">主协程释放了读锁</span><br></pre></td></tr></table></figure>\n\n<p>下面的示例是主协程获取了写锁想修改count的值，子协程想获取读锁读取count的值</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> count <span class=\"keyword\">int</span> = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">PracticeCond5</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> wg sync.WaitGroup</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> mx sync.RWMutex</span><br><span class=\"line\"></span><br><span class=\"line\">\tmx.Lock()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"主协程获取了写锁\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Add(<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">1</span>; i &lt;= <span class=\"number\">2</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(x <span class=\"keyword\">int</span>)</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\tmx.RLock()</span><br><span class=\"line\">\t\t\tfmt.Printf(<span class=\"string\">\"协程%d获取了读锁\\n\"</span>, x)</span><br><span class=\"line\">\t\t\tfmt.Println(count)</span><br><span class=\"line\">\t\t\tmx.RUnlock()</span><br><span class=\"line\">\t\t\tfmt.Printf(<span class=\"string\">\"协程%d释放了读锁\\n\"</span>, x)</span><br><span class=\"line\">\t\t&#125;(i)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tcount++</span><br><span class=\"line\">\tmx.Unlock()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"主协程释放了写锁\"</span>)</span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">主协程获取了写锁</span><br><span class=\"line\">主协程释放了写锁</span><br><span class=\"line\">协程2获取了读锁</span><br><span class=\"line\">1</span><br><span class=\"line\">协程2释放了读锁</span><br><span class=\"line\">协程1获取了读锁</span><br><span class=\"line\">1</span><br><span class=\"line\">协程1释放了读锁</span><br></pre></td></tr></table></figure>\n\n<p>可以看出子协程都是等到主协程将count值加一然后释放写锁后才获取的读锁。</p>\n<h2 id=\"Cond-条件变量\"><a href=\"#Cond-条件变量\" class=\"headerlink\" title=\"Cond 条件变量\"></a>Cond 条件变量</h2><p>条件变量适用于多个协程等待某一个资源就绪的情况。条件变量依赖于互斥锁或者读写锁。</p>\n<p>使用互斥锁创建条件变量</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">   wx   := <span class=\"built_in\">new</span>(sync.Mutex)</span><br><span class=\"line\">cond := sync.NewCond(wx)</span><br></pre></td></tr></table></figure>\n\n<p>在使用的过程中有以下几个函数</p>\n<ul>\n<li>cond.Wait() 当前协程等待资源就绪，整个过程会阻塞当前协程，直到被通知资源就绪</li>\n<li>cond.Signal() 通知1个等待的协程，使其能够继续工作</li>\n<li>cond.Broadcast() 广播，通知所有的协程继续工作</li>\n</ul>\n<p>需要强调以下几点</p>\n<ol>\n<li>调用cond.wait()之前一定要先<code>cond.L.Lock()</code>因为wait函数是<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(c *Cond)</span> <span class=\"title\">Wait</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tc.checker.check()</span><br><span class=\"line\">\tt := runtime_notifyListAdd(&amp;c.notify)</span><br><span class=\"line\">\tc.L.Unlock()</span><br><span class=\"line\">\truntime_notifyListWait(&amp;c.notify, t)</span><br><span class=\"line\">\tc.L.Lock()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<p>它是先将协程加入到监听队列然后再释放锁。等到资源就绪的时候再尝试获取互斥锁。</p>\n<p>来看一个完整的例子</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tmx   := <span class=\"built_in\">new</span>(sync.Mutex)</span><br><span class=\"line\">\tcond := sync.NewCond(mx)</span><br><span class=\"line\">\twg   := sync.WaitGroup&#123;&#125;</span><br><span class=\"line\">\twg.Add(<span class=\"number\">4</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">1</span>; i &lt;= <span class=\"number\">4</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(x <span class=\"keyword\">int</span>)</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\tcond.L.Lock()</span><br><span class=\"line\">\t\t\tcond.Wait()</span><br><span class=\"line\">\t\t\tfmt.Println(x)</span><br><span class=\"line\">\t\t\ttime.Sleep(time.Second)</span><br><span class=\"line\">\t\t\tfmt.Printf(<span class=\"string\">\"%d准备释放锁\\n\"</span>, x)</span><br><span class=\"line\">\t\t\tcond.L.Unlock()</span><br><span class=\"line\">\t\t&#125;(i)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"start\"</span>)</span><br><span class=\"line\">\ttime.Sleep(time.Second * <span class=\"number\">3</span>)</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"下发第一个通知\"</span>)</span><br><span class=\"line\">\tcond.Signal()</span><br><span class=\"line\">\ttime.Sleep(time.Second * <span class=\"number\">3</span>)</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"下发第二个通知\"</span>)</span><br><span class=\"line\">\tcond.Signal()</span><br><span class=\"line\">\ttime.Sleep(time.Second * <span class=\"number\">3</span>)</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"开始广播\"</span>)</span><br><span class=\"line\">\tcond.Broadcast()</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"退出\"</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">start</span><br><span class=\"line\">下发第一个通知</span><br><span class=\"line\">1</span><br><span class=\"line\">1准备释放锁</span><br><span class=\"line\">下发第二个通知</span><br><span class=\"line\">2</span><br><span class=\"line\">2准备释放锁</span><br><span class=\"line\">开始广播</span><br><span class=\"line\">3</span><br><span class=\"line\">3准备释放锁</span><br><span class=\"line\">4</span><br><span class=\"line\">4准备释放锁</span><br><span class=\"line\">退出</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"<p>总结一下这段时间学习的有关go语言中的锁的知识。</p>","more":"<p>多线程和多协程编程能够充分利用多核处理器的优势，是系统性能提升。但是有时也会给我们意外的“惊喜”，比如下面的计数器的例子</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> count <span class=\"keyword\">int</span> = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\twg := sync.WaitGroup&#123;&#125;</span><br><span class=\"line\">\twg.Add(<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">1</span>; i &lt;= <span class=\"number\">5</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\tcount++</span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    wg.Wait()</span><br><span class=\"line\">\tfmt.Println(count)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>我们期待的结果是5，但事实上结果是不确定的。因为5个协程是并发执行的，当每个协程执行到<code>count += i</code>的时候count的值是不确定的，因此结果也是不确定的。</p>\n<p>向例子中的count变量可以成为临界资源，当多个线程或协程对临界资源进行修改的时候就必须要“上锁”。使用锁可以保证在对临界资源进行修改的这一动作上各个并行的协程是“串行修改的”。</p>\n<h2 id=\"Mutex-互斥锁\"><a href=\"#Mutex-互斥锁\" class=\"headerlink\" title=\"Mutex 互斥锁\"></a>Mutex 互斥锁</h2><p>创建一个互斥锁</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mx := <span class=\"built_in\">new</span>(sync.Mutex)</span><br></pre></td></tr></table></figure>\n\n<p>1.mx.Lock()加锁，mx.Unlock()解锁<br>2. 锁是针对资源的，不是针对协程的，哪个协程加锁，就得哪个协程解锁。<br>3. 一个协程获得锁后其他协程无论读写只能等待，直到占用锁的协程释放锁<br>4. Lock()之前Unlock()会导致panic，还未Unlock()之后Lock()会产生死锁</p>\n<p>还是上面的例子，我们稍加修改使用互斥锁</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> count <span class=\"keyword\">int</span> = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">    wg := sync.WaitGroup&#123;&#125;</span><br><span class=\"line\">\twg.Add(<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\tmx := sync.Mutex&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">1</span>; i &lt;= <span class=\"number\">5</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\tmx.Lock()</span><br><span class=\"line\">\t\t\tcount++</span><br><span class=\"line\">\t\t\tmx.Unlock()</span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">\tfmt.Println(count)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>输出的结果恒为5。</p>\n<h2 id=\"RWMutex-读写锁\"><a href=\"#RWMutex-读写锁\" class=\"headerlink\" title=\"RWMutex 读写锁\"></a>RWMutex 读写锁</h2><p>互斥锁的优势是简单，劣势是太粗暴了。假设对于一个临界资源，有的协程想写，有的只想读。如果在某一时刻只能允许一个协程读，其他的协程必须等待的话就显得效率太低了。因此读写锁出现了。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rwmx := sync.RWMutex&#123;&#125;</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>rwmx.Lock()加写锁，rwmx.Unlock()解写锁。写锁排斥任何读锁和写锁</li>\n<li>rwmx.RLock()加读锁，rwmx.RUnlock()解读锁。读锁排斥写锁但是不排斥读锁</li>\n</ol>\n<p>下面的例子，主协程上了读锁，子协程也都可以获取读锁，整个程序和没有加锁是一样的</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> count <span class=\"keyword\">int</span> = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> wg sync.WaitGroup</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> mx sync.RWMutex</span><br><span class=\"line\"></span><br><span class=\"line\">\tmx.RLock()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"主协程获取了读锁\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Add(<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">1</span>; i &lt;= <span class=\"number\">2</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(x <span class=\"keyword\">int</span>)</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\tmx.RLock()</span><br><span class=\"line\">\t\t\tfmt.Printf(<span class=\"string\">\"协程%d获取了读锁\\n\"</span>, x)</span><br><span class=\"line\">\t\t\tfmt.Println(count)</span><br><span class=\"line\">\t\t\tmx.RUnlock()</span><br><span class=\"line\">\t\t\tfmt.Printf(<span class=\"string\">\"协程%d释放了读锁\\n\"</span>, x)</span><br><span class=\"line\">\t\t&#125;(i)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">\tmx.RUnlock()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"主协程释放了读锁\"</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果为：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">主协程获取了读锁</span><br><span class=\"line\">协程2获取了读锁</span><br><span class=\"line\">0</span><br><span class=\"line\">协程2释放了读锁</span><br><span class=\"line\">协程1获取了读锁</span><br><span class=\"line\">0</span><br><span class=\"line\">协程1释放了读锁</span><br><span class=\"line\">主协程释放了读锁</span><br></pre></td></tr></table></figure>\n\n<p>下面的示例是主协程获取了写锁想修改count的值，子协程想获取读锁读取count的值</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> count <span class=\"keyword\">int</span> = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">PracticeCond5</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> wg sync.WaitGroup</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> mx sync.RWMutex</span><br><span class=\"line\"></span><br><span class=\"line\">\tmx.Lock()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"主协程获取了写锁\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Add(<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">1</span>; i &lt;= <span class=\"number\">2</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(x <span class=\"keyword\">int</span>)</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\tmx.RLock()</span><br><span class=\"line\">\t\t\tfmt.Printf(<span class=\"string\">\"协程%d获取了读锁\\n\"</span>, x)</span><br><span class=\"line\">\t\t\tfmt.Println(count)</span><br><span class=\"line\">\t\t\tmx.RUnlock()</span><br><span class=\"line\">\t\t\tfmt.Printf(<span class=\"string\">\"协程%d释放了读锁\\n\"</span>, x)</span><br><span class=\"line\">\t\t&#125;(i)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tcount++</span><br><span class=\"line\">\tmx.Unlock()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"主协程释放了写锁\"</span>)</span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">主协程获取了写锁</span><br><span class=\"line\">主协程释放了写锁</span><br><span class=\"line\">协程2获取了读锁</span><br><span class=\"line\">1</span><br><span class=\"line\">协程2释放了读锁</span><br><span class=\"line\">协程1获取了读锁</span><br><span class=\"line\">1</span><br><span class=\"line\">协程1释放了读锁</span><br></pre></td></tr></table></figure>\n\n<p>可以看出子协程都是等到主协程将count值加一然后释放写锁后才获取的读锁。</p>\n<h2 id=\"Cond-条件变量\"><a href=\"#Cond-条件变量\" class=\"headerlink\" title=\"Cond 条件变量\"></a>Cond 条件变量</h2><p>条件变量适用于多个协程等待某一个资源就绪的情况。条件变量依赖于互斥锁或者读写锁。</p>\n<p>使用互斥锁创建条件变量</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">   wx   := <span class=\"built_in\">new</span>(sync.Mutex)</span><br><span class=\"line\">cond := sync.NewCond(wx)</span><br></pre></td></tr></table></figure>\n\n<p>在使用的过程中有以下几个函数</p>\n<ul>\n<li>cond.Wait() 当前协程等待资源就绪，整个过程会阻塞当前协程，直到被通知资源就绪</li>\n<li>cond.Signal() 通知1个等待的协程，使其能够继续工作</li>\n<li>cond.Broadcast() 广播，通知所有的协程继续工作</li>\n</ul>\n<p>需要强调以下几点</p>\n<ol>\n<li>调用cond.wait()之前一定要先<code>cond.L.Lock()</code>因为wait函数是<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(c *Cond)</span> <span class=\"title\">Wait</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tc.checker.check()</span><br><span class=\"line\">\tt := runtime_notifyListAdd(&amp;c.notify)</span><br><span class=\"line\">\tc.L.Unlock()</span><br><span class=\"line\">\truntime_notifyListWait(&amp;c.notify, t)</span><br><span class=\"line\">\tc.L.Lock()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<p>它是先将协程加入到监听队列然后再释放锁。等到资源就绪的时候再尝试获取互斥锁。</p>\n<p>来看一个完整的例子</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tmx   := <span class=\"built_in\">new</span>(sync.Mutex)</span><br><span class=\"line\">\tcond := sync.NewCond(mx)</span><br><span class=\"line\">\twg   := sync.WaitGroup&#123;&#125;</span><br><span class=\"line\">\twg.Add(<span class=\"number\">4</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">1</span>; i &lt;= <span class=\"number\">4</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(x <span class=\"keyword\">int</span>)</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\tcond.L.Lock()</span><br><span class=\"line\">\t\t\tcond.Wait()</span><br><span class=\"line\">\t\t\tfmt.Println(x)</span><br><span class=\"line\">\t\t\ttime.Sleep(time.Second)</span><br><span class=\"line\">\t\t\tfmt.Printf(<span class=\"string\">\"%d准备释放锁\\n\"</span>, x)</span><br><span class=\"line\">\t\t\tcond.L.Unlock()</span><br><span class=\"line\">\t\t&#125;(i)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"start\"</span>)</span><br><span class=\"line\">\ttime.Sleep(time.Second * <span class=\"number\">3</span>)</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"下发第一个通知\"</span>)</span><br><span class=\"line\">\tcond.Signal()</span><br><span class=\"line\">\ttime.Sleep(time.Second * <span class=\"number\">3</span>)</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"下发第二个通知\"</span>)</span><br><span class=\"line\">\tcond.Signal()</span><br><span class=\"line\">\ttime.Sleep(time.Second * <span class=\"number\">3</span>)</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"开始广播\"</span>)</span><br><span class=\"line\">\tcond.Broadcast()</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"退出\"</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">start</span><br><span class=\"line\">下发第一个通知</span><br><span class=\"line\">1</span><br><span class=\"line\">1准备释放锁</span><br><span class=\"line\">下发第二个通知</span><br><span class=\"line\">2</span><br><span class=\"line\">2准备释放锁</span><br><span class=\"line\">开始广播</span><br><span class=\"line\">3</span><br><span class=\"line\">3准备释放锁</span><br><span class=\"line\">4</span><br><span class=\"line\">4准备释放锁</span><br><span class=\"line\">退出</span><br></pre></td></tr></table></figure>"},{"title":"Https","date":"2019-11-15T06:50:20.000Z","tags":["https"],"photos":[["http://sysummerblog.club/https_cover.jpeg"]],"_content":"https是在应用层(http)与传输层之间多了一个SSL(TSL)层。这个层负责先将http要发送的数据使用一个密室加密之后再交给传输层。相应的，接收方的传输层先将加密的数据交给SSL(TLS)层解密后，再发送给应用层(http)。\n<!--more-->\n## 对称加密与非对称加密\n对称加密: 通信双方的密匙是一样的，这个密匙既用于加密有用于解密。\n\n非对称加密：有一对公匙和密匙。公匙加密的内容公匙自己不能解密，必须得私匙解密。同样的，私匙加密的内容私匙自己不能解密，得用公匙解密。\n\n摘要：对一段内用使用hash函数生成一个固定长度的字符串。\n\n数字签名：对摘要使用一个密匙(公匙)加密。\n\n## Https通信过程\n\n![https的简易流程](http://sysummerblog.club/https.jpg)\n\n上图中还缺少一些步骤，比如通信双方还会对双方密码能力的信息，比如支持的SSL(TSL)版本，加密组件等进行协商约定等。但是本文只想介绍https的原理和关键步骤，所以没有画出。\n\n总的来说，https最开始使用非对称加密在客户端与服务器之间产生一个密匙。之后的数据通信就使用这个密匙进行对称加密。\n\n其中第三步是重点，服务器会给客户端发送一个证书，然后客户端根据验证这个证书的结果来判断是否执行下一步。\n\n### CA颁发的证书\nCA是一个在互联网上权威的第三方机构，我们可以简单的认为所有的网站和用户都信任他。\n\n如果一个网站要支持https协议，那么他就得向CA申请一个证书。假如证书最开始是一张白纸，申请证书的流程如下\n\n1. 网站向CA提供自身的一些信息，如果域名、公匙等，CA验证这些信息没问题后就把这些信息以明文的方式写到证书上。\n2. 生成数字签名。对第一步的明文信息使用hash函数取摘要，然后用CA的密匙(私匙)对这个摘要加密就行程了数字签名。把这个数字签名也放到证书上。\n3. 在证书上附上颁发证书机构的信息，以及证书的有效期等信息。\n\n到此证书的制作就完成了。以后任何一个客户端想和网站发起https协议的时候网站都会先把这个证书给发起端检验。\n\n### 发起端验证证书\n为什么我用发起端这个词而不用客户端呢？因为服务器或网站也可以对客户端进行https校验，过程和原理也是一样的。那么当发起端收到证书后会有以下步骤的校验。\n\n1. 颁发证书的CA机构是否合法，是否仍然有资质。\n2. 验证证书是否在有效期内。\n3. 验证数字签名。我们可以简单的认为，浏览器具有所有CA机构的公钥。浏览器用颁发该证书的CA的公匙，去解密数字签名。如果解密成功说明这个证书是该CA发的，否则证书有问题。解密之后就获得了这个证书明文部分的摘要。\n4. 客户端用同样的hash函数对证书中的明文部分取摘要，如果与第三步中的摘要相同，那么说明证书的内容是准确的，没有被篡改过 。\n5. 对明文部分的信息进行一些校验，比如域名。\n\n此时发起端已经拿到了对方的公匙。\n\n### 发起端与对方交换\"对称加密\"的密匙\n发起端随机生成一个加密字符串，然后使用对方的公匙非对称加密，发送给对方。对方收到后用私匙解密获取这个字符串。然后对方会告诉发起端，我已收到这个加密字符串，以后咱俩再通信的时候咱么都用这个字符串加密通信的内容。\n\n之后双方都是用这个加密字符串对称加密发送的内容。\n","source":"posts/https.md","raw":"---\ntitle: Https\ndate: 2019-11-15 14:50:20\ntags:\n  - https\nphotos:\n  - [\"http://sysummerblog.club/https_cover.jpeg\"]\n---\nhttps是在应用层(http)与传输层之间多了一个SSL(TSL)层。这个层负责先将http要发送的数据使用一个密室加密之后再交给传输层。相应的，接收方的传输层先将加密的数据交给SSL(TLS)层解密后，再发送给应用层(http)。\n<!--more-->\n## 对称加密与非对称加密\n对称加密: 通信双方的密匙是一样的，这个密匙既用于加密有用于解密。\n\n非对称加密：有一对公匙和密匙。公匙加密的内容公匙自己不能解密，必须得私匙解密。同样的，私匙加密的内容私匙自己不能解密，得用公匙解密。\n\n摘要：对一段内用使用hash函数生成一个固定长度的字符串。\n\n数字签名：对摘要使用一个密匙(公匙)加密。\n\n## Https通信过程\n\n![https的简易流程](http://sysummerblog.club/https.jpg)\n\n上图中还缺少一些步骤，比如通信双方还会对双方密码能力的信息，比如支持的SSL(TSL)版本，加密组件等进行协商约定等。但是本文只想介绍https的原理和关键步骤，所以没有画出。\n\n总的来说，https最开始使用非对称加密在客户端与服务器之间产生一个密匙。之后的数据通信就使用这个密匙进行对称加密。\n\n其中第三步是重点，服务器会给客户端发送一个证书，然后客户端根据验证这个证书的结果来判断是否执行下一步。\n\n### CA颁发的证书\nCA是一个在互联网上权威的第三方机构，我们可以简单的认为所有的网站和用户都信任他。\n\n如果一个网站要支持https协议，那么他就得向CA申请一个证书。假如证书最开始是一张白纸，申请证书的流程如下\n\n1. 网站向CA提供自身的一些信息，如果域名、公匙等，CA验证这些信息没问题后就把这些信息以明文的方式写到证书上。\n2. 生成数字签名。对第一步的明文信息使用hash函数取摘要，然后用CA的密匙(私匙)对这个摘要加密就行程了数字签名。把这个数字签名也放到证书上。\n3. 在证书上附上颁发证书机构的信息，以及证书的有效期等信息。\n\n到此证书的制作就完成了。以后任何一个客户端想和网站发起https协议的时候网站都会先把这个证书给发起端检验。\n\n### 发起端验证证书\n为什么我用发起端这个词而不用客户端呢？因为服务器或网站也可以对客户端进行https校验，过程和原理也是一样的。那么当发起端收到证书后会有以下步骤的校验。\n\n1. 颁发证书的CA机构是否合法，是否仍然有资质。\n2. 验证证书是否在有效期内。\n3. 验证数字签名。我们可以简单的认为，浏览器具有所有CA机构的公钥。浏览器用颁发该证书的CA的公匙，去解密数字签名。如果解密成功说明这个证书是该CA发的，否则证书有问题。解密之后就获得了这个证书明文部分的摘要。\n4. 客户端用同样的hash函数对证书中的明文部分取摘要，如果与第三步中的摘要相同，那么说明证书的内容是准确的，没有被篡改过 。\n5. 对明文部分的信息进行一些校验，比如域名。\n\n此时发起端已经拿到了对方的公匙。\n\n### 发起端与对方交换\"对称加密\"的密匙\n发起端随机生成一个加密字符串，然后使用对方的公匙非对称加密，发送给对方。对方收到后用私匙解密获取这个字符串。然后对方会告诉发起端，我已收到这个加密字符串，以后咱俩再通信的时候咱么都用这个字符串加密通信的内容。\n\n之后双方都是用这个加密字符串对称加密发送的内容。\n","updated":"2020-11-23T15:20:08.940Z","path":"posts/https.html","comments":1,"layout":"page","_id":"ckhupaq9k000j1no8wxzuhk8i","content":"<p>https是在应用层(http)与传输层之间多了一个SSL(TSL)层。这个层负责先将http要发送的数据使用一个密室加密之后再交给传输层。相应的，接收方的传输层先将加密的数据交给SSL(TLS)层解密后，再发送给应用层(http)。</p>\n<a id=\"more\"></a>\n<h2 id=\"对称加密与非对称加密\"><a href=\"#对称加密与非对称加密\" class=\"headerlink\" title=\"对称加密与非对称加密\"></a>对称加密与非对称加密</h2><p>对称加密: 通信双方的密匙是一样的，这个密匙既用于加密有用于解密。</p>\n<p>非对称加密：有一对公匙和密匙。公匙加密的内容公匙自己不能解密，必须得私匙解密。同样的，私匙加密的内容私匙自己不能解密，得用公匙解密。</p>\n<p>摘要：对一段内用使用hash函数生成一个固定长度的字符串。</p>\n<p>数字签名：对摘要使用一个密匙(公匙)加密。</p>\n<h2 id=\"Https通信过程\"><a href=\"#Https通信过程\" class=\"headerlink\" title=\"Https通信过程\"></a>Https通信过程</h2><p><img src=\"http://sysummerblog.club/https.jpg\" alt=\"https的简易流程\"></p>\n<p>上图中还缺少一些步骤，比如通信双方还会对双方密码能力的信息，比如支持的SSL(TSL)版本，加密组件等进行协商约定等。但是本文只想介绍https的原理和关键步骤，所以没有画出。</p>\n<p>总的来说，https最开始使用非对称加密在客户端与服务器之间产生一个密匙。之后的数据通信就使用这个密匙进行对称加密。</p>\n<p>其中第三步是重点，服务器会给客户端发送一个证书，然后客户端根据验证这个证书的结果来判断是否执行下一步。</p>\n<h3 id=\"CA颁发的证书\"><a href=\"#CA颁发的证书\" class=\"headerlink\" title=\"CA颁发的证书\"></a>CA颁发的证书</h3><p>CA是一个在互联网上权威的第三方机构，我们可以简单的认为所有的网站和用户都信任他。</p>\n<p>如果一个网站要支持https协议，那么他就得向CA申请一个证书。假如证书最开始是一张白纸，申请证书的流程如下</p>\n<ol>\n<li>网站向CA提供自身的一些信息，如果域名、公匙等，CA验证这些信息没问题后就把这些信息以明文的方式写到证书上。</li>\n<li>生成数字签名。对第一步的明文信息使用hash函数取摘要，然后用CA的密匙(私匙)对这个摘要加密就行程了数字签名。把这个数字签名也放到证书上。</li>\n<li>在证书上附上颁发证书机构的信息，以及证书的有效期等信息。</li>\n</ol>\n<p>到此证书的制作就完成了。以后任何一个客户端想和网站发起https协议的时候网站都会先把这个证书给发起端检验。</p>\n<h3 id=\"发起端验证证书\"><a href=\"#发起端验证证书\" class=\"headerlink\" title=\"发起端验证证书\"></a>发起端验证证书</h3><p>为什么我用发起端这个词而不用客户端呢？因为服务器或网站也可以对客户端进行https校验，过程和原理也是一样的。那么当发起端收到证书后会有以下步骤的校验。</p>\n<ol>\n<li>颁发证书的CA机构是否合法，是否仍然有资质。</li>\n<li>验证证书是否在有效期内。</li>\n<li>验证数字签名。我们可以简单的认为，浏览器具有所有CA机构的公钥。浏览器用颁发该证书的CA的公匙，去解密数字签名。如果解密成功说明这个证书是该CA发的，否则证书有问题。解密之后就获得了这个证书明文部分的摘要。</li>\n<li>客户端用同样的hash函数对证书中的明文部分取摘要，如果与第三步中的摘要相同，那么说明证书的内容是准确的，没有被篡改过 。</li>\n<li>对明文部分的信息进行一些校验，比如域名。</li>\n</ol>\n<p>此时发起端已经拿到了对方的公匙。</p>\n<h3 id=\"发起端与对方交换”对称加密”的密匙\"><a href=\"#发起端与对方交换”对称加密”的密匙\" class=\"headerlink\" title=\"发起端与对方交换”对称加密”的密匙\"></a>发起端与对方交换”对称加密”的密匙</h3><p>发起端随机生成一个加密字符串，然后使用对方的公匙非对称加密，发送给对方。对方收到后用私匙解密获取这个字符串。然后对方会告诉发起端，我已收到这个加密字符串，以后咱俩再通信的时候咱么都用这个字符串加密通信的内容。</p>\n<p>之后双方都是用这个加密字符串对称加密发送的内容。</p>\n","site":{"data":{}},"excerpt":"<p>https是在应用层(http)与传输层之间多了一个SSL(TSL)层。这个层负责先将http要发送的数据使用一个密室加密之后再交给传输层。相应的，接收方的传输层先将加密的数据交给SSL(TLS)层解密后，再发送给应用层(http)。</p>","more":"<h2 id=\"对称加密与非对称加密\"><a href=\"#对称加密与非对称加密\" class=\"headerlink\" title=\"对称加密与非对称加密\"></a>对称加密与非对称加密</h2><p>对称加密: 通信双方的密匙是一样的，这个密匙既用于加密有用于解密。</p>\n<p>非对称加密：有一对公匙和密匙。公匙加密的内容公匙自己不能解密，必须得私匙解密。同样的，私匙加密的内容私匙自己不能解密，得用公匙解密。</p>\n<p>摘要：对一段内用使用hash函数生成一个固定长度的字符串。</p>\n<p>数字签名：对摘要使用一个密匙(公匙)加密。</p>\n<h2 id=\"Https通信过程\"><a href=\"#Https通信过程\" class=\"headerlink\" title=\"Https通信过程\"></a>Https通信过程</h2><p><img src=\"http://sysummerblog.club/https.jpg\" alt=\"https的简易流程\"></p>\n<p>上图中还缺少一些步骤，比如通信双方还会对双方密码能力的信息，比如支持的SSL(TSL)版本，加密组件等进行协商约定等。但是本文只想介绍https的原理和关键步骤，所以没有画出。</p>\n<p>总的来说，https最开始使用非对称加密在客户端与服务器之间产生一个密匙。之后的数据通信就使用这个密匙进行对称加密。</p>\n<p>其中第三步是重点，服务器会给客户端发送一个证书，然后客户端根据验证这个证书的结果来判断是否执行下一步。</p>\n<h3 id=\"CA颁发的证书\"><a href=\"#CA颁发的证书\" class=\"headerlink\" title=\"CA颁发的证书\"></a>CA颁发的证书</h3><p>CA是一个在互联网上权威的第三方机构，我们可以简单的认为所有的网站和用户都信任他。</p>\n<p>如果一个网站要支持https协议，那么他就得向CA申请一个证书。假如证书最开始是一张白纸，申请证书的流程如下</p>\n<ol>\n<li>网站向CA提供自身的一些信息，如果域名、公匙等，CA验证这些信息没问题后就把这些信息以明文的方式写到证书上。</li>\n<li>生成数字签名。对第一步的明文信息使用hash函数取摘要，然后用CA的密匙(私匙)对这个摘要加密就行程了数字签名。把这个数字签名也放到证书上。</li>\n<li>在证书上附上颁发证书机构的信息，以及证书的有效期等信息。</li>\n</ol>\n<p>到此证书的制作就完成了。以后任何一个客户端想和网站发起https协议的时候网站都会先把这个证书给发起端检验。</p>\n<h3 id=\"发起端验证证书\"><a href=\"#发起端验证证书\" class=\"headerlink\" title=\"发起端验证证书\"></a>发起端验证证书</h3><p>为什么我用发起端这个词而不用客户端呢？因为服务器或网站也可以对客户端进行https校验，过程和原理也是一样的。那么当发起端收到证书后会有以下步骤的校验。</p>\n<ol>\n<li>颁发证书的CA机构是否合法，是否仍然有资质。</li>\n<li>验证证书是否在有效期内。</li>\n<li>验证数字签名。我们可以简单的认为，浏览器具有所有CA机构的公钥。浏览器用颁发该证书的CA的公匙，去解密数字签名。如果解密成功说明这个证书是该CA发的，否则证书有问题。解密之后就获得了这个证书明文部分的摘要。</li>\n<li>客户端用同样的hash函数对证书中的明文部分取摘要，如果与第三步中的摘要相同，那么说明证书的内容是准确的，没有被篡改过 。</li>\n<li>对明文部分的信息进行一些校验，比如域名。</li>\n</ol>\n<p>此时发起端已经拿到了对方的公匙。</p>\n<h3 id=\"发起端与对方交换”对称加密”的密匙\"><a href=\"#发起端与对方交换”对称加密”的密匙\" class=\"headerlink\" title=\"发起端与对方交换”对称加密”的密匙\"></a>发起端与对方交换”对称加密”的密匙</h3><p>发起端随机生成一个加密字符串，然后使用对方的公匙非对称加密，发送给对方。对方收到后用私匙解密获取这个字符串。然后对方会告诉发起端，我已收到这个加密字符串，以后咱俩再通信的时候咱么都用这个字符串加密通信的内容。</p>\n<p>之后双方都是用这个加密字符串对称加密发送的内容。</p>"},{"title":"Innodb中的锁","date":"2019-12-07T03:47:11.000Z","tags":["mysql","innodb"],"photos":[["http://sysummerblog.club/lock_cover.jpg"]],"_content":"从粒度上来分可以分为**行锁**、**页锁**、**表锁**; 从“性格”上分可以分为**乐观锁**与**悲观锁**; 从粒度上的分类应该很容易理解，不再敖述。所以是说说锁在性格上的分类。\n<!--more-->\n\n# 1. 锁的分类\n\n## 1.1 乐观锁\n用数据版本记录机制实现，是实现乐观锁的最常用的方式。每次取出一条数据的时候同时也会读取出这行数据的版本version；每次更新数据的时候也会把相应的版本version加一。如果更新的时候发现数据的版本号与第一次取出来的不一样，那么肯定是有别的事务更新了数据，就不更新；如果前后版本号一样，则更新。\n\n## 1.2 悲观锁\n\n### 1.2.1 共享锁\n简称s锁，可以允许用户并发的读取数据。共享锁之间可以兼容，共享锁与排它锁不兼容\n\n```sql\n# 行粒度的共享锁\nselect * from students where id =1 in share mode;\n\n# 表粒度的共享锁\nlock table students read;\n```\n\n### 1.2.2 排它锁\n简称x锁，排它锁之间不兼容，排它锁与共享锁也不兼容\n\n```sql\n# 行粒度的排它锁\nselect * from students where id=1 for update;\n\n# 表粒度的排他锁\nlock table students write;\n```\n**需要注意的是，如果在一个事务里面锁住了一张表，即使事务提交了表锁仍然存在必须手动调用**`unlock tables`**命令释放表锁。**\n\n# 2. innodb中的锁\n根据上面锁的分类，我们可以立马知道innodb里面有**共享行锁**、**共享表锁**、**排他行锁**、**排他表锁**。\n\n## 2.1 innodb中的行锁\n行锁有时候锁住的可能不止是一行而是一个**间隙**。按行锁锁住的范围来说可以分为三种\n\n* Record Lock 单个行记录上的锁，只锁住一行\n* Gap Lock 锁住两个边界值之间的间隙，但是不包括两个边界值\n* Next-Key Lock 锁住一个间隙和间隙的右边界\n\n\n**行锁是通过锁住索引的方式来锁住记录的。**如果在一个事务中使用`select ... for update`或者`select ... in share mode`显示的获取行锁的时候，如果查询没有命中索引，那么会锁住整张表！因此下面我们从索引的角度并且事务的隔离级别为Repeatable Read下的情况来研究行锁是怎么工作的。\n\n### 2.1.1 主键（唯一）索引\n一般在查询的条件使用了主键索引或者唯一索引的值去查询的时候只会为查找到的记录上锁。比如直接用主键去获取一条数据\n```sql\nselect * from students where id=10 for update;\n```\n如果是in查询比如\n```sql\nselect * students where id in (10,20,30) for update;\n```\n也会锁住匹配的行数据不会锁住任何的间隙\n但是如果是主键或唯一索引的范围查询那么不仅会锁住一行数据还会锁住一个间隙，比如我有一张score表\n![](http://sysummerblog.club/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_c712bf1b-119b-4309-ab36-0251fa0538ae.png)\n里面只有两条数据id分别为35和37\n\n| 事务1 | 事务2 |\n| --- | --- |\n|select * from score where id>=35 and id<37 for update; |  |\n|  | select * from score where id=35 for update;(这条sql语句被阻塞，说明id=35的数据被Record Lock锁住了) |\n| commit；(提交事务释放锁) |  |\n|  | 由于事务1提交了，相应的锁也释放了，事务2阻塞结束 |\n| begin； |  |\n| select * from score where id>=35 and id<37 for update;（与之前的sql是相同的） |  |\n|  | select * from score where id=37 for update;(这条sql语句没有被阻塞，说明id=37的数据没有被Record Lock锁住) |\n|  | insert into score(id,student_id,subject_id,score)value(36,1,1,90);(这条sql语句被阻塞了，因为id=36位于id=35和id=37之间) |\n| commit； |  |\n|  | 阻塞结束，成功插入了语句 |\n|  | commit；|\n\n结论\n\n* 如果只是使用一个或者几个主键（或者唯一索引）获取锁的时候，只会锁住记录不会锁住间隙\n* 如果是使用主键或者唯一索引范围查询，会锁住这两个值之间的间隙（Gap Lock）。锁不锁住边界值取决于查询里面有没有等于边界值\n\n### 2.1.2 普通索引\n现在score表变成了这样\n\n![](http://sysummerblog.club/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_96c4d877-3f2e-4bd2-a3cd-486e2233b1ea.png)\n\n\n\n| 事务1 | 事务2 |\n| --- | --- |\n| begin; | begin; |\n|select * from score where score=87 for update;||\n|  | insert into score(id,student_id,subject_id,score)value(7,1,7,86);（sql被阻塞） |\n| commit; |  |\n|  | 阻塞结束，成功插入了数据； |\n|  | rollback;（不保存插入的结果） |\n| begin; |  |\n| select * from score where score=87 for update;（与上一条sql一样） |  |\n|  | insert into score(id,student_id,subject_id,score)value(8,1,7,88);（sql被阻塞） |\n| commit; |  |\n|  | 阻塞结束，成功插入了数据； |\n|  | rollback；(不保存插入的结果) |\n| begin; |  |\n| select * from score where score=87 for update;（与上一条sql一样） |  |\n|  | insert into score(id,student_id,subject_id,score)value(10,2,2,89);（没有被阻塞插入成功）|\n|  | insert into score(id,student_id,subject_id,score)value(11,2,2,84);（没有被阻塞插入成功） |\n|  | select * from score where id=2 for update;(sql被阻塞) |\n| commit; |  |\n|  | 阻塞结束 |\n|  | commit; |\n\n结论\n\n* 当使用普通索引（score=87）获取锁的时候首先会在索引值的上区间加上一个Next-Key Lock锁，即锁住(84,87]这个区间，同时会为下区间加上一个Gap Lock，即锁住(84,89)这个区间\n* 使用普通索引，同时会使用Record Lock锁住主键索引。这可能也是因为所有的非主键索引的查询最后都会转化成使用主键索引查询，因为innodb的数据是在主键索引的叶子节点上。\n\n## 2.2 innodb中的表锁\ninnodb除了拥有mysql数据库级别的表锁外，还有另外两个表锁\n\n* 意向共享锁\n* 意向排它锁\n\n这两个表锁有啥作用？设想一下当我想给一张表加一个排他锁的时候，那么我得检查以下三项\n\n1. 该表有没有共享锁\n2. 该表有没有排它锁\n3. 该表的某（几）条记录有没有共享锁\n4. 该表的某（几）条记录有没有排它锁\n\n这其中1和2是比较好确定的，但是3、4怎么确定？锁是属于一个事务的不是属于一张表的，难道一条条数据的检查？显然是不行的，意向锁就应运而生。看一下意向锁与其他锁的兼容情况\n\n|  | 意向共享锁 | 意向排它锁 | 行级共享锁 | 行级排它锁 | 表级共享锁 | 表级排它锁 |\n| --- | --- | --- | --- | --- | --- | --- |\n| 意向共享锁 | 兼容 | 兼容 | 兼容 | 兼容 | 兼容 | 互斥 |\n| 意向排它锁 | 兼容 | 兼容 | 兼容 | 兼容 | 互斥 | 互斥 |\n\n意向锁与意向锁、行级锁都是兼容的。表级锁中只与共享锁兼容。好像意向锁就是为了\"抵抗\"表级锁而生。\n\n意向锁的添加是innodb来完成的，我们没有办法干预。举个例子，事务1想为数据a加了一个排它锁，那么在为这行数据加锁前会为整张表加一张**意向排它锁**，这时事务2想为数据b加一个共享锁，那么会先为表加一个意向共享锁，因为意向锁之间兼容，所以事务2不会阻塞，共享锁也会加到数据b上。这时事务3想为整个数据表加一个表级的排他锁，因为表级排它锁与意向锁相排斥所以事务3会被阻塞，直至事务1和事务2提交或者回滚。\n\n# 3. innodb中的事务与锁\n之前在2.1.1和2.2.2中讨论的内容在事务中同样适用。正式因为Gap Lock和Next-Key Lock的存在才会使innodb在Repeatable Read下能够避免幻读。\n\n## 3.1 一致性非锁定度\n也叫快照读。在一个事务中同一个查询得到的结果总是相同的。这个是因为数据读取的是数据的一个版本。这个版本可能是表中的数据（最新的版本），也可能是undo log中的该行的一个历史版本。读取的时候是不会加任何的锁。比如\n```sql\nselect * from score;\n```\n那么什么时候直接读取表的记录？又什么时候去undo log找历史版本呢？这与最后更改数据的事务id与当前活跃的事务id数组的关系决定的\n\n1. 如果最后修改数据行的事务id比所有的活跃的事务id都小，那么这行数据对当前事务是可见的\n2. 如果最后修改数据行的事务id比所有活跃的事务id大，那么是不可见的要去undo log中找合适的版本\n3. 如果等于当前事务的id，当然是可见的\n4. 如果即不大于也不小于，那么要遍历活跃事务id数组如果最后修改数据行的事务id在这里面就对当前事务不可见，如果不在说明已经commit了就可见\n\n## 3.2 一致性锁定读\n也叫当前读。当事务中执行 select...for update, insert, update, delete操作的时候读取的就是数据表当前的数据（最新的版本）并同时加上行级排它锁。\n\n# 4. 自增锁\n自增锁不是innodb独有的，很多存储引擎都可以为一张表的某一列设置成auto increment，innodb也不例外。因为平时工作中所有表的id都是auto increment的，因此想学习一下自增锁。\n\n一个参数innodb_autoinc_lock_mode控制着在向auto_increment列的表插入数据时，相关的锁行为。\n```sql\nshow  variables like 'innodb_autoinc_lock_mode'\n```\n\n这个参数有三个值\n\n* 0，这个模式下在插入语句开始的时候会得到一个表级别的锁，语句结束则释放。**注意：是语句开始的时候加锁结束的时候释放锁**\n* 1，这个是mysql默认的值，可以理解成插入的时候先锁住这个“自增值”，然后拿到这个自增值作为插入记录的id，然后再把这个自增值的值加一，最后释放锁。\n* 2，没有锁\n","source":"posts/innodb-locks.md","raw":"---\ntitle: Innodb中的锁\ndate: 2019-12-07 11:47:11\ntags:\n    - mysql\n    - innodb\nphotos:\n    - [\"http://sysummerblog.club/lock_cover.jpg\"]\n---\n从粒度上来分可以分为**行锁**、**页锁**、**表锁**; 从“性格”上分可以分为**乐观锁**与**悲观锁**; 从粒度上的分类应该很容易理解，不再敖述。所以是说说锁在性格上的分类。\n<!--more-->\n\n# 1. 锁的分类\n\n## 1.1 乐观锁\n用数据版本记录机制实现，是实现乐观锁的最常用的方式。每次取出一条数据的时候同时也会读取出这行数据的版本version；每次更新数据的时候也会把相应的版本version加一。如果更新的时候发现数据的版本号与第一次取出来的不一样，那么肯定是有别的事务更新了数据，就不更新；如果前后版本号一样，则更新。\n\n## 1.2 悲观锁\n\n### 1.2.1 共享锁\n简称s锁，可以允许用户并发的读取数据。共享锁之间可以兼容，共享锁与排它锁不兼容\n\n```sql\n# 行粒度的共享锁\nselect * from students where id =1 in share mode;\n\n# 表粒度的共享锁\nlock table students read;\n```\n\n### 1.2.2 排它锁\n简称x锁，排它锁之间不兼容，排它锁与共享锁也不兼容\n\n```sql\n# 行粒度的排它锁\nselect * from students where id=1 for update;\n\n# 表粒度的排他锁\nlock table students write;\n```\n**需要注意的是，如果在一个事务里面锁住了一张表，即使事务提交了表锁仍然存在必须手动调用**`unlock tables`**命令释放表锁。**\n\n# 2. innodb中的锁\n根据上面锁的分类，我们可以立马知道innodb里面有**共享行锁**、**共享表锁**、**排他行锁**、**排他表锁**。\n\n## 2.1 innodb中的行锁\n行锁有时候锁住的可能不止是一行而是一个**间隙**。按行锁锁住的范围来说可以分为三种\n\n* Record Lock 单个行记录上的锁，只锁住一行\n* Gap Lock 锁住两个边界值之间的间隙，但是不包括两个边界值\n* Next-Key Lock 锁住一个间隙和间隙的右边界\n\n\n**行锁是通过锁住索引的方式来锁住记录的。**如果在一个事务中使用`select ... for update`或者`select ... in share mode`显示的获取行锁的时候，如果查询没有命中索引，那么会锁住整张表！因此下面我们从索引的角度并且事务的隔离级别为Repeatable Read下的情况来研究行锁是怎么工作的。\n\n### 2.1.1 主键（唯一）索引\n一般在查询的条件使用了主键索引或者唯一索引的值去查询的时候只会为查找到的记录上锁。比如直接用主键去获取一条数据\n```sql\nselect * from students where id=10 for update;\n```\n如果是in查询比如\n```sql\nselect * students where id in (10,20,30) for update;\n```\n也会锁住匹配的行数据不会锁住任何的间隙\n但是如果是主键或唯一索引的范围查询那么不仅会锁住一行数据还会锁住一个间隙，比如我有一张score表\n![](http://sysummerblog.club/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_c712bf1b-119b-4309-ab36-0251fa0538ae.png)\n里面只有两条数据id分别为35和37\n\n| 事务1 | 事务2 |\n| --- | --- |\n|select * from score where id>=35 and id<37 for update; |  |\n|  | select * from score where id=35 for update;(这条sql语句被阻塞，说明id=35的数据被Record Lock锁住了) |\n| commit；(提交事务释放锁) |  |\n|  | 由于事务1提交了，相应的锁也释放了，事务2阻塞结束 |\n| begin； |  |\n| select * from score where id>=35 and id<37 for update;（与之前的sql是相同的） |  |\n|  | select * from score where id=37 for update;(这条sql语句没有被阻塞，说明id=37的数据没有被Record Lock锁住) |\n|  | insert into score(id,student_id,subject_id,score)value(36,1,1,90);(这条sql语句被阻塞了，因为id=36位于id=35和id=37之间) |\n| commit； |  |\n|  | 阻塞结束，成功插入了语句 |\n|  | commit；|\n\n结论\n\n* 如果只是使用一个或者几个主键（或者唯一索引）获取锁的时候，只会锁住记录不会锁住间隙\n* 如果是使用主键或者唯一索引范围查询，会锁住这两个值之间的间隙（Gap Lock）。锁不锁住边界值取决于查询里面有没有等于边界值\n\n### 2.1.2 普通索引\n现在score表变成了这样\n\n![](http://sysummerblog.club/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_96c4d877-3f2e-4bd2-a3cd-486e2233b1ea.png)\n\n\n\n| 事务1 | 事务2 |\n| --- | --- |\n| begin; | begin; |\n|select * from score where score=87 for update;||\n|  | insert into score(id,student_id,subject_id,score)value(7,1,7,86);（sql被阻塞） |\n| commit; |  |\n|  | 阻塞结束，成功插入了数据； |\n|  | rollback;（不保存插入的结果） |\n| begin; |  |\n| select * from score where score=87 for update;（与上一条sql一样） |  |\n|  | insert into score(id,student_id,subject_id,score)value(8,1,7,88);（sql被阻塞） |\n| commit; |  |\n|  | 阻塞结束，成功插入了数据； |\n|  | rollback；(不保存插入的结果) |\n| begin; |  |\n| select * from score where score=87 for update;（与上一条sql一样） |  |\n|  | insert into score(id,student_id,subject_id,score)value(10,2,2,89);（没有被阻塞插入成功）|\n|  | insert into score(id,student_id,subject_id,score)value(11,2,2,84);（没有被阻塞插入成功） |\n|  | select * from score where id=2 for update;(sql被阻塞) |\n| commit; |  |\n|  | 阻塞结束 |\n|  | commit; |\n\n结论\n\n* 当使用普通索引（score=87）获取锁的时候首先会在索引值的上区间加上一个Next-Key Lock锁，即锁住(84,87]这个区间，同时会为下区间加上一个Gap Lock，即锁住(84,89)这个区间\n* 使用普通索引，同时会使用Record Lock锁住主键索引。这可能也是因为所有的非主键索引的查询最后都会转化成使用主键索引查询，因为innodb的数据是在主键索引的叶子节点上。\n\n## 2.2 innodb中的表锁\ninnodb除了拥有mysql数据库级别的表锁外，还有另外两个表锁\n\n* 意向共享锁\n* 意向排它锁\n\n这两个表锁有啥作用？设想一下当我想给一张表加一个排他锁的时候，那么我得检查以下三项\n\n1. 该表有没有共享锁\n2. 该表有没有排它锁\n3. 该表的某（几）条记录有没有共享锁\n4. 该表的某（几）条记录有没有排它锁\n\n这其中1和2是比较好确定的，但是3、4怎么确定？锁是属于一个事务的不是属于一张表的，难道一条条数据的检查？显然是不行的，意向锁就应运而生。看一下意向锁与其他锁的兼容情况\n\n|  | 意向共享锁 | 意向排它锁 | 行级共享锁 | 行级排它锁 | 表级共享锁 | 表级排它锁 |\n| --- | --- | --- | --- | --- | --- | --- |\n| 意向共享锁 | 兼容 | 兼容 | 兼容 | 兼容 | 兼容 | 互斥 |\n| 意向排它锁 | 兼容 | 兼容 | 兼容 | 兼容 | 互斥 | 互斥 |\n\n意向锁与意向锁、行级锁都是兼容的。表级锁中只与共享锁兼容。好像意向锁就是为了\"抵抗\"表级锁而生。\n\n意向锁的添加是innodb来完成的，我们没有办法干预。举个例子，事务1想为数据a加了一个排它锁，那么在为这行数据加锁前会为整张表加一张**意向排它锁**，这时事务2想为数据b加一个共享锁，那么会先为表加一个意向共享锁，因为意向锁之间兼容，所以事务2不会阻塞，共享锁也会加到数据b上。这时事务3想为整个数据表加一个表级的排他锁，因为表级排它锁与意向锁相排斥所以事务3会被阻塞，直至事务1和事务2提交或者回滚。\n\n# 3. innodb中的事务与锁\n之前在2.1.1和2.2.2中讨论的内容在事务中同样适用。正式因为Gap Lock和Next-Key Lock的存在才会使innodb在Repeatable Read下能够避免幻读。\n\n## 3.1 一致性非锁定度\n也叫快照读。在一个事务中同一个查询得到的结果总是相同的。这个是因为数据读取的是数据的一个版本。这个版本可能是表中的数据（最新的版本），也可能是undo log中的该行的一个历史版本。读取的时候是不会加任何的锁。比如\n```sql\nselect * from score;\n```\n那么什么时候直接读取表的记录？又什么时候去undo log找历史版本呢？这与最后更改数据的事务id与当前活跃的事务id数组的关系决定的\n\n1. 如果最后修改数据行的事务id比所有的活跃的事务id都小，那么这行数据对当前事务是可见的\n2. 如果最后修改数据行的事务id比所有活跃的事务id大，那么是不可见的要去undo log中找合适的版本\n3. 如果等于当前事务的id，当然是可见的\n4. 如果即不大于也不小于，那么要遍历活跃事务id数组如果最后修改数据行的事务id在这里面就对当前事务不可见，如果不在说明已经commit了就可见\n\n## 3.2 一致性锁定读\n也叫当前读。当事务中执行 select...for update, insert, update, delete操作的时候读取的就是数据表当前的数据（最新的版本）并同时加上行级排它锁。\n\n# 4. 自增锁\n自增锁不是innodb独有的，很多存储引擎都可以为一张表的某一列设置成auto increment，innodb也不例外。因为平时工作中所有表的id都是auto increment的，因此想学习一下自增锁。\n\n一个参数innodb_autoinc_lock_mode控制着在向auto_increment列的表插入数据时，相关的锁行为。\n```sql\nshow  variables like 'innodb_autoinc_lock_mode'\n```\n\n这个参数有三个值\n\n* 0，这个模式下在插入语句开始的时候会得到一个表级别的锁，语句结束则释放。**注意：是语句开始的时候加锁结束的时候释放锁**\n* 1，这个是mysql默认的值，可以理解成插入的时候先锁住这个“自增值”，然后拿到这个自增值作为插入记录的id，然后再把这个自增值的值加一，最后释放锁。\n* 2，没有锁\n","updated":"2020-11-23T15:20:08.940Z","path":"posts/innodb-locks.html","comments":1,"layout":"page","_id":"ckhupaq9m000m1no8eyilmqd2","content":"<p>从粒度上来分可以分为<strong>行锁</strong>、<strong>页锁</strong>、<strong>表锁</strong>; 从“性格”上分可以分为<strong>乐观锁</strong>与<strong>悲观锁</strong>; 从粒度上的分类应该很容易理解，不再敖述。所以是说说锁在性格上的分类。</p>\n<a id=\"more\"></a>\n\n<h1 id=\"1-锁的分类\"><a href=\"#1-锁的分类\" class=\"headerlink\" title=\"1. 锁的分类\"></a>1. 锁的分类</h1><h2 id=\"1-1-乐观锁\"><a href=\"#1-1-乐观锁\" class=\"headerlink\" title=\"1.1 乐观锁\"></a>1.1 乐观锁</h2><p>用数据版本记录机制实现，是实现乐观锁的最常用的方式。每次取出一条数据的时候同时也会读取出这行数据的版本version；每次更新数据的时候也会把相应的版本version加一。如果更新的时候发现数据的版本号与第一次取出来的不一样，那么肯定是有别的事务更新了数据，就不更新；如果前后版本号一样，则更新。</p>\n<h2 id=\"1-2-悲观锁\"><a href=\"#1-2-悲观锁\" class=\"headerlink\" title=\"1.2 悲观锁\"></a>1.2 悲观锁</h2><h3 id=\"1-2-1-共享锁\"><a href=\"#1-2-1-共享锁\" class=\"headerlink\" title=\"1.2.1 共享锁\"></a>1.2.1 共享锁</h3><p>简称s锁，可以允许用户并发的读取数据。共享锁之间可以兼容，共享锁与排它锁不兼容</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 行粒度的共享锁</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> students <span class=\"keyword\">where</span> <span class=\"keyword\">id</span> =<span class=\"number\">1</span> <span class=\"keyword\">in</span> <span class=\"keyword\">share</span> <span class=\"keyword\">mode</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 表粒度的共享锁</span></span><br><span class=\"line\"><span class=\"keyword\">lock</span> <span class=\"keyword\">table</span> students <span class=\"keyword\">read</span>;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"1-2-2-排它锁\"><a href=\"#1-2-2-排它锁\" class=\"headerlink\" title=\"1.2.2 排它锁\"></a>1.2.2 排它锁</h3><p>简称x锁，排它锁之间不兼容，排它锁与共享锁也不兼容</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 行粒度的排它锁</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> students <span class=\"keyword\">where</span> <span class=\"keyword\">id</span>=<span class=\"number\">1</span> <span class=\"keyword\">for</span> <span class=\"keyword\">update</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 表粒度的排他锁</span></span><br><span class=\"line\"><span class=\"keyword\">lock</span> <span class=\"keyword\">table</span> students write;</span><br></pre></td></tr></table></figure>\n\n<p><strong>需要注意的是，如果在一个事务里面锁住了一张表，即使事务提交了表锁仍然存在必须手动调用</strong><code>unlock tables</code><strong>命令释放表锁。</strong></p>\n<h1 id=\"2-innodb中的锁\"><a href=\"#2-innodb中的锁\" class=\"headerlink\" title=\"2. innodb中的锁\"></a>2. innodb中的锁</h1><p>根据上面锁的分类，我们可以立马知道innodb里面有<strong>共享行锁</strong>、<strong>共享表锁</strong>、<strong>排他行锁</strong>、<strong>排他表锁</strong>。</p>\n<h2 id=\"2-1-innodb中的行锁\"><a href=\"#2-1-innodb中的行锁\" class=\"headerlink\" title=\"2.1 innodb中的行锁\"></a>2.1 innodb中的行锁</h2><p>行锁有时候锁住的可能不止是一行而是一个<strong>间隙</strong>。按行锁锁住的范围来说可以分为三种</p>\n<ul>\n<li>Record Lock 单个行记录上的锁，只锁住一行</li>\n<li>Gap Lock 锁住两个边界值之间的间隙，但是不包括两个边界值</li>\n<li>Next-Key Lock 锁住一个间隙和间隙的右边界</li>\n</ul>\n<p><strong>行锁是通过锁住索引的方式来锁住记录的。</strong>如果在一个事务中使用<code>select ... for update</code>或者<code>select ... in share mode</code>显示的获取行锁的时候，如果查询没有命中索引，那么会锁住整张表！因此下面我们从索引的角度并且事务的隔离级别为Repeatable Read下的情况来研究行锁是怎么工作的。</p>\n<h3 id=\"2-1-1-主键（唯一）索引\"><a href=\"#2-1-1-主键（唯一）索引\" class=\"headerlink\" title=\"2.1.1 主键（唯一）索引\"></a>2.1.1 主键（唯一）索引</h3><p>一般在查询的条件使用了主键索引或者唯一索引的值去查询的时候只会为查找到的记录上锁。比如直接用主键去获取一条数据</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> students <span class=\"keyword\">where</span> <span class=\"keyword\">id</span>=<span class=\"number\">10</span> <span class=\"keyword\">for</span> <span class=\"keyword\">update</span>;</span><br></pre></td></tr></table></figure>\n\n<p>如果是in查询比如</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">select</span> * students <span class=\"keyword\">where</span> <span class=\"keyword\">id</span> <span class=\"keyword\">in</span> (<span class=\"number\">10</span>,<span class=\"number\">20</span>,<span class=\"number\">30</span>) <span class=\"keyword\">for</span> <span class=\"keyword\">update</span>;</span><br></pre></td></tr></table></figure>\n\n<p>也会锁住匹配的行数据不会锁住任何的间隙<br>但是如果是主键或唯一索引的范围查询那么不仅会锁住一行数据还会锁住一个间隙，比如我有一张score表<br><img src=\"http://sysummerblog.club/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_c712bf1b-119b-4309-ab36-0251fa0538ae.png\" alt><br>里面只有两条数据id分别为35和37</p>\n<table>\n<thead>\n<tr>\n<th>事务1</th>\n<th>事务2</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>select * from score where id&gt;=35 and id&lt;37 for update;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>select * from score where id=35 for update;(这条sql语句被阻塞，说明id=35的数据被Record Lock锁住了)</td>\n</tr>\n<tr>\n<td>commit；(提交事务释放锁)</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>由于事务1提交了，相应的锁也释放了，事务2阻塞结束</td>\n</tr>\n<tr>\n<td>begin；</td>\n<td></td>\n</tr>\n<tr>\n<td>select * from score where id&gt;=35 and id&lt;37 for update;（与之前的sql是相同的）</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>select * from score where id=37 for update;(这条sql语句没有被阻塞，说明id=37的数据没有被Record Lock锁住)</td>\n</tr>\n<tr>\n<td></td>\n<td>insert into score(id,student_id,subject_id,score)value(36,1,1,90);(这条sql语句被阻塞了，因为id=36位于id=35和id=37之间)</td>\n</tr>\n<tr>\n<td>commit；</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>阻塞结束，成功插入了语句</td>\n</tr>\n<tr>\n<td></td>\n<td>commit；</td>\n</tr>\n</tbody></table>\n<p>结论</p>\n<ul>\n<li>如果只是使用一个或者几个主键（或者唯一索引）获取锁的时候，只会锁住记录不会锁住间隙</li>\n<li>如果是使用主键或者唯一索引范围查询，会锁住这两个值之间的间隙（Gap Lock）。锁不锁住边界值取决于查询里面有没有等于边界值</li>\n</ul>\n<h3 id=\"2-1-2-普通索引\"><a href=\"#2-1-2-普通索引\" class=\"headerlink\" title=\"2.1.2 普通索引\"></a>2.1.2 普通索引</h3><p>现在score表变成了这样</p>\n<p><img src=\"http://sysummerblog.club/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_96c4d877-3f2e-4bd2-a3cd-486e2233b1ea.png\" alt></p>\n<table>\n<thead>\n<tr>\n<th>事务1</th>\n<th>事务2</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>begin;</td>\n<td>begin;</td>\n</tr>\n<tr>\n<td>select * from score where score=87 for update;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>insert into score(id,student_id,subject_id,score)value(7,1,7,86);（sql被阻塞）</td>\n</tr>\n<tr>\n<td>commit;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>阻塞结束，成功插入了数据；</td>\n</tr>\n<tr>\n<td></td>\n<td>rollback;（不保存插入的结果）</td>\n</tr>\n<tr>\n<td>begin;</td>\n<td></td>\n</tr>\n<tr>\n<td>select * from score where score=87 for update;（与上一条sql一样）</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>insert into score(id,student_id,subject_id,score)value(8,1,7,88);（sql被阻塞）</td>\n</tr>\n<tr>\n<td>commit;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>阻塞结束，成功插入了数据；</td>\n</tr>\n<tr>\n<td></td>\n<td>rollback；(不保存插入的结果)</td>\n</tr>\n<tr>\n<td>begin;</td>\n<td></td>\n</tr>\n<tr>\n<td>select * from score where score=87 for update;（与上一条sql一样）</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>insert into score(id,student_id,subject_id,score)value(10,2,2,89);（没有被阻塞插入成功）</td>\n</tr>\n<tr>\n<td></td>\n<td>insert into score(id,student_id,subject_id,score)value(11,2,2,84);（没有被阻塞插入成功）</td>\n</tr>\n<tr>\n<td></td>\n<td>select * from score where id=2 for update;(sql被阻塞)</td>\n</tr>\n<tr>\n<td>commit;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>阻塞结束</td>\n</tr>\n<tr>\n<td></td>\n<td>commit;</td>\n</tr>\n</tbody></table>\n<p>结论</p>\n<ul>\n<li>当使用普通索引（score=87）获取锁的时候首先会在索引值的上区间加上一个Next-Key Lock锁，即锁住(84,87]这个区间，同时会为下区间加上一个Gap Lock，即锁住(84,89)这个区间</li>\n<li>使用普通索引，同时会使用Record Lock锁住主键索引。这可能也是因为所有的非主键索引的查询最后都会转化成使用主键索引查询，因为innodb的数据是在主键索引的叶子节点上。</li>\n</ul>\n<h2 id=\"2-2-innodb中的表锁\"><a href=\"#2-2-innodb中的表锁\" class=\"headerlink\" title=\"2.2 innodb中的表锁\"></a>2.2 innodb中的表锁</h2><p>innodb除了拥有mysql数据库级别的表锁外，还有另外两个表锁</p>\n<ul>\n<li>意向共享锁</li>\n<li>意向排它锁</li>\n</ul>\n<p>这两个表锁有啥作用？设想一下当我想给一张表加一个排他锁的时候，那么我得检查以下三项</p>\n<ol>\n<li>该表有没有共享锁</li>\n<li>该表有没有排它锁</li>\n<li>该表的某（几）条记录有没有共享锁</li>\n<li>该表的某（几）条记录有没有排它锁</li>\n</ol>\n<p>这其中1和2是比较好确定的，但是3、4怎么确定？锁是属于一个事务的不是属于一张表的，难道一条条数据的检查？显然是不行的，意向锁就应运而生。看一下意向锁与其他锁的兼容情况</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>意向共享锁</th>\n<th>意向排它锁</th>\n<th>行级共享锁</th>\n<th>行级排它锁</th>\n<th>表级共享锁</th>\n<th>表级排它锁</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>意向共享锁</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>互斥</td>\n</tr>\n<tr>\n<td>意向排它锁</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>互斥</td>\n<td>互斥</td>\n</tr>\n</tbody></table>\n<p>意向锁与意向锁、行级锁都是兼容的。表级锁中只与共享锁兼容。好像意向锁就是为了”抵抗”表级锁而生。</p>\n<p>意向锁的添加是innodb来完成的，我们没有办法干预。举个例子，事务1想为数据a加了一个排它锁，那么在为这行数据加锁前会为整张表加一张<strong>意向排它锁</strong>，这时事务2想为数据b加一个共享锁，那么会先为表加一个意向共享锁，因为意向锁之间兼容，所以事务2不会阻塞，共享锁也会加到数据b上。这时事务3想为整个数据表加一个表级的排他锁，因为表级排它锁与意向锁相排斥所以事务3会被阻塞，直至事务1和事务2提交或者回滚。</p>\n<h1 id=\"3-innodb中的事务与锁\"><a href=\"#3-innodb中的事务与锁\" class=\"headerlink\" title=\"3. innodb中的事务与锁\"></a>3. innodb中的事务与锁</h1><p>之前在2.1.1和2.2.2中讨论的内容在事务中同样适用。正式因为Gap Lock和Next-Key Lock的存在才会使innodb在Repeatable Read下能够避免幻读。</p>\n<h2 id=\"3-1-一致性非锁定度\"><a href=\"#3-1-一致性非锁定度\" class=\"headerlink\" title=\"3.1 一致性非锁定度\"></a>3.1 一致性非锁定度</h2><p>也叫快照读。在一个事务中同一个查询得到的结果总是相同的。这个是因为数据读取的是数据的一个版本。这个版本可能是表中的数据（最新的版本），也可能是undo log中的该行的一个历史版本。读取的时候是不会加任何的锁。比如</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> score;</span><br></pre></td></tr></table></figure>\n\n<p>那么什么时候直接读取表的记录？又什么时候去undo log找历史版本呢？这与最后更改数据的事务id与当前活跃的事务id数组的关系决定的</p>\n<ol>\n<li>如果最后修改数据行的事务id比所有的活跃的事务id都小，那么这行数据对当前事务是可见的</li>\n<li>如果最后修改数据行的事务id比所有活跃的事务id大，那么是不可见的要去undo log中找合适的版本</li>\n<li>如果等于当前事务的id，当然是可见的</li>\n<li>如果即不大于也不小于，那么要遍历活跃事务id数组如果最后修改数据行的事务id在这里面就对当前事务不可见，如果不在说明已经commit了就可见</li>\n</ol>\n<h2 id=\"3-2-一致性锁定读\"><a href=\"#3-2-一致性锁定读\" class=\"headerlink\" title=\"3.2 一致性锁定读\"></a>3.2 一致性锁定读</h2><p>也叫当前读。当事务中执行 select…for update, insert, update, delete操作的时候读取的就是数据表当前的数据（最新的版本）并同时加上行级排它锁。</p>\n<h1 id=\"4-自增锁\"><a href=\"#4-自增锁\" class=\"headerlink\" title=\"4. 自增锁\"></a>4. 自增锁</h1><p>自增锁不是innodb独有的，很多存储引擎都可以为一张表的某一列设置成auto increment，innodb也不例外。因为平时工作中所有表的id都是auto increment的，因此想学习一下自增锁。</p>\n<p>一个参数innodb_autoinc_lock_mode控制着在向auto_increment列的表插入数据时，相关的锁行为。</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span>  <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'innodb_autoinc_lock_mode'</span></span><br></pre></td></tr></table></figure>\n\n<p>这个参数有三个值</p>\n<ul>\n<li>0，这个模式下在插入语句开始的时候会得到一个表级别的锁，语句结束则释放。<strong>注意：是语句开始的时候加锁结束的时候释放锁</strong></li>\n<li>1，这个是mysql默认的值，可以理解成插入的时候先锁住这个“自增值”，然后拿到这个自增值作为插入记录的id，然后再把这个自增值的值加一，最后释放锁。</li>\n<li>2，没有锁</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>从粒度上来分可以分为<strong>行锁</strong>、<strong>页锁</strong>、<strong>表锁</strong>; 从“性格”上分可以分为<strong>乐观锁</strong>与<strong>悲观锁</strong>; 从粒度上的分类应该很容易理解，不再敖述。所以是说说锁在性格上的分类。</p>","more":"<h1 id=\"1-锁的分类\"><a href=\"#1-锁的分类\" class=\"headerlink\" title=\"1. 锁的分类\"></a>1. 锁的分类</h1><h2 id=\"1-1-乐观锁\"><a href=\"#1-1-乐观锁\" class=\"headerlink\" title=\"1.1 乐观锁\"></a>1.1 乐观锁</h2><p>用数据版本记录机制实现，是实现乐观锁的最常用的方式。每次取出一条数据的时候同时也会读取出这行数据的版本version；每次更新数据的时候也会把相应的版本version加一。如果更新的时候发现数据的版本号与第一次取出来的不一样，那么肯定是有别的事务更新了数据，就不更新；如果前后版本号一样，则更新。</p>\n<h2 id=\"1-2-悲观锁\"><a href=\"#1-2-悲观锁\" class=\"headerlink\" title=\"1.2 悲观锁\"></a>1.2 悲观锁</h2><h3 id=\"1-2-1-共享锁\"><a href=\"#1-2-1-共享锁\" class=\"headerlink\" title=\"1.2.1 共享锁\"></a>1.2.1 共享锁</h3><p>简称s锁，可以允许用户并发的读取数据。共享锁之间可以兼容，共享锁与排它锁不兼容</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 行粒度的共享锁</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> students <span class=\"keyword\">where</span> <span class=\"keyword\">id</span> =<span class=\"number\">1</span> <span class=\"keyword\">in</span> <span class=\"keyword\">share</span> <span class=\"keyword\">mode</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 表粒度的共享锁</span></span><br><span class=\"line\"><span class=\"keyword\">lock</span> <span class=\"keyword\">table</span> students <span class=\"keyword\">read</span>;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"1-2-2-排它锁\"><a href=\"#1-2-2-排它锁\" class=\"headerlink\" title=\"1.2.2 排它锁\"></a>1.2.2 排它锁</h3><p>简称x锁，排它锁之间不兼容，排它锁与共享锁也不兼容</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 行粒度的排它锁</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> students <span class=\"keyword\">where</span> <span class=\"keyword\">id</span>=<span class=\"number\">1</span> <span class=\"keyword\">for</span> <span class=\"keyword\">update</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 表粒度的排他锁</span></span><br><span class=\"line\"><span class=\"keyword\">lock</span> <span class=\"keyword\">table</span> students write;</span><br></pre></td></tr></table></figure>\n\n<p><strong>需要注意的是，如果在一个事务里面锁住了一张表，即使事务提交了表锁仍然存在必须手动调用</strong><code>unlock tables</code><strong>命令释放表锁。</strong></p>\n<h1 id=\"2-innodb中的锁\"><a href=\"#2-innodb中的锁\" class=\"headerlink\" title=\"2. innodb中的锁\"></a>2. innodb中的锁</h1><p>根据上面锁的分类，我们可以立马知道innodb里面有<strong>共享行锁</strong>、<strong>共享表锁</strong>、<strong>排他行锁</strong>、<strong>排他表锁</strong>。</p>\n<h2 id=\"2-1-innodb中的行锁\"><a href=\"#2-1-innodb中的行锁\" class=\"headerlink\" title=\"2.1 innodb中的行锁\"></a>2.1 innodb中的行锁</h2><p>行锁有时候锁住的可能不止是一行而是一个<strong>间隙</strong>。按行锁锁住的范围来说可以分为三种</p>\n<ul>\n<li>Record Lock 单个行记录上的锁，只锁住一行</li>\n<li>Gap Lock 锁住两个边界值之间的间隙，但是不包括两个边界值</li>\n<li>Next-Key Lock 锁住一个间隙和间隙的右边界</li>\n</ul>\n<p><strong>行锁是通过锁住索引的方式来锁住记录的。</strong>如果在一个事务中使用<code>select ... for update</code>或者<code>select ... in share mode</code>显示的获取行锁的时候，如果查询没有命中索引，那么会锁住整张表！因此下面我们从索引的角度并且事务的隔离级别为Repeatable Read下的情况来研究行锁是怎么工作的。</p>\n<h3 id=\"2-1-1-主键（唯一）索引\"><a href=\"#2-1-1-主键（唯一）索引\" class=\"headerlink\" title=\"2.1.1 主键（唯一）索引\"></a>2.1.1 主键（唯一）索引</h3><p>一般在查询的条件使用了主键索引或者唯一索引的值去查询的时候只会为查找到的记录上锁。比如直接用主键去获取一条数据</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> students <span class=\"keyword\">where</span> <span class=\"keyword\">id</span>=<span class=\"number\">10</span> <span class=\"keyword\">for</span> <span class=\"keyword\">update</span>;</span><br></pre></td></tr></table></figure>\n\n<p>如果是in查询比如</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">select</span> * students <span class=\"keyword\">where</span> <span class=\"keyword\">id</span> <span class=\"keyword\">in</span> (<span class=\"number\">10</span>,<span class=\"number\">20</span>,<span class=\"number\">30</span>) <span class=\"keyword\">for</span> <span class=\"keyword\">update</span>;</span><br></pre></td></tr></table></figure>\n\n<p>也会锁住匹配的行数据不会锁住任何的间隙<br>但是如果是主键或唯一索引的范围查询那么不仅会锁住一行数据还会锁住一个间隙，比如我有一张score表<br><img src=\"http://sysummerblog.club/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_c712bf1b-119b-4309-ab36-0251fa0538ae.png\" alt><br>里面只有两条数据id分别为35和37</p>\n<table>\n<thead>\n<tr>\n<th>事务1</th>\n<th>事务2</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>select * from score where id&gt;=35 and id&lt;37 for update;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>select * from score where id=35 for update;(这条sql语句被阻塞，说明id=35的数据被Record Lock锁住了)</td>\n</tr>\n<tr>\n<td>commit；(提交事务释放锁)</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>由于事务1提交了，相应的锁也释放了，事务2阻塞结束</td>\n</tr>\n<tr>\n<td>begin；</td>\n<td></td>\n</tr>\n<tr>\n<td>select * from score where id&gt;=35 and id&lt;37 for update;（与之前的sql是相同的）</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>select * from score where id=37 for update;(这条sql语句没有被阻塞，说明id=37的数据没有被Record Lock锁住)</td>\n</tr>\n<tr>\n<td></td>\n<td>insert into score(id,student_id,subject_id,score)value(36,1,1,90);(这条sql语句被阻塞了，因为id=36位于id=35和id=37之间)</td>\n</tr>\n<tr>\n<td>commit；</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>阻塞结束，成功插入了语句</td>\n</tr>\n<tr>\n<td></td>\n<td>commit；</td>\n</tr>\n</tbody></table>\n<p>结论</p>\n<ul>\n<li>如果只是使用一个或者几个主键（或者唯一索引）获取锁的时候，只会锁住记录不会锁住间隙</li>\n<li>如果是使用主键或者唯一索引范围查询，会锁住这两个值之间的间隙（Gap Lock）。锁不锁住边界值取决于查询里面有没有等于边界值</li>\n</ul>\n<h3 id=\"2-1-2-普通索引\"><a href=\"#2-1-2-普通索引\" class=\"headerlink\" title=\"2.1.2 普通索引\"></a>2.1.2 普通索引</h3><p>现在score表变成了这样</p>\n<p><img src=\"http://sysummerblog.club/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_96c4d877-3f2e-4bd2-a3cd-486e2233b1ea.png\" alt></p>\n<table>\n<thead>\n<tr>\n<th>事务1</th>\n<th>事务2</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>begin;</td>\n<td>begin;</td>\n</tr>\n<tr>\n<td>select * from score where score=87 for update;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>insert into score(id,student_id,subject_id,score)value(7,1,7,86);（sql被阻塞）</td>\n</tr>\n<tr>\n<td>commit;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>阻塞结束，成功插入了数据；</td>\n</tr>\n<tr>\n<td></td>\n<td>rollback;（不保存插入的结果）</td>\n</tr>\n<tr>\n<td>begin;</td>\n<td></td>\n</tr>\n<tr>\n<td>select * from score where score=87 for update;（与上一条sql一样）</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>insert into score(id,student_id,subject_id,score)value(8,1,7,88);（sql被阻塞）</td>\n</tr>\n<tr>\n<td>commit;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>阻塞结束，成功插入了数据；</td>\n</tr>\n<tr>\n<td></td>\n<td>rollback；(不保存插入的结果)</td>\n</tr>\n<tr>\n<td>begin;</td>\n<td></td>\n</tr>\n<tr>\n<td>select * from score where score=87 for update;（与上一条sql一样）</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>insert into score(id,student_id,subject_id,score)value(10,2,2,89);（没有被阻塞插入成功）</td>\n</tr>\n<tr>\n<td></td>\n<td>insert into score(id,student_id,subject_id,score)value(11,2,2,84);（没有被阻塞插入成功）</td>\n</tr>\n<tr>\n<td></td>\n<td>select * from score where id=2 for update;(sql被阻塞)</td>\n</tr>\n<tr>\n<td>commit;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>阻塞结束</td>\n</tr>\n<tr>\n<td></td>\n<td>commit;</td>\n</tr>\n</tbody></table>\n<p>结论</p>\n<ul>\n<li>当使用普通索引（score=87）获取锁的时候首先会在索引值的上区间加上一个Next-Key Lock锁，即锁住(84,87]这个区间，同时会为下区间加上一个Gap Lock，即锁住(84,89)这个区间</li>\n<li>使用普通索引，同时会使用Record Lock锁住主键索引。这可能也是因为所有的非主键索引的查询最后都会转化成使用主键索引查询，因为innodb的数据是在主键索引的叶子节点上。</li>\n</ul>\n<h2 id=\"2-2-innodb中的表锁\"><a href=\"#2-2-innodb中的表锁\" class=\"headerlink\" title=\"2.2 innodb中的表锁\"></a>2.2 innodb中的表锁</h2><p>innodb除了拥有mysql数据库级别的表锁外，还有另外两个表锁</p>\n<ul>\n<li>意向共享锁</li>\n<li>意向排它锁</li>\n</ul>\n<p>这两个表锁有啥作用？设想一下当我想给一张表加一个排他锁的时候，那么我得检查以下三项</p>\n<ol>\n<li>该表有没有共享锁</li>\n<li>该表有没有排它锁</li>\n<li>该表的某（几）条记录有没有共享锁</li>\n<li>该表的某（几）条记录有没有排它锁</li>\n</ol>\n<p>这其中1和2是比较好确定的，但是3、4怎么确定？锁是属于一个事务的不是属于一张表的，难道一条条数据的检查？显然是不行的，意向锁就应运而生。看一下意向锁与其他锁的兼容情况</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>意向共享锁</th>\n<th>意向排它锁</th>\n<th>行级共享锁</th>\n<th>行级排它锁</th>\n<th>表级共享锁</th>\n<th>表级排它锁</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>意向共享锁</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>互斥</td>\n</tr>\n<tr>\n<td>意向排它锁</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>互斥</td>\n<td>互斥</td>\n</tr>\n</tbody></table>\n<p>意向锁与意向锁、行级锁都是兼容的。表级锁中只与共享锁兼容。好像意向锁就是为了”抵抗”表级锁而生。</p>\n<p>意向锁的添加是innodb来完成的，我们没有办法干预。举个例子，事务1想为数据a加了一个排它锁，那么在为这行数据加锁前会为整张表加一张<strong>意向排它锁</strong>，这时事务2想为数据b加一个共享锁，那么会先为表加一个意向共享锁，因为意向锁之间兼容，所以事务2不会阻塞，共享锁也会加到数据b上。这时事务3想为整个数据表加一个表级的排他锁，因为表级排它锁与意向锁相排斥所以事务3会被阻塞，直至事务1和事务2提交或者回滚。</p>\n<h1 id=\"3-innodb中的事务与锁\"><a href=\"#3-innodb中的事务与锁\" class=\"headerlink\" title=\"3. innodb中的事务与锁\"></a>3. innodb中的事务与锁</h1><p>之前在2.1.1和2.2.2中讨论的内容在事务中同样适用。正式因为Gap Lock和Next-Key Lock的存在才会使innodb在Repeatable Read下能够避免幻读。</p>\n<h2 id=\"3-1-一致性非锁定度\"><a href=\"#3-1-一致性非锁定度\" class=\"headerlink\" title=\"3.1 一致性非锁定度\"></a>3.1 一致性非锁定度</h2><p>也叫快照读。在一个事务中同一个查询得到的结果总是相同的。这个是因为数据读取的是数据的一个版本。这个版本可能是表中的数据（最新的版本），也可能是undo log中的该行的一个历史版本。读取的时候是不会加任何的锁。比如</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> score;</span><br></pre></td></tr></table></figure>\n\n<p>那么什么时候直接读取表的记录？又什么时候去undo log找历史版本呢？这与最后更改数据的事务id与当前活跃的事务id数组的关系决定的</p>\n<ol>\n<li>如果最后修改数据行的事务id比所有的活跃的事务id都小，那么这行数据对当前事务是可见的</li>\n<li>如果最后修改数据行的事务id比所有活跃的事务id大，那么是不可见的要去undo log中找合适的版本</li>\n<li>如果等于当前事务的id，当然是可见的</li>\n<li>如果即不大于也不小于，那么要遍历活跃事务id数组如果最后修改数据行的事务id在这里面就对当前事务不可见，如果不在说明已经commit了就可见</li>\n</ol>\n<h2 id=\"3-2-一致性锁定读\"><a href=\"#3-2-一致性锁定读\" class=\"headerlink\" title=\"3.2 一致性锁定读\"></a>3.2 一致性锁定读</h2><p>也叫当前读。当事务中执行 select…for update, insert, update, delete操作的时候读取的就是数据表当前的数据（最新的版本）并同时加上行级排它锁。</p>\n<h1 id=\"4-自增锁\"><a href=\"#4-自增锁\" class=\"headerlink\" title=\"4. 自增锁\"></a>4. 自增锁</h1><p>自增锁不是innodb独有的，很多存储引擎都可以为一张表的某一列设置成auto increment，innodb也不例外。因为平时工作中所有表的id都是auto increment的，因此想学习一下自增锁。</p>\n<p>一个参数innodb_autoinc_lock_mode控制着在向auto_increment列的表插入数据时，相关的锁行为。</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span>  <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'innodb_autoinc_lock_mode'</span></span><br></pre></td></tr></table></figure>\n\n<p>这个参数有三个值</p>\n<ul>\n<li>0，这个模式下在插入语句开始的时候会得到一个表级别的锁，语句结束则释放。<strong>注意：是语句开始的时候加锁结束的时候释放锁</strong></li>\n<li>1，这个是mysql默认的值，可以理解成插入的时候先锁住这个“自增值”，然后拿到这个自增值作为插入记录的id，然后再把这个自增值的值加一，最后释放锁。</li>\n<li>2，没有锁</li>\n</ul>"},{"title":"Innodb存储引擎","date":"2019-12-03T04:20:14.000Z","tags":["mysql","innodb"],"photos":[["http://sysummerblog.club/innodb_cover.jpeg"]],"_content":"innodb存储引擎是现在mysql的默认存储引擎，其特点是行锁设计、支持MVCC、支持外键、提供一致性非锁定读、同时被用来最有效的利用以及使用内存和CPU。\n<!--more-->\n## 缓冲池\ninnodb维护了一个内存缓冲池名叫innodb_pool_buffer。当我们读一条数据的时候，先去缓冲池里面找存放改数据的页是不是在这个缓冲池中，如果在直接读取，如果不在那么先从硬盘上读取该页并放到缓冲池中供后续读取使用。写操作也是一样的，先写入缓冲池中的数据页，此时该页也叫脏页，然后再以一定的策略刷新到磁盘。缓冲池中存在的数据大致如下\n![](http://sysummerblog.club/1.jpg)\n\n缓冲池的大小非常重要。说的极端一点，如果我们可以把数据库的页全部缓存在缓冲池中，那么数据库中的数据就相当于缓存了。可以通过以下命令查看缓冲池的大小\n```sql\nshow variables like 'innodb_buffer_pool_size'\n```\n现在innodb也支持同时启动多个缓冲池，数据页会根据哈希值被分配到不同的实例中去。可以通过以下命令查看缓冲池实例的个数\n```sql\nshow variables like 'innodb_buffer_pool_instance'\n```\n\n缓冲池是一片连续的内存空间，innodb为每一个缓存页都创建了一些所谓的控制信息，这些信息包括该页所属的表空间编号、页号、页在缓冲池中的地址、一些锁信息以及LSN信息等。\n\n每个缓存页的大小是一样的为16k，这个值是可以更改的。每个缓存页对应的控制信息占用的内存大小是相同的，我们就姑且把这些控制信息占用的一块内存称为一个控制块。控制块和缓存页是一对一的，都在缓冲池中。他们之间的关系大致是这样的\n![](http://sysummerblog.club/2.jpg)\n\n### LRU List、Free List、Flush List\n这三个list结构上很相似，都是双向链表，除了一些元信息之外还有就是指向控制块的指针。以free list为例（这个图是我能找到的最直观的图）\n![](http://sysummerblog.club/3.jpg)\n\n这三个列表虽然结构类似，但是功能却大不相同。\n\n**LRU List** 是用来管理innodb的缓冲池的。缓冲池的目的就是尽量的把热点数据缓存在内存中，进而保证数据库的性能。LRU list的职责就是尽量把热点的数据页留在内存中，把非热点的数据页从内存中移除。LRU List的前端是最频繁使用的数据页，尾端是最少使用的。当一个数据页从硬盘加载到内存中的时候在LRU List的3/8处会更新一些原信息并将指针指向一个新的**控制块**，而这控制块又指向一个16kb大小的数据页，这个数据页里面存放的就是刚刚从硬盘里面读取出来的数据。这个数据页会在innodb_old_blocks_time之后移动到LRU List的头部。之所以这么做是因为防止类似于扫描全表的操作污染了LRU List。当LRU List的一个节点(比如该节点叫node_lru)将要被移除的时候，Free List中会增加一个节点(比如该节点叫node_free)，node_free指向的控制块其实就是之前node_lru指向的控制块该控制块中所指向的数据页被LRU List认为是非热点数据了，这块地方要“腾出来存放别的热点数据了”\n\n**Free List** 是用来管理空闲的数据页的。当数据库刚刚启动的时候肯定还没有任何的数据页加载到缓冲池中，这个时候Free List的节点的数目应该和**控制块的**的数目相等的。慢慢的当有数据页缓存到缓冲池中的时候Free List这个双向链表的节点数会慢慢变少。当一个从硬盘读取的数据页想要进入缓冲池中的时候是通过Free List来完成的。\n\n**Flush List** 用来管理脏的数据页。写操作和读操作一样，也是先把数据页加载到内存中然后修改内存中的数据。一旦一个数据页变成了脏页那么Flush List这个链表里面就会有一个结点指向这个数据页所对应的**控制块**，意为这个数据页是脏的需要刷新回磁盘。**同时这个数据页也一定会出现在LRU列表中**，如果这个数据页将要从LRU列表中移除时那么肯定会把这个数据页同步到磁盘，这个数据页在Flush列表中的相应的节点也会被删除，这个是我们后面要将的checkpoint的技术。\n\n需要强调的是当数据库实例启动的时候控制块和缓存页就已经初始化好了。就像酒店里的房间，你住不住人房间都在那里。没有人住房间就是空的，同一个房间在不同的时间段内可能是不同的人在居住。而这三个list中的节点是会增加会减少会改变的。\n\n### checkpoint\n把缓冲池中的脏页刷新回磁盘是一件很重要的事情。checkpoint所做的就是这个重要的事情。innodb中的checkpoint如下\n\nSharp Checkpoint 数据库关闭的时候把所有的脏页刷新回磁盘\nFUZZY Checkpoint\n\n* Master Thread Checkpoint 主线程以一个固定的时间间隔异步的刷新脏页回磁盘\n* FLUSH_LRU_LIST Checkpoint 当LRU列表要移除数据页时并且这个数据页还标记在在Flush列表中的时候要强行的刷新这个数据页回磁盘\n* Async/Sync Flush Checkpoint 重做日志文件将要被覆盖的时候\n* Dirty Page too much Checkpoint 脏页的数量太多\n\n## 关键特性\n\n### 插入缓冲\n一般innodb的数据表都会有一个自增的id。因此每次插入一条数据的时候很容易找到待插入的位置，因为数据是存在主键索引的叶子节点上的。但是这有可能导致非主键索引插入的离散性。插入缓冲其实就是解决这个问题的。innodb对于非聚集索引的插入或者更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在则直接插入；若不在先放到一个插入缓冲中，然后再以一定的频率和情况进行插入缓冲和辅助索引页子节点的合并操作，这时通常能将多个插入合并到一个合并操作中，大大的提高了效率。\n### 两次写\n缓冲池中有2MB的内存叫做doublewrite buffer。同样硬盘上也有2M的“二次写”空间。第一次写是将内存的doublewrite buffer里的数据写到硬盘上的“二次写”空间，这个过程是顺序写，开销不大。第二次写是将doublewrite buffer里的数据写到表空间中，这个过程是离散的。如果在第二次写的过程中宕机，那么在“二次写”的硬盘空间中还备份了副本，可以用这个副本恢复数据页。\n![](http://sysummerblog.club/4.jpg)\n### 自适应哈希索引\nInnodb存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引可以带来速度的提升，则建立哈希索引，成为自适应哈希索引。貌似我们对这个特性什么都做不了，是innodb自己完成的。\n### 异步IO\n脏页刷新回磁盘的操作是异步的，这样不会阻塞用户线程。\n### 刷新邻接页\n如果innodb决定刷新一个脏页回磁盘的时候，会检测该页所在的区的所有页需不需要一起刷新。\n","source":"posts/innodb.md","raw":"---\ntitle: Innodb存储引擎\ndate: 2019-12-03 12:20:14\ntags:\n    - mysql\n    - innodb\nphotos:\n    - [\"http://sysummerblog.club/innodb_cover.jpeg\"]\n---\ninnodb存储引擎是现在mysql的默认存储引擎，其特点是行锁设计、支持MVCC、支持外键、提供一致性非锁定读、同时被用来最有效的利用以及使用内存和CPU。\n<!--more-->\n## 缓冲池\ninnodb维护了一个内存缓冲池名叫innodb_pool_buffer。当我们读一条数据的时候，先去缓冲池里面找存放改数据的页是不是在这个缓冲池中，如果在直接读取，如果不在那么先从硬盘上读取该页并放到缓冲池中供后续读取使用。写操作也是一样的，先写入缓冲池中的数据页，此时该页也叫脏页，然后再以一定的策略刷新到磁盘。缓冲池中存在的数据大致如下\n![](http://sysummerblog.club/1.jpg)\n\n缓冲池的大小非常重要。说的极端一点，如果我们可以把数据库的页全部缓存在缓冲池中，那么数据库中的数据就相当于缓存了。可以通过以下命令查看缓冲池的大小\n```sql\nshow variables like 'innodb_buffer_pool_size'\n```\n现在innodb也支持同时启动多个缓冲池，数据页会根据哈希值被分配到不同的实例中去。可以通过以下命令查看缓冲池实例的个数\n```sql\nshow variables like 'innodb_buffer_pool_instance'\n```\n\n缓冲池是一片连续的内存空间，innodb为每一个缓存页都创建了一些所谓的控制信息，这些信息包括该页所属的表空间编号、页号、页在缓冲池中的地址、一些锁信息以及LSN信息等。\n\n每个缓存页的大小是一样的为16k，这个值是可以更改的。每个缓存页对应的控制信息占用的内存大小是相同的，我们就姑且把这些控制信息占用的一块内存称为一个控制块。控制块和缓存页是一对一的，都在缓冲池中。他们之间的关系大致是这样的\n![](http://sysummerblog.club/2.jpg)\n\n### LRU List、Free List、Flush List\n这三个list结构上很相似，都是双向链表，除了一些元信息之外还有就是指向控制块的指针。以free list为例（这个图是我能找到的最直观的图）\n![](http://sysummerblog.club/3.jpg)\n\n这三个列表虽然结构类似，但是功能却大不相同。\n\n**LRU List** 是用来管理innodb的缓冲池的。缓冲池的目的就是尽量的把热点数据缓存在内存中，进而保证数据库的性能。LRU list的职责就是尽量把热点的数据页留在内存中，把非热点的数据页从内存中移除。LRU List的前端是最频繁使用的数据页，尾端是最少使用的。当一个数据页从硬盘加载到内存中的时候在LRU List的3/8处会更新一些原信息并将指针指向一个新的**控制块**，而这控制块又指向一个16kb大小的数据页，这个数据页里面存放的就是刚刚从硬盘里面读取出来的数据。这个数据页会在innodb_old_blocks_time之后移动到LRU List的头部。之所以这么做是因为防止类似于扫描全表的操作污染了LRU List。当LRU List的一个节点(比如该节点叫node_lru)将要被移除的时候，Free List中会增加一个节点(比如该节点叫node_free)，node_free指向的控制块其实就是之前node_lru指向的控制块该控制块中所指向的数据页被LRU List认为是非热点数据了，这块地方要“腾出来存放别的热点数据了”\n\n**Free List** 是用来管理空闲的数据页的。当数据库刚刚启动的时候肯定还没有任何的数据页加载到缓冲池中，这个时候Free List的节点的数目应该和**控制块的**的数目相等的。慢慢的当有数据页缓存到缓冲池中的时候Free List这个双向链表的节点数会慢慢变少。当一个从硬盘读取的数据页想要进入缓冲池中的时候是通过Free List来完成的。\n\n**Flush List** 用来管理脏的数据页。写操作和读操作一样，也是先把数据页加载到内存中然后修改内存中的数据。一旦一个数据页变成了脏页那么Flush List这个链表里面就会有一个结点指向这个数据页所对应的**控制块**，意为这个数据页是脏的需要刷新回磁盘。**同时这个数据页也一定会出现在LRU列表中**，如果这个数据页将要从LRU列表中移除时那么肯定会把这个数据页同步到磁盘，这个数据页在Flush列表中的相应的节点也会被删除，这个是我们后面要将的checkpoint的技术。\n\n需要强调的是当数据库实例启动的时候控制块和缓存页就已经初始化好了。就像酒店里的房间，你住不住人房间都在那里。没有人住房间就是空的，同一个房间在不同的时间段内可能是不同的人在居住。而这三个list中的节点是会增加会减少会改变的。\n\n### checkpoint\n把缓冲池中的脏页刷新回磁盘是一件很重要的事情。checkpoint所做的就是这个重要的事情。innodb中的checkpoint如下\n\nSharp Checkpoint 数据库关闭的时候把所有的脏页刷新回磁盘\nFUZZY Checkpoint\n\n* Master Thread Checkpoint 主线程以一个固定的时间间隔异步的刷新脏页回磁盘\n* FLUSH_LRU_LIST Checkpoint 当LRU列表要移除数据页时并且这个数据页还标记在在Flush列表中的时候要强行的刷新这个数据页回磁盘\n* Async/Sync Flush Checkpoint 重做日志文件将要被覆盖的时候\n* Dirty Page too much Checkpoint 脏页的数量太多\n\n## 关键特性\n\n### 插入缓冲\n一般innodb的数据表都会有一个自增的id。因此每次插入一条数据的时候很容易找到待插入的位置，因为数据是存在主键索引的叶子节点上的。但是这有可能导致非主键索引插入的离散性。插入缓冲其实就是解决这个问题的。innodb对于非聚集索引的插入或者更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在则直接插入；若不在先放到一个插入缓冲中，然后再以一定的频率和情况进行插入缓冲和辅助索引页子节点的合并操作，这时通常能将多个插入合并到一个合并操作中，大大的提高了效率。\n### 两次写\n缓冲池中有2MB的内存叫做doublewrite buffer。同样硬盘上也有2M的“二次写”空间。第一次写是将内存的doublewrite buffer里的数据写到硬盘上的“二次写”空间，这个过程是顺序写，开销不大。第二次写是将doublewrite buffer里的数据写到表空间中，这个过程是离散的。如果在第二次写的过程中宕机，那么在“二次写”的硬盘空间中还备份了副本，可以用这个副本恢复数据页。\n![](http://sysummerblog.club/4.jpg)\n### 自适应哈希索引\nInnodb存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引可以带来速度的提升，则建立哈希索引，成为自适应哈希索引。貌似我们对这个特性什么都做不了，是innodb自己完成的。\n### 异步IO\n脏页刷新回磁盘的操作是异步的，这样不会阻塞用户线程。\n### 刷新邻接页\n如果innodb决定刷新一个脏页回磁盘的时候，会检测该页所在的区的所有页需不需要一起刷新。\n","updated":"2020-11-23T15:20:08.939Z","path":"posts/innodb.html","comments":1,"layout":"page","_id":"ckhupaq9p000q1no80r1vy3zw","content":"<p>innodb存储引擎是现在mysql的默认存储引擎，其特点是行锁设计、支持MVCC、支持外键、提供一致性非锁定读、同时被用来最有效的利用以及使用内存和CPU。</p>\n<a id=\"more\"></a>\n<h2 id=\"缓冲池\"><a href=\"#缓冲池\" class=\"headerlink\" title=\"缓冲池\"></a>缓冲池</h2><p>innodb维护了一个内存缓冲池名叫innodb_pool_buffer。当我们读一条数据的时候，先去缓冲池里面找存放改数据的页是不是在这个缓冲池中，如果在直接读取，如果不在那么先从硬盘上读取该页并放到缓冲池中供后续读取使用。写操作也是一样的，先写入缓冲池中的数据页，此时该页也叫脏页，然后再以一定的策略刷新到磁盘。缓冲池中存在的数据大致如下<br><img src=\"http://sysummerblog.club/1.jpg\" alt></p>\n<p>缓冲池的大小非常重要。说的极端一点，如果我们可以把数据库的页全部缓存在缓冲池中，那么数据库中的数据就相当于缓存了。可以通过以下命令查看缓冲池的大小</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'innodb_buffer_pool_size'</span></span><br></pre></td></tr></table></figure>\n\n<p>现在innodb也支持同时启动多个缓冲池，数据页会根据哈希值被分配到不同的实例中去。可以通过以下命令查看缓冲池实例的个数</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'innodb_buffer_pool_instance'</span></span><br></pre></td></tr></table></figure>\n\n<p>缓冲池是一片连续的内存空间，innodb为每一个缓存页都创建了一些所谓的控制信息，这些信息包括该页所属的表空间编号、页号、页在缓冲池中的地址、一些锁信息以及LSN信息等。</p>\n<p>每个缓存页的大小是一样的为16k，这个值是可以更改的。每个缓存页对应的控制信息占用的内存大小是相同的，我们就姑且把这些控制信息占用的一块内存称为一个控制块。控制块和缓存页是一对一的，都在缓冲池中。他们之间的关系大致是这样的<br><img src=\"http://sysummerblog.club/2.jpg\" alt></p>\n<h3 id=\"LRU-List、Free-List、Flush-List\"><a href=\"#LRU-List、Free-List、Flush-List\" class=\"headerlink\" title=\"LRU List、Free List、Flush List\"></a>LRU List、Free List、Flush List</h3><p>这三个list结构上很相似，都是双向链表，除了一些元信息之外还有就是指向控制块的指针。以free list为例（这个图是我能找到的最直观的图）<br><img src=\"http://sysummerblog.club/3.jpg\" alt></p>\n<p>这三个列表虽然结构类似，但是功能却大不相同。</p>\n<p><strong>LRU List</strong> 是用来管理innodb的缓冲池的。缓冲池的目的就是尽量的把热点数据缓存在内存中，进而保证数据库的性能。LRU list的职责就是尽量把热点的数据页留在内存中，把非热点的数据页从内存中移除。LRU List的前端是最频繁使用的数据页，尾端是最少使用的。当一个数据页从硬盘加载到内存中的时候在LRU List的3/8处会更新一些原信息并将指针指向一个新的<strong>控制块</strong>，而这控制块又指向一个16kb大小的数据页，这个数据页里面存放的就是刚刚从硬盘里面读取出来的数据。这个数据页会在innodb_old_blocks_time之后移动到LRU List的头部。之所以这么做是因为防止类似于扫描全表的操作污染了LRU List。当LRU List的一个节点(比如该节点叫node_lru)将要被移除的时候，Free List中会增加一个节点(比如该节点叫node_free)，node_free指向的控制块其实就是之前node_lru指向的控制块该控制块中所指向的数据页被LRU List认为是非热点数据了，这块地方要“腾出来存放别的热点数据了”</p>\n<p><strong>Free List</strong> 是用来管理空闲的数据页的。当数据库刚刚启动的时候肯定还没有任何的数据页加载到缓冲池中，这个时候Free List的节点的数目应该和<strong>控制块的</strong>的数目相等的。慢慢的当有数据页缓存到缓冲池中的时候Free List这个双向链表的节点数会慢慢变少。当一个从硬盘读取的数据页想要进入缓冲池中的时候是通过Free List来完成的。</p>\n<p><strong>Flush List</strong> 用来管理脏的数据页。写操作和读操作一样，也是先把数据页加载到内存中然后修改内存中的数据。一旦一个数据页变成了脏页那么Flush List这个链表里面就会有一个结点指向这个数据页所对应的<strong>控制块</strong>，意为这个数据页是脏的需要刷新回磁盘。<strong>同时这个数据页也一定会出现在LRU列表中</strong>，如果这个数据页将要从LRU列表中移除时那么肯定会把这个数据页同步到磁盘，这个数据页在Flush列表中的相应的节点也会被删除，这个是我们后面要将的checkpoint的技术。</p>\n<p>需要强调的是当数据库实例启动的时候控制块和缓存页就已经初始化好了。就像酒店里的房间，你住不住人房间都在那里。没有人住房间就是空的，同一个房间在不同的时间段内可能是不同的人在居住。而这三个list中的节点是会增加会减少会改变的。</p>\n<h3 id=\"checkpoint\"><a href=\"#checkpoint\" class=\"headerlink\" title=\"checkpoint\"></a>checkpoint</h3><p>把缓冲池中的脏页刷新回磁盘是一件很重要的事情。checkpoint所做的就是这个重要的事情。innodb中的checkpoint如下</p>\n<p>Sharp Checkpoint 数据库关闭的时候把所有的脏页刷新回磁盘<br>FUZZY Checkpoint</p>\n<ul>\n<li>Master Thread Checkpoint 主线程以一个固定的时间间隔异步的刷新脏页回磁盘</li>\n<li>FLUSH_LRU_LIST Checkpoint 当LRU列表要移除数据页时并且这个数据页还标记在在Flush列表中的时候要强行的刷新这个数据页回磁盘</li>\n<li>Async/Sync Flush Checkpoint 重做日志文件将要被覆盖的时候</li>\n<li>Dirty Page too much Checkpoint 脏页的数量太多</li>\n</ul>\n<h2 id=\"关键特性\"><a href=\"#关键特性\" class=\"headerlink\" title=\"关键特性\"></a>关键特性</h2><h3 id=\"插入缓冲\"><a href=\"#插入缓冲\" class=\"headerlink\" title=\"插入缓冲\"></a>插入缓冲</h3><p>一般innodb的数据表都会有一个自增的id。因此每次插入一条数据的时候很容易找到待插入的位置，因为数据是存在主键索引的叶子节点上的。但是这有可能导致非主键索引插入的离散性。插入缓冲其实就是解决这个问题的。innodb对于非聚集索引的插入或者更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在则直接插入；若不在先放到一个插入缓冲中，然后再以一定的频率和情况进行插入缓冲和辅助索引页子节点的合并操作，这时通常能将多个插入合并到一个合并操作中，大大的提高了效率。</p>\n<h3 id=\"两次写\"><a href=\"#两次写\" class=\"headerlink\" title=\"两次写\"></a>两次写</h3><p>缓冲池中有2MB的内存叫做doublewrite buffer。同样硬盘上也有2M的“二次写”空间。第一次写是将内存的doublewrite buffer里的数据写到硬盘上的“二次写”空间，这个过程是顺序写，开销不大。第二次写是将doublewrite buffer里的数据写到表空间中，这个过程是离散的。如果在第二次写的过程中宕机，那么在“二次写”的硬盘空间中还备份了副本，可以用这个副本恢复数据页。<br><img src=\"http://sysummerblog.club/4.jpg\" alt></p>\n<h3 id=\"自适应哈希索引\"><a href=\"#自适应哈希索引\" class=\"headerlink\" title=\"自适应哈希索引\"></a>自适应哈希索引</h3><p>Innodb存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引可以带来速度的提升，则建立哈希索引，成为自适应哈希索引。貌似我们对这个特性什么都做不了，是innodb自己完成的。</p>\n<h3 id=\"异步IO\"><a href=\"#异步IO\" class=\"headerlink\" title=\"异步IO\"></a>异步IO</h3><p>脏页刷新回磁盘的操作是异步的，这样不会阻塞用户线程。</p>\n<h3 id=\"刷新邻接页\"><a href=\"#刷新邻接页\" class=\"headerlink\" title=\"刷新邻接页\"></a>刷新邻接页</h3><p>如果innodb决定刷新一个脏页回磁盘的时候，会检测该页所在的区的所有页需不需要一起刷新。</p>\n","site":{"data":{}},"excerpt":"<p>innodb存储引擎是现在mysql的默认存储引擎，其特点是行锁设计、支持MVCC、支持外键、提供一致性非锁定读、同时被用来最有效的利用以及使用内存和CPU。</p>","more":"<h2 id=\"缓冲池\"><a href=\"#缓冲池\" class=\"headerlink\" title=\"缓冲池\"></a>缓冲池</h2><p>innodb维护了一个内存缓冲池名叫innodb_pool_buffer。当我们读一条数据的时候，先去缓冲池里面找存放改数据的页是不是在这个缓冲池中，如果在直接读取，如果不在那么先从硬盘上读取该页并放到缓冲池中供后续读取使用。写操作也是一样的，先写入缓冲池中的数据页，此时该页也叫脏页，然后再以一定的策略刷新到磁盘。缓冲池中存在的数据大致如下<br><img src=\"http://sysummerblog.club/1.jpg\" alt></p>\n<p>缓冲池的大小非常重要。说的极端一点，如果我们可以把数据库的页全部缓存在缓冲池中，那么数据库中的数据就相当于缓存了。可以通过以下命令查看缓冲池的大小</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'innodb_buffer_pool_size'</span></span><br></pre></td></tr></table></figure>\n\n<p>现在innodb也支持同时启动多个缓冲池，数据页会根据哈希值被分配到不同的实例中去。可以通过以下命令查看缓冲池实例的个数</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'innodb_buffer_pool_instance'</span></span><br></pre></td></tr></table></figure>\n\n<p>缓冲池是一片连续的内存空间，innodb为每一个缓存页都创建了一些所谓的控制信息，这些信息包括该页所属的表空间编号、页号、页在缓冲池中的地址、一些锁信息以及LSN信息等。</p>\n<p>每个缓存页的大小是一样的为16k，这个值是可以更改的。每个缓存页对应的控制信息占用的内存大小是相同的，我们就姑且把这些控制信息占用的一块内存称为一个控制块。控制块和缓存页是一对一的，都在缓冲池中。他们之间的关系大致是这样的<br><img src=\"http://sysummerblog.club/2.jpg\" alt></p>\n<h3 id=\"LRU-List、Free-List、Flush-List\"><a href=\"#LRU-List、Free-List、Flush-List\" class=\"headerlink\" title=\"LRU List、Free List、Flush List\"></a>LRU List、Free List、Flush List</h3><p>这三个list结构上很相似，都是双向链表，除了一些元信息之外还有就是指向控制块的指针。以free list为例（这个图是我能找到的最直观的图）<br><img src=\"http://sysummerblog.club/3.jpg\" alt></p>\n<p>这三个列表虽然结构类似，但是功能却大不相同。</p>\n<p><strong>LRU List</strong> 是用来管理innodb的缓冲池的。缓冲池的目的就是尽量的把热点数据缓存在内存中，进而保证数据库的性能。LRU list的职责就是尽量把热点的数据页留在内存中，把非热点的数据页从内存中移除。LRU List的前端是最频繁使用的数据页，尾端是最少使用的。当一个数据页从硬盘加载到内存中的时候在LRU List的3/8处会更新一些原信息并将指针指向一个新的<strong>控制块</strong>，而这控制块又指向一个16kb大小的数据页，这个数据页里面存放的就是刚刚从硬盘里面读取出来的数据。这个数据页会在innodb_old_blocks_time之后移动到LRU List的头部。之所以这么做是因为防止类似于扫描全表的操作污染了LRU List。当LRU List的一个节点(比如该节点叫node_lru)将要被移除的时候，Free List中会增加一个节点(比如该节点叫node_free)，node_free指向的控制块其实就是之前node_lru指向的控制块该控制块中所指向的数据页被LRU List认为是非热点数据了，这块地方要“腾出来存放别的热点数据了”</p>\n<p><strong>Free List</strong> 是用来管理空闲的数据页的。当数据库刚刚启动的时候肯定还没有任何的数据页加载到缓冲池中，这个时候Free List的节点的数目应该和<strong>控制块的</strong>的数目相等的。慢慢的当有数据页缓存到缓冲池中的时候Free List这个双向链表的节点数会慢慢变少。当一个从硬盘读取的数据页想要进入缓冲池中的时候是通过Free List来完成的。</p>\n<p><strong>Flush List</strong> 用来管理脏的数据页。写操作和读操作一样，也是先把数据页加载到内存中然后修改内存中的数据。一旦一个数据页变成了脏页那么Flush List这个链表里面就会有一个结点指向这个数据页所对应的<strong>控制块</strong>，意为这个数据页是脏的需要刷新回磁盘。<strong>同时这个数据页也一定会出现在LRU列表中</strong>，如果这个数据页将要从LRU列表中移除时那么肯定会把这个数据页同步到磁盘，这个数据页在Flush列表中的相应的节点也会被删除，这个是我们后面要将的checkpoint的技术。</p>\n<p>需要强调的是当数据库实例启动的时候控制块和缓存页就已经初始化好了。就像酒店里的房间，你住不住人房间都在那里。没有人住房间就是空的，同一个房间在不同的时间段内可能是不同的人在居住。而这三个list中的节点是会增加会减少会改变的。</p>\n<h3 id=\"checkpoint\"><a href=\"#checkpoint\" class=\"headerlink\" title=\"checkpoint\"></a>checkpoint</h3><p>把缓冲池中的脏页刷新回磁盘是一件很重要的事情。checkpoint所做的就是这个重要的事情。innodb中的checkpoint如下</p>\n<p>Sharp Checkpoint 数据库关闭的时候把所有的脏页刷新回磁盘<br>FUZZY Checkpoint</p>\n<ul>\n<li>Master Thread Checkpoint 主线程以一个固定的时间间隔异步的刷新脏页回磁盘</li>\n<li>FLUSH_LRU_LIST Checkpoint 当LRU列表要移除数据页时并且这个数据页还标记在在Flush列表中的时候要强行的刷新这个数据页回磁盘</li>\n<li>Async/Sync Flush Checkpoint 重做日志文件将要被覆盖的时候</li>\n<li>Dirty Page too much Checkpoint 脏页的数量太多</li>\n</ul>\n<h2 id=\"关键特性\"><a href=\"#关键特性\" class=\"headerlink\" title=\"关键特性\"></a>关键特性</h2><h3 id=\"插入缓冲\"><a href=\"#插入缓冲\" class=\"headerlink\" title=\"插入缓冲\"></a>插入缓冲</h3><p>一般innodb的数据表都会有一个自增的id。因此每次插入一条数据的时候很容易找到待插入的位置，因为数据是存在主键索引的叶子节点上的。但是这有可能导致非主键索引插入的离散性。插入缓冲其实就是解决这个问题的。innodb对于非聚集索引的插入或者更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在则直接插入；若不在先放到一个插入缓冲中，然后再以一定的频率和情况进行插入缓冲和辅助索引页子节点的合并操作，这时通常能将多个插入合并到一个合并操作中，大大的提高了效率。</p>\n<h3 id=\"两次写\"><a href=\"#两次写\" class=\"headerlink\" title=\"两次写\"></a>两次写</h3><p>缓冲池中有2MB的内存叫做doublewrite buffer。同样硬盘上也有2M的“二次写”空间。第一次写是将内存的doublewrite buffer里的数据写到硬盘上的“二次写”空间，这个过程是顺序写，开销不大。第二次写是将doublewrite buffer里的数据写到表空间中，这个过程是离散的。如果在第二次写的过程中宕机，那么在“二次写”的硬盘空间中还备份了副本，可以用这个副本恢复数据页。<br><img src=\"http://sysummerblog.club/4.jpg\" alt></p>\n<h3 id=\"自适应哈希索引\"><a href=\"#自适应哈希索引\" class=\"headerlink\" title=\"自适应哈希索引\"></a>自适应哈希索引</h3><p>Innodb存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引可以带来速度的提升，则建立哈希索引，成为自适应哈希索引。貌似我们对这个特性什么都做不了，是innodb自己完成的。</p>\n<h3 id=\"异步IO\"><a href=\"#异步IO\" class=\"headerlink\" title=\"异步IO\"></a>异步IO</h3><p>脏页刷新回磁盘的操作是异步的，这样不会阻塞用户线程。</p>\n<h3 id=\"刷新邻接页\"><a href=\"#刷新邻接页\" class=\"headerlink\" title=\"刷新邻接页\"></a>刷新邻接页</h3><p>如果innodb决定刷新一个脏页回磁盘的时候，会检测该页所在的区的所有页需不需要一起刷新。</p>"},{"title":"Nginx学习笔记","date":"2019-08-04T01:04:05.000Z","tags":["nginx"],"photos":[["http://sysummerblog.club/nginx_cover.jpeg"]],"_content":"Nginx 是一个免费、开源、高性能、轻量级的 HTTP 和反向代理服务器，也是一个电子邮件(IMAP/POP3)代理服务器，其特点是占有内存少，并发能力强。\n<!--more-->\n\n## nginx的架构\nNginx 里有一个 master 进程和多个 worker 进程。master 进程并不处理网络请求，主要负责调度工作进程：加载配置、启动工作进程及非停升级。worker 进程负责处理网络请求与响应。\n\n![](http://sysummerblog.club/nginx_process.png)\n\nmaster进程主要用来管理worker进程，具体包括如下4个主要功能：\n\n接收来自外界的信号。\n\n向各worker进程发送信号。\n\n监控woker进程的运行状态。\n\n当woker进程退出后（异常情况下），会自动重新启动新的woker进程。\n\nwoker进程主要用来处理基本的网络事件：\n\n多个worker进程之间是对等且相互独立的，他们同等竞争来自客户端的请求。\n\n一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。\n\nworker进程的个数是可以设置的，一般我们会设置与机器cpu核数一致。同时，nginx为了更好的利用多核特性，具有cpu绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。\n## 建立连接的步骤\n\n1. 最开始master进程会建立、绑定、监听一个socket。\n2. 然后fork出多个work进程，work进程共享master监听的文件描述符\n3. 当socket上有数据的时候，work进程会通过锁来竞争资源\n4. 竞争到资源的work进程调用accept方法接收连接，accept方法会返回一个新的socket，之后就是这个新的socket与客户端建立3次握手和数据的交换。需要注意的是新建立的这个socket所监听的端口号还是80或443。唯一确定一个socket（只考虑tcp协议的）是四元组：客户端ip, 客户端端口, 服务器ip, 服务器端口。只要有一个元素不一样，就表示不同的连接。因此一单建立了连接，下次再通信的时候数据就会直接到第一次accept的那个socket，并不会再到达master进程最开始监听的那个socket了。\n\n\n## 处理事件\n每个work进程可以处理两类事件\n\n1. 处理已监听的socket的读或写就绪事件\n2. 处理新的连接\n\n多个进程间通过争夺一块锁来决定谁处理新的连接。同一时刻只能有一个进程获取到锁。也因此不会产生“惊群”现象。\n\n获取到锁的进程调用epoll_wait方法返回的事件列表中既有已监听的socket的读或写就绪事件，也有要处理新的连接事件。新的连接事件的优先级比较高。\n\n没有获取到锁的进程调用epoll_wait方法只会获取到该进程监听的socket上的读或写就绪事件。\n\n每个work进程在启动后都会调用内核的epoll_create方法。该方法返回一个文件描述符，并在内核维护一个epoll模块。之后work进程通过这个文件描述符来实现对自己感兴趣的事件的添加、删除、修改、监听。\n\n当work进程获得一个新的连接的时候，会把这个socket上的读就绪事件通过epoll_ctl函数挂载在epoll模块的红黑树上。\n\nwork进程通过epoll_wait函数获取到了socket上有可读事件后就开始处理该事件，处理的过程很短，就是把该请求根据用户的配置交到下游处理模块中。\n\n## 模块\nNginx 由内核和一系列模块组成，内核提供 Web 服务的基本功能，如启用网络协议，创建运行环境，接收和分配客户端请求，处理模块之间的交互。\n\nNginx 的各种功能和操作都由模块来实现。Nginx 的模块从结构上分为：\n\n* 核心模块：HTTP 模块、EVENT 模块和 MAIL 模块。\n* 基础模块：HTTP Access 模块、HTTP FastCGI 模块、HTTP Proxy 模块和 HTTP Rewrite 模块。\n* 第三方模块：HTTP Upstream Request Hash 模块、Notice 模块和 HTTP Access Key 模块及用户自己开发的模块。\n\n## 配置\nnginx的配置有三大模块\n\n1. 全局块\n2. event块\n3. http块\n\n### 全局块\n全局块负责一些全局的配置，部分配置如下\n\n1. user 规定运行nginx的用户和用户组\n2. worker_processes worker进程的数量\n3. worker_rlimit_nofile 一个worker进程最大的打开文件的数量\n\n### event块\nevent块里的配置是有关事件的，部分配置如下\n\n1. worker_connections 一个work进程能够处理的最大的连接数\n2. accept_mutex 当一个新连接到达时，如果激活了accept_mutex，那么多个Worker将以串行方式来处理，其中有一个Worker会被唤醒，其他的Worker继续保持休眠状态；如果没有激活accept_mutex，那么所有的Worker都会被唤醒，不过只有一个Worker能获取新连接，其它的Worker会重新进入休眠状态\n3. use epoll 使用epoll来管理io事件\n\n### http块\nhttp块中的配置包含两部分，公共部分和server部分。公共部分是所有server都采用的，server部分是每个server单独采用的。\n\n#### 公共配置\n\n1. client_header_buffer_size 请求头缓冲区大小\n2. large_client_header_buffers 当请求头太大的时候client_header_buffer_size放不下了，会向large_client_header_buffers申请一块额外的内存\n3. client_max_body_size 请求body的最大\n4. client_body_timeout 读取请求body的超时时间\n5. client_header_timeout 读取请求header的超时时间\n6. log_format access_log的日志格式\n7. sendfile 支持“零拷贝”\n8. keepalive_timeout 长连接的超时时间。超时后会nginx会释放socket资源。如果客户端再想通信需重新3次握手\n\n#### server配置\nserver配置中一般会有多个location，把不同的url分配给不同的下游服务\n\nnginx中以$开头的都是nginx的变量。nginx在把请求发给fastcgi之前会把nginx的变量转化成fastcgi变量。fastcgi的变量由大写字母和下划线组成。在php的进程中，fastcgi的变量都在SERVERA全局数组中。\n\n##### rewrite\n```sh\nif (!-e $request_filename) {\n    rewrite ^(.*)$ /index.php?_url=$1 last;\n}\n```\n$request_filename是根路径拼接的uri(域名后面的一段)。如果用户请求的不是一个文件那么久将进行重写。重写的规则是请求根域名下的index.php,而uri变成了_url参数\n\nrewrite最后会有一个标识符\n\n* break url重写后，直接使用当前资源，不再执行location里余下的语句，完成本次请求，地址栏url不变 \n* last url重写后，马上发起一个新的请求，再次进入server块，重试location匹配，超过10次匹配不到报500错误，地址栏url不变\n* redirect 返回302临时重定向，地址栏显示重定向后的url，爬虫不会更新url（因为是临时）\n* permanent 返回301永久重定向, 地址栏显示重定向后的url，爬虫更新url\n\n##### location\n在匹配location的时候\n\n* =  精确匹配\n* ~  表示大小写敏感的正则匹配\n* ~* 表示大小写不敏感的正则匹配\n\n以php为例。以.php为结尾的请求都转给fastcgi\n```sh\nlocation ~ \\.php$ {\n    set $real_script_name $fastcgi_script_name;\n    if ($fastcgi_script_name ~ /lianjia(/.*)$) {\n        set $real_script_name $1;\n    }\n    fastcgi_pass    127.0.0.1:18181;\n    fastcgi_index  index.php;\n    fastcgi_param  SCRIPT_FILENAME $document_root$real_script_name;\n    include        tengine.fastcgi_params;\n}\n```\n\n## 负载均衡\nnginx的负载均衡策略有三种\n\n1. 平均分配\n2. 根据权重\n3. 根据客户端的ip\n\n无论哪一种，如果其中的一台机器出问题了，nginx会自动剔除，用起来很方便\n\n### 平均负载\n```sh\nhttp{\n    # 待选服务器列表\n    upstream myproject{\n        server 125.219.42.4;\n        server 172.31.2.183;\n    }\n\n    server{\n        listen 80; \n        location / {            \n            proxy_pass http://myproject;\n        }\n\n   }\n}\n```\n\n### 根据权重负载\n```sh\nhttp{\n    # 待选服务器列表\n    upstream myproject{\n        server 125.219.42.4 weight 1;\n        server 172.31.2.183 weight 2;\n    }\n\n    server{\n        listen 80; \n        location / {            \n            proxy_pass http://myproject;\n        }\n\n   }\n}\n```\n\n### 根据用户ip负载 \n```sh\nhttp{\n    # 待选服务器列表\n    upstream myproject{\n        ip_hash;\n        server 125.219.42.4;\n        server 172.31.2.183;\n    }\n\n    server{\n        listen 80; \n        location / {            \n            proxy_pass http://myproject;\n        }\n\n   }\n}\n```\n","source":"posts/nginx-notes.md","raw":"---\ntitle: Nginx学习笔记\ndate: 2019-08-04 09:04:05\ntags:\n  - nginx\nphotos:\n  - [\"http://sysummerblog.club/nginx_cover.jpeg\"]\n---\nNginx 是一个免费、开源、高性能、轻量级的 HTTP 和反向代理服务器，也是一个电子邮件(IMAP/POP3)代理服务器，其特点是占有内存少，并发能力强。\n<!--more-->\n\n## nginx的架构\nNginx 里有一个 master 进程和多个 worker 进程。master 进程并不处理网络请求，主要负责调度工作进程：加载配置、启动工作进程及非停升级。worker 进程负责处理网络请求与响应。\n\n![](http://sysummerblog.club/nginx_process.png)\n\nmaster进程主要用来管理worker进程，具体包括如下4个主要功能：\n\n接收来自外界的信号。\n\n向各worker进程发送信号。\n\n监控woker进程的运行状态。\n\n当woker进程退出后（异常情况下），会自动重新启动新的woker进程。\n\nwoker进程主要用来处理基本的网络事件：\n\n多个worker进程之间是对等且相互独立的，他们同等竞争来自客户端的请求。\n\n一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。\n\nworker进程的个数是可以设置的，一般我们会设置与机器cpu核数一致。同时，nginx为了更好的利用多核特性，具有cpu绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。\n## 建立连接的步骤\n\n1. 最开始master进程会建立、绑定、监听一个socket。\n2. 然后fork出多个work进程，work进程共享master监听的文件描述符\n3. 当socket上有数据的时候，work进程会通过锁来竞争资源\n4. 竞争到资源的work进程调用accept方法接收连接，accept方法会返回一个新的socket，之后就是这个新的socket与客户端建立3次握手和数据的交换。需要注意的是新建立的这个socket所监听的端口号还是80或443。唯一确定一个socket（只考虑tcp协议的）是四元组：客户端ip, 客户端端口, 服务器ip, 服务器端口。只要有一个元素不一样，就表示不同的连接。因此一单建立了连接，下次再通信的时候数据就会直接到第一次accept的那个socket，并不会再到达master进程最开始监听的那个socket了。\n\n\n## 处理事件\n每个work进程可以处理两类事件\n\n1. 处理已监听的socket的读或写就绪事件\n2. 处理新的连接\n\n多个进程间通过争夺一块锁来决定谁处理新的连接。同一时刻只能有一个进程获取到锁。也因此不会产生“惊群”现象。\n\n获取到锁的进程调用epoll_wait方法返回的事件列表中既有已监听的socket的读或写就绪事件，也有要处理新的连接事件。新的连接事件的优先级比较高。\n\n没有获取到锁的进程调用epoll_wait方法只会获取到该进程监听的socket上的读或写就绪事件。\n\n每个work进程在启动后都会调用内核的epoll_create方法。该方法返回一个文件描述符，并在内核维护一个epoll模块。之后work进程通过这个文件描述符来实现对自己感兴趣的事件的添加、删除、修改、监听。\n\n当work进程获得一个新的连接的时候，会把这个socket上的读就绪事件通过epoll_ctl函数挂载在epoll模块的红黑树上。\n\nwork进程通过epoll_wait函数获取到了socket上有可读事件后就开始处理该事件，处理的过程很短，就是把该请求根据用户的配置交到下游处理模块中。\n\n## 模块\nNginx 由内核和一系列模块组成，内核提供 Web 服务的基本功能，如启用网络协议，创建运行环境，接收和分配客户端请求，处理模块之间的交互。\n\nNginx 的各种功能和操作都由模块来实现。Nginx 的模块从结构上分为：\n\n* 核心模块：HTTP 模块、EVENT 模块和 MAIL 模块。\n* 基础模块：HTTP Access 模块、HTTP FastCGI 模块、HTTP Proxy 模块和 HTTP Rewrite 模块。\n* 第三方模块：HTTP Upstream Request Hash 模块、Notice 模块和 HTTP Access Key 模块及用户自己开发的模块。\n\n## 配置\nnginx的配置有三大模块\n\n1. 全局块\n2. event块\n3. http块\n\n### 全局块\n全局块负责一些全局的配置，部分配置如下\n\n1. user 规定运行nginx的用户和用户组\n2. worker_processes worker进程的数量\n3. worker_rlimit_nofile 一个worker进程最大的打开文件的数量\n\n### event块\nevent块里的配置是有关事件的，部分配置如下\n\n1. worker_connections 一个work进程能够处理的最大的连接数\n2. accept_mutex 当一个新连接到达时，如果激活了accept_mutex，那么多个Worker将以串行方式来处理，其中有一个Worker会被唤醒，其他的Worker继续保持休眠状态；如果没有激活accept_mutex，那么所有的Worker都会被唤醒，不过只有一个Worker能获取新连接，其它的Worker会重新进入休眠状态\n3. use epoll 使用epoll来管理io事件\n\n### http块\nhttp块中的配置包含两部分，公共部分和server部分。公共部分是所有server都采用的，server部分是每个server单独采用的。\n\n#### 公共配置\n\n1. client_header_buffer_size 请求头缓冲区大小\n2. large_client_header_buffers 当请求头太大的时候client_header_buffer_size放不下了，会向large_client_header_buffers申请一块额外的内存\n3. client_max_body_size 请求body的最大\n4. client_body_timeout 读取请求body的超时时间\n5. client_header_timeout 读取请求header的超时时间\n6. log_format access_log的日志格式\n7. sendfile 支持“零拷贝”\n8. keepalive_timeout 长连接的超时时间。超时后会nginx会释放socket资源。如果客户端再想通信需重新3次握手\n\n#### server配置\nserver配置中一般会有多个location，把不同的url分配给不同的下游服务\n\nnginx中以$开头的都是nginx的变量。nginx在把请求发给fastcgi之前会把nginx的变量转化成fastcgi变量。fastcgi的变量由大写字母和下划线组成。在php的进程中，fastcgi的变量都在SERVERA全局数组中。\n\n##### rewrite\n```sh\nif (!-e $request_filename) {\n    rewrite ^(.*)$ /index.php?_url=$1 last;\n}\n```\n$request_filename是根路径拼接的uri(域名后面的一段)。如果用户请求的不是一个文件那么久将进行重写。重写的规则是请求根域名下的index.php,而uri变成了_url参数\n\nrewrite最后会有一个标识符\n\n* break url重写后，直接使用当前资源，不再执行location里余下的语句，完成本次请求，地址栏url不变 \n* last url重写后，马上发起一个新的请求，再次进入server块，重试location匹配，超过10次匹配不到报500错误，地址栏url不变\n* redirect 返回302临时重定向，地址栏显示重定向后的url，爬虫不会更新url（因为是临时）\n* permanent 返回301永久重定向, 地址栏显示重定向后的url，爬虫更新url\n\n##### location\n在匹配location的时候\n\n* =  精确匹配\n* ~  表示大小写敏感的正则匹配\n* ~* 表示大小写不敏感的正则匹配\n\n以php为例。以.php为结尾的请求都转给fastcgi\n```sh\nlocation ~ \\.php$ {\n    set $real_script_name $fastcgi_script_name;\n    if ($fastcgi_script_name ~ /lianjia(/.*)$) {\n        set $real_script_name $1;\n    }\n    fastcgi_pass    127.0.0.1:18181;\n    fastcgi_index  index.php;\n    fastcgi_param  SCRIPT_FILENAME $document_root$real_script_name;\n    include        tengine.fastcgi_params;\n}\n```\n\n## 负载均衡\nnginx的负载均衡策略有三种\n\n1. 平均分配\n2. 根据权重\n3. 根据客户端的ip\n\n无论哪一种，如果其中的一台机器出问题了，nginx会自动剔除，用起来很方便\n\n### 平均负载\n```sh\nhttp{\n    # 待选服务器列表\n    upstream myproject{\n        server 125.219.42.4;\n        server 172.31.2.183;\n    }\n\n    server{\n        listen 80; \n        location / {            \n            proxy_pass http://myproject;\n        }\n\n   }\n}\n```\n\n### 根据权重负载\n```sh\nhttp{\n    # 待选服务器列表\n    upstream myproject{\n        server 125.219.42.4 weight 1;\n        server 172.31.2.183 weight 2;\n    }\n\n    server{\n        listen 80; \n        location / {            \n            proxy_pass http://myproject;\n        }\n\n   }\n}\n```\n\n### 根据用户ip负载 \n```sh\nhttp{\n    # 待选服务器列表\n    upstream myproject{\n        ip_hash;\n        server 125.219.42.4;\n        server 172.31.2.183;\n    }\n\n    server{\n        listen 80; \n        location / {            \n            proxy_pass http://myproject;\n        }\n\n   }\n}\n```\n","updated":"2020-11-23T15:20:08.939Z","path":"posts/nginx-notes.html","comments":1,"layout":"page","_id":"ckhupaq9r000t1no8clvfw9aa","content":"<p>Nginx 是一个免费、开源、高性能、轻量级的 HTTP 和反向代理服务器，也是一个电子邮件(IMAP/POP3)代理服务器，其特点是占有内存少，并发能力强。</p>\n<a id=\"more\"></a>\n\n<h2 id=\"nginx的架构\"><a href=\"#nginx的架构\" class=\"headerlink\" title=\"nginx的架构\"></a>nginx的架构</h2><p>Nginx 里有一个 master 进程和多个 worker 进程。master 进程并不处理网络请求，主要负责调度工作进程：加载配置、启动工作进程及非停升级。worker 进程负责处理网络请求与响应。</p>\n<p><img src=\"http://sysummerblog.club/nginx_process.png\" alt></p>\n<p>master进程主要用来管理worker进程，具体包括如下4个主要功能：</p>\n<p>接收来自外界的信号。</p>\n<p>向各worker进程发送信号。</p>\n<p>监控woker进程的运行状态。</p>\n<p>当woker进程退出后（异常情况下），会自动重新启动新的woker进程。</p>\n<p>woker进程主要用来处理基本的网络事件：</p>\n<p>多个worker进程之间是对等且相互独立的，他们同等竞争来自客户端的请求。</p>\n<p>一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。</p>\n<p>worker进程的个数是可以设置的，一般我们会设置与机器cpu核数一致。同时，nginx为了更好的利用多核特性，具有cpu绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。</p>\n<h2 id=\"建立连接的步骤\"><a href=\"#建立连接的步骤\" class=\"headerlink\" title=\"建立连接的步骤\"></a>建立连接的步骤</h2><ol>\n<li>最开始master进程会建立、绑定、监听一个socket。</li>\n<li>然后fork出多个work进程，work进程共享master监听的文件描述符</li>\n<li>当socket上有数据的时候，work进程会通过锁来竞争资源</li>\n<li>竞争到资源的work进程调用accept方法接收连接，accept方法会返回一个新的socket，之后就是这个新的socket与客户端建立3次握手和数据的交换。需要注意的是新建立的这个socket所监听的端口号还是80或443。唯一确定一个socket（只考虑tcp协议的）是四元组：客户端ip, 客户端端口, 服务器ip, 服务器端口。只要有一个元素不一样，就表示不同的连接。因此一单建立了连接，下次再通信的时候数据就会直接到第一次accept的那个socket，并不会再到达master进程最开始监听的那个socket了。</li>\n</ol>\n<h2 id=\"处理事件\"><a href=\"#处理事件\" class=\"headerlink\" title=\"处理事件\"></a>处理事件</h2><p>每个work进程可以处理两类事件</p>\n<ol>\n<li>处理已监听的socket的读或写就绪事件</li>\n<li>处理新的连接</li>\n</ol>\n<p>多个进程间通过争夺一块锁来决定谁处理新的连接。同一时刻只能有一个进程获取到锁。也因此不会产生“惊群”现象。</p>\n<p>获取到锁的进程调用epoll_wait方法返回的事件列表中既有已监听的socket的读或写就绪事件，也有要处理新的连接事件。新的连接事件的优先级比较高。</p>\n<p>没有获取到锁的进程调用epoll_wait方法只会获取到该进程监听的socket上的读或写就绪事件。</p>\n<p>每个work进程在启动后都会调用内核的epoll_create方法。该方法返回一个文件描述符，并在内核维护一个epoll模块。之后work进程通过这个文件描述符来实现对自己感兴趣的事件的添加、删除、修改、监听。</p>\n<p>当work进程获得一个新的连接的时候，会把这个socket上的读就绪事件通过epoll_ctl函数挂载在epoll模块的红黑树上。</p>\n<p>work进程通过epoll_wait函数获取到了socket上有可读事件后就开始处理该事件，处理的过程很短，就是把该请求根据用户的配置交到下游处理模块中。</p>\n<h2 id=\"模块\"><a href=\"#模块\" class=\"headerlink\" title=\"模块\"></a>模块</h2><p>Nginx 由内核和一系列模块组成，内核提供 Web 服务的基本功能，如启用网络协议，创建运行环境，接收和分配客户端请求，处理模块之间的交互。</p>\n<p>Nginx 的各种功能和操作都由模块来实现。Nginx 的模块从结构上分为：</p>\n<ul>\n<li>核心模块：HTTP 模块、EVENT 模块和 MAIL 模块。</li>\n<li>基础模块：HTTP Access 模块、HTTP FastCGI 模块、HTTP Proxy 模块和 HTTP Rewrite 模块。</li>\n<li>第三方模块：HTTP Upstream Request Hash 模块、Notice 模块和 HTTP Access Key 模块及用户自己开发的模块。</li>\n</ul>\n<h2 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h2><p>nginx的配置有三大模块</p>\n<ol>\n<li>全局块</li>\n<li>event块</li>\n<li>http块</li>\n</ol>\n<h3 id=\"全局块\"><a href=\"#全局块\" class=\"headerlink\" title=\"全局块\"></a>全局块</h3><p>全局块负责一些全局的配置，部分配置如下</p>\n<ol>\n<li>user 规定运行nginx的用户和用户组</li>\n<li>worker_processes worker进程的数量</li>\n<li>worker_rlimit_nofile 一个worker进程最大的打开文件的数量</li>\n</ol>\n<h3 id=\"event块\"><a href=\"#event块\" class=\"headerlink\" title=\"event块\"></a>event块</h3><p>event块里的配置是有关事件的，部分配置如下</p>\n<ol>\n<li>worker_connections 一个work进程能够处理的最大的连接数</li>\n<li>accept_mutex 当一个新连接到达时，如果激活了accept_mutex，那么多个Worker将以串行方式来处理，其中有一个Worker会被唤醒，其他的Worker继续保持休眠状态；如果没有激活accept_mutex，那么所有的Worker都会被唤醒，不过只有一个Worker能获取新连接，其它的Worker会重新进入休眠状态</li>\n<li>use epoll 使用epoll来管理io事件</li>\n</ol>\n<h3 id=\"http块\"><a href=\"#http块\" class=\"headerlink\" title=\"http块\"></a>http块</h3><p>http块中的配置包含两部分，公共部分和server部分。公共部分是所有server都采用的，server部分是每个server单独采用的。</p>\n<h4 id=\"公共配置\"><a href=\"#公共配置\" class=\"headerlink\" title=\"公共配置\"></a>公共配置</h4><ol>\n<li>client_header_buffer_size 请求头缓冲区大小</li>\n<li>large_client_header_buffers 当请求头太大的时候client_header_buffer_size放不下了，会向large_client_header_buffers申请一块额外的内存</li>\n<li>client_max_body_size 请求body的最大</li>\n<li>client_body_timeout 读取请求body的超时时间</li>\n<li>client_header_timeout 读取请求header的超时时间</li>\n<li>log_format access_log的日志格式</li>\n<li>sendfile 支持“零拷贝”</li>\n<li>keepalive_timeout 长连接的超时时间。超时后会nginx会释放socket资源。如果客户端再想通信需重新3次握手</li>\n</ol>\n<h4 id=\"server配置\"><a href=\"#server配置\" class=\"headerlink\" title=\"server配置\"></a>server配置</h4><p>server配置中一般会有多个location，把不同的url分配给不同的下游服务</p>\n<p>nginx中以$开头的都是nginx的变量。nginx在把请求发给fastcgi之前会把nginx的变量转化成fastcgi变量。fastcgi的变量由大写字母和下划线组成。在php的进程中，fastcgi的变量都在SERVERA全局数组中。</p>\n<h5 id=\"rewrite\"><a href=\"#rewrite\" class=\"headerlink\" title=\"rewrite\"></a>rewrite</h5><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (!-e <span class=\"variable\">$request_filename</span>) &#123;</span><br><span class=\"line\">    rewrite ^(.*)$ /index.php?_url=<span class=\"variable\">$1</span> last;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>$request_filename是根路径拼接的uri(域名后面的一段)。如果用户请求的不是一个文件那么久将进行重写。重写的规则是请求根域名下的index.php,而uri变成了_url参数</p>\n<p>rewrite最后会有一个标识符</p>\n<ul>\n<li>break url重写后，直接使用当前资源，不再执行location里余下的语句，完成本次请求，地址栏url不变 </li>\n<li>last url重写后，马上发起一个新的请求，再次进入server块，重试location匹配，超过10次匹配不到报500错误，地址栏url不变</li>\n<li>redirect 返回302临时重定向，地址栏显示重定向后的url，爬虫不会更新url（因为是临时）</li>\n<li>permanent 返回301永久重定向, 地址栏显示重定向后的url，爬虫更新url</li>\n</ul>\n<h5 id=\"location\"><a href=\"#location\" class=\"headerlink\" title=\"location\"></a>location</h5><p>在匹配location的时候</p>\n<ul>\n<li>=  精确匹配</li>\n<li>~  表示大小写敏感的正则匹配</li>\n<li>~* 表示大小写不敏感的正则匹配</li>\n</ul>\n<p>以php为例。以.php为结尾的请求都转给fastcgi</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location ~ \\.php$ &#123;</span><br><span class=\"line\">    <span class=\"built_in\">set</span> <span class=\"variable\">$real_script_name</span> <span class=\"variable\">$fastcgi_script_name</span>;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"variable\">$fastcgi_script_name</span> ~ /lianjia(/.*)$) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">set</span> <span class=\"variable\">$real_script_name</span> <span class=\"variable\">$1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    fastcgi_pass    127.0.0.1:18181;</span><br><span class=\"line\">    fastcgi_index  index.php;</span><br><span class=\"line\">    fastcgi_param  SCRIPT_FILENAME <span class=\"variable\">$document_root</span><span class=\"variable\">$real_script_name</span>;</span><br><span class=\"line\">    include        tengine.fastcgi_params;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"负载均衡\"><a href=\"#负载均衡\" class=\"headerlink\" title=\"负载均衡\"></a>负载均衡</h2><p>nginx的负载均衡策略有三种</p>\n<ol>\n<li>平均分配</li>\n<li>根据权重</li>\n<li>根据客户端的ip</li>\n</ol>\n<p>无论哪一种，如果其中的一台机器出问题了，nginx会自动剔除，用起来很方便</p>\n<h3 id=\"平均负载\"><a href=\"#平均负载\" class=\"headerlink\" title=\"平均负载\"></a>平均负载</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http&#123;</span><br><span class=\"line\">    <span class=\"comment\"># 待选服务器列表</span></span><br><span class=\"line\">    upstream myproject&#123;</span><br><span class=\"line\">        server 125.219.42.4;</span><br><span class=\"line\">        server 172.31.2.183;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    server&#123;</span><br><span class=\"line\">        listen 80; </span><br><span class=\"line\">        location / &#123;            </span><br><span class=\"line\">            proxy_pass http://myproject;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"根据权重负载\"><a href=\"#根据权重负载\" class=\"headerlink\" title=\"根据权重负载\"></a>根据权重负载</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http&#123;</span><br><span class=\"line\">    <span class=\"comment\"># 待选服务器列表</span></span><br><span class=\"line\">    upstream myproject&#123;</span><br><span class=\"line\">        server 125.219.42.4 weight 1;</span><br><span class=\"line\">        server 172.31.2.183 weight 2;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    server&#123;</span><br><span class=\"line\">        listen 80; </span><br><span class=\"line\">        location / &#123;            </span><br><span class=\"line\">            proxy_pass http://myproject;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"根据用户ip负载\"><a href=\"#根据用户ip负载\" class=\"headerlink\" title=\"根据用户ip负载\"></a>根据用户ip负载</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http&#123;</span><br><span class=\"line\">    <span class=\"comment\"># 待选服务器列表</span></span><br><span class=\"line\">    upstream myproject&#123;</span><br><span class=\"line\">        ip_hash;</span><br><span class=\"line\">        server 125.219.42.4;</span><br><span class=\"line\">        server 172.31.2.183;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    server&#123;</span><br><span class=\"line\">        listen 80; </span><br><span class=\"line\">        location / &#123;            </span><br><span class=\"line\">            proxy_pass http://myproject;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"<p>Nginx 是一个免费、开源、高性能、轻量级的 HTTP 和反向代理服务器，也是一个电子邮件(IMAP/POP3)代理服务器，其特点是占有内存少，并发能力强。</p>","more":"<h2 id=\"nginx的架构\"><a href=\"#nginx的架构\" class=\"headerlink\" title=\"nginx的架构\"></a>nginx的架构</h2><p>Nginx 里有一个 master 进程和多个 worker 进程。master 进程并不处理网络请求，主要负责调度工作进程：加载配置、启动工作进程及非停升级。worker 进程负责处理网络请求与响应。</p>\n<p><img src=\"http://sysummerblog.club/nginx_process.png\" alt></p>\n<p>master进程主要用来管理worker进程，具体包括如下4个主要功能：</p>\n<p>接收来自外界的信号。</p>\n<p>向各worker进程发送信号。</p>\n<p>监控woker进程的运行状态。</p>\n<p>当woker进程退出后（异常情况下），会自动重新启动新的woker进程。</p>\n<p>woker进程主要用来处理基本的网络事件：</p>\n<p>多个worker进程之间是对等且相互独立的，他们同等竞争来自客户端的请求。</p>\n<p>一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。</p>\n<p>worker进程的个数是可以设置的，一般我们会设置与机器cpu核数一致。同时，nginx为了更好的利用多核特性，具有cpu绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。</p>\n<h2 id=\"建立连接的步骤\"><a href=\"#建立连接的步骤\" class=\"headerlink\" title=\"建立连接的步骤\"></a>建立连接的步骤</h2><ol>\n<li>最开始master进程会建立、绑定、监听一个socket。</li>\n<li>然后fork出多个work进程，work进程共享master监听的文件描述符</li>\n<li>当socket上有数据的时候，work进程会通过锁来竞争资源</li>\n<li>竞争到资源的work进程调用accept方法接收连接，accept方法会返回一个新的socket，之后就是这个新的socket与客户端建立3次握手和数据的交换。需要注意的是新建立的这个socket所监听的端口号还是80或443。唯一确定一个socket（只考虑tcp协议的）是四元组：客户端ip, 客户端端口, 服务器ip, 服务器端口。只要有一个元素不一样，就表示不同的连接。因此一单建立了连接，下次再通信的时候数据就会直接到第一次accept的那个socket，并不会再到达master进程最开始监听的那个socket了。</li>\n</ol>\n<h2 id=\"处理事件\"><a href=\"#处理事件\" class=\"headerlink\" title=\"处理事件\"></a>处理事件</h2><p>每个work进程可以处理两类事件</p>\n<ol>\n<li>处理已监听的socket的读或写就绪事件</li>\n<li>处理新的连接</li>\n</ol>\n<p>多个进程间通过争夺一块锁来决定谁处理新的连接。同一时刻只能有一个进程获取到锁。也因此不会产生“惊群”现象。</p>\n<p>获取到锁的进程调用epoll_wait方法返回的事件列表中既有已监听的socket的读或写就绪事件，也有要处理新的连接事件。新的连接事件的优先级比较高。</p>\n<p>没有获取到锁的进程调用epoll_wait方法只会获取到该进程监听的socket上的读或写就绪事件。</p>\n<p>每个work进程在启动后都会调用内核的epoll_create方法。该方法返回一个文件描述符，并在内核维护一个epoll模块。之后work进程通过这个文件描述符来实现对自己感兴趣的事件的添加、删除、修改、监听。</p>\n<p>当work进程获得一个新的连接的时候，会把这个socket上的读就绪事件通过epoll_ctl函数挂载在epoll模块的红黑树上。</p>\n<p>work进程通过epoll_wait函数获取到了socket上有可读事件后就开始处理该事件，处理的过程很短，就是把该请求根据用户的配置交到下游处理模块中。</p>\n<h2 id=\"模块\"><a href=\"#模块\" class=\"headerlink\" title=\"模块\"></a>模块</h2><p>Nginx 由内核和一系列模块组成，内核提供 Web 服务的基本功能，如启用网络协议，创建运行环境，接收和分配客户端请求，处理模块之间的交互。</p>\n<p>Nginx 的各种功能和操作都由模块来实现。Nginx 的模块从结构上分为：</p>\n<ul>\n<li>核心模块：HTTP 模块、EVENT 模块和 MAIL 模块。</li>\n<li>基础模块：HTTP Access 模块、HTTP FastCGI 模块、HTTP Proxy 模块和 HTTP Rewrite 模块。</li>\n<li>第三方模块：HTTP Upstream Request Hash 模块、Notice 模块和 HTTP Access Key 模块及用户自己开发的模块。</li>\n</ul>\n<h2 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h2><p>nginx的配置有三大模块</p>\n<ol>\n<li>全局块</li>\n<li>event块</li>\n<li>http块</li>\n</ol>\n<h3 id=\"全局块\"><a href=\"#全局块\" class=\"headerlink\" title=\"全局块\"></a>全局块</h3><p>全局块负责一些全局的配置，部分配置如下</p>\n<ol>\n<li>user 规定运行nginx的用户和用户组</li>\n<li>worker_processes worker进程的数量</li>\n<li>worker_rlimit_nofile 一个worker进程最大的打开文件的数量</li>\n</ol>\n<h3 id=\"event块\"><a href=\"#event块\" class=\"headerlink\" title=\"event块\"></a>event块</h3><p>event块里的配置是有关事件的，部分配置如下</p>\n<ol>\n<li>worker_connections 一个work进程能够处理的最大的连接数</li>\n<li>accept_mutex 当一个新连接到达时，如果激活了accept_mutex，那么多个Worker将以串行方式来处理，其中有一个Worker会被唤醒，其他的Worker继续保持休眠状态；如果没有激活accept_mutex，那么所有的Worker都会被唤醒，不过只有一个Worker能获取新连接，其它的Worker会重新进入休眠状态</li>\n<li>use epoll 使用epoll来管理io事件</li>\n</ol>\n<h3 id=\"http块\"><a href=\"#http块\" class=\"headerlink\" title=\"http块\"></a>http块</h3><p>http块中的配置包含两部分，公共部分和server部分。公共部分是所有server都采用的，server部分是每个server单独采用的。</p>\n<h4 id=\"公共配置\"><a href=\"#公共配置\" class=\"headerlink\" title=\"公共配置\"></a>公共配置</h4><ol>\n<li>client_header_buffer_size 请求头缓冲区大小</li>\n<li>large_client_header_buffers 当请求头太大的时候client_header_buffer_size放不下了，会向large_client_header_buffers申请一块额外的内存</li>\n<li>client_max_body_size 请求body的最大</li>\n<li>client_body_timeout 读取请求body的超时时间</li>\n<li>client_header_timeout 读取请求header的超时时间</li>\n<li>log_format access_log的日志格式</li>\n<li>sendfile 支持“零拷贝”</li>\n<li>keepalive_timeout 长连接的超时时间。超时后会nginx会释放socket资源。如果客户端再想通信需重新3次握手</li>\n</ol>\n<h4 id=\"server配置\"><a href=\"#server配置\" class=\"headerlink\" title=\"server配置\"></a>server配置</h4><p>server配置中一般会有多个location，把不同的url分配给不同的下游服务</p>\n<p>nginx中以$开头的都是nginx的变量。nginx在把请求发给fastcgi之前会把nginx的变量转化成fastcgi变量。fastcgi的变量由大写字母和下划线组成。在php的进程中，fastcgi的变量都在SERVERA全局数组中。</p>\n<h5 id=\"rewrite\"><a href=\"#rewrite\" class=\"headerlink\" title=\"rewrite\"></a>rewrite</h5><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (!-e <span class=\"variable\">$request_filename</span>) &#123;</span><br><span class=\"line\">    rewrite ^(.*)$ /index.php?_url=<span class=\"variable\">$1</span> last;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>$request_filename是根路径拼接的uri(域名后面的一段)。如果用户请求的不是一个文件那么久将进行重写。重写的规则是请求根域名下的index.php,而uri变成了_url参数</p>\n<p>rewrite最后会有一个标识符</p>\n<ul>\n<li>break url重写后，直接使用当前资源，不再执行location里余下的语句，完成本次请求，地址栏url不变 </li>\n<li>last url重写后，马上发起一个新的请求，再次进入server块，重试location匹配，超过10次匹配不到报500错误，地址栏url不变</li>\n<li>redirect 返回302临时重定向，地址栏显示重定向后的url，爬虫不会更新url（因为是临时）</li>\n<li>permanent 返回301永久重定向, 地址栏显示重定向后的url，爬虫更新url</li>\n</ul>\n<h5 id=\"location\"><a href=\"#location\" class=\"headerlink\" title=\"location\"></a>location</h5><p>在匹配location的时候</p>\n<ul>\n<li>=  精确匹配</li>\n<li>~  表示大小写敏感的正则匹配</li>\n<li>~* 表示大小写不敏感的正则匹配</li>\n</ul>\n<p>以php为例。以.php为结尾的请求都转给fastcgi</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location ~ \\.php$ &#123;</span><br><span class=\"line\">    <span class=\"built_in\">set</span> <span class=\"variable\">$real_script_name</span> <span class=\"variable\">$fastcgi_script_name</span>;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"variable\">$fastcgi_script_name</span> ~ /lianjia(/.*)$) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">set</span> <span class=\"variable\">$real_script_name</span> <span class=\"variable\">$1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    fastcgi_pass    127.0.0.1:18181;</span><br><span class=\"line\">    fastcgi_index  index.php;</span><br><span class=\"line\">    fastcgi_param  SCRIPT_FILENAME <span class=\"variable\">$document_root</span><span class=\"variable\">$real_script_name</span>;</span><br><span class=\"line\">    include        tengine.fastcgi_params;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"负载均衡\"><a href=\"#负载均衡\" class=\"headerlink\" title=\"负载均衡\"></a>负载均衡</h2><p>nginx的负载均衡策略有三种</p>\n<ol>\n<li>平均分配</li>\n<li>根据权重</li>\n<li>根据客户端的ip</li>\n</ol>\n<p>无论哪一种，如果其中的一台机器出问题了，nginx会自动剔除，用起来很方便</p>\n<h3 id=\"平均负载\"><a href=\"#平均负载\" class=\"headerlink\" title=\"平均负载\"></a>平均负载</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http&#123;</span><br><span class=\"line\">    <span class=\"comment\"># 待选服务器列表</span></span><br><span class=\"line\">    upstream myproject&#123;</span><br><span class=\"line\">        server 125.219.42.4;</span><br><span class=\"line\">        server 172.31.2.183;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    server&#123;</span><br><span class=\"line\">        listen 80; </span><br><span class=\"line\">        location / &#123;            </span><br><span class=\"line\">            proxy_pass http://myproject;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"根据权重负载\"><a href=\"#根据权重负载\" class=\"headerlink\" title=\"根据权重负载\"></a>根据权重负载</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http&#123;</span><br><span class=\"line\">    <span class=\"comment\"># 待选服务器列表</span></span><br><span class=\"line\">    upstream myproject&#123;</span><br><span class=\"line\">        server 125.219.42.4 weight 1;</span><br><span class=\"line\">        server 172.31.2.183 weight 2;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    server&#123;</span><br><span class=\"line\">        listen 80; </span><br><span class=\"line\">        location / &#123;            </span><br><span class=\"line\">            proxy_pass http://myproject;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"根据用户ip负载\"><a href=\"#根据用户ip负载\" class=\"headerlink\" title=\"根据用户ip负载\"></a>根据用户ip负载</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http&#123;</span><br><span class=\"line\">    <span class=\"comment\"># 待选服务器列表</span></span><br><span class=\"line\">    upstream myproject&#123;</span><br><span class=\"line\">        ip_hash;</span><br><span class=\"line\">        server 125.219.42.4;</span><br><span class=\"line\">        server 172.31.2.183;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    server&#123;</span><br><span class=\"line\">        listen 80; </span><br><span class=\"line\">        location / &#123;            </span><br><span class=\"line\">            proxy_pass http://myproject;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"Basic Paxos 与 Multi Paxos","date":"2020-03-14T14:25:13.000Z","tags":["分布式"],"photos":[["https://sysummerblog.club/yizhi.jpg"]],"_content":"Paxos算法是Leslie Lamport于1990年提出的一种基于消息传递且具有高度容错特性的一致性算法，是目前公认的解决分布式一致性问题最有效的算法之一。\n<!--more-->\n这篇文章是基于[Paxos算法详解](https://zhuanlan.zhihu.com/p/31780743)加上自己的理解和总结完成的。\n## Basic Paxos\n### 角色\n![](https://sysummerblog.club/paxosjuese.jpg)\n1. proposer，负责接收客户端的请求并向acceptor提prepare请求和accept请求。\n2. acceptor，接受proposer的请求并在特定情况下给与回复。\n3. learner，不参与决策，学习最终达成一致的提案，一旦有多数acceptor对值达成了共识那么就写入值。\n\n### 流程\n![](https://sysummerblog.club/paxos%E6%B5%81%E7%A8%8B.jpg)\n在说流程前先确定几个名词的意义\n* max_proposal_id acceptor目前通过prepare请求收到的最大的proposal的id\n* accept_id acceptor目前决定要accept的proposal的id\n\n下面是流程：\n1. 一个客户端请求将一个字段值变成value。proposer为每一个客户端的请求封装成一个proposal，并为这个proposal生成一个去全局唯一的proposal_id。\n2. proposal向所有的acceptor发送prepare请求，请求中包含proposal_id，可以不包含value。\n3. acceptor对prepare请求进行处理。如果请求中的proposal_id大于max_proposal_id，那么acceptor是接受这个proposal的，会把自己的max_proposal_id更新成proposal_id同时会返回给proposer当前自己已经accept的proposal的value，如果自己之前没有accept任何proposal则会返回空（让proposer自己去决定下一步accept的时候使用哪个value）。如果请求中的proposal_id小于max_proposal_id，则不做回应。\n4. 如果proposer收到了多一半的acceptor的回应时，会挑出最大的value，如果所有的value都为空就用自己的value。\n5. proposer用第4步获得的value和自己的proposal_id发起accept请求。\n6. acceptor处理accept请求。如果请求中的proposal_id大于等于acceptor的max_proposal_id，那么会更新自己的accept_id、max_proposal_id，同时accept这个proposal。如果请求中的proposal_id小于acceptor的max_proposal_id那么会直接返回max_proposal_id。\n7. proposal收到了多一半acceptor的结果后，如果发现有结果大于自己的proposal_id的则说明accept了别的proposal，会从步骤1开始重新执行。\n\n下面想做几点说明\n\n1. prepare返回的结果中是acceptor希望尽快达成共识的value（也就是一个acceptor已经accept的value），所以一个proposer发起accept的value不一定使自己的value。\n2. prepare通俗点来说的话就是acceptor“决定”讨论哪个proposal，决定的尺度很简单就是要大于acceptor之前已经决定讨论过的proposal_id的最大值。accept通俗来讲就是决定接受一个value。当多一半acceptor接受一个value后整个流程也就结束了。\n3. basic paxos有局限性。他必须走完一轮流程后才能走下一轮流程，因为它没有日志的概念。\n4. basic paxos会有活锁的可能。\n\n下面是几个案例。s1提出把值更新为x，s5提出把值更新成y。P代表prepare阶段，A代表accept阶段。s1的proposal_id是3.1，s5的proposal_id是4.5。\n![](https://sysummerblog.club/paxos%E6%A1%88%E4%BE%8B1.jpg)\n\ns1的proposal已经被大多数accept了，此时s5的prepare发出后，如果有大多数acceptor返回那么返回的结果中要不是x要不是空而且x一定存在。所以s5的accept请求中的value是想而不是自己的y。最终的结果是x被写入。s5的y只能走下一轮的流程。\n\n![](https://sysummerblog.club/paxos%E7%A4%BA%E4%BE%8B2.jpg)\n\n如果s1的proposal只被一个acceptor请求，即s3，同时s5的prepare请求收到了s3的回应，那么s5的accept请求中的值还是x\n\n![](https://sysummerblog.club/paxos%E7%A4%BA%E4%BE%8B3.jpg)\n这个案例的情况与上面的正好相反，s1的proposal只被s1自己accept了，而s5的prepare返回的结果中不包含s1的结果，此时s5就会用自己的值y来发起accept请求。\n\n## Multi Paxos\nmulti paxos算法中在所有proposers中选举一个leader，由leader唯一地提交proposal给acceptors进行表决。这样没有proposer竞争，解决了活锁问题。在系统中仅有一个leader进行value提交的情况下，prepare阶段就可以跳过，从而将两阶段变为一阶段，提高效率。\n\n既然所有的选举都走leader，那么leader就负责为每一个proposal生成一个全局唯一的proposal_id。leader的选举算法可以使用basic paxos,需要两段请求，而且有活锁的可能。一单选出leader就不用再经历prepare阶段了。\n\n## 总结\n上面的两个算法是强一致性的。虽然这两个算法中也有“大多数”的概念，但是这个大多数与raft和zab中的又不大一样。paxos中的大多数的作用是决定写入哪个值，一单给客户端返回结果那么各个节点的值一定是最新的，即强一致性。raft与zba中只要大多数节点的值写入就返回，是最终一致性，他们的“大多数”是为了高可用。\n\n","source":"posts/paxos.md","raw":"---\ntitle: Basic Paxos 与 Multi Paxos\ndate: 2020-03-14 22:25:13\ntags:\n   - 分布式\nphotos:\n   - [\"https://sysummerblog.club/yizhi.jpg\"]\n---\nPaxos算法是Leslie Lamport于1990年提出的一种基于消息传递且具有高度容错特性的一致性算法，是目前公认的解决分布式一致性问题最有效的算法之一。\n<!--more-->\n这篇文章是基于[Paxos算法详解](https://zhuanlan.zhihu.com/p/31780743)加上自己的理解和总结完成的。\n## Basic Paxos\n### 角色\n![](https://sysummerblog.club/paxosjuese.jpg)\n1. proposer，负责接收客户端的请求并向acceptor提prepare请求和accept请求。\n2. acceptor，接受proposer的请求并在特定情况下给与回复。\n3. learner，不参与决策，学习最终达成一致的提案，一旦有多数acceptor对值达成了共识那么就写入值。\n\n### 流程\n![](https://sysummerblog.club/paxos%E6%B5%81%E7%A8%8B.jpg)\n在说流程前先确定几个名词的意义\n* max_proposal_id acceptor目前通过prepare请求收到的最大的proposal的id\n* accept_id acceptor目前决定要accept的proposal的id\n\n下面是流程：\n1. 一个客户端请求将一个字段值变成value。proposer为每一个客户端的请求封装成一个proposal，并为这个proposal生成一个去全局唯一的proposal_id。\n2. proposal向所有的acceptor发送prepare请求，请求中包含proposal_id，可以不包含value。\n3. acceptor对prepare请求进行处理。如果请求中的proposal_id大于max_proposal_id，那么acceptor是接受这个proposal的，会把自己的max_proposal_id更新成proposal_id同时会返回给proposer当前自己已经accept的proposal的value，如果自己之前没有accept任何proposal则会返回空（让proposer自己去决定下一步accept的时候使用哪个value）。如果请求中的proposal_id小于max_proposal_id，则不做回应。\n4. 如果proposer收到了多一半的acceptor的回应时，会挑出最大的value，如果所有的value都为空就用自己的value。\n5. proposer用第4步获得的value和自己的proposal_id发起accept请求。\n6. acceptor处理accept请求。如果请求中的proposal_id大于等于acceptor的max_proposal_id，那么会更新自己的accept_id、max_proposal_id，同时accept这个proposal。如果请求中的proposal_id小于acceptor的max_proposal_id那么会直接返回max_proposal_id。\n7. proposal收到了多一半acceptor的结果后，如果发现有结果大于自己的proposal_id的则说明accept了别的proposal，会从步骤1开始重新执行。\n\n下面想做几点说明\n\n1. prepare返回的结果中是acceptor希望尽快达成共识的value（也就是一个acceptor已经accept的value），所以一个proposer发起accept的value不一定使自己的value。\n2. prepare通俗点来说的话就是acceptor“决定”讨论哪个proposal，决定的尺度很简单就是要大于acceptor之前已经决定讨论过的proposal_id的最大值。accept通俗来讲就是决定接受一个value。当多一半acceptor接受一个value后整个流程也就结束了。\n3. basic paxos有局限性。他必须走完一轮流程后才能走下一轮流程，因为它没有日志的概念。\n4. basic paxos会有活锁的可能。\n\n下面是几个案例。s1提出把值更新为x，s5提出把值更新成y。P代表prepare阶段，A代表accept阶段。s1的proposal_id是3.1，s5的proposal_id是4.5。\n![](https://sysummerblog.club/paxos%E6%A1%88%E4%BE%8B1.jpg)\n\ns1的proposal已经被大多数accept了，此时s5的prepare发出后，如果有大多数acceptor返回那么返回的结果中要不是x要不是空而且x一定存在。所以s5的accept请求中的value是想而不是自己的y。最终的结果是x被写入。s5的y只能走下一轮的流程。\n\n![](https://sysummerblog.club/paxos%E7%A4%BA%E4%BE%8B2.jpg)\n\n如果s1的proposal只被一个acceptor请求，即s3，同时s5的prepare请求收到了s3的回应，那么s5的accept请求中的值还是x\n\n![](https://sysummerblog.club/paxos%E7%A4%BA%E4%BE%8B3.jpg)\n这个案例的情况与上面的正好相反，s1的proposal只被s1自己accept了，而s5的prepare返回的结果中不包含s1的结果，此时s5就会用自己的值y来发起accept请求。\n\n## Multi Paxos\nmulti paxos算法中在所有proposers中选举一个leader，由leader唯一地提交proposal给acceptors进行表决。这样没有proposer竞争，解决了活锁问题。在系统中仅有一个leader进行value提交的情况下，prepare阶段就可以跳过，从而将两阶段变为一阶段，提高效率。\n\n既然所有的选举都走leader，那么leader就负责为每一个proposal生成一个全局唯一的proposal_id。leader的选举算法可以使用basic paxos,需要两段请求，而且有活锁的可能。一单选出leader就不用再经历prepare阶段了。\n\n## 总结\n上面的两个算法是强一致性的。虽然这两个算法中也有“大多数”的概念，但是这个大多数与raft和zab中的又不大一样。paxos中的大多数的作用是决定写入哪个值，一单给客户端返回结果那么各个节点的值一定是最新的，即强一致性。raft与zba中只要大多数节点的值写入就返回，是最终一致性，他们的“大多数”是为了高可用。\n\n","updated":"2020-11-23T15:20:08.940Z","path":"posts/paxos.html","comments":1,"layout":"page","_id":"ckhupaq9u000x1no8bwvvsb4n","content":"<p>Paxos算法是Leslie Lamport于1990年提出的一种基于消息传递且具有高度容错特性的一致性算法，是目前公认的解决分布式一致性问题最有效的算法之一。</p>\n<a id=\"more\"></a>\n<p>这篇文章是基于<a href=\"https://zhuanlan.zhihu.com/p/31780743\" target=\"_blank\" rel=\"noopener\">Paxos算法详解</a>加上自己的理解和总结完成的。</p>\n<h2 id=\"Basic-Paxos\"><a href=\"#Basic-Paxos\" class=\"headerlink\" title=\"Basic Paxos\"></a>Basic Paxos</h2><h3 id=\"角色\"><a href=\"#角色\" class=\"headerlink\" title=\"角色\"></a>角色</h3><p><img src=\"https://sysummerblog.club/paxosjuese.jpg\" alt></p>\n<ol>\n<li>proposer，负责接收客户端的请求并向acceptor提prepare请求和accept请求。</li>\n<li>acceptor，接受proposer的请求并在特定情况下给与回复。</li>\n<li>learner，不参与决策，学习最终达成一致的提案，一旦有多数acceptor对值达成了共识那么就写入值。</li>\n</ol>\n<h3 id=\"流程\"><a href=\"#流程\" class=\"headerlink\" title=\"流程\"></a>流程</h3><p><img src=\"https://sysummerblog.club/paxos%E6%B5%81%E7%A8%8B.jpg\" alt><br>在说流程前先确定几个名词的意义</p>\n<ul>\n<li>max_proposal_id acceptor目前通过prepare请求收到的最大的proposal的id</li>\n<li>accept_id acceptor目前决定要accept的proposal的id</li>\n</ul>\n<p>下面是流程：</p>\n<ol>\n<li>一个客户端请求将一个字段值变成value。proposer为每一个客户端的请求封装成一个proposal，并为这个proposal生成一个去全局唯一的proposal_id。</li>\n<li>proposal向所有的acceptor发送prepare请求，请求中包含proposal_id，可以不包含value。</li>\n<li>acceptor对prepare请求进行处理。如果请求中的proposal_id大于max_proposal_id，那么acceptor是接受这个proposal的，会把自己的max_proposal_id更新成proposal_id同时会返回给proposer当前自己已经accept的proposal的value，如果自己之前没有accept任何proposal则会返回空（让proposer自己去决定下一步accept的时候使用哪个value）。如果请求中的proposal_id小于max_proposal_id，则不做回应。</li>\n<li>如果proposer收到了多一半的acceptor的回应时，会挑出最大的value，如果所有的value都为空就用自己的value。</li>\n<li>proposer用第4步获得的value和自己的proposal_id发起accept请求。</li>\n<li>acceptor处理accept请求。如果请求中的proposal_id大于等于acceptor的max_proposal_id，那么会更新自己的accept_id、max_proposal_id，同时accept这个proposal。如果请求中的proposal_id小于acceptor的max_proposal_id那么会直接返回max_proposal_id。</li>\n<li>proposal收到了多一半acceptor的结果后，如果发现有结果大于自己的proposal_id的则说明accept了别的proposal，会从步骤1开始重新执行。</li>\n</ol>\n<p>下面想做几点说明</p>\n<ol>\n<li>prepare返回的结果中是acceptor希望尽快达成共识的value（也就是一个acceptor已经accept的value），所以一个proposer发起accept的value不一定使自己的value。</li>\n<li>prepare通俗点来说的话就是acceptor“决定”讨论哪个proposal，决定的尺度很简单就是要大于acceptor之前已经决定讨论过的proposal_id的最大值。accept通俗来讲就是决定接受一个value。当多一半acceptor接受一个value后整个流程也就结束了。</li>\n<li>basic paxos有局限性。他必须走完一轮流程后才能走下一轮流程，因为它没有日志的概念。</li>\n<li>basic paxos会有活锁的可能。</li>\n</ol>\n<p>下面是几个案例。s1提出把值更新为x，s5提出把值更新成y。P代表prepare阶段，A代表accept阶段。s1的proposal_id是3.1，s5的proposal_id是4.5。<br><img src=\"https://sysummerblog.club/paxos%E6%A1%88%E4%BE%8B1.jpg\" alt></p>\n<p>s1的proposal已经被大多数accept了，此时s5的prepare发出后，如果有大多数acceptor返回那么返回的结果中要不是x要不是空而且x一定存在。所以s5的accept请求中的value是想而不是自己的y。最终的结果是x被写入。s5的y只能走下一轮的流程。</p>\n<p><img src=\"https://sysummerblog.club/paxos%E7%A4%BA%E4%BE%8B2.jpg\" alt></p>\n<p>如果s1的proposal只被一个acceptor请求，即s3，同时s5的prepare请求收到了s3的回应，那么s5的accept请求中的值还是x</p>\n<p><img src=\"https://sysummerblog.club/paxos%E7%A4%BA%E4%BE%8B3.jpg\" alt><br>这个案例的情况与上面的正好相反，s1的proposal只被s1自己accept了，而s5的prepare返回的结果中不包含s1的结果，此时s5就会用自己的值y来发起accept请求。</p>\n<h2 id=\"Multi-Paxos\"><a href=\"#Multi-Paxos\" class=\"headerlink\" title=\"Multi Paxos\"></a>Multi Paxos</h2><p>multi paxos算法中在所有proposers中选举一个leader，由leader唯一地提交proposal给acceptors进行表决。这样没有proposer竞争，解决了活锁问题。在系统中仅有一个leader进行value提交的情况下，prepare阶段就可以跳过，从而将两阶段变为一阶段，提高效率。</p>\n<p>既然所有的选举都走leader，那么leader就负责为每一个proposal生成一个全局唯一的proposal_id。leader的选举算法可以使用basic paxos,需要两段请求，而且有活锁的可能。一单选出leader就不用再经历prepare阶段了。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>上面的两个算法是强一致性的。虽然这两个算法中也有“大多数”的概念，但是这个大多数与raft和zab中的又不大一样。paxos中的大多数的作用是决定写入哪个值，一单给客户端返回结果那么各个节点的值一定是最新的，即强一致性。raft与zba中只要大多数节点的值写入就返回，是最终一致性，他们的“大多数”是为了高可用。</p>\n","site":{"data":{}},"excerpt":"<p>Paxos算法是Leslie Lamport于1990年提出的一种基于消息传递且具有高度容错特性的一致性算法，是目前公认的解决分布式一致性问题最有效的算法之一。</p>","more":"<p>这篇文章是基于<a href=\"https://zhuanlan.zhihu.com/p/31780743\" target=\"_blank\" rel=\"noopener\">Paxos算法详解</a>加上自己的理解和总结完成的。</p>\n<h2 id=\"Basic-Paxos\"><a href=\"#Basic-Paxos\" class=\"headerlink\" title=\"Basic Paxos\"></a>Basic Paxos</h2><h3 id=\"角色\"><a href=\"#角色\" class=\"headerlink\" title=\"角色\"></a>角色</h3><p><img src=\"https://sysummerblog.club/paxosjuese.jpg\" alt></p>\n<ol>\n<li>proposer，负责接收客户端的请求并向acceptor提prepare请求和accept请求。</li>\n<li>acceptor，接受proposer的请求并在特定情况下给与回复。</li>\n<li>learner，不参与决策，学习最终达成一致的提案，一旦有多数acceptor对值达成了共识那么就写入值。</li>\n</ol>\n<h3 id=\"流程\"><a href=\"#流程\" class=\"headerlink\" title=\"流程\"></a>流程</h3><p><img src=\"https://sysummerblog.club/paxos%E6%B5%81%E7%A8%8B.jpg\" alt><br>在说流程前先确定几个名词的意义</p>\n<ul>\n<li>max_proposal_id acceptor目前通过prepare请求收到的最大的proposal的id</li>\n<li>accept_id acceptor目前决定要accept的proposal的id</li>\n</ul>\n<p>下面是流程：</p>\n<ol>\n<li>一个客户端请求将一个字段值变成value。proposer为每一个客户端的请求封装成一个proposal，并为这个proposal生成一个去全局唯一的proposal_id。</li>\n<li>proposal向所有的acceptor发送prepare请求，请求中包含proposal_id，可以不包含value。</li>\n<li>acceptor对prepare请求进行处理。如果请求中的proposal_id大于max_proposal_id，那么acceptor是接受这个proposal的，会把自己的max_proposal_id更新成proposal_id同时会返回给proposer当前自己已经accept的proposal的value，如果自己之前没有accept任何proposal则会返回空（让proposer自己去决定下一步accept的时候使用哪个value）。如果请求中的proposal_id小于max_proposal_id，则不做回应。</li>\n<li>如果proposer收到了多一半的acceptor的回应时，会挑出最大的value，如果所有的value都为空就用自己的value。</li>\n<li>proposer用第4步获得的value和自己的proposal_id发起accept请求。</li>\n<li>acceptor处理accept请求。如果请求中的proposal_id大于等于acceptor的max_proposal_id，那么会更新自己的accept_id、max_proposal_id，同时accept这个proposal。如果请求中的proposal_id小于acceptor的max_proposal_id那么会直接返回max_proposal_id。</li>\n<li>proposal收到了多一半acceptor的结果后，如果发现有结果大于自己的proposal_id的则说明accept了别的proposal，会从步骤1开始重新执行。</li>\n</ol>\n<p>下面想做几点说明</p>\n<ol>\n<li>prepare返回的结果中是acceptor希望尽快达成共识的value（也就是一个acceptor已经accept的value），所以一个proposer发起accept的value不一定使自己的value。</li>\n<li>prepare通俗点来说的话就是acceptor“决定”讨论哪个proposal，决定的尺度很简单就是要大于acceptor之前已经决定讨论过的proposal_id的最大值。accept通俗来讲就是决定接受一个value。当多一半acceptor接受一个value后整个流程也就结束了。</li>\n<li>basic paxos有局限性。他必须走完一轮流程后才能走下一轮流程，因为它没有日志的概念。</li>\n<li>basic paxos会有活锁的可能。</li>\n</ol>\n<p>下面是几个案例。s1提出把值更新为x，s5提出把值更新成y。P代表prepare阶段，A代表accept阶段。s1的proposal_id是3.1，s5的proposal_id是4.5。<br><img src=\"https://sysummerblog.club/paxos%E6%A1%88%E4%BE%8B1.jpg\" alt></p>\n<p>s1的proposal已经被大多数accept了，此时s5的prepare发出后，如果有大多数acceptor返回那么返回的结果中要不是x要不是空而且x一定存在。所以s5的accept请求中的value是想而不是自己的y。最终的结果是x被写入。s5的y只能走下一轮的流程。</p>\n<p><img src=\"https://sysummerblog.club/paxos%E7%A4%BA%E4%BE%8B2.jpg\" alt></p>\n<p>如果s1的proposal只被一个acceptor请求，即s3，同时s5的prepare请求收到了s3的回应，那么s5的accept请求中的值还是x</p>\n<p><img src=\"https://sysummerblog.club/paxos%E7%A4%BA%E4%BE%8B3.jpg\" alt><br>这个案例的情况与上面的正好相反，s1的proposal只被s1自己accept了，而s5的prepare返回的结果中不包含s1的结果，此时s5就会用自己的值y来发起accept请求。</p>\n<h2 id=\"Multi-Paxos\"><a href=\"#Multi-Paxos\" class=\"headerlink\" title=\"Multi Paxos\"></a>Multi Paxos</h2><p>multi paxos算法中在所有proposers中选举一个leader，由leader唯一地提交proposal给acceptors进行表决。这样没有proposer竞争，解决了活锁问题。在系统中仅有一个leader进行value提交的情况下，prepare阶段就可以跳过，从而将两阶段变为一阶段，提高效率。</p>\n<p>既然所有的选举都走leader，那么leader就负责为每一个proposal生成一个全局唯一的proposal_id。leader的选举算法可以使用basic paxos,需要两段请求，而且有活锁的可能。一单选出leader就不用再经历prepare阶段了。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>上面的两个算法是强一致性的。虽然这两个算法中也有“大多数”的概念，但是这个大多数与raft和zab中的又不大一样。paxos中的大多数的作用是决定写入哪个值，一单给客户端返回结果那么各个节点的值一定是最新的，即强一致性。raft与zba中只要大多数节点的值写入就返回，是最终一致性，他们的“大多数”是为了高可用。</p>"},{"title":"Raft协议学习笔记","date":"2020-03-15T13:03:50.000Z","tags":["分布式"],"photos":[["https://sysummerblog.club/raft.jpg"]],"_content":"raft也是分布式系统的一个共识算法，号称比paxos更容易理解。\n<!--more-->\n## 状态机\nraft中有一个状态机的概念。如果多个节点的初始状态相同，所经历的操作（日志中记录的command）以及这些操作的顺序一致，那么每个节点最终的状态是一致的。\n\n## 节点的角色\nraft协议里面的角色有三类\n\n* leader 领导者\n* follower 追随者\n* candidate 候选者\n\n每一个节点一开始都是follower, 每个folloewr都会一个随机的“超时时间”，一但超时时间到了之后follower没有接收到leader的心跳自己就会变成candidate,然后发起一轮竞选，如果能收到大多数的票数就是竞选成功称为leader。因此raft中哪个节点的随机超时时间短，最开始就哪个节点有可能成为leader。\n\n## leader的选举\n1. leader节点维护着自己与follower的心跳。一但follower在自己的超时时间内没有收到leader的心跳，就变成candidate并发起选举并投自己一票。\n2. 给其他节点发送vote rpc请求\n3. 等待结果，如果收到大多数的票数，那么自己就是leader，此时会给其他的节点发送rpc消息告诉他们“我是leader”；如果被告知别人当选就变成follower。如果票数被瓜分，那么等到超时时间过了以后再次发起选举。\n\n当一个节点收到别人的选票的时候怎么判断是“投他还是投自己”？方法是比较term和entry log id。term可以理解为leader的任期，每个节点发起一轮选举的时候都会将自己的本地term_id自增，如果收到的投票的term比自己的小那么不会回复，如果比自己的大则投票给对方，如果一样就比较entry log id如果entry  log id大就投票给对方否则不投。entry log id是该节点在该term下的最大的entry log id。\n\n所以raft中因为随机超时时间的存在，极大地避免了同一时刻多个节点同时竞选的情形。能不能当leader取决于你现在的数据”够不够新“。\n\n### 怎么确保只有一个leader\n1. 在一个选举周期里（一个term内），一个节点只能投一票。\n2. 获得大半数票的节点才能成为leader。\n3. 获得leader的节点的term以及entry log id不能落后于其他的节点。\n4. 每个结点的“超时时间”是随机的，可以认为每个节点都不相同，同时竞选的可能性比较小。\n5. 如果一个leader 的term比另一个节点的term小，那么会自动变成follower\n\n## 数据的同步\n和zk的zab协议一样，raft也是先在大多数的节点上写入entry  log后，然后通知各个节点提交。但是在描述上二者有区别，raft第一阶段叫commit，第二阶段叫apply。log entry的示意图如下\n![](https://sysummerblog.club/raftlogentry.jpg)\n\nraft的每一个entry log都有一个entry log id，因此可以保证消息的顺序。\n\n### 正常的同步\n有了leader之后，集群的读写请求都要经过leader，follower只做备份。\n\n当leader收到一个写请求后会记录一个entry log，然后把这个entry发送给集群中的follower，其他的follower收到entry之后会发送确认信息给leader，如果leader收到超过一半的follower的确认信息之后就会把数据写进去（前面记录entry并不会apply数据），并通知其他follower写数据。\n\n任何一个follower重启后都会接收到leader的心跳，日志的内容也会与leader变成一致。\n\n如果是leader挂了，那么肯定是team和team index最大的那个称为新的leader\n\n### 重新选举leader后的数据同步\n这个我想说的通俗点，就是leader与follower比较各自已经commit的entrty log id。直至找到二者的第一个”共同点“。之后leader就会把”共同点“后面的entrty log同步给follower。\n\n下图是一个leader节点对应的follower的状态\n![](https://sysummerblog.club/raftlandf.png)\n\n如果follower是b,那么leader与follower会先找到term为4 entrty log id为4的日志的位置作为”共同点“，之后leader会把”共同点“后面的日志同步给follower。\n\n### State Machine Safety\n如果一个节点在某一个log entry的位置apply了这条log里面的command，那么其他节点也必须在这个log entry的位置apply这条log。\n","source":"posts/raft-note.md","raw":"---\ntitle: Raft协议学习笔记\ndate: 2020-03-15 21:03:50\ntags:\n   - 分布式\nphotos:\n   - [\"https://sysummerblog.club/raft.jpg\"]\n---\nraft也是分布式系统的一个共识算法，号称比paxos更容易理解。\n<!--more-->\n## 状态机\nraft中有一个状态机的概念。如果多个节点的初始状态相同，所经历的操作（日志中记录的command）以及这些操作的顺序一致，那么每个节点最终的状态是一致的。\n\n## 节点的角色\nraft协议里面的角色有三类\n\n* leader 领导者\n* follower 追随者\n* candidate 候选者\n\n每一个节点一开始都是follower, 每个folloewr都会一个随机的“超时时间”，一但超时时间到了之后follower没有接收到leader的心跳自己就会变成candidate,然后发起一轮竞选，如果能收到大多数的票数就是竞选成功称为leader。因此raft中哪个节点的随机超时时间短，最开始就哪个节点有可能成为leader。\n\n## leader的选举\n1. leader节点维护着自己与follower的心跳。一但follower在自己的超时时间内没有收到leader的心跳，就变成candidate并发起选举并投自己一票。\n2. 给其他节点发送vote rpc请求\n3. 等待结果，如果收到大多数的票数，那么自己就是leader，此时会给其他的节点发送rpc消息告诉他们“我是leader”；如果被告知别人当选就变成follower。如果票数被瓜分，那么等到超时时间过了以后再次发起选举。\n\n当一个节点收到别人的选票的时候怎么判断是“投他还是投自己”？方法是比较term和entry log id。term可以理解为leader的任期，每个节点发起一轮选举的时候都会将自己的本地term_id自增，如果收到的投票的term比自己的小那么不会回复，如果比自己的大则投票给对方，如果一样就比较entry log id如果entry  log id大就投票给对方否则不投。entry log id是该节点在该term下的最大的entry log id。\n\n所以raft中因为随机超时时间的存在，极大地避免了同一时刻多个节点同时竞选的情形。能不能当leader取决于你现在的数据”够不够新“。\n\n### 怎么确保只有一个leader\n1. 在一个选举周期里（一个term内），一个节点只能投一票。\n2. 获得大半数票的节点才能成为leader。\n3. 获得leader的节点的term以及entry log id不能落后于其他的节点。\n4. 每个结点的“超时时间”是随机的，可以认为每个节点都不相同，同时竞选的可能性比较小。\n5. 如果一个leader 的term比另一个节点的term小，那么会自动变成follower\n\n## 数据的同步\n和zk的zab协议一样，raft也是先在大多数的节点上写入entry  log后，然后通知各个节点提交。但是在描述上二者有区别，raft第一阶段叫commit，第二阶段叫apply。log entry的示意图如下\n![](https://sysummerblog.club/raftlogentry.jpg)\n\nraft的每一个entry log都有一个entry log id，因此可以保证消息的顺序。\n\n### 正常的同步\n有了leader之后，集群的读写请求都要经过leader，follower只做备份。\n\n当leader收到一个写请求后会记录一个entry log，然后把这个entry发送给集群中的follower，其他的follower收到entry之后会发送确认信息给leader，如果leader收到超过一半的follower的确认信息之后就会把数据写进去（前面记录entry并不会apply数据），并通知其他follower写数据。\n\n任何一个follower重启后都会接收到leader的心跳，日志的内容也会与leader变成一致。\n\n如果是leader挂了，那么肯定是team和team index最大的那个称为新的leader\n\n### 重新选举leader后的数据同步\n这个我想说的通俗点，就是leader与follower比较各自已经commit的entrty log id。直至找到二者的第一个”共同点“。之后leader就会把”共同点“后面的entrty log同步给follower。\n\n下图是一个leader节点对应的follower的状态\n![](https://sysummerblog.club/raftlandf.png)\n\n如果follower是b,那么leader与follower会先找到term为4 entrty log id为4的日志的位置作为”共同点“，之后leader会把”共同点“后面的日志同步给follower。\n\n### State Machine Safety\n如果一个节点在某一个log entry的位置apply了这条log里面的command，那么其他节点也必须在这个log entry的位置apply这条log。\n","updated":"2020-11-23T15:20:08.939Z","path":"posts/raft-note.html","comments":1,"layout":"page","_id":"ckhupaq9w00101no8nrb8v8ya","content":"<p>raft也是分布式系统的一个共识算法，号称比paxos更容易理解。</p>\n<a id=\"more\"></a>\n<h2 id=\"状态机\"><a href=\"#状态机\" class=\"headerlink\" title=\"状态机\"></a>状态机</h2><p>raft中有一个状态机的概念。如果多个节点的初始状态相同，所经历的操作（日志中记录的command）以及这些操作的顺序一致，那么每个节点最终的状态是一致的。</p>\n<h2 id=\"节点的角色\"><a href=\"#节点的角色\" class=\"headerlink\" title=\"节点的角色\"></a>节点的角色</h2><p>raft协议里面的角色有三类</p>\n<ul>\n<li>leader 领导者</li>\n<li>follower 追随者</li>\n<li>candidate 候选者</li>\n</ul>\n<p>每一个节点一开始都是follower, 每个folloewr都会一个随机的“超时时间”，一但超时时间到了之后follower没有接收到leader的心跳自己就会变成candidate,然后发起一轮竞选，如果能收到大多数的票数就是竞选成功称为leader。因此raft中哪个节点的随机超时时间短，最开始就哪个节点有可能成为leader。</p>\n<h2 id=\"leader的选举\"><a href=\"#leader的选举\" class=\"headerlink\" title=\"leader的选举\"></a>leader的选举</h2><ol>\n<li>leader节点维护着自己与follower的心跳。一但follower在自己的超时时间内没有收到leader的心跳，就变成candidate并发起选举并投自己一票。</li>\n<li>给其他节点发送vote rpc请求</li>\n<li>等待结果，如果收到大多数的票数，那么自己就是leader，此时会给其他的节点发送rpc消息告诉他们“我是leader”；如果被告知别人当选就变成follower。如果票数被瓜分，那么等到超时时间过了以后再次发起选举。</li>\n</ol>\n<p>当一个节点收到别人的选票的时候怎么判断是“投他还是投自己”？方法是比较term和entry log id。term可以理解为leader的任期，每个节点发起一轮选举的时候都会将自己的本地term_id自增，如果收到的投票的term比自己的小那么不会回复，如果比自己的大则投票给对方，如果一样就比较entry log id如果entry  log id大就投票给对方否则不投。entry log id是该节点在该term下的最大的entry log id。</p>\n<p>所以raft中因为随机超时时间的存在，极大地避免了同一时刻多个节点同时竞选的情形。能不能当leader取决于你现在的数据”够不够新“。</p>\n<h3 id=\"怎么确保只有一个leader\"><a href=\"#怎么确保只有一个leader\" class=\"headerlink\" title=\"怎么确保只有一个leader\"></a>怎么确保只有一个leader</h3><ol>\n<li>在一个选举周期里（一个term内），一个节点只能投一票。</li>\n<li>获得大半数票的节点才能成为leader。</li>\n<li>获得leader的节点的term以及entry log id不能落后于其他的节点。</li>\n<li>每个结点的“超时时间”是随机的，可以认为每个节点都不相同，同时竞选的可能性比较小。</li>\n<li>如果一个leader 的term比另一个节点的term小，那么会自动变成follower</li>\n</ol>\n<h2 id=\"数据的同步\"><a href=\"#数据的同步\" class=\"headerlink\" title=\"数据的同步\"></a>数据的同步</h2><p>和zk的zab协议一样，raft也是先在大多数的节点上写入entry  log后，然后通知各个节点提交。但是在描述上二者有区别，raft第一阶段叫commit，第二阶段叫apply。log entry的示意图如下<br><img src=\"https://sysummerblog.club/raftlogentry.jpg\" alt></p>\n<p>raft的每一个entry log都有一个entry log id，因此可以保证消息的顺序。</p>\n<h3 id=\"正常的同步\"><a href=\"#正常的同步\" class=\"headerlink\" title=\"正常的同步\"></a>正常的同步</h3><p>有了leader之后，集群的读写请求都要经过leader，follower只做备份。</p>\n<p>当leader收到一个写请求后会记录一个entry log，然后把这个entry发送给集群中的follower，其他的follower收到entry之后会发送确认信息给leader，如果leader收到超过一半的follower的确认信息之后就会把数据写进去（前面记录entry并不会apply数据），并通知其他follower写数据。</p>\n<p>任何一个follower重启后都会接收到leader的心跳，日志的内容也会与leader变成一致。</p>\n<p>如果是leader挂了，那么肯定是team和team index最大的那个称为新的leader</p>\n<h3 id=\"重新选举leader后的数据同步\"><a href=\"#重新选举leader后的数据同步\" class=\"headerlink\" title=\"重新选举leader后的数据同步\"></a>重新选举leader后的数据同步</h3><p>这个我想说的通俗点，就是leader与follower比较各自已经commit的entrty log id。直至找到二者的第一个”共同点“。之后leader就会把”共同点“后面的entrty log同步给follower。</p>\n<p>下图是一个leader节点对应的follower的状态<br><img src=\"https://sysummerblog.club/raftlandf.png\" alt></p>\n<p>如果follower是b,那么leader与follower会先找到term为4 entrty log id为4的日志的位置作为”共同点“，之后leader会把”共同点“后面的日志同步给follower。</p>\n<h3 id=\"State-Machine-Safety\"><a href=\"#State-Machine-Safety\" class=\"headerlink\" title=\"State Machine Safety\"></a>State Machine Safety</h3><p>如果一个节点在某一个log entry的位置apply了这条log里面的command，那么其他节点也必须在这个log entry的位置apply这条log。</p>\n","site":{"data":{}},"excerpt":"<p>raft也是分布式系统的一个共识算法，号称比paxos更容易理解。</p>","more":"<h2 id=\"状态机\"><a href=\"#状态机\" class=\"headerlink\" title=\"状态机\"></a>状态机</h2><p>raft中有一个状态机的概念。如果多个节点的初始状态相同，所经历的操作（日志中记录的command）以及这些操作的顺序一致，那么每个节点最终的状态是一致的。</p>\n<h2 id=\"节点的角色\"><a href=\"#节点的角色\" class=\"headerlink\" title=\"节点的角色\"></a>节点的角色</h2><p>raft协议里面的角色有三类</p>\n<ul>\n<li>leader 领导者</li>\n<li>follower 追随者</li>\n<li>candidate 候选者</li>\n</ul>\n<p>每一个节点一开始都是follower, 每个folloewr都会一个随机的“超时时间”，一但超时时间到了之后follower没有接收到leader的心跳自己就会变成candidate,然后发起一轮竞选，如果能收到大多数的票数就是竞选成功称为leader。因此raft中哪个节点的随机超时时间短，最开始就哪个节点有可能成为leader。</p>\n<h2 id=\"leader的选举\"><a href=\"#leader的选举\" class=\"headerlink\" title=\"leader的选举\"></a>leader的选举</h2><ol>\n<li>leader节点维护着自己与follower的心跳。一但follower在自己的超时时间内没有收到leader的心跳，就变成candidate并发起选举并投自己一票。</li>\n<li>给其他节点发送vote rpc请求</li>\n<li>等待结果，如果收到大多数的票数，那么自己就是leader，此时会给其他的节点发送rpc消息告诉他们“我是leader”；如果被告知别人当选就变成follower。如果票数被瓜分，那么等到超时时间过了以后再次发起选举。</li>\n</ol>\n<p>当一个节点收到别人的选票的时候怎么判断是“投他还是投自己”？方法是比较term和entry log id。term可以理解为leader的任期，每个节点发起一轮选举的时候都会将自己的本地term_id自增，如果收到的投票的term比自己的小那么不会回复，如果比自己的大则投票给对方，如果一样就比较entry log id如果entry  log id大就投票给对方否则不投。entry log id是该节点在该term下的最大的entry log id。</p>\n<p>所以raft中因为随机超时时间的存在，极大地避免了同一时刻多个节点同时竞选的情形。能不能当leader取决于你现在的数据”够不够新“。</p>\n<h3 id=\"怎么确保只有一个leader\"><a href=\"#怎么确保只有一个leader\" class=\"headerlink\" title=\"怎么确保只有一个leader\"></a>怎么确保只有一个leader</h3><ol>\n<li>在一个选举周期里（一个term内），一个节点只能投一票。</li>\n<li>获得大半数票的节点才能成为leader。</li>\n<li>获得leader的节点的term以及entry log id不能落后于其他的节点。</li>\n<li>每个结点的“超时时间”是随机的，可以认为每个节点都不相同，同时竞选的可能性比较小。</li>\n<li>如果一个leader 的term比另一个节点的term小，那么会自动变成follower</li>\n</ol>\n<h2 id=\"数据的同步\"><a href=\"#数据的同步\" class=\"headerlink\" title=\"数据的同步\"></a>数据的同步</h2><p>和zk的zab协议一样，raft也是先在大多数的节点上写入entry  log后，然后通知各个节点提交。但是在描述上二者有区别，raft第一阶段叫commit，第二阶段叫apply。log entry的示意图如下<br><img src=\"https://sysummerblog.club/raftlogentry.jpg\" alt></p>\n<p>raft的每一个entry log都有一个entry log id，因此可以保证消息的顺序。</p>\n<h3 id=\"正常的同步\"><a href=\"#正常的同步\" class=\"headerlink\" title=\"正常的同步\"></a>正常的同步</h3><p>有了leader之后，集群的读写请求都要经过leader，follower只做备份。</p>\n<p>当leader收到一个写请求后会记录一个entry log，然后把这个entry发送给集群中的follower，其他的follower收到entry之后会发送确认信息给leader，如果leader收到超过一半的follower的确认信息之后就会把数据写进去（前面记录entry并不会apply数据），并通知其他follower写数据。</p>\n<p>任何一个follower重启后都会接收到leader的心跳，日志的内容也会与leader变成一致。</p>\n<p>如果是leader挂了，那么肯定是team和team index最大的那个称为新的leader</p>\n<h3 id=\"重新选举leader后的数据同步\"><a href=\"#重新选举leader后的数据同步\" class=\"headerlink\" title=\"重新选举leader后的数据同步\"></a>重新选举leader后的数据同步</h3><p>这个我想说的通俗点，就是leader与follower比较各自已经commit的entrty log id。直至找到二者的第一个”共同点“。之后leader就会把”共同点“后面的entrty log同步给follower。</p>\n<p>下图是一个leader节点对应的follower的状态<br><img src=\"https://sysummerblog.club/raftlandf.png\" alt></p>\n<p>如果follower是b,那么leader与follower会先找到term为4 entrty log id为4的日志的位置作为”共同点“，之后leader会把”共同点“后面的日志同步给follower。</p>\n<h3 id=\"State-Machine-Safety\"><a href=\"#State-Machine-Safety\" class=\"headerlink\" title=\"State Machine Safety\"></a>State Machine Safety</h3><p>如果一个节点在某一个log entry的位置apply了这条log里面的command，那么其他节点也必须在这个log entry的位置apply这条log。</p>"},{"title":"Mysql中的日志文件","date":"2019-11-17T00:52:53.000Z","tags":["mysql","innodb"],"photos":[["http://sysummerblog.club/mysql_cover.jpg"]],"_content":"mysql中有很多重要的日志文件，这些日志文件主要可以分为两大类：服务器的日志文件以及存储引擎的日志文件。平时我们用的存储引擎都是innodb，因此今天介绍的存储引擎的日志文件也是innodb的日志文件。\n<!--more-->\n## 服务器日志文件\n* error log 错误日志\n* slow query log 慢查询日志\n* bin log 二进制日志\n* relay log 中继日志\n\n\n## innodb存储引擎的日志\n\n* redo log 重做日志\n* undo log 撤回日志\n\n### 1.1 error log\nerror log存在于数据库的数据根目录下。用于记录mysql的启动、运行、关闭的过程中出现的错误和警告。在mysql启动异常的时候尤其有用。可以通过以下的命令来查看error log的具体的位置\n\n```sql\n show variables like 'log_error'\\G\n```\n### 1.2 slow query log\nslow query log 记录了所有查询时间大于(不包括等于)查询阈值的sql语句。可以通过以下命令获取查询阈值\n\n```sql\nshow variables like 'long_query_time'\\G\n```\n另一个和慢查询日志有关的参数是`log_queries_not_using_indexes`,表示如果查询没有用到索引也会被记录到慢查询日志当中去，无论有没有超过查询阈值。\n\n### 1.3 bin log\nbin log记录的mysql所有数据库的所有数据表的更改的所有操作，无论使用的是什么存储引擎。他也是唯一一个使用二进制记录的日志。如果在更新一条记录的一个字段的时候是用原值更新的那么这条记录并没有改变但是还是会写入bin log。\n\nbin log主要用来复制，在主库上源源不断的产生bin log并同步给各个从库来保证主从之间的数据一致。\n\nbin log也可以以支持point-in-time的数据恢复。\n\nbin log 的格式主要有三种\n1. row 基于每一行\n2. statement 基于sql语句\n3. mixed 既有row形式的又有statement形式的\n\n### 1.4 relay log\n在从库中会有一个专门的IO线程不断的从主库中读取bin log并把读取的内容写入relay log中。然后会有另外的线程会将新产生的relay log重放到从库中。主从复制的流程大致为\n\n![](http://sysummerblog.club/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_cde5d8b5-3035-4efa-bb0b-367394045f75.png)\n### 2.1 redo log\n存在于共享表空间中，是**物理日志**，记录的是一个事务中数据页的变化信息，不是某行的数据的变化信息。\n\n用于保证事务的持久性。在使用innodb存储引擎的时候，当一页数据被更新时首先在innodb的缓冲池中进行更新，然后才会根据一定的策略异步刷新回磁盘。那么问题来了，如果缓冲池中的数据页还未来的急刷新回磁盘服务器就宕机了怎么办？innodb是采用的日志先于数据刷新到磁盘的策略。\n\n每当一个事务写入数据的时候，innodb会向redo log缓存里写入**数据页**的物理变化信息，并以一定的策略更新到硬盘上。等到事务提交的时候强制redo log把数据页信息的更改更新到磁盘上。也就是说，当事务提交成功后相应的数据页可能还没更新到磁盘上，但是redo log一定更新到了磁盘上。如果此时宕机，那么innodb在重启时可以根据redo log来更新数据。\n\n如果缓冲池中的脏页都已经刷新到磁盘了，那么redo log就相当于完成了他的使命。\n\nredo log每次更新到磁盘的数据大小都是512kb，正好是一个扇区的大小，因此这个过程是原子性的。\n\nredo log刷新回磁盘的策略\n\n1. 主线程每秒刷新一次\n2. 每次事务提交时\n3. 当redo log的可用空间少于一半的时候\n\n因此，redo log写入磁盘不是在事务提交的那一刹那完成的，是在提交之前就已经开始“运动”了。所以即使一个大的事务提交，redo log的写入磁盘都会很快，不会成为事务提交慢的原因。\n\n### 2.2 undo log\n存在于共享表空间里，5.7可以存放在单独的表空间里。是存放在一个叫做undo log segment里面。undo log不像redo log那样有缓冲池，是顺序的往物理页上面写的。\n\nundo log记录的是一个事务中数据的逻辑改变。如果你删除一条数据那么他就增加一条数据，如果你更改一条数据那么他就反向更改一条数据。\n\nundo log的作用主要有两点\n\n1. 用于事务的回滚\n2. 用于MVCC\n\n每当一个事务开启的时候，当要更新一条数据的时候会先写undo log，只有undo log成功的写入了，整个事务才会有“后路”，才能回滚。之后才是写数据写redo log。特别需要注意的是，undo log 也是 redo log的保护对象，每一条undo log的写入都会有redo log的写入。\n\n当一条数据被事务T1修改中，此时T2事务中想要读取此数据，那么T2读取的永远是T1还未修改的那个版本，这就能保证在T2中不会出现幻读的情况。\n\n当一条数据更新时先写undo log，再写数据，再写redo log。\n\nundo log是数据库并发(MVCC)的关关键。innodb为每一行的数据都分配了两个隐藏的列：**事务id和回滚指针**。事务id能代表当前哪个事务正在写这行数据。回滚指针指向undo log中的这条数据的“上一个版本”，一单回滚就使用undo log中的日志恢复数据。undo log与read view一起工作实现了innodb的MVCC。\n","source":"posts/the-log-files-in-mysql.md","raw":"---\ntitle: Mysql中的日志文件\ndate: 2019-11-17 08:52:53\ntags:\n    - mysql\n    - innodb\nphotos:\n    - [\"http://sysummerblog.club/mysql_cover.jpg\"]\n---\nmysql中有很多重要的日志文件，这些日志文件主要可以分为两大类：服务器的日志文件以及存储引擎的日志文件。平时我们用的存储引擎都是innodb，因此今天介绍的存储引擎的日志文件也是innodb的日志文件。\n<!--more-->\n## 服务器日志文件\n* error log 错误日志\n* slow query log 慢查询日志\n* bin log 二进制日志\n* relay log 中继日志\n\n\n## innodb存储引擎的日志\n\n* redo log 重做日志\n* undo log 撤回日志\n\n### 1.1 error log\nerror log存在于数据库的数据根目录下。用于记录mysql的启动、运行、关闭的过程中出现的错误和警告。在mysql启动异常的时候尤其有用。可以通过以下的命令来查看error log的具体的位置\n\n```sql\n show variables like 'log_error'\\G\n```\n### 1.2 slow query log\nslow query log 记录了所有查询时间大于(不包括等于)查询阈值的sql语句。可以通过以下命令获取查询阈值\n\n```sql\nshow variables like 'long_query_time'\\G\n```\n另一个和慢查询日志有关的参数是`log_queries_not_using_indexes`,表示如果查询没有用到索引也会被记录到慢查询日志当中去，无论有没有超过查询阈值。\n\n### 1.3 bin log\nbin log记录的mysql所有数据库的所有数据表的更改的所有操作，无论使用的是什么存储引擎。他也是唯一一个使用二进制记录的日志。如果在更新一条记录的一个字段的时候是用原值更新的那么这条记录并没有改变但是还是会写入bin log。\n\nbin log主要用来复制，在主库上源源不断的产生bin log并同步给各个从库来保证主从之间的数据一致。\n\nbin log也可以以支持point-in-time的数据恢复。\n\nbin log 的格式主要有三种\n1. row 基于每一行\n2. statement 基于sql语句\n3. mixed 既有row形式的又有statement形式的\n\n### 1.4 relay log\n在从库中会有一个专门的IO线程不断的从主库中读取bin log并把读取的内容写入relay log中。然后会有另外的线程会将新产生的relay log重放到从库中。主从复制的流程大致为\n\n![](http://sysummerblog.club/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_cde5d8b5-3035-4efa-bb0b-367394045f75.png)\n### 2.1 redo log\n存在于共享表空间中，是**物理日志**，记录的是一个事务中数据页的变化信息，不是某行的数据的变化信息。\n\n用于保证事务的持久性。在使用innodb存储引擎的时候，当一页数据被更新时首先在innodb的缓冲池中进行更新，然后才会根据一定的策略异步刷新回磁盘。那么问题来了，如果缓冲池中的数据页还未来的急刷新回磁盘服务器就宕机了怎么办？innodb是采用的日志先于数据刷新到磁盘的策略。\n\n每当一个事务写入数据的时候，innodb会向redo log缓存里写入**数据页**的物理变化信息，并以一定的策略更新到硬盘上。等到事务提交的时候强制redo log把数据页信息的更改更新到磁盘上。也就是说，当事务提交成功后相应的数据页可能还没更新到磁盘上，但是redo log一定更新到了磁盘上。如果此时宕机，那么innodb在重启时可以根据redo log来更新数据。\n\n如果缓冲池中的脏页都已经刷新到磁盘了，那么redo log就相当于完成了他的使命。\n\nredo log每次更新到磁盘的数据大小都是512kb，正好是一个扇区的大小，因此这个过程是原子性的。\n\nredo log刷新回磁盘的策略\n\n1. 主线程每秒刷新一次\n2. 每次事务提交时\n3. 当redo log的可用空间少于一半的时候\n\n因此，redo log写入磁盘不是在事务提交的那一刹那完成的，是在提交之前就已经开始“运动”了。所以即使一个大的事务提交，redo log的写入磁盘都会很快，不会成为事务提交慢的原因。\n\n### 2.2 undo log\n存在于共享表空间里，5.7可以存放在单独的表空间里。是存放在一个叫做undo log segment里面。undo log不像redo log那样有缓冲池，是顺序的往物理页上面写的。\n\nundo log记录的是一个事务中数据的逻辑改变。如果你删除一条数据那么他就增加一条数据，如果你更改一条数据那么他就反向更改一条数据。\n\nundo log的作用主要有两点\n\n1. 用于事务的回滚\n2. 用于MVCC\n\n每当一个事务开启的时候，当要更新一条数据的时候会先写undo log，只有undo log成功的写入了，整个事务才会有“后路”，才能回滚。之后才是写数据写redo log。特别需要注意的是，undo log 也是 redo log的保护对象，每一条undo log的写入都会有redo log的写入。\n\n当一条数据被事务T1修改中，此时T2事务中想要读取此数据，那么T2读取的永远是T1还未修改的那个版本，这就能保证在T2中不会出现幻读的情况。\n\n当一条数据更新时先写undo log，再写数据，再写redo log。\n\nundo log是数据库并发(MVCC)的关关键。innodb为每一行的数据都分配了两个隐藏的列：**事务id和回滚指针**。事务id能代表当前哪个事务正在写这行数据。回滚指针指向undo log中的这条数据的“上一个版本”，一单回滚就使用undo log中的日志恢复数据。undo log与read view一起工作实现了innodb的MVCC。\n","updated":"2020-11-23T15:20:08.940Z","path":"posts/the-log-files-in-mysql.html","comments":1,"layout":"page","_id":"ckhupaq9y00131no8kxvs7edn","content":"<p>mysql中有很多重要的日志文件，这些日志文件主要可以分为两大类：服务器的日志文件以及存储引擎的日志文件。平时我们用的存储引擎都是innodb，因此今天介绍的存储引擎的日志文件也是innodb的日志文件。</p>\n<a id=\"more\"></a>\n<h2 id=\"服务器日志文件\"><a href=\"#服务器日志文件\" class=\"headerlink\" title=\"服务器日志文件\"></a>服务器日志文件</h2><ul>\n<li>error log 错误日志</li>\n<li>slow query log 慢查询日志</li>\n<li>bin log 二进制日志</li>\n<li>relay log 中继日志</li>\n</ul>\n<h2 id=\"innodb存储引擎的日志\"><a href=\"#innodb存储引擎的日志\" class=\"headerlink\" title=\"innodb存储引擎的日志\"></a>innodb存储引擎的日志</h2><ul>\n<li>redo log 重做日志</li>\n<li>undo log 撤回日志</li>\n</ul>\n<h3 id=\"1-1-error-log\"><a href=\"#1-1-error-log\" class=\"headerlink\" title=\"1.1 error log\"></a>1.1 error log</h3><p>error log存在于数据库的数据根目录下。用于记录mysql的启动、运行、关闭的过程中出现的错误和警告。在mysql启动异常的时候尤其有用。可以通过以下的命令来查看error log的具体的位置</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'log_error'</span>\\G</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"1-2-slow-query-log\"><a href=\"#1-2-slow-query-log\" class=\"headerlink\" title=\"1.2 slow query log\"></a>1.2 slow query log</h3><p>slow query log 记录了所有查询时间大于(不包括等于)查询阈值的sql语句。可以通过以下命令获取查询阈值</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'long_query_time'</span>\\G</span><br></pre></td></tr></table></figure>\n\n<p>另一个和慢查询日志有关的参数是<code>log_queries_not_using_indexes</code>,表示如果查询没有用到索引也会被记录到慢查询日志当中去，无论有没有超过查询阈值。</p>\n<h3 id=\"1-3-bin-log\"><a href=\"#1-3-bin-log\" class=\"headerlink\" title=\"1.3 bin log\"></a>1.3 bin log</h3><p>bin log记录的mysql所有数据库的所有数据表的更改的所有操作，无论使用的是什么存储引擎。他也是唯一一个使用二进制记录的日志。如果在更新一条记录的一个字段的时候是用原值更新的那么这条记录并没有改变但是还是会写入bin log。</p>\n<p>bin log主要用来复制，在主库上源源不断的产生bin log并同步给各个从库来保证主从之间的数据一致。</p>\n<p>bin log也可以以支持point-in-time的数据恢复。</p>\n<p>bin log 的格式主要有三种</p>\n<ol>\n<li>row 基于每一行</li>\n<li>statement 基于sql语句</li>\n<li>mixed 既有row形式的又有statement形式的</li>\n</ol>\n<h3 id=\"1-4-relay-log\"><a href=\"#1-4-relay-log\" class=\"headerlink\" title=\"1.4 relay log\"></a>1.4 relay log</h3><p>在从库中会有一个专门的IO线程不断的从主库中读取bin log并把读取的内容写入relay log中。然后会有另外的线程会将新产生的relay log重放到从库中。主从复制的流程大致为</p>\n<p><img src=\"http://sysummerblog.club/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_cde5d8b5-3035-4efa-bb0b-367394045f75.png\" alt></p>\n<h3 id=\"2-1-redo-log\"><a href=\"#2-1-redo-log\" class=\"headerlink\" title=\"2.1 redo log\"></a>2.1 redo log</h3><p>存在于共享表空间中，是<strong>物理日志</strong>，记录的是一个事务中数据页的变化信息，不是某行的数据的变化信息。</p>\n<p>用于保证事务的持久性。在使用innodb存储引擎的时候，当一页数据被更新时首先在innodb的缓冲池中进行更新，然后才会根据一定的策略异步刷新回磁盘。那么问题来了，如果缓冲池中的数据页还未来的急刷新回磁盘服务器就宕机了怎么办？innodb是采用的日志先于数据刷新到磁盘的策略。</p>\n<p>每当一个事务写入数据的时候，innodb会向redo log缓存里写入<strong>数据页</strong>的物理变化信息，并以一定的策略更新到硬盘上。等到事务提交的时候强制redo log把数据页信息的更改更新到磁盘上。也就是说，当事务提交成功后相应的数据页可能还没更新到磁盘上，但是redo log一定更新到了磁盘上。如果此时宕机，那么innodb在重启时可以根据redo log来更新数据。</p>\n<p>如果缓冲池中的脏页都已经刷新到磁盘了，那么redo log就相当于完成了他的使命。</p>\n<p>redo log每次更新到磁盘的数据大小都是512kb，正好是一个扇区的大小，因此这个过程是原子性的。</p>\n<p>redo log刷新回磁盘的策略</p>\n<ol>\n<li>主线程每秒刷新一次</li>\n<li>每次事务提交时</li>\n<li>当redo log的可用空间少于一半的时候</li>\n</ol>\n<p>因此，redo log写入磁盘不是在事务提交的那一刹那完成的，是在提交之前就已经开始“运动”了。所以即使一个大的事务提交，redo log的写入磁盘都会很快，不会成为事务提交慢的原因。</p>\n<h3 id=\"2-2-undo-log\"><a href=\"#2-2-undo-log\" class=\"headerlink\" title=\"2.2 undo log\"></a>2.2 undo log</h3><p>存在于共享表空间里，5.7可以存放在单独的表空间里。是存放在一个叫做undo log segment里面。undo log不像redo log那样有缓冲池，是顺序的往物理页上面写的。</p>\n<p>undo log记录的是一个事务中数据的逻辑改变。如果你删除一条数据那么他就增加一条数据，如果你更改一条数据那么他就反向更改一条数据。</p>\n<p>undo log的作用主要有两点</p>\n<ol>\n<li>用于事务的回滚</li>\n<li>用于MVCC</li>\n</ol>\n<p>每当一个事务开启的时候，当要更新一条数据的时候会先写undo log，只有undo log成功的写入了，整个事务才会有“后路”，才能回滚。之后才是写数据写redo log。特别需要注意的是，undo log 也是 redo log的保护对象，每一条undo log的写入都会有redo log的写入。</p>\n<p>当一条数据被事务T1修改中，此时T2事务中想要读取此数据，那么T2读取的永远是T1还未修改的那个版本，这就能保证在T2中不会出现幻读的情况。</p>\n<p>当一条数据更新时先写undo log，再写数据，再写redo log。</p>\n<p>undo log是数据库并发(MVCC)的关关键。innodb为每一行的数据都分配了两个隐藏的列：<strong>事务id和回滚指针</strong>。事务id能代表当前哪个事务正在写这行数据。回滚指针指向undo log中的这条数据的“上一个版本”，一单回滚就使用undo log中的日志恢复数据。undo log与read view一起工作实现了innodb的MVCC。</p>\n","site":{"data":{}},"excerpt":"<p>mysql中有很多重要的日志文件，这些日志文件主要可以分为两大类：服务器的日志文件以及存储引擎的日志文件。平时我们用的存储引擎都是innodb，因此今天介绍的存储引擎的日志文件也是innodb的日志文件。</p>","more":"<h2 id=\"服务器日志文件\"><a href=\"#服务器日志文件\" class=\"headerlink\" title=\"服务器日志文件\"></a>服务器日志文件</h2><ul>\n<li>error log 错误日志</li>\n<li>slow query log 慢查询日志</li>\n<li>bin log 二进制日志</li>\n<li>relay log 中继日志</li>\n</ul>\n<h2 id=\"innodb存储引擎的日志\"><a href=\"#innodb存储引擎的日志\" class=\"headerlink\" title=\"innodb存储引擎的日志\"></a>innodb存储引擎的日志</h2><ul>\n<li>redo log 重做日志</li>\n<li>undo log 撤回日志</li>\n</ul>\n<h3 id=\"1-1-error-log\"><a href=\"#1-1-error-log\" class=\"headerlink\" title=\"1.1 error log\"></a>1.1 error log</h3><p>error log存在于数据库的数据根目录下。用于记录mysql的启动、运行、关闭的过程中出现的错误和警告。在mysql启动异常的时候尤其有用。可以通过以下的命令来查看error log的具体的位置</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'log_error'</span>\\G</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"1-2-slow-query-log\"><a href=\"#1-2-slow-query-log\" class=\"headerlink\" title=\"1.2 slow query log\"></a>1.2 slow query log</h3><p>slow query log 记录了所有查询时间大于(不包括等于)查询阈值的sql语句。可以通过以下命令获取查询阈值</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'long_query_time'</span>\\G</span><br></pre></td></tr></table></figure>\n\n<p>另一个和慢查询日志有关的参数是<code>log_queries_not_using_indexes</code>,表示如果查询没有用到索引也会被记录到慢查询日志当中去，无论有没有超过查询阈值。</p>\n<h3 id=\"1-3-bin-log\"><a href=\"#1-3-bin-log\" class=\"headerlink\" title=\"1.3 bin log\"></a>1.3 bin log</h3><p>bin log记录的mysql所有数据库的所有数据表的更改的所有操作，无论使用的是什么存储引擎。他也是唯一一个使用二进制记录的日志。如果在更新一条记录的一个字段的时候是用原值更新的那么这条记录并没有改变但是还是会写入bin log。</p>\n<p>bin log主要用来复制，在主库上源源不断的产生bin log并同步给各个从库来保证主从之间的数据一致。</p>\n<p>bin log也可以以支持point-in-time的数据恢复。</p>\n<p>bin log 的格式主要有三种</p>\n<ol>\n<li>row 基于每一行</li>\n<li>statement 基于sql语句</li>\n<li>mixed 既有row形式的又有statement形式的</li>\n</ol>\n<h3 id=\"1-4-relay-log\"><a href=\"#1-4-relay-log\" class=\"headerlink\" title=\"1.4 relay log\"></a>1.4 relay log</h3><p>在从库中会有一个专门的IO线程不断的从主库中读取bin log并把读取的内容写入relay log中。然后会有另外的线程会将新产生的relay log重放到从库中。主从复制的流程大致为</p>\n<p><img src=\"http://sysummerblog.club/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_cde5d8b5-3035-4efa-bb0b-367394045f75.png\" alt></p>\n<h3 id=\"2-1-redo-log\"><a href=\"#2-1-redo-log\" class=\"headerlink\" title=\"2.1 redo log\"></a>2.1 redo log</h3><p>存在于共享表空间中，是<strong>物理日志</strong>，记录的是一个事务中数据页的变化信息，不是某行的数据的变化信息。</p>\n<p>用于保证事务的持久性。在使用innodb存储引擎的时候，当一页数据被更新时首先在innodb的缓冲池中进行更新，然后才会根据一定的策略异步刷新回磁盘。那么问题来了，如果缓冲池中的数据页还未来的急刷新回磁盘服务器就宕机了怎么办？innodb是采用的日志先于数据刷新到磁盘的策略。</p>\n<p>每当一个事务写入数据的时候，innodb会向redo log缓存里写入<strong>数据页</strong>的物理变化信息，并以一定的策略更新到硬盘上。等到事务提交的时候强制redo log把数据页信息的更改更新到磁盘上。也就是说，当事务提交成功后相应的数据页可能还没更新到磁盘上，但是redo log一定更新到了磁盘上。如果此时宕机，那么innodb在重启时可以根据redo log来更新数据。</p>\n<p>如果缓冲池中的脏页都已经刷新到磁盘了，那么redo log就相当于完成了他的使命。</p>\n<p>redo log每次更新到磁盘的数据大小都是512kb，正好是一个扇区的大小，因此这个过程是原子性的。</p>\n<p>redo log刷新回磁盘的策略</p>\n<ol>\n<li>主线程每秒刷新一次</li>\n<li>每次事务提交时</li>\n<li>当redo log的可用空间少于一半的时候</li>\n</ol>\n<p>因此，redo log写入磁盘不是在事务提交的那一刹那完成的，是在提交之前就已经开始“运动”了。所以即使一个大的事务提交，redo log的写入磁盘都会很快，不会成为事务提交慢的原因。</p>\n<h3 id=\"2-2-undo-log\"><a href=\"#2-2-undo-log\" class=\"headerlink\" title=\"2.2 undo log\"></a>2.2 undo log</h3><p>存在于共享表空间里，5.7可以存放在单独的表空间里。是存放在一个叫做undo log segment里面。undo log不像redo log那样有缓冲池，是顺序的往物理页上面写的。</p>\n<p>undo log记录的是一个事务中数据的逻辑改变。如果你删除一条数据那么他就增加一条数据，如果你更改一条数据那么他就反向更改一条数据。</p>\n<p>undo log的作用主要有两点</p>\n<ol>\n<li>用于事务的回滚</li>\n<li>用于MVCC</li>\n</ol>\n<p>每当一个事务开启的时候，当要更新一条数据的时候会先写undo log，只有undo log成功的写入了，整个事务才会有“后路”，才能回滚。之后才是写数据写redo log。特别需要注意的是，undo log 也是 redo log的保护对象，每一条undo log的写入都会有redo log的写入。</p>\n<p>当一条数据被事务T1修改中，此时T2事务中想要读取此数据，那么T2读取的永远是T1还未修改的那个版本，这就能保证在T2中不会出现幻读的情况。</p>\n<p>当一条数据更新时先写undo log，再写数据，再写redo log。</p>\n<p>undo log是数据库并发(MVCC)的关关键。innodb为每一行的数据都分配了两个隐藏的列：<strong>事务id和回滚指针</strong>。事务id能代表当前哪个事务正在写这行数据。回滚指针指向undo log中的这条数据的“上一个版本”，一单回滚就使用undo log中的日志恢复数据。undo log与read view一起工作实现了innodb的MVCC。</p>"},{"title":"ZooKeeper总结","date":"2020-03-17T05:17:11.000Z","tags":["分布式"],"photo":[["https://sysummerblog.club/zk.png"]],"_content":"ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。\n<!--more-->\n## zookeeper所能提供的功能\n\n### 命名服务\n在zk下创建一个节点作为服务，然后节点下面的子节点中存放该服务的各个机器的ip\n\n### 配置管理\n在zk下存放一个节点，当节点的数据发生变化的时候通知watch这个节点的client\n\n### 集群管理\n当一个服务的集群增加或者减少机器的时候会在相应的服务节点上增加或删除子节点并通知watch这个服务节点的的所有的client。如果子节点是顺序节点，那么可以顺理成章的把编号最小的那个作为master\n\n### 选举算法\n所有的节点都向zk的一个路径下面创建临时有序节点,序号最小的那个就是leader。\n\n### 锁定和同步\n保持独占：各个client在zk上创建一个相同的znode，创建成功的client就相当于获取到了锁。保持独占这个方法实现比较简单，但是zk是leader负责写入的，如果很多个客户端同时写的话会有问题。\n控制时序：各个client往一个znode下面创建临时有序节点，创建的节点的编号最小的client获取到了锁。没获取到锁的client开始watch这个znode下面的节点。获取到锁的client执行完后删除这个锁节点，其他watch的client会受到通知然后看谁的编号最小谁就获取到了这个锁\n\n获取锁的时候，创建的节点都是暂时的，如果获得锁的进程意外退出，那么这个暂时的节点会立马被删除。\n\n### 高度可靠地数据注册表\n\n![](https://sysummerblog.club/zkc.jpg)\n## znode\nZooKeeper命名空间内部拥有一个树状的内存模型，其中各节点被称为znode。每个znode包含一个路径和与之相关的元数据，以及该znode下关联的子节点列表。\n![](https://sysummerblog.club/znode.png)\n\n### znode节点类型\n\n1. 持久节点\n2. 持久顺序节点\n3. 临时节点\n4. 临时顺序节点\n\nznode可以存储一些数据外还有一些元数据\n\n* czxid 创建节点的事务id\n* ctime 创建时间\n* mzxid 最后一次更新节点的事务id\n* mtime 最后一次更新时间\n* dataLength 数据长度\n* numChildren 子节点数\n\n## 会话\n一个客户端与zookeeper连接后就形成了一个会话，客户端通过心跳与zookeeper保持联系。一单在超时时间内zookeeper没有收到心跳，就认为客户端已经“失联”，该客户端创建的所有临时znode都会被删除。\n\n## 监视\n客户端在读取特定的znode时可以设置监视这个znode，一单这个znode发生白变化客户端就会收到通知。\n\n## 节点的角色\n\n1. leader\n2. follower\n3. observer\n\n这3中角色的节点都能接受客户端的连接，都能响应读请求。如果follower或者observer收到了写请求会把这个请求转发给leader。\n\nobserver节点不会参与leader的选举。\n\n为什么有observer？如果连接的客户端很多，那么就要扩充zk的节点数量。扩充了之后在选举的时候就会”变慢“，因此引入observer，扩充了节点数量但是参与投票的节点还没有那么多。\n\n## 节点的状态\n1. leading 该节点目前是leader\n2. following 该节点目前是follower\n3. looking 该节点找不到leader，正在“寻找”leader\n4. observering 该节点是observer\n\n## 选举\n选举出现在三种情况\n\n1. 集群启动的时候。\n2. leader出问题了，需要重新选举。\n3. zxid的高位或者低位用尽。\n\n在选取leader的过程中zookeeper集群是不可用的。\nleaer通过心跳与follower和observer通信。当follower失去与leader的联系后会进入looking状态并“投自己一票”然后向集群内的其他节点广播。\n\n选举的核心逻辑就是比较。比较什么呢？比较logicClock、zxid和serverid。 \n\n* logicClock是投票的轮数，每个节点发起投票的时候会将自己的logicClock加1。如果一个节点收到其他节点的投票的时候发现对方的logicClock比自己的小那么会直接忽略该投票。如果发现比自己的大，那么会更新自己的logicClock并重新广播自己的投票（自己的投票之前可能已经被别的节点忽略了）。如果logicClock一样大就去比较zxid。\n* zxid是一个64位的数字，类似于事务id。前32位是epoch，有点类似于raft中的term, 每一次新leader的产生都会使前32位加1。后32位是此次“epoch”周期内的单调递增id。如果zxid一样就去比较serverid。\n* serverid是集群内每个机器的id，一个zk集群在启动的时候就已经确认好了这个集群有几个节点。每一个节点的配置文件里都有这个集群每一个节点的信息。\n\n**一但zxid的高位或者低位用尽则会重新强制重新选举。**\n\n每次选举的时候各个节点首先都是“先投自己一票”然后广播。每一个follower收到“其他节点的投票”的时候都会与自己刚刚投的票相比较（logicClock、zxid和server id），如果自己被pk下去了那么就更新自己本地的投票然后广播，如果不需要修改就什么都不做。\n\n因为每一个节点的投票信息其他的节点都会通过广播收到，因此每一个节点都有当前整个集群中所有节点的投票信息。一但有一个节点获取到了大多数票那么投票就结束了。\n\n如果一个节点新加入或者宕机后新加入，首先会发起选举，但是其他的节点会告诉他我们已经有leader了，然后此节点会自动变成follower。\n\n如果集群刚启动或者leader出现了问题，那么集群会进入崩溃恢复模式选举产生新的leader。新的leader出现后，**有超过半数的follower已经与leader同步过数据后集群就进入了消息广播模式，即正常工作模式**\n\n## 数据同步\n### 正常的同步\nzookeepe使用自己的zab协议实现数据同步。\n写请求都会转发到leader上，随后leader会发出一个proposal，**leader与follower之间的通信是通过队列来实现的并且每个proposal都有一个唯一的zxid**，因此保证了follower中数据写入的顺序。当follower收到proposal后会写入本地日志到磁盘，并返回ack给leader。leader收到大多数的follower的ack后自己commit然后通知各个follower也commit同时返回客户端结果。\n\n### 重新选举出leader后的同步\n新leader先判断自己的未被commit的proposa是否能够commit（依据是此时整个集群额大多数节点都有这个proposal），如果可以就commit，如果不可以就不commit。因此最开始是先搞好leader的数据，之后leader会告诉follower增减数据。\n\n### 如果leader刚发出proposal就宕机了，follower都没有收到\n\n那么新产生的leader将不知道有这个proposal，也就相当于这个proposal被废掉了，即使之前的leader加入集群，这个proposal也会被新的leader废掉。\n\n### 如果leader收到大多数的ack，但是还没有commit\n收到的这些follower中肯定会有一个是新的leader。在其成为leader后会“领导大家”commit这个proposal\n\n## zk保证了一致性和分区可用性，在选举leader的时候集群不可用，牺牲了可用性\n","source":"posts/zk-first-exploration.md","raw":"---\ntitle: ZooKeeper总结\ndate: 2020-03-17 13:17:11\ntags:\n   - 分布式\nphoto:\n   - [https://sysummerblog.club/zk.png]\n---\nZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。\n<!--more-->\n## zookeeper所能提供的功能\n\n### 命名服务\n在zk下创建一个节点作为服务，然后节点下面的子节点中存放该服务的各个机器的ip\n\n### 配置管理\n在zk下存放一个节点，当节点的数据发生变化的时候通知watch这个节点的client\n\n### 集群管理\n当一个服务的集群增加或者减少机器的时候会在相应的服务节点上增加或删除子节点并通知watch这个服务节点的的所有的client。如果子节点是顺序节点，那么可以顺理成章的把编号最小的那个作为master\n\n### 选举算法\n所有的节点都向zk的一个路径下面创建临时有序节点,序号最小的那个就是leader。\n\n### 锁定和同步\n保持独占：各个client在zk上创建一个相同的znode，创建成功的client就相当于获取到了锁。保持独占这个方法实现比较简单，但是zk是leader负责写入的，如果很多个客户端同时写的话会有问题。\n控制时序：各个client往一个znode下面创建临时有序节点，创建的节点的编号最小的client获取到了锁。没获取到锁的client开始watch这个znode下面的节点。获取到锁的client执行完后删除这个锁节点，其他watch的client会受到通知然后看谁的编号最小谁就获取到了这个锁\n\n获取锁的时候，创建的节点都是暂时的，如果获得锁的进程意外退出，那么这个暂时的节点会立马被删除。\n\n### 高度可靠地数据注册表\n\n![](https://sysummerblog.club/zkc.jpg)\n## znode\nZooKeeper命名空间内部拥有一个树状的内存模型，其中各节点被称为znode。每个znode包含一个路径和与之相关的元数据，以及该znode下关联的子节点列表。\n![](https://sysummerblog.club/znode.png)\n\n### znode节点类型\n\n1. 持久节点\n2. 持久顺序节点\n3. 临时节点\n4. 临时顺序节点\n\nznode可以存储一些数据外还有一些元数据\n\n* czxid 创建节点的事务id\n* ctime 创建时间\n* mzxid 最后一次更新节点的事务id\n* mtime 最后一次更新时间\n* dataLength 数据长度\n* numChildren 子节点数\n\n## 会话\n一个客户端与zookeeper连接后就形成了一个会话，客户端通过心跳与zookeeper保持联系。一单在超时时间内zookeeper没有收到心跳，就认为客户端已经“失联”，该客户端创建的所有临时znode都会被删除。\n\n## 监视\n客户端在读取特定的znode时可以设置监视这个znode，一单这个znode发生白变化客户端就会收到通知。\n\n## 节点的角色\n\n1. leader\n2. follower\n3. observer\n\n这3中角色的节点都能接受客户端的连接，都能响应读请求。如果follower或者observer收到了写请求会把这个请求转发给leader。\n\nobserver节点不会参与leader的选举。\n\n为什么有observer？如果连接的客户端很多，那么就要扩充zk的节点数量。扩充了之后在选举的时候就会”变慢“，因此引入observer，扩充了节点数量但是参与投票的节点还没有那么多。\n\n## 节点的状态\n1. leading 该节点目前是leader\n2. following 该节点目前是follower\n3. looking 该节点找不到leader，正在“寻找”leader\n4. observering 该节点是observer\n\n## 选举\n选举出现在三种情况\n\n1. 集群启动的时候。\n2. leader出问题了，需要重新选举。\n3. zxid的高位或者低位用尽。\n\n在选取leader的过程中zookeeper集群是不可用的。\nleaer通过心跳与follower和observer通信。当follower失去与leader的联系后会进入looking状态并“投自己一票”然后向集群内的其他节点广播。\n\n选举的核心逻辑就是比较。比较什么呢？比较logicClock、zxid和serverid。 \n\n* logicClock是投票的轮数，每个节点发起投票的时候会将自己的logicClock加1。如果一个节点收到其他节点的投票的时候发现对方的logicClock比自己的小那么会直接忽略该投票。如果发现比自己的大，那么会更新自己的logicClock并重新广播自己的投票（自己的投票之前可能已经被别的节点忽略了）。如果logicClock一样大就去比较zxid。\n* zxid是一个64位的数字，类似于事务id。前32位是epoch，有点类似于raft中的term, 每一次新leader的产生都会使前32位加1。后32位是此次“epoch”周期内的单调递增id。如果zxid一样就去比较serverid。\n* serverid是集群内每个机器的id，一个zk集群在启动的时候就已经确认好了这个集群有几个节点。每一个节点的配置文件里都有这个集群每一个节点的信息。\n\n**一但zxid的高位或者低位用尽则会重新强制重新选举。**\n\n每次选举的时候各个节点首先都是“先投自己一票”然后广播。每一个follower收到“其他节点的投票”的时候都会与自己刚刚投的票相比较（logicClock、zxid和server id），如果自己被pk下去了那么就更新自己本地的投票然后广播，如果不需要修改就什么都不做。\n\n因为每一个节点的投票信息其他的节点都会通过广播收到，因此每一个节点都有当前整个集群中所有节点的投票信息。一但有一个节点获取到了大多数票那么投票就结束了。\n\n如果一个节点新加入或者宕机后新加入，首先会发起选举，但是其他的节点会告诉他我们已经有leader了，然后此节点会自动变成follower。\n\n如果集群刚启动或者leader出现了问题，那么集群会进入崩溃恢复模式选举产生新的leader。新的leader出现后，**有超过半数的follower已经与leader同步过数据后集群就进入了消息广播模式，即正常工作模式**\n\n## 数据同步\n### 正常的同步\nzookeepe使用自己的zab协议实现数据同步。\n写请求都会转发到leader上，随后leader会发出一个proposal，**leader与follower之间的通信是通过队列来实现的并且每个proposal都有一个唯一的zxid**，因此保证了follower中数据写入的顺序。当follower收到proposal后会写入本地日志到磁盘，并返回ack给leader。leader收到大多数的follower的ack后自己commit然后通知各个follower也commit同时返回客户端结果。\n\n### 重新选举出leader后的同步\n新leader先判断自己的未被commit的proposa是否能够commit（依据是此时整个集群额大多数节点都有这个proposal），如果可以就commit，如果不可以就不commit。因此最开始是先搞好leader的数据，之后leader会告诉follower增减数据。\n\n### 如果leader刚发出proposal就宕机了，follower都没有收到\n\n那么新产生的leader将不知道有这个proposal，也就相当于这个proposal被废掉了，即使之前的leader加入集群，这个proposal也会被新的leader废掉。\n\n### 如果leader收到大多数的ack，但是还没有commit\n收到的这些follower中肯定会有一个是新的leader。在其成为leader后会“领导大家”commit这个proposal\n\n## zk保证了一致性和分区可用性，在选举leader的时候集群不可用，牺牲了可用性\n","updated":"2020-11-23T15:20:08.940Z","path":"posts/zk-first-exploration.html","comments":1,"layout":"page","_id":"ckhupaq9z00151no8qq9l3oo6","content":"<p>ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。</p>\n<a id=\"more\"></a>\n<h2 id=\"zookeeper所能提供的功能\"><a href=\"#zookeeper所能提供的功能\" class=\"headerlink\" title=\"zookeeper所能提供的功能\"></a>zookeeper所能提供的功能</h2><h3 id=\"命名服务\"><a href=\"#命名服务\" class=\"headerlink\" title=\"命名服务\"></a>命名服务</h3><p>在zk下创建一个节点作为服务，然后节点下面的子节点中存放该服务的各个机器的ip</p>\n<h3 id=\"配置管理\"><a href=\"#配置管理\" class=\"headerlink\" title=\"配置管理\"></a>配置管理</h3><p>在zk下存放一个节点，当节点的数据发生变化的时候通知watch这个节点的client</p>\n<h3 id=\"集群管理\"><a href=\"#集群管理\" class=\"headerlink\" title=\"集群管理\"></a>集群管理</h3><p>当一个服务的集群增加或者减少机器的时候会在相应的服务节点上增加或删除子节点并通知watch这个服务节点的的所有的client。如果子节点是顺序节点，那么可以顺理成章的把编号最小的那个作为master</p>\n<h3 id=\"选举算法\"><a href=\"#选举算法\" class=\"headerlink\" title=\"选举算法\"></a>选举算法</h3><p>所有的节点都向zk的一个路径下面创建临时有序节点,序号最小的那个就是leader。</p>\n<h3 id=\"锁定和同步\"><a href=\"#锁定和同步\" class=\"headerlink\" title=\"锁定和同步\"></a>锁定和同步</h3><p>保持独占：各个client在zk上创建一个相同的znode，创建成功的client就相当于获取到了锁。保持独占这个方法实现比较简单，但是zk是leader负责写入的，如果很多个客户端同时写的话会有问题。<br>控制时序：各个client往一个znode下面创建临时有序节点，创建的节点的编号最小的client获取到了锁。没获取到锁的client开始watch这个znode下面的节点。获取到锁的client执行完后删除这个锁节点，其他watch的client会受到通知然后看谁的编号最小谁就获取到了这个锁</p>\n<p>获取锁的时候，创建的节点都是暂时的，如果获得锁的进程意外退出，那么这个暂时的节点会立马被删除。</p>\n<h3 id=\"高度可靠地数据注册表\"><a href=\"#高度可靠地数据注册表\" class=\"headerlink\" title=\"高度可靠地数据注册表\"></a>高度可靠地数据注册表</h3><p><img src=\"https://sysummerblog.club/zkc.jpg\" alt></p>\n<h2 id=\"znode\"><a href=\"#znode\" class=\"headerlink\" title=\"znode\"></a>znode</h2><p>ZooKeeper命名空间内部拥有一个树状的内存模型，其中各节点被称为znode。每个znode包含一个路径和与之相关的元数据，以及该znode下关联的子节点列表。<br><img src=\"https://sysummerblog.club/znode.png\" alt></p>\n<h3 id=\"znode节点类型\"><a href=\"#znode节点类型\" class=\"headerlink\" title=\"znode节点类型\"></a>znode节点类型</h3><ol>\n<li>持久节点</li>\n<li>持久顺序节点</li>\n<li>临时节点</li>\n<li>临时顺序节点</li>\n</ol>\n<p>znode可以存储一些数据外还有一些元数据</p>\n<ul>\n<li>czxid 创建节点的事务id</li>\n<li>ctime 创建时间</li>\n<li>mzxid 最后一次更新节点的事务id</li>\n<li>mtime 最后一次更新时间</li>\n<li>dataLength 数据长度</li>\n<li>numChildren 子节点数</li>\n</ul>\n<h2 id=\"会话\"><a href=\"#会话\" class=\"headerlink\" title=\"会话\"></a>会话</h2><p>一个客户端与zookeeper连接后就形成了一个会话，客户端通过心跳与zookeeper保持联系。一单在超时时间内zookeeper没有收到心跳，就认为客户端已经“失联”，该客户端创建的所有临时znode都会被删除。</p>\n<h2 id=\"监视\"><a href=\"#监视\" class=\"headerlink\" title=\"监视\"></a>监视</h2><p>客户端在读取特定的znode时可以设置监视这个znode，一单这个znode发生白变化客户端就会收到通知。</p>\n<h2 id=\"节点的角色\"><a href=\"#节点的角色\" class=\"headerlink\" title=\"节点的角色\"></a>节点的角色</h2><ol>\n<li>leader</li>\n<li>follower</li>\n<li>observer</li>\n</ol>\n<p>这3中角色的节点都能接受客户端的连接，都能响应读请求。如果follower或者observer收到了写请求会把这个请求转发给leader。</p>\n<p>observer节点不会参与leader的选举。</p>\n<p>为什么有observer？如果连接的客户端很多，那么就要扩充zk的节点数量。扩充了之后在选举的时候就会”变慢“，因此引入observer，扩充了节点数量但是参与投票的节点还没有那么多。</p>\n<h2 id=\"节点的状态\"><a href=\"#节点的状态\" class=\"headerlink\" title=\"节点的状态\"></a>节点的状态</h2><ol>\n<li>leading 该节点目前是leader</li>\n<li>following 该节点目前是follower</li>\n<li>looking 该节点找不到leader，正在“寻找”leader</li>\n<li>observering 该节点是observer</li>\n</ol>\n<h2 id=\"选举\"><a href=\"#选举\" class=\"headerlink\" title=\"选举\"></a>选举</h2><p>选举出现在三种情况</p>\n<ol>\n<li>集群启动的时候。</li>\n<li>leader出问题了，需要重新选举。</li>\n<li>zxid的高位或者低位用尽。</li>\n</ol>\n<p>在选取leader的过程中zookeeper集群是不可用的。<br>leaer通过心跳与follower和observer通信。当follower失去与leader的联系后会进入looking状态并“投自己一票”然后向集群内的其他节点广播。</p>\n<p>选举的核心逻辑就是比较。比较什么呢？比较logicClock、zxid和serverid。 </p>\n<ul>\n<li>logicClock是投票的轮数，每个节点发起投票的时候会将自己的logicClock加1。如果一个节点收到其他节点的投票的时候发现对方的logicClock比自己的小那么会直接忽略该投票。如果发现比自己的大，那么会更新自己的logicClock并重新广播自己的投票（自己的投票之前可能已经被别的节点忽略了）。如果logicClock一样大就去比较zxid。</li>\n<li>zxid是一个64位的数字，类似于事务id。前32位是epoch，有点类似于raft中的term, 每一次新leader的产生都会使前32位加1。后32位是此次“epoch”周期内的单调递增id。如果zxid一样就去比较serverid。</li>\n<li>serverid是集群内每个机器的id，一个zk集群在启动的时候就已经确认好了这个集群有几个节点。每一个节点的配置文件里都有这个集群每一个节点的信息。</li>\n</ul>\n<p><strong>一但zxid的高位或者低位用尽则会重新强制重新选举。</strong></p>\n<p>每次选举的时候各个节点首先都是“先投自己一票”然后广播。每一个follower收到“其他节点的投票”的时候都会与自己刚刚投的票相比较（logicClock、zxid和server id），如果自己被pk下去了那么就更新自己本地的投票然后广播，如果不需要修改就什么都不做。</p>\n<p>因为每一个节点的投票信息其他的节点都会通过广播收到，因此每一个节点都有当前整个集群中所有节点的投票信息。一但有一个节点获取到了大多数票那么投票就结束了。</p>\n<p>如果一个节点新加入或者宕机后新加入，首先会发起选举，但是其他的节点会告诉他我们已经有leader了，然后此节点会自动变成follower。</p>\n<p>如果集群刚启动或者leader出现了问题，那么集群会进入崩溃恢复模式选举产生新的leader。新的leader出现后，<strong>有超过半数的follower已经与leader同步过数据后集群就进入了消息广播模式，即正常工作模式</strong></p>\n<h2 id=\"数据同步\"><a href=\"#数据同步\" class=\"headerlink\" title=\"数据同步\"></a>数据同步</h2><h3 id=\"正常的同步\"><a href=\"#正常的同步\" class=\"headerlink\" title=\"正常的同步\"></a>正常的同步</h3><p>zookeepe使用自己的zab协议实现数据同步。<br>写请求都会转发到leader上，随后leader会发出一个proposal，<strong>leader与follower之间的通信是通过队列来实现的并且每个proposal都有一个唯一的zxid</strong>，因此保证了follower中数据写入的顺序。当follower收到proposal后会写入本地日志到磁盘，并返回ack给leader。leader收到大多数的follower的ack后自己commit然后通知各个follower也commit同时返回客户端结果。</p>\n<h3 id=\"重新选举出leader后的同步\"><a href=\"#重新选举出leader后的同步\" class=\"headerlink\" title=\"重新选举出leader后的同步\"></a>重新选举出leader后的同步</h3><p>新leader先判断自己的未被commit的proposa是否能够commit（依据是此时整个集群额大多数节点都有这个proposal），如果可以就commit，如果不可以就不commit。因此最开始是先搞好leader的数据，之后leader会告诉follower增减数据。</p>\n<h3 id=\"如果leader刚发出proposal就宕机了，follower都没有收到\"><a href=\"#如果leader刚发出proposal就宕机了，follower都没有收到\" class=\"headerlink\" title=\"如果leader刚发出proposal就宕机了，follower都没有收到\"></a>如果leader刚发出proposal就宕机了，follower都没有收到</h3><p>那么新产生的leader将不知道有这个proposal，也就相当于这个proposal被废掉了，即使之前的leader加入集群，这个proposal也会被新的leader废掉。</p>\n<h3 id=\"如果leader收到大多数的ack，但是还没有commit\"><a href=\"#如果leader收到大多数的ack，但是还没有commit\" class=\"headerlink\" title=\"如果leader收到大多数的ack，但是还没有commit\"></a>如果leader收到大多数的ack，但是还没有commit</h3><p>收到的这些follower中肯定会有一个是新的leader。在其成为leader后会“领导大家”commit这个proposal</p>\n<h2 id=\"zk保证了一致性和分区可用性，在选举leader的时候集群不可用，牺牲了可用性\"><a href=\"#zk保证了一致性和分区可用性，在选举leader的时候集群不可用，牺牲了可用性\" class=\"headerlink\" title=\"zk保证了一致性和分区可用性，在选举leader的时候集群不可用，牺牲了可用性\"></a>zk保证了一致性和分区可用性，在选举leader的时候集群不可用，牺牲了可用性</h2>","site":{"data":{}},"excerpt":"<p>ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。</p>","more":"<h2 id=\"zookeeper所能提供的功能\"><a href=\"#zookeeper所能提供的功能\" class=\"headerlink\" title=\"zookeeper所能提供的功能\"></a>zookeeper所能提供的功能</h2><h3 id=\"命名服务\"><a href=\"#命名服务\" class=\"headerlink\" title=\"命名服务\"></a>命名服务</h3><p>在zk下创建一个节点作为服务，然后节点下面的子节点中存放该服务的各个机器的ip</p>\n<h3 id=\"配置管理\"><a href=\"#配置管理\" class=\"headerlink\" title=\"配置管理\"></a>配置管理</h3><p>在zk下存放一个节点，当节点的数据发生变化的时候通知watch这个节点的client</p>\n<h3 id=\"集群管理\"><a href=\"#集群管理\" class=\"headerlink\" title=\"集群管理\"></a>集群管理</h3><p>当一个服务的集群增加或者减少机器的时候会在相应的服务节点上增加或删除子节点并通知watch这个服务节点的的所有的client。如果子节点是顺序节点，那么可以顺理成章的把编号最小的那个作为master</p>\n<h3 id=\"选举算法\"><a href=\"#选举算法\" class=\"headerlink\" title=\"选举算法\"></a>选举算法</h3><p>所有的节点都向zk的一个路径下面创建临时有序节点,序号最小的那个就是leader。</p>\n<h3 id=\"锁定和同步\"><a href=\"#锁定和同步\" class=\"headerlink\" title=\"锁定和同步\"></a>锁定和同步</h3><p>保持独占：各个client在zk上创建一个相同的znode，创建成功的client就相当于获取到了锁。保持独占这个方法实现比较简单，但是zk是leader负责写入的，如果很多个客户端同时写的话会有问题。<br>控制时序：各个client往一个znode下面创建临时有序节点，创建的节点的编号最小的client获取到了锁。没获取到锁的client开始watch这个znode下面的节点。获取到锁的client执行完后删除这个锁节点，其他watch的client会受到通知然后看谁的编号最小谁就获取到了这个锁</p>\n<p>获取锁的时候，创建的节点都是暂时的，如果获得锁的进程意外退出，那么这个暂时的节点会立马被删除。</p>\n<h3 id=\"高度可靠地数据注册表\"><a href=\"#高度可靠地数据注册表\" class=\"headerlink\" title=\"高度可靠地数据注册表\"></a>高度可靠地数据注册表</h3><p><img src=\"https://sysummerblog.club/zkc.jpg\" alt></p>\n<h2 id=\"znode\"><a href=\"#znode\" class=\"headerlink\" title=\"znode\"></a>znode</h2><p>ZooKeeper命名空间内部拥有一个树状的内存模型，其中各节点被称为znode。每个znode包含一个路径和与之相关的元数据，以及该znode下关联的子节点列表。<br><img src=\"https://sysummerblog.club/znode.png\" alt></p>\n<h3 id=\"znode节点类型\"><a href=\"#znode节点类型\" class=\"headerlink\" title=\"znode节点类型\"></a>znode节点类型</h3><ol>\n<li>持久节点</li>\n<li>持久顺序节点</li>\n<li>临时节点</li>\n<li>临时顺序节点</li>\n</ol>\n<p>znode可以存储一些数据外还有一些元数据</p>\n<ul>\n<li>czxid 创建节点的事务id</li>\n<li>ctime 创建时间</li>\n<li>mzxid 最后一次更新节点的事务id</li>\n<li>mtime 最后一次更新时间</li>\n<li>dataLength 数据长度</li>\n<li>numChildren 子节点数</li>\n</ul>\n<h2 id=\"会话\"><a href=\"#会话\" class=\"headerlink\" title=\"会话\"></a>会话</h2><p>一个客户端与zookeeper连接后就形成了一个会话，客户端通过心跳与zookeeper保持联系。一单在超时时间内zookeeper没有收到心跳，就认为客户端已经“失联”，该客户端创建的所有临时znode都会被删除。</p>\n<h2 id=\"监视\"><a href=\"#监视\" class=\"headerlink\" title=\"监视\"></a>监视</h2><p>客户端在读取特定的znode时可以设置监视这个znode，一单这个znode发生白变化客户端就会收到通知。</p>\n<h2 id=\"节点的角色\"><a href=\"#节点的角色\" class=\"headerlink\" title=\"节点的角色\"></a>节点的角色</h2><ol>\n<li>leader</li>\n<li>follower</li>\n<li>observer</li>\n</ol>\n<p>这3中角色的节点都能接受客户端的连接，都能响应读请求。如果follower或者observer收到了写请求会把这个请求转发给leader。</p>\n<p>observer节点不会参与leader的选举。</p>\n<p>为什么有observer？如果连接的客户端很多，那么就要扩充zk的节点数量。扩充了之后在选举的时候就会”变慢“，因此引入observer，扩充了节点数量但是参与投票的节点还没有那么多。</p>\n<h2 id=\"节点的状态\"><a href=\"#节点的状态\" class=\"headerlink\" title=\"节点的状态\"></a>节点的状态</h2><ol>\n<li>leading 该节点目前是leader</li>\n<li>following 该节点目前是follower</li>\n<li>looking 该节点找不到leader，正在“寻找”leader</li>\n<li>observering 该节点是observer</li>\n</ol>\n<h2 id=\"选举\"><a href=\"#选举\" class=\"headerlink\" title=\"选举\"></a>选举</h2><p>选举出现在三种情况</p>\n<ol>\n<li>集群启动的时候。</li>\n<li>leader出问题了，需要重新选举。</li>\n<li>zxid的高位或者低位用尽。</li>\n</ol>\n<p>在选取leader的过程中zookeeper集群是不可用的。<br>leaer通过心跳与follower和observer通信。当follower失去与leader的联系后会进入looking状态并“投自己一票”然后向集群内的其他节点广播。</p>\n<p>选举的核心逻辑就是比较。比较什么呢？比较logicClock、zxid和serverid。 </p>\n<ul>\n<li>logicClock是投票的轮数，每个节点发起投票的时候会将自己的logicClock加1。如果一个节点收到其他节点的投票的时候发现对方的logicClock比自己的小那么会直接忽略该投票。如果发现比自己的大，那么会更新自己的logicClock并重新广播自己的投票（自己的投票之前可能已经被别的节点忽略了）。如果logicClock一样大就去比较zxid。</li>\n<li>zxid是一个64位的数字，类似于事务id。前32位是epoch，有点类似于raft中的term, 每一次新leader的产生都会使前32位加1。后32位是此次“epoch”周期内的单调递增id。如果zxid一样就去比较serverid。</li>\n<li>serverid是集群内每个机器的id，一个zk集群在启动的时候就已经确认好了这个集群有几个节点。每一个节点的配置文件里都有这个集群每一个节点的信息。</li>\n</ul>\n<p><strong>一但zxid的高位或者低位用尽则会重新强制重新选举。</strong></p>\n<p>每次选举的时候各个节点首先都是“先投自己一票”然后广播。每一个follower收到“其他节点的投票”的时候都会与自己刚刚投的票相比较（logicClock、zxid和server id），如果自己被pk下去了那么就更新自己本地的投票然后广播，如果不需要修改就什么都不做。</p>\n<p>因为每一个节点的投票信息其他的节点都会通过广播收到，因此每一个节点都有当前整个集群中所有节点的投票信息。一但有一个节点获取到了大多数票那么投票就结束了。</p>\n<p>如果一个节点新加入或者宕机后新加入，首先会发起选举，但是其他的节点会告诉他我们已经有leader了，然后此节点会自动变成follower。</p>\n<p>如果集群刚启动或者leader出现了问题，那么集群会进入崩溃恢复模式选举产生新的leader。新的leader出现后，<strong>有超过半数的follower已经与leader同步过数据后集群就进入了消息广播模式，即正常工作模式</strong></p>\n<h2 id=\"数据同步\"><a href=\"#数据同步\" class=\"headerlink\" title=\"数据同步\"></a>数据同步</h2><h3 id=\"正常的同步\"><a href=\"#正常的同步\" class=\"headerlink\" title=\"正常的同步\"></a>正常的同步</h3><p>zookeepe使用自己的zab协议实现数据同步。<br>写请求都会转发到leader上，随后leader会发出一个proposal，<strong>leader与follower之间的通信是通过队列来实现的并且每个proposal都有一个唯一的zxid</strong>，因此保证了follower中数据写入的顺序。当follower收到proposal后会写入本地日志到磁盘，并返回ack给leader。leader收到大多数的follower的ack后自己commit然后通知各个follower也commit同时返回客户端结果。</p>\n<h3 id=\"重新选举出leader后的同步\"><a href=\"#重新选举出leader后的同步\" class=\"headerlink\" title=\"重新选举出leader后的同步\"></a>重新选举出leader后的同步</h3><p>新leader先判断自己的未被commit的proposa是否能够commit（依据是此时整个集群额大多数节点都有这个proposal），如果可以就commit，如果不可以就不commit。因此最开始是先搞好leader的数据，之后leader会告诉follower增减数据。</p>\n<h3 id=\"如果leader刚发出proposal就宕机了，follower都没有收到\"><a href=\"#如果leader刚发出proposal就宕机了，follower都没有收到\" class=\"headerlink\" title=\"如果leader刚发出proposal就宕机了，follower都没有收到\"></a>如果leader刚发出proposal就宕机了，follower都没有收到</h3><p>那么新产生的leader将不知道有这个proposal，也就相当于这个proposal被废掉了，即使之前的leader加入集群，这个proposal也会被新的leader废掉。</p>\n<h3 id=\"如果leader收到大多数的ack，但是还没有commit\"><a href=\"#如果leader收到大多数的ack，但是还没有commit\" class=\"headerlink\" title=\"如果leader收到大多数的ack，但是还没有commit\"></a>如果leader收到大多数的ack，但是还没有commit</h3><p>收到的这些follower中肯定会有一个是新的leader。在其成为leader后会“领导大家”commit这个proposal</p>\n<h2 id=\"zk保证了一致性和分区可用性，在选举leader的时候集群不可用，牺牲了可用性\"><a href=\"#zk保证了一致性和分区可用性，在选举leader的时候集群不可用，牺牲了可用性\" class=\"headerlink\" title=\"zk保证了一致性和分区可用性，在选举leader的时候集群不可用，牺牲了可用性\"></a>zk保证了一致性和分区可用性，在选举leader的时候集群不可用，牺牲了可用性</h2>"},{"title":"标签","date":"2019-11-17T02:49:51.000Z","type":"tags","layout":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: 标签\ndate: 2019-11-17 10:49:51\ntype: \"tags\"\nlayout: \"tags\"\n---\n","updated":"2019-11-17T10:56:33.879Z","path":"tags/index.html","comments":1,"_id":"ckhupaqa000171no8z6lqnb0b","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Innodb查看B+tree的高度","date":"2019-11-21T02:46:47.000Z","photos":["http://sysummery.top/b-plus-tree_cover.png"],"_content":"在innodb中无论是主键索引还是非主键索引数据结构都是B+tree。而B+tree数的高度直接决定了在不考虑缓存的情况下读取一个数据页硬盘所需的IO次数，因此B+tree的高度相当重要。生产环境下高度一般为2~3.\n<!--more-->\n## 一颗B+tree能存放多少数据？\n先回顾几个名词\n\n* 磁盘的最小存储单元是扇区，大小为512字节\n* 文件系统的最小存储单元是4kb\n* innodb中数据的最小存储单元是页，大小为16kb（16384字节，不过也可以设置的更小）可以通过以下命令获取\n```sql\nshow variables like 'innodb_page_size'\n```\n* innodb中聚簇索引（主键）的叶子节点存放的是数据，非叶子节点存放的是关键字和指向下一层的指针，如下图所示，不过实际上叶子结点之间是一个双向链表而不是单向链表\n![](http://sysummery.top/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%882.41.29.jpg)\n\n我们假设主键是8字节的bigint型的，B+tree中的指针是6字节，那么一对数据+指针就是14字节，一个数据页的大小时16kb,但是一个数据页中不可能全部存放数据，还会有一些元信息，关于页结构可以参考这篇[文章](http://www.cnblogs.com/bdsir/p/8745553.html)。我们假设一个数据页存放数据部分最大16282字节。那么一个数据页可以存放`16282/14=1163`对“键值与指针”。\n\n如果一个数据表的主键索引的高度是2，说明他的第一层是键值和指针，第二层就是数据页了。第一层有1163个指针，也就说明第二层有1163个数据页，总共能存放`1163*16282=18935966`比特的数据。如果一行数据的平均大小为1kb,那么高度为2的B+tree可以存放`18935966/1024=18492`条数据。下面的这个是sql是查看一张表的行数据的平均大小\n```sql\nSELECT\n\t* \nFROM\n\tinformation_schema.TABLES \nWHERE\n\tinformation_schema.TABLES.TABLE_SCHEMA = 'test' \n\tAND information_schema.TABLES.TABLE_NAME = 'insert_asc'\n```\n其中test是库名insert_asc是表名。返回结果中的'AVG_ROW_LENGTH'就是每行数据的平均长度。\n\n如果高度是3的B+tree，第一层有1163个关键字于指针对，第二层就有`1163*1163`个关键字与指针对，叶子层就可以存放`1163*1163*16282`比特的数据。还是假如平均一行的数据大小是1kb,那么高度是3的B+tree可以存放`1163*1163*16282/1024=21506375`条数据。\n\n以上的推论过程有如下的局限性\n\n1. 一个数据页可以用来存放数据的空间是多少，我们假设是16282比特，但具体是多少我查了很多资料都没找到。\n2. 当一个数据页中的数据行的某一字段太大的时候，会把一部分数据放到额外的页中，为的是保证一个数据页至少有两条数据。所以啊，实际存储数据的数据页可能大于主键B+tree的叶子节点的数目。\n\n尽管上面的论证有一些局限性，但是我们还是能够得到如下的结论\n\n1. 如果单行数据不是太大的情况下，比如1kb,那么一课高度为3的主键索引可以存储2000多万行的数据，如果单行数据为0.5kb那么可以存储4000多万行的数据。\n2. 如果数据行的字段很多，会导致行数据的平均大小变大，可能会使B+tree的高度变大\n3. 一般来说B+tree的高度为2~3的时候性能是不错的，换言之如果单行记录不大的情况下，innodb的一张表能轻松地hold住2000万级别的数据\n\n## 直接查看B+tree的高度\n在innodb的表空间文件中,约定在根页偏移量64的地方存放了B+tree的高度。高度是从0开始算的。使用sql\n```sql\nSELECT\n\tb.NAME,\n\ta.NAME,\n\tindex_id,\n\ttype,\n\ta.space,\n\ta.PAGE_NO \nFROM\n\tinformation_schema.INNODB_SYS_INDEXES a,\n\tinformation_schema.INNODB_SYS_TABLES b \nWHERE\n\ta.table_id = b.table_id \n\tAND a.space <> 0 \n\tAND b.NAME = 'test/insert_desc';\n```\n可看到test数据库insert_desc表的所有索引信息\n![](http://sysummery.top/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%884.44.31.jpg)\n\n可以看到第一行是主键索引，他的根页在表空间的第三页。resblock_id是一个普通的索引，他的根页在表空间的第四页。使用\n```sh\nhexdump -s 49216 -n 10 insert_asc.ibd\n```\n可以看到表insert_asc.ibd主键索引的高度。\n![](http://sysummery.top/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%885.00.59.jpg)\n可以看到前两个字节是2，因此高度是3因为高度是从0开始算的。\n\n`-s 49216`表示从表空间文件的49216字节的偏移量开始读取，为什么是49216？因为主键索引的是在第三页,`49216=16kb*3+64`,其中16kb是数据页的大小。同理resblock_id的索引高度读取方法是\n```\nhexdump -s 65600 -n 10 insert_asc.ibd\n```\n得到的结果是\n![](http://sysummery.top/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%885.04.23.jpg)\n\n也就是改索引的高度是1.\n","source":"_posts/btree-height.md","raw":"---\ntitle: Innodb查看B+tree的高度\ndate: 2019-11-21 10:46:47\ntags:\n    - mysql\n    - innodb\nphotos:\n    - [\"http://sysummery.top/b-plus-tree_cover.png\"]\n---\n在innodb中无论是主键索引还是非主键索引数据结构都是B+tree。而B+tree数的高度直接决定了在不考虑缓存的情况下读取一个数据页硬盘所需的IO次数，因此B+tree的高度相当重要。生产环境下高度一般为2~3.\n<!--more-->\n## 一颗B+tree能存放多少数据？\n先回顾几个名词\n\n* 磁盘的最小存储单元是扇区，大小为512字节\n* 文件系统的最小存储单元是4kb\n* innodb中数据的最小存储单元是页，大小为16kb（16384字节，不过也可以设置的更小）可以通过以下命令获取\n```sql\nshow variables like 'innodb_page_size'\n```\n* innodb中聚簇索引（主键）的叶子节点存放的是数据，非叶子节点存放的是关键字和指向下一层的指针，如下图所示，不过实际上叶子结点之间是一个双向链表而不是单向链表\n![](http://sysummery.top/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%882.41.29.jpg)\n\n我们假设主键是8字节的bigint型的，B+tree中的指针是6字节，那么一对数据+指针就是14字节，一个数据页的大小时16kb,但是一个数据页中不可能全部存放数据，还会有一些元信息，关于页结构可以参考这篇[文章](http://www.cnblogs.com/bdsir/p/8745553.html)。我们假设一个数据页存放数据部分最大16282字节。那么一个数据页可以存放`16282/14=1163`对“键值与指针”。\n\n如果一个数据表的主键索引的高度是2，说明他的第一层是键值和指针，第二层就是数据页了。第一层有1163个指针，也就说明第二层有1163个数据页，总共能存放`1163*16282=18935966`比特的数据。如果一行数据的平均大小为1kb,那么高度为2的B+tree可以存放`18935966/1024=18492`条数据。下面的这个是sql是查看一张表的行数据的平均大小\n```sql\nSELECT\n\t* \nFROM\n\tinformation_schema.TABLES \nWHERE\n\tinformation_schema.TABLES.TABLE_SCHEMA = 'test' \n\tAND information_schema.TABLES.TABLE_NAME = 'insert_asc'\n```\n其中test是库名insert_asc是表名。返回结果中的'AVG_ROW_LENGTH'就是每行数据的平均长度。\n\n如果高度是3的B+tree，第一层有1163个关键字于指针对，第二层就有`1163*1163`个关键字与指针对，叶子层就可以存放`1163*1163*16282`比特的数据。还是假如平均一行的数据大小是1kb,那么高度是3的B+tree可以存放`1163*1163*16282/1024=21506375`条数据。\n\n以上的推论过程有如下的局限性\n\n1. 一个数据页可以用来存放数据的空间是多少，我们假设是16282比特，但具体是多少我查了很多资料都没找到。\n2. 当一个数据页中的数据行的某一字段太大的时候，会把一部分数据放到额外的页中，为的是保证一个数据页至少有两条数据。所以啊，实际存储数据的数据页可能大于主键B+tree的叶子节点的数目。\n\n尽管上面的论证有一些局限性，但是我们还是能够得到如下的结论\n\n1. 如果单行数据不是太大的情况下，比如1kb,那么一课高度为3的主键索引可以存储2000多万行的数据，如果单行数据为0.5kb那么可以存储4000多万行的数据。\n2. 如果数据行的字段很多，会导致行数据的平均大小变大，可能会使B+tree的高度变大\n3. 一般来说B+tree的高度为2~3的时候性能是不错的，换言之如果单行记录不大的情况下，innodb的一张表能轻松地hold住2000万级别的数据\n\n## 直接查看B+tree的高度\n在innodb的表空间文件中,约定在根页偏移量64的地方存放了B+tree的高度。高度是从0开始算的。使用sql\n```sql\nSELECT\n\tb.NAME,\n\ta.NAME,\n\tindex_id,\n\ttype,\n\ta.space,\n\ta.PAGE_NO \nFROM\n\tinformation_schema.INNODB_SYS_INDEXES a,\n\tinformation_schema.INNODB_SYS_TABLES b \nWHERE\n\ta.table_id = b.table_id \n\tAND a.space <> 0 \n\tAND b.NAME = 'test/insert_desc';\n```\n可看到test数据库insert_desc表的所有索引信息\n![](http://sysummery.top/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%884.44.31.jpg)\n\n可以看到第一行是主键索引，他的根页在表空间的第三页。resblock_id是一个普通的索引，他的根页在表空间的第四页。使用\n```sh\nhexdump -s 49216 -n 10 insert_asc.ibd\n```\n可以看到表insert_asc.ibd主键索引的高度。\n![](http://sysummery.top/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%885.00.59.jpg)\n可以看到前两个字节是2，因此高度是3因为高度是从0开始算的。\n\n`-s 49216`表示从表空间文件的49216字节的偏移量开始读取，为什么是49216？因为主键索引的是在第三页,`49216=16kb*3+64`,其中16kb是数据页的大小。同理resblock_id的索引高度读取方法是\n```\nhexdump -s 65600 -n 10 insert_asc.ibd\n```\n得到的结果是\n![](http://sysummery.top/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%885.04.23.jpg)\n\n也就是改索引的高度是1.\n","slug":"btree-height","published":1,"updated":"2020-11-23T15:23:47.775Z","comments":1,"layout":"post","link":"","_id":"ckhupaq8z00001no8mjznkcgi","content":"<p>在innodb中无论是主键索引还是非主键索引数据结构都是B+tree。而B+tree数的高度直接决定了在不考虑缓存的情况下读取一个数据页硬盘所需的IO次数，因此B+tree的高度相当重要。生产环境下高度一般为2~3.</p>\n<a id=\"more\"></a>\n<h2 id=\"一颗B-tree能存放多少数据？\"><a href=\"#一颗B-tree能存放多少数据？\" class=\"headerlink\" title=\"一颗B+tree能存放多少数据？\"></a>一颗B+tree能存放多少数据？</h2><p>先回顾几个名词</p>\n<ul>\n<li><p>磁盘的最小存储单元是扇区，大小为512字节</p>\n</li>\n<li><p>文件系统的最小存储单元是4kb</p>\n</li>\n<li><p>innodb中数据的最小存储单元是页，大小为16kb（16384字节，不过也可以设置的更小）可以通过以下命令获取</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'innodb_page_size'</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>innodb中聚簇索引（主键）的叶子节点存放的是数据，非叶子节点存放的是关键字和指向下一层的指针，如下图所示，不过实际上叶子结点之间是一个双向链表而不是单向链表<br><img src=\"http://sysummery.top/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%882.41.29.jpg\" alt></p>\n</li>\n</ul>\n<p>我们假设主键是8字节的bigint型的，B+tree中的指针是6字节，那么一对数据+指针就是14字节，一个数据页的大小时16kb,但是一个数据页中不可能全部存放数据，还会有一些元信息，关于页结构可以参考这篇<a href=\"http://www.cnblogs.com/bdsir/p/8745553.html\" target=\"_blank\" rel=\"noopener\">文章</a>。我们假设一个数据页存放数据部分最大16282字节。那么一个数据页可以存放<code>16282/14=1163</code>对“键值与指针”。</p>\n<p>如果一个数据表的主键索引的高度是2，说明他的第一层是键值和指针，第二层就是数据页了。第一层有1163个指针，也就说明第二层有1163个数据页，总共能存放<code>1163*16282=18935966</code>比特的数据。如果一行数据的平均大小为1kb,那么高度为2的B+tree可以存放<code>18935966/1024=18492</code>条数据。下面的这个是sql是查看一张表的行数据的平均大小</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">SELECT</span></span><br><span class=\"line\">\t* </span><br><span class=\"line\"><span class=\"keyword\">FROM</span></span><br><span class=\"line\">\tinformation_schema.TABLES </span><br><span class=\"line\"><span class=\"keyword\">WHERE</span></span><br><span class=\"line\">\tinformation_schema.TABLES.TABLE_SCHEMA = <span class=\"string\">'test'</span> </span><br><span class=\"line\">\t<span class=\"keyword\">AND</span> information_schema.TABLES.TABLE_NAME = <span class=\"string\">'insert_asc'</span></span><br></pre></td></tr></table></figure>\n\n<p>其中test是库名insert_asc是表名。返回结果中的’AVG_ROW_LENGTH’就是每行数据的平均长度。</p>\n<p>如果高度是3的B+tree，第一层有1163个关键字于指针对，第二层就有<code>1163*1163</code>个关键字与指针对，叶子层就可以存放<code>1163*1163*16282</code>比特的数据。还是假如平均一行的数据大小是1kb,那么高度是3的B+tree可以存放<code>1163*1163*16282/1024=21506375</code>条数据。</p>\n<p>以上的推论过程有如下的局限性</p>\n<ol>\n<li>一个数据页可以用来存放数据的空间是多少，我们假设是16282比特，但具体是多少我查了很多资料都没找到。</li>\n<li>当一个数据页中的数据行的某一字段太大的时候，会把一部分数据放到额外的页中，为的是保证一个数据页至少有两条数据。所以啊，实际存储数据的数据页可能大于主键B+tree的叶子节点的数目。</li>\n</ol>\n<p>尽管上面的论证有一些局限性，但是我们还是能够得到如下的结论</p>\n<ol>\n<li>如果单行数据不是太大的情况下，比如1kb,那么一课高度为3的主键索引可以存储2000多万行的数据，如果单行数据为0.5kb那么可以存储4000多万行的数据。</li>\n<li>如果数据行的字段很多，会导致行数据的平均大小变大，可能会使B+tree的高度变大</li>\n<li>一般来说B+tree的高度为2~3的时候性能是不错的，换言之如果单行记录不大的情况下，innodb的一张表能轻松地hold住2000万级别的数据</li>\n</ol>\n<h2 id=\"直接查看B-tree的高度\"><a href=\"#直接查看B-tree的高度\" class=\"headerlink\" title=\"直接查看B+tree的高度\"></a>直接查看B+tree的高度</h2><p>在innodb的表空间文件中,约定在根页偏移量64的地方存放了B+tree的高度。高度是从0开始算的。使用sql</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">SELECT</span></span><br><span class=\"line\">\tb.NAME,</span><br><span class=\"line\">\ta.NAME,</span><br><span class=\"line\">\tindex_id,</span><br><span class=\"line\">\t<span class=\"keyword\">type</span>,</span><br><span class=\"line\">\ta.space,</span><br><span class=\"line\">\ta.PAGE_NO </span><br><span class=\"line\"><span class=\"keyword\">FROM</span></span><br><span class=\"line\">\tinformation_schema.INNODB_SYS_INDEXES a,</span><br><span class=\"line\">\tinformation_schema.INNODB_SYS_TABLES b </span><br><span class=\"line\"><span class=\"keyword\">WHERE</span></span><br><span class=\"line\">\ta.table_id = b.table_id </span><br><span class=\"line\">\t<span class=\"keyword\">AND</span> a.space &lt;&gt; <span class=\"number\">0</span> </span><br><span class=\"line\">\t<span class=\"keyword\">AND</span> b.NAME = <span class=\"string\">'test/insert_desc'</span>;</span><br></pre></td></tr></table></figure>\n\n<p>可看到test数据库insert_desc表的所有索引信息<br><img src=\"http://sysummery.top/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%884.44.31.jpg\" alt></p>\n<p>可以看到第一行是主键索引，他的根页在表空间的第三页。resblock_id是一个普通的索引，他的根页在表空间的第四页。使用</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexdump -s 49216 -n 10 insert_asc.ibd</span><br></pre></td></tr></table></figure>\n\n<p>可以看到表insert_asc.ibd主键索引的高度。<br><img src=\"http://sysummery.top/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%885.00.59.jpg\" alt><br>可以看到前两个字节是2，因此高度是3因为高度是从0开始算的。</p>\n<p><code>-s 49216</code>表示从表空间文件的49216字节的偏移量开始读取，为什么是49216？因为主键索引的是在第三页,<code>49216=16kb*3+64</code>,其中16kb是数据页的大小。同理resblock_id的索引高度读取方法是</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexdump -s 65600 -n 10 insert_asc.ibd</span><br></pre></td></tr></table></figure>\n\n<p>得到的结果是<br><img src=\"http://sysummery.top/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%885.04.23.jpg\" alt></p>\n<p>也就是改索引的高度是1.</p>\n","site":{"data":{}},"excerpt":"<p>在innodb中无论是主键索引还是非主键索引数据结构都是B+tree。而B+tree数的高度直接决定了在不考虑缓存的情况下读取一个数据页硬盘所需的IO次数，因此B+tree的高度相当重要。生产环境下高度一般为2~3.</p>","more":"<h2 id=\"一颗B-tree能存放多少数据？\"><a href=\"#一颗B-tree能存放多少数据？\" class=\"headerlink\" title=\"一颗B+tree能存放多少数据？\"></a>一颗B+tree能存放多少数据？</h2><p>先回顾几个名词</p>\n<ul>\n<li><p>磁盘的最小存储单元是扇区，大小为512字节</p>\n</li>\n<li><p>文件系统的最小存储单元是4kb</p>\n</li>\n<li><p>innodb中数据的最小存储单元是页，大小为16kb（16384字节，不过也可以设置的更小）可以通过以下命令获取</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'innodb_page_size'</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>innodb中聚簇索引（主键）的叶子节点存放的是数据，非叶子节点存放的是关键字和指向下一层的指针，如下图所示，不过实际上叶子结点之间是一个双向链表而不是单向链表<br><img src=\"http://sysummery.top/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%882.41.29.jpg\" alt></p>\n</li>\n</ul>\n<p>我们假设主键是8字节的bigint型的，B+tree中的指针是6字节，那么一对数据+指针就是14字节，一个数据页的大小时16kb,但是一个数据页中不可能全部存放数据，还会有一些元信息，关于页结构可以参考这篇<a href=\"http://www.cnblogs.com/bdsir/p/8745553.html\" target=\"_blank\" rel=\"noopener\">文章</a>。我们假设一个数据页存放数据部分最大16282字节。那么一个数据页可以存放<code>16282/14=1163</code>对“键值与指针”。</p>\n<p>如果一个数据表的主键索引的高度是2，说明他的第一层是键值和指针，第二层就是数据页了。第一层有1163个指针，也就说明第二层有1163个数据页，总共能存放<code>1163*16282=18935966</code>比特的数据。如果一行数据的平均大小为1kb,那么高度为2的B+tree可以存放<code>18935966/1024=18492</code>条数据。下面的这个是sql是查看一张表的行数据的平均大小</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">SELECT</span></span><br><span class=\"line\">\t* </span><br><span class=\"line\"><span class=\"keyword\">FROM</span></span><br><span class=\"line\">\tinformation_schema.TABLES </span><br><span class=\"line\"><span class=\"keyword\">WHERE</span></span><br><span class=\"line\">\tinformation_schema.TABLES.TABLE_SCHEMA = <span class=\"string\">'test'</span> </span><br><span class=\"line\">\t<span class=\"keyword\">AND</span> information_schema.TABLES.TABLE_NAME = <span class=\"string\">'insert_asc'</span></span><br></pre></td></tr></table></figure>\n\n<p>其中test是库名insert_asc是表名。返回结果中的’AVG_ROW_LENGTH’就是每行数据的平均长度。</p>\n<p>如果高度是3的B+tree，第一层有1163个关键字于指针对，第二层就有<code>1163*1163</code>个关键字与指针对，叶子层就可以存放<code>1163*1163*16282</code>比特的数据。还是假如平均一行的数据大小是1kb,那么高度是3的B+tree可以存放<code>1163*1163*16282/1024=21506375</code>条数据。</p>\n<p>以上的推论过程有如下的局限性</p>\n<ol>\n<li>一个数据页可以用来存放数据的空间是多少，我们假设是16282比特，但具体是多少我查了很多资料都没找到。</li>\n<li>当一个数据页中的数据行的某一字段太大的时候，会把一部分数据放到额外的页中，为的是保证一个数据页至少有两条数据。所以啊，实际存储数据的数据页可能大于主键B+tree的叶子节点的数目。</li>\n</ol>\n<p>尽管上面的论证有一些局限性，但是我们还是能够得到如下的结论</p>\n<ol>\n<li>如果单行数据不是太大的情况下，比如1kb,那么一课高度为3的主键索引可以存储2000多万行的数据，如果单行数据为0.5kb那么可以存储4000多万行的数据。</li>\n<li>如果数据行的字段很多，会导致行数据的平均大小变大，可能会使B+tree的高度变大</li>\n<li>一般来说B+tree的高度为2~3的时候性能是不错的，换言之如果单行记录不大的情况下，innodb的一张表能轻松地hold住2000万级别的数据</li>\n</ol>\n<h2 id=\"直接查看B-tree的高度\"><a href=\"#直接查看B-tree的高度\" class=\"headerlink\" title=\"直接查看B+tree的高度\"></a>直接查看B+tree的高度</h2><p>在innodb的表空间文件中,约定在根页偏移量64的地方存放了B+tree的高度。高度是从0开始算的。使用sql</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">SELECT</span></span><br><span class=\"line\">\tb.NAME,</span><br><span class=\"line\">\ta.NAME,</span><br><span class=\"line\">\tindex_id,</span><br><span class=\"line\">\t<span class=\"keyword\">type</span>,</span><br><span class=\"line\">\ta.space,</span><br><span class=\"line\">\ta.PAGE_NO </span><br><span class=\"line\"><span class=\"keyword\">FROM</span></span><br><span class=\"line\">\tinformation_schema.INNODB_SYS_INDEXES a,</span><br><span class=\"line\">\tinformation_schema.INNODB_SYS_TABLES b </span><br><span class=\"line\"><span class=\"keyword\">WHERE</span></span><br><span class=\"line\">\ta.table_id = b.table_id </span><br><span class=\"line\">\t<span class=\"keyword\">AND</span> a.space &lt;&gt; <span class=\"number\">0</span> </span><br><span class=\"line\">\t<span class=\"keyword\">AND</span> b.NAME = <span class=\"string\">'test/insert_desc'</span>;</span><br></pre></td></tr></table></figure>\n\n<p>可看到test数据库insert_desc表的所有索引信息<br><img src=\"http://sysummery.top/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%884.44.31.jpg\" alt></p>\n<p>可以看到第一行是主键索引，他的根页在表空间的第三页。resblock_id是一个普通的索引，他的根页在表空间的第四页。使用</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexdump -s 49216 -n 10 insert_asc.ibd</span><br></pre></td></tr></table></figure>\n\n<p>可以看到表insert_asc.ibd主键索引的高度。<br><img src=\"http://sysummery.top/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%885.00.59.jpg\" alt><br>可以看到前两个字节是2，因此高度是3因为高度是从0开始算的。</p>\n<p><code>-s 49216</code>表示从表空间文件的49216字节的偏移量开始读取，为什么是49216？因为主键索引的是在第三页,<code>49216=16kb*3+64</code>,其中16kb是数据页的大小。同理resblock_id的索引高度读取方法是</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexdump -s 65600 -n 10 insert_asc.ibd</span><br></pre></td></tr></table></figure>\n\n<p>得到的结果是<br><img src=\"http://sysummery.top/%E6%88%AA%E5%B1%8F2019-11-21%E4%B8%8B%E5%8D%885.04.23.jpg\" alt></p>\n<p>也就是改索引的高度是1.</p>"},{"title":"从Cookie到OAuth2再到JWT","date":"2019-08-15T09:00:39.000Z","photos":["http://sysummery.top/jwt.jpeg"],"_content":"cookie加session认证是比较传统的方法，但是随着分布式系统的出现，这种认证方式局限性就渐渐显露出来了。OAuth2认证主要是用于使用公共平台的身份去登陆第三方网站。JWT是一种简单的认证方式，适合分布式系统。今天想总结一下工作几年来使用的三种认证方式\n<!--more-->\n## Cookie认证\nCookie认证是每次客户端向服务器请求的时候都会在http报文的header中传送一个字段叫Cookie，他的格式是形如这样的\n![](http://sysummery.top/cookie.jpg)\n以分号分隔，比如Cookie:a=b;c=d, 那么到达服务器以后以php为例会有一个全局能访问的数组$\\_COOKIE保存这两个键值对。\n```php\n$var_a = $_COOKIE['a'] //值为b\n$var_c = $_COOKIE['c'] //值为d \n```\n\nCookie并不是专门用来认证的，实时上他是用来和服务器交换数据的。因为http协议是无状态的，因此每次服务器返回给客户端的时候在返回的header里面会告诉浏览器保存哪些信息，然后再次请求这个域名的时候要带上这些信息，通过这种形式来模拟“有状态”。\n\n![](http://sysummery.top/setcookie.jpg)\n\n所以Cookie认证就是在发送的Cookie里面放一个用于表示认证的字段，这个字段的值就是一个凭证，这个凭证就像一把钥匙，能够与服务器上的“数据”相联系，这个数据叫做session。当服务器获得了浏览器传过来的“钥匙”的时候就会通过这把钥匙去找相应的session数据，session数据在哪？有可能在本机的文件系统，也有可能是在redis集群里面。使用redis的好处除了读取和写入的速度要快于文件之外还有一个就是对分布式系统支持良好。假如你的一个服务有a,b,c三台服务器，第一次请求负载均衡到了a机器上，理应session文件应该存储到a服务器的一个文件夹中，第二次负载到了b机器上，这时候b机器没有相应的文件，之前写到a机器上的数据就不见了。服务器获取到session数据后会加载到$\\_SESSION超全局数组中。\n\n最后说一下曾今困扰我的一个问题，就是session过期的问题。比如我的请求在10:30，服务端设立的session过期时间是30分钟，那么在11:00session应该就是过期的。但是如果我10:31再次请求的时候，服务端会认为这个session的过期时间是11:01，session的过期时间是每次请求都会更新的。\n\n## OAuth2 认证\nOAuth2的应用场景是第三方应用授权登录：在APP或者网页接入一些第三方应用时，时常会需要用户登录另一个合作平台，比如QQ，微博，微信的授权登录,第三方应用通过oauth2方式获取用户信息。\n\n他的流程图大致如下\n![](http://sysummery.top/oauth2.png)\n\n1. 用户访问一个网站A，并在网站的登陆页面选择使用\"微信\"登陆。\n2. 客户端扫描微信登陆的二维码，此时A网站向微信服务器发起授权请求，这个请求里面会告诉微信服务器哪个微信用户想使用微信信息登陆A网站。\n3. 微信服务器收到A网站的请求后会推送消息给用户让用户选择是否同意A网站使用用户的微信名或者微信头像等信息。网站A与微信服务器的tcp连接是一直连接着的，在http应用层面是通过不断的轮训来”保持连接“的。\n4. 用户同意\n5. 微信服务器会把网站A对微信服务器的请求转到A网站提前设定好的重定向地址中，同时还会附加一个code\n6. A网站通过code和A网站之前已经向微信服务器申请的app_id和app_secret向微信服务器申请调用微信用户信息接口的access_token和refresh_token。\n7. A网站使用access_token向微信的接口获取用户的用户名和头像\n8. 做一些用户信息处理，比如把该用户的信息存在自己的服务器\n9. 返回用户的头像和用户名给浏览器\n\n所以整个过程简单再说一下：先是用户选择微信登陆，然后网站A向微信服务器发起请求，微信服务器收到用户的确认后把请求重定向到网站A的服务器，网站A获取到用户的信息后返回给客户端，至此整个过程结束。\n\n## JWT认证\n传统的cookie与session认证在分布式系统里显得很无力很苍白。我们当然可以使用一个redis集群来整一个分布式的session。不过，还有一个方法就是使用JWT(json web token)\n\n他的原理其实很简单，每次客户端登陆成功后，服务器都会为这个用户产生一个认证的字符串，作为之后权限认证的token并放在返回的header中。之后客户端在请求的时候会在请求的header里面附上这个jwt token。服务器收到这个token后会进行一系列的验证，然后判断token的有效性。\n\n那么这个token长得啥样字呢？如下\n```\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ\n```\n\n一个jwt的token由3部分组成，分别称作header、payload、signature。header和payload原本都是json格式的数据，他们分别经过base64编码变成两段字符串。最后将这两段字符串使用\\.连接起来使用一个固定的密匙和加密算法生成第三段signature。\n\n### header\njwt的头部承载两部分信息：\n\n1. 声明类型，这里是jwt\n2. 声明加密的算法 通常直接使用 HMAC SHA256\n\n```js\n{\n  'typ': 'JWT',\n  'alg': 'HS256'\n}\n```\n然后将头部进行base64加密（该加密是可以对称解密的),构成了第一部分。\n```\neyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9\n```\n\n### payload\n载荷就是存放有效信息的地方。这个名字像是特指飞机上承载的货品，这些有效信息包含三个部分。\n\n1. 标准中注册的声明\n2. 公共的声明\n3. 私有的声明\n\n标准中注册的声明 (建议但不强制使用) ：\n\n1. iss: jwt签发者\n2. sub: jwt所面向的用户\n3. aud: 接收jwt的一方\n4. exp: jwt的过期时间，这个过期时间必须要大于签发时间\n5. nbf: 定义在什么时间之前，该jwt都是不可用的.\n6. iat: jwt的签发时间\n7. jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。\n\n公共的声明 ：\n公共的声明可以添加任何的信息，一般添加用户的相关信息或其他业务需要的必要信息.但不建议添加敏感信息，因为该部分在客户端可解密.\n\n私有的声明 ：\n私有声明是提供者和消费者所共同定义的声明，一般不建议存放敏感信息，因为base64是对称解密的，意味着该部分信息可以归类为明文信息。\n\n定义一个payload:\n```js\n{\n  \"sub\": \"1234567890\",\n  \"name\": \"John Doe\",\n  \"admin\": true\n}\n```\n然后将其进行base64加密，得到Jwt的第二部分。\n```\neyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9\n```\n### signature\n把上两步生成的字符串连接起来使用一个固定的secret和加密算法生成signature。然后把这三部分连接起来就是整个token。\n\n### 服务器验证token\n\n1. 首先先使用secret和加密算法重新对token的第一部分和第二部分加密得到signature，检查得到的signature是否与token的第三部分相同，如果不相同说明token可能是别人伪造的。\n2. 解析token的payload，检查token有没有过期等信息\n3. 应用层也要对token进行验证，比如payload中有没有user_id字段，如果有就可以通过user_id找当前登陆的用户，如果没有告诉客户端重新登陆。\n\n如果是分布式服务，那么只要每台机器的加密算法和加密secret都相同那么无论请求负载均衡到哪台机器上都是一样的。\n\n","source":"_posts/cookie-oauth2-jwt.md","raw":"---\ntitle: 从Cookie到OAuth2再到JWT\ndate: 2019-08-15 17:00:39\ntags:\n    - cookie\n    - oauth2\n    - jwt\nphotos:\n    - [\"http://sysummery.top/jwt.jpeg\"]\n---\ncookie加session认证是比较传统的方法，但是随着分布式系统的出现，这种认证方式局限性就渐渐显露出来了。OAuth2认证主要是用于使用公共平台的身份去登陆第三方网站。JWT是一种简单的认证方式，适合分布式系统。今天想总结一下工作几年来使用的三种认证方式\n<!--more-->\n## Cookie认证\nCookie认证是每次客户端向服务器请求的时候都会在http报文的header中传送一个字段叫Cookie，他的格式是形如这样的\n![](http://sysummery.top/cookie.jpg)\n以分号分隔，比如Cookie:a=b;c=d, 那么到达服务器以后以php为例会有一个全局能访问的数组$\\_COOKIE保存这两个键值对。\n```php\n$var_a = $_COOKIE['a'] //值为b\n$var_c = $_COOKIE['c'] //值为d \n```\n\nCookie并不是专门用来认证的，实时上他是用来和服务器交换数据的。因为http协议是无状态的，因此每次服务器返回给客户端的时候在返回的header里面会告诉浏览器保存哪些信息，然后再次请求这个域名的时候要带上这些信息，通过这种形式来模拟“有状态”。\n\n![](http://sysummery.top/setcookie.jpg)\n\n所以Cookie认证就是在发送的Cookie里面放一个用于表示认证的字段，这个字段的值就是一个凭证，这个凭证就像一把钥匙，能够与服务器上的“数据”相联系，这个数据叫做session。当服务器获得了浏览器传过来的“钥匙”的时候就会通过这把钥匙去找相应的session数据，session数据在哪？有可能在本机的文件系统，也有可能是在redis集群里面。使用redis的好处除了读取和写入的速度要快于文件之外还有一个就是对分布式系统支持良好。假如你的一个服务有a,b,c三台服务器，第一次请求负载均衡到了a机器上，理应session文件应该存储到a服务器的一个文件夹中，第二次负载到了b机器上，这时候b机器没有相应的文件，之前写到a机器上的数据就不见了。服务器获取到session数据后会加载到$\\_SESSION超全局数组中。\n\n最后说一下曾今困扰我的一个问题，就是session过期的问题。比如我的请求在10:30，服务端设立的session过期时间是30分钟，那么在11:00session应该就是过期的。但是如果我10:31再次请求的时候，服务端会认为这个session的过期时间是11:01，session的过期时间是每次请求都会更新的。\n\n## OAuth2 认证\nOAuth2的应用场景是第三方应用授权登录：在APP或者网页接入一些第三方应用时，时常会需要用户登录另一个合作平台，比如QQ，微博，微信的授权登录,第三方应用通过oauth2方式获取用户信息。\n\n他的流程图大致如下\n![](http://sysummery.top/oauth2.png)\n\n1. 用户访问一个网站A，并在网站的登陆页面选择使用\"微信\"登陆。\n2. 客户端扫描微信登陆的二维码，此时A网站向微信服务器发起授权请求，这个请求里面会告诉微信服务器哪个微信用户想使用微信信息登陆A网站。\n3. 微信服务器收到A网站的请求后会推送消息给用户让用户选择是否同意A网站使用用户的微信名或者微信头像等信息。网站A与微信服务器的tcp连接是一直连接着的，在http应用层面是通过不断的轮训来”保持连接“的。\n4. 用户同意\n5. 微信服务器会把网站A对微信服务器的请求转到A网站提前设定好的重定向地址中，同时还会附加一个code\n6. A网站通过code和A网站之前已经向微信服务器申请的app_id和app_secret向微信服务器申请调用微信用户信息接口的access_token和refresh_token。\n7. A网站使用access_token向微信的接口获取用户的用户名和头像\n8. 做一些用户信息处理，比如把该用户的信息存在自己的服务器\n9. 返回用户的头像和用户名给浏览器\n\n所以整个过程简单再说一下：先是用户选择微信登陆，然后网站A向微信服务器发起请求，微信服务器收到用户的确认后把请求重定向到网站A的服务器，网站A获取到用户的信息后返回给客户端，至此整个过程结束。\n\n## JWT认证\n传统的cookie与session认证在分布式系统里显得很无力很苍白。我们当然可以使用一个redis集群来整一个分布式的session。不过，还有一个方法就是使用JWT(json web token)\n\n他的原理其实很简单，每次客户端登陆成功后，服务器都会为这个用户产生一个认证的字符串，作为之后权限认证的token并放在返回的header中。之后客户端在请求的时候会在请求的header里面附上这个jwt token。服务器收到这个token后会进行一系列的验证，然后判断token的有效性。\n\n那么这个token长得啥样字呢？如下\n```\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ\n```\n\n一个jwt的token由3部分组成，分别称作header、payload、signature。header和payload原本都是json格式的数据，他们分别经过base64编码变成两段字符串。最后将这两段字符串使用\\.连接起来使用一个固定的密匙和加密算法生成第三段signature。\n\n### header\njwt的头部承载两部分信息：\n\n1. 声明类型，这里是jwt\n2. 声明加密的算法 通常直接使用 HMAC SHA256\n\n```js\n{\n  'typ': 'JWT',\n  'alg': 'HS256'\n}\n```\n然后将头部进行base64加密（该加密是可以对称解密的),构成了第一部分。\n```\neyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9\n```\n\n### payload\n载荷就是存放有效信息的地方。这个名字像是特指飞机上承载的货品，这些有效信息包含三个部分。\n\n1. 标准中注册的声明\n2. 公共的声明\n3. 私有的声明\n\n标准中注册的声明 (建议但不强制使用) ：\n\n1. iss: jwt签发者\n2. sub: jwt所面向的用户\n3. aud: 接收jwt的一方\n4. exp: jwt的过期时间，这个过期时间必须要大于签发时间\n5. nbf: 定义在什么时间之前，该jwt都是不可用的.\n6. iat: jwt的签发时间\n7. jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。\n\n公共的声明 ：\n公共的声明可以添加任何的信息，一般添加用户的相关信息或其他业务需要的必要信息.但不建议添加敏感信息，因为该部分在客户端可解密.\n\n私有的声明 ：\n私有声明是提供者和消费者所共同定义的声明，一般不建议存放敏感信息，因为base64是对称解密的，意味着该部分信息可以归类为明文信息。\n\n定义一个payload:\n```js\n{\n  \"sub\": \"1234567890\",\n  \"name\": \"John Doe\",\n  \"admin\": true\n}\n```\n然后将其进行base64加密，得到Jwt的第二部分。\n```\neyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9\n```\n### signature\n把上两步生成的字符串连接起来使用一个固定的secret和加密算法生成signature。然后把这三部分连接起来就是整个token。\n\n### 服务器验证token\n\n1. 首先先使用secret和加密算法重新对token的第一部分和第二部分加密得到signature，检查得到的signature是否与token的第三部分相同，如果不相同说明token可能是别人伪造的。\n2. 解析token的payload，检查token有没有过期等信息\n3. 应用层也要对token进行验证，比如payload中有没有user_id字段，如果有就可以通过user_id找当前登陆的用户，如果没有告诉客户端重新登陆。\n\n如果是分布式服务，那么只要每台机器的加密算法和加密secret都相同那么无论请求负载均衡到哪台机器上都是一样的。\n\n","slug":"cookie-oauth2-jwt","published":1,"updated":"2020-11-23T15:23:47.775Z","comments":1,"layout":"post","link":"","_id":"ckhupaq9400021no8eawhmatt","content":"<p>cookie加session认证是比较传统的方法，但是随着分布式系统的出现，这种认证方式局限性就渐渐显露出来了。OAuth2认证主要是用于使用公共平台的身份去登陆第三方网站。JWT是一种简单的认证方式，适合分布式系统。今天想总结一下工作几年来使用的三种认证方式</p>\n<a id=\"more\"></a>\n<h2 id=\"Cookie认证\"><a href=\"#Cookie认证\" class=\"headerlink\" title=\"Cookie认证\"></a>Cookie认证</h2><p>Cookie认证是每次客户端向服务器请求的时候都会在http报文的header中传送一个字段叫Cookie，他的格式是形如这样的<br><img src=\"http://sysummery.top/cookie.jpg\" alt><br>以分号分隔，比如Cookie:a=b;c=d, 那么到达服务器以后以php为例会有一个全局能访问的数组$_COOKIE保存这两个键值对。</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$var_a = $_COOKIE[<span class=\"string\">'a'</span>] <span class=\"comment\">//值为b</span></span><br><span class=\"line\">$var_c = $_COOKIE[<span class=\"string\">'c'</span>] <span class=\"comment\">//值为d</span></span><br></pre></td></tr></table></figure>\n\n<p>Cookie并不是专门用来认证的，实时上他是用来和服务器交换数据的。因为http协议是无状态的，因此每次服务器返回给客户端的时候在返回的header里面会告诉浏览器保存哪些信息，然后再次请求这个域名的时候要带上这些信息，通过这种形式来模拟“有状态”。</p>\n<p><img src=\"http://sysummery.top/setcookie.jpg\" alt></p>\n<p>所以Cookie认证就是在发送的Cookie里面放一个用于表示认证的字段，这个字段的值就是一个凭证，这个凭证就像一把钥匙，能够与服务器上的“数据”相联系，这个数据叫做session。当服务器获得了浏览器传过来的“钥匙”的时候就会通过这把钥匙去找相应的session数据，session数据在哪？有可能在本机的文件系统，也有可能是在redis集群里面。使用redis的好处除了读取和写入的速度要快于文件之外还有一个就是对分布式系统支持良好。假如你的一个服务有a,b,c三台服务器，第一次请求负载均衡到了a机器上，理应session文件应该存储到a服务器的一个文件夹中，第二次负载到了b机器上，这时候b机器没有相应的文件，之前写到a机器上的数据就不见了。服务器获取到session数据后会加载到$_SESSION超全局数组中。</p>\n<p>最后说一下曾今困扰我的一个问题，就是session过期的问题。比如我的请求在10:30，服务端设立的session过期时间是30分钟，那么在11:00session应该就是过期的。但是如果我10:31再次请求的时候，服务端会认为这个session的过期时间是11:01，session的过期时间是每次请求都会更新的。</p>\n<h2 id=\"OAuth2-认证\"><a href=\"#OAuth2-认证\" class=\"headerlink\" title=\"OAuth2 认证\"></a>OAuth2 认证</h2><p>OAuth2的应用场景是第三方应用授权登录：在APP或者网页接入一些第三方应用时，时常会需要用户登录另一个合作平台，比如QQ，微博，微信的授权登录,第三方应用通过oauth2方式获取用户信息。</p>\n<p>他的流程图大致如下<br><img src=\"http://sysummery.top/oauth2.png\" alt></p>\n<ol>\n<li>用户访问一个网站A，并在网站的登陆页面选择使用”微信”登陆。</li>\n<li>客户端扫描微信登陆的二维码，此时A网站向微信服务器发起授权请求，这个请求里面会告诉微信服务器哪个微信用户想使用微信信息登陆A网站。</li>\n<li>微信服务器收到A网站的请求后会推送消息给用户让用户选择是否同意A网站使用用户的微信名或者微信头像等信息。网站A与微信服务器的tcp连接是一直连接着的，在http应用层面是通过不断的轮训来”保持连接“的。</li>\n<li>用户同意</li>\n<li>微信服务器会把网站A对微信服务器的请求转到A网站提前设定好的重定向地址中，同时还会附加一个code</li>\n<li>A网站通过code和A网站之前已经向微信服务器申请的app_id和app_secret向微信服务器申请调用微信用户信息接口的access_token和refresh_token。</li>\n<li>A网站使用access_token向微信的接口获取用户的用户名和头像</li>\n<li>做一些用户信息处理，比如把该用户的信息存在自己的服务器</li>\n<li>返回用户的头像和用户名给浏览器</li>\n</ol>\n<p>所以整个过程简单再说一下：先是用户选择微信登陆，然后网站A向微信服务器发起请求，微信服务器收到用户的确认后把请求重定向到网站A的服务器，网站A获取到用户的信息后返回给客户端，至此整个过程结束。</p>\n<h2 id=\"JWT认证\"><a href=\"#JWT认证\" class=\"headerlink\" title=\"JWT认证\"></a>JWT认证</h2><p>传统的cookie与session认证在分布式系统里显得很无力很苍白。我们当然可以使用一个redis集群来整一个分布式的session。不过，还有一个方法就是使用JWT(json web token)</p>\n<p>他的原理其实很简单，每次客户端登陆成功后，服务器都会为这个用户产生一个认证的字符串，作为之后权限认证的token并放在返回的header中。之后客户端在请求的时候会在请求的header里面附上这个jwt token。服务器收到这个token后会进行一系列的验证，然后判断token的有效性。</p>\n<p>那么这个token长得啥样字呢？如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ</span><br></pre></td></tr></table></figure>\n\n<p>一个jwt的token由3部分组成，分别称作header、payload、signature。header和payload原本都是json格式的数据，他们分别经过base64编码变成两段字符串。最后将这两段字符串使用.连接起来使用一个固定的密匙和加密算法生成第三段signature。</p>\n<h3 id=\"header\"><a href=\"#header\" class=\"headerlink\" title=\"header\"></a>header</h3><p>jwt的头部承载两部分信息：</p>\n<ol>\n<li>声明类型，这里是jwt</li>\n<li>声明加密的算法 通常直接使用 HMAC SHA256</li>\n</ol>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">'typ'</span>: <span class=\"string\">'JWT'</span>,</span><br><span class=\"line\">  <span class=\"string\">'alg'</span>: <span class=\"string\">'HS256'</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>然后将头部进行base64加密（该加密是可以对称解密的),构成了第一部分。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"payload\"><a href=\"#payload\" class=\"headerlink\" title=\"payload\"></a>payload</h3><p>载荷就是存放有效信息的地方。这个名字像是特指飞机上承载的货品，这些有效信息包含三个部分。</p>\n<ol>\n<li>标准中注册的声明</li>\n<li>公共的声明</li>\n<li>私有的声明</li>\n</ol>\n<p>标准中注册的声明 (建议但不强制使用) ：</p>\n<ol>\n<li>iss: jwt签发者</li>\n<li>sub: jwt所面向的用户</li>\n<li>aud: 接收jwt的一方</li>\n<li>exp: jwt的过期时间，这个过期时间必须要大于签发时间</li>\n<li>nbf: 定义在什么时间之前，该jwt都是不可用的.</li>\n<li>iat: jwt的签发时间</li>\n<li>jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。</li>\n</ol>\n<p>公共的声明 ：<br>公共的声明可以添加任何的信息，一般添加用户的相关信息或其他业务需要的必要信息.但不建议添加敏感信息，因为该部分在客户端可解密.</p>\n<p>私有的声明 ：<br>私有声明是提供者和消费者所共同定义的声明，一般不建议存放敏感信息，因为base64是对称解密的，意味着该部分信息可以归类为明文信息。</p>\n<p>定义一个payload:</p>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"sub\"</span>: <span class=\"string\">\"1234567890\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"name\"</span>: <span class=\"string\">\"John Doe\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"admin\"</span>: <span class=\"literal\">true</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>然后将其进行base64加密，得到Jwt的第二部分。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"signature\"><a href=\"#signature\" class=\"headerlink\" title=\"signature\"></a>signature</h3><p>把上两步生成的字符串连接起来使用一个固定的secret和加密算法生成signature。然后把这三部分连接起来就是整个token。</p>\n<h3 id=\"服务器验证token\"><a href=\"#服务器验证token\" class=\"headerlink\" title=\"服务器验证token\"></a>服务器验证token</h3><ol>\n<li>首先先使用secret和加密算法重新对token的第一部分和第二部分加密得到signature，检查得到的signature是否与token的第三部分相同，如果不相同说明token可能是别人伪造的。</li>\n<li>解析token的payload，检查token有没有过期等信息</li>\n<li>应用层也要对token进行验证，比如payload中有没有user_id字段，如果有就可以通过user_id找当前登陆的用户，如果没有告诉客户端重新登陆。</li>\n</ol>\n<p>如果是分布式服务，那么只要每台机器的加密算法和加密secret都相同那么无论请求负载均衡到哪台机器上都是一样的。</p>\n","site":{"data":{}},"excerpt":"<p>cookie加session认证是比较传统的方法，但是随着分布式系统的出现，这种认证方式局限性就渐渐显露出来了。OAuth2认证主要是用于使用公共平台的身份去登陆第三方网站。JWT是一种简单的认证方式，适合分布式系统。今天想总结一下工作几年来使用的三种认证方式</p>","more":"<h2 id=\"Cookie认证\"><a href=\"#Cookie认证\" class=\"headerlink\" title=\"Cookie认证\"></a>Cookie认证</h2><p>Cookie认证是每次客户端向服务器请求的时候都会在http报文的header中传送一个字段叫Cookie，他的格式是形如这样的<br><img src=\"http://sysummery.top/cookie.jpg\" alt><br>以分号分隔，比如Cookie:a=b;c=d, 那么到达服务器以后以php为例会有一个全局能访问的数组$_COOKIE保存这两个键值对。</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$var_a = $_COOKIE[<span class=\"string\">'a'</span>] <span class=\"comment\">//值为b</span></span><br><span class=\"line\">$var_c = $_COOKIE[<span class=\"string\">'c'</span>] <span class=\"comment\">//值为d</span></span><br></pre></td></tr></table></figure>\n\n<p>Cookie并不是专门用来认证的，实时上他是用来和服务器交换数据的。因为http协议是无状态的，因此每次服务器返回给客户端的时候在返回的header里面会告诉浏览器保存哪些信息，然后再次请求这个域名的时候要带上这些信息，通过这种形式来模拟“有状态”。</p>\n<p><img src=\"http://sysummery.top/setcookie.jpg\" alt></p>\n<p>所以Cookie认证就是在发送的Cookie里面放一个用于表示认证的字段，这个字段的值就是一个凭证，这个凭证就像一把钥匙，能够与服务器上的“数据”相联系，这个数据叫做session。当服务器获得了浏览器传过来的“钥匙”的时候就会通过这把钥匙去找相应的session数据，session数据在哪？有可能在本机的文件系统，也有可能是在redis集群里面。使用redis的好处除了读取和写入的速度要快于文件之外还有一个就是对分布式系统支持良好。假如你的一个服务有a,b,c三台服务器，第一次请求负载均衡到了a机器上，理应session文件应该存储到a服务器的一个文件夹中，第二次负载到了b机器上，这时候b机器没有相应的文件，之前写到a机器上的数据就不见了。服务器获取到session数据后会加载到$_SESSION超全局数组中。</p>\n<p>最后说一下曾今困扰我的一个问题，就是session过期的问题。比如我的请求在10:30，服务端设立的session过期时间是30分钟，那么在11:00session应该就是过期的。但是如果我10:31再次请求的时候，服务端会认为这个session的过期时间是11:01，session的过期时间是每次请求都会更新的。</p>\n<h2 id=\"OAuth2-认证\"><a href=\"#OAuth2-认证\" class=\"headerlink\" title=\"OAuth2 认证\"></a>OAuth2 认证</h2><p>OAuth2的应用场景是第三方应用授权登录：在APP或者网页接入一些第三方应用时，时常会需要用户登录另一个合作平台，比如QQ，微博，微信的授权登录,第三方应用通过oauth2方式获取用户信息。</p>\n<p>他的流程图大致如下<br><img src=\"http://sysummery.top/oauth2.png\" alt></p>\n<ol>\n<li>用户访问一个网站A，并在网站的登陆页面选择使用”微信”登陆。</li>\n<li>客户端扫描微信登陆的二维码，此时A网站向微信服务器发起授权请求，这个请求里面会告诉微信服务器哪个微信用户想使用微信信息登陆A网站。</li>\n<li>微信服务器收到A网站的请求后会推送消息给用户让用户选择是否同意A网站使用用户的微信名或者微信头像等信息。网站A与微信服务器的tcp连接是一直连接着的，在http应用层面是通过不断的轮训来”保持连接“的。</li>\n<li>用户同意</li>\n<li>微信服务器会把网站A对微信服务器的请求转到A网站提前设定好的重定向地址中，同时还会附加一个code</li>\n<li>A网站通过code和A网站之前已经向微信服务器申请的app_id和app_secret向微信服务器申请调用微信用户信息接口的access_token和refresh_token。</li>\n<li>A网站使用access_token向微信的接口获取用户的用户名和头像</li>\n<li>做一些用户信息处理，比如把该用户的信息存在自己的服务器</li>\n<li>返回用户的头像和用户名给浏览器</li>\n</ol>\n<p>所以整个过程简单再说一下：先是用户选择微信登陆，然后网站A向微信服务器发起请求，微信服务器收到用户的确认后把请求重定向到网站A的服务器，网站A获取到用户的信息后返回给客户端，至此整个过程结束。</p>\n<h2 id=\"JWT认证\"><a href=\"#JWT认证\" class=\"headerlink\" title=\"JWT认证\"></a>JWT认证</h2><p>传统的cookie与session认证在分布式系统里显得很无力很苍白。我们当然可以使用一个redis集群来整一个分布式的session。不过，还有一个方法就是使用JWT(json web token)</p>\n<p>他的原理其实很简单，每次客户端登陆成功后，服务器都会为这个用户产生一个认证的字符串，作为之后权限认证的token并放在返回的header中。之后客户端在请求的时候会在请求的header里面附上这个jwt token。服务器收到这个token后会进行一系列的验证，然后判断token的有效性。</p>\n<p>那么这个token长得啥样字呢？如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ</span><br></pre></td></tr></table></figure>\n\n<p>一个jwt的token由3部分组成，分别称作header、payload、signature。header和payload原本都是json格式的数据，他们分别经过base64编码变成两段字符串。最后将这两段字符串使用.连接起来使用一个固定的密匙和加密算法生成第三段signature。</p>\n<h3 id=\"header\"><a href=\"#header\" class=\"headerlink\" title=\"header\"></a>header</h3><p>jwt的头部承载两部分信息：</p>\n<ol>\n<li>声明类型，这里是jwt</li>\n<li>声明加密的算法 通常直接使用 HMAC SHA256</li>\n</ol>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">'typ'</span>: <span class=\"string\">'JWT'</span>,</span><br><span class=\"line\">  <span class=\"string\">'alg'</span>: <span class=\"string\">'HS256'</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>然后将头部进行base64加密（该加密是可以对称解密的),构成了第一部分。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"payload\"><a href=\"#payload\" class=\"headerlink\" title=\"payload\"></a>payload</h3><p>载荷就是存放有效信息的地方。这个名字像是特指飞机上承载的货品，这些有效信息包含三个部分。</p>\n<ol>\n<li>标准中注册的声明</li>\n<li>公共的声明</li>\n<li>私有的声明</li>\n</ol>\n<p>标准中注册的声明 (建议但不强制使用) ：</p>\n<ol>\n<li>iss: jwt签发者</li>\n<li>sub: jwt所面向的用户</li>\n<li>aud: 接收jwt的一方</li>\n<li>exp: jwt的过期时间，这个过期时间必须要大于签发时间</li>\n<li>nbf: 定义在什么时间之前，该jwt都是不可用的.</li>\n<li>iat: jwt的签发时间</li>\n<li>jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。</li>\n</ol>\n<p>公共的声明 ：<br>公共的声明可以添加任何的信息，一般添加用户的相关信息或其他业务需要的必要信息.但不建议添加敏感信息，因为该部分在客户端可解密.</p>\n<p>私有的声明 ：<br>私有声明是提供者和消费者所共同定义的声明，一般不建议存放敏感信息，因为base64是对称解密的，意味着该部分信息可以归类为明文信息。</p>\n<p>定义一个payload:</p>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"sub\"</span>: <span class=\"string\">\"1234567890\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"name\"</span>: <span class=\"string\">\"John Doe\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"admin\"</span>: <span class=\"literal\">true</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>然后将其进行base64加密，得到Jwt的第二部分。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"signature\"><a href=\"#signature\" class=\"headerlink\" title=\"signature\"></a>signature</h3><p>把上两步生成的字符串连接起来使用一个固定的secret和加密算法生成signature。然后把这三部分连接起来就是整个token。</p>\n<h3 id=\"服务器验证token\"><a href=\"#服务器验证token\" class=\"headerlink\" title=\"服务器验证token\"></a>服务器验证token</h3><ol>\n<li>首先先使用secret和加密算法重新对token的第一部分和第二部分加密得到signature，检查得到的signature是否与token的第三部分相同，如果不相同说明token可能是别人伪造的。</li>\n<li>解析token的payload，检查token有没有过期等信息</li>\n<li>应用层也要对token进行验证，比如payload中有没有user_id字段，如果有就可以通过user_id找当前登陆的用户，如果没有告诉客户端重新登陆。</li>\n</ol>\n<p>如果是分布式服务，那么只要每台机器的加密算法和加密secret都相同那么无论请求负载均衡到哪台机器上都是一样的。</p>"},{"title":"Git进阶","date":"2019-12-01T04:18:22.000Z","photos":["http://sysummery.top/git_cover.jpeg"],"_content":"以下是我在工作中总结的关于git命令的一些使用方法。比较常用的那些我都不说了，主要是一些经常用但是又经常忘的命令，因此在这里总结一下，仅供参考。\n<!--more-->\n### 超看操作日志\n查看当前分支的所有的提交日志\n```sh\ngit log\n```\n查看当前分支最后n次的提交日志\n```sh\ngit log -n\n```\n在一行内显示当前分支的所有提交日志\n```sh\ngit log --oneline\n```\n\n在提交的msg里搜索当前分支的日志\n```sh\ngit log --grep='cps'\n```\n\n根据作者搜索当前分支的日志\n```sh\ngit log --author='suyang'\n```\n\n查看所有的提交日志，包括已经删除的分支的\n```sh\ngit reflog\n```\n`git reflog`与`git log`一样也可以使用`-n, --online,--grep,--author`\n\n### 操作子模块\n\n克隆项目的时候连同子模块一起克隆\n```sh\ngit clone --recursive [url][path]\n```\n如果克隆的时候没有连同子模块一起克隆那么还可以\n```sh\ngit submodule update --init --recursive\n```\n之后想更新子模块的内容\n```sh\ngit submodule update\n```\n如果想修改子模块，操作和正常的git仓库一致。\n\n### 提交\n下面的命令\n```sh\ngit commit -m'提交' -a\n```\n相当于两条命令\n```sh\ngit add .\ngit commit -m'提交'\n```\n\n修改上次提交的message\n```sh\ngit commit --amend\n```\n如果分支已经push了，那么千万不要使用该命令。因为该命令会改变commit的hash值，这样就使当前的分支与远程的分支“开叉”了。\n\n### 分支\n```sh\ngit checkout -b dev origin/dev\n```\n这个命令的初衷是新建本地的dev分支并跟踪远程的dev分支。这个命令的执行前提是本地知道远程有个dev分支，否则会报错。那么怎么才能让本地知道远程的分支呢?使用`git pull`。这个命令不仅能拉取跟踪分支的最新代码，还能拉取分支和标签信息。\n\n如果误删除了分支怎么办？像我这种不想留不再使用的东西的人，已经误删过好几次了，解决办法很简单先试用`git reflog`找到你误删除的分支的最后一次commit的hash值，然后通过下面的命令恢复\n```sh\ngit checkout -b recovery hash值\n```\n\n查看远程和本地的所有分支\n```sh\ngit branch -a\n```\n\n切换到刚才的分支\n```sh\ngit checkout -\n```\n下面说说rebase。\n1. 我的分支a是基于本地的master创建的，我的master跟踪远程的master\n2. 我在分支a上开发，有3个commit\n3. 在我开发的过程中，别人向远程的master提交了新的代码，这次提交总公有2个commit\n\n这个时候我们可以知道本地的master和现在远程最新的master都是基于之前旧版本的master的，如果我现在要向远程推送代码那么我应该\n\n1. 先checkout到我本地的master\n2. 拉取远程最新的master到我的master\n3. 在我本地merge分支a，其实在这个merge的过程就是三方合并，这三方分别是最初的master，现在远程最新的master，我的分支a\n\n上面的这种方式会让提交看起来很难看，因此还有另外一种方法\n\n1. 先checkout到我本地的master\n2. 拉取远程最新的master到我的master\n3. 切换会分支a，然后执行\n```sh\ngit rebase master\n```\n这个命令的意思是，使用现在的master的分支作为基础，重新把我在a分支上的提交依次覆盖到maste分支上作为新的a的分支。变基后a分支就在当前master分支的“直接上游”\n4. 切回master分支然后merge刚才变完基的a分支，这个过程是一个fast-forward\n\n### 撤销命令汇总\n\n撤销最后n次commit，并把撤销出来的更改放到暂存区。工作区不会受影响\n```sh\ngit reset --soft HEAD~n\n```\n\n如果想直接丢弃撤销出来的内容\n```sh\ngit reset --hard HEAD~n\n```\n将fileName从暂存区删除，这不会对此时的工作区有任何的影响，仅仅是从暂存区删除了fileName而已.但是此时git会重新对filename就行评估，如果此时filename与版本库不一致，那么filename还是会出现在工作区，但这与reset命令没有关系\n```sh\ngit reset fileName\n```\n\n用版本库里的代码强行刷新暂存区与工作区\n```sh\ngit checkout -f\n```\n\n拉区版本库的 fileName 同时替换工作区与暂存区的fileName\n```sh\ngit checkout HEAD filename\n```\n\n将工作区的fileName替换为暂存区的fileName，如果暂存区没有，那么会去版本库拉去fileName替换工作区的fileName。之后filename肯定不会出现在工作区\n```sh\ngit checkout filename\n```\n\n最后说一下git revert命令\n```\ngit revert hash值\n```\nrevert命令会撤销某一次的提交，与reset不同的是，当前的版本库不会回退,而是向前一步\n","source":"_posts/git-advance.md","raw":"---\ntitle: Git进阶\ndate: 2019-12-01 12:18:22\ntags:\n   - git\nphotos:\n   - [\"http://sysummery.top/git_cover.jpeg\"]\n---\n以下是我在工作中总结的关于git命令的一些使用方法。比较常用的那些我都不说了，主要是一些经常用但是又经常忘的命令，因此在这里总结一下，仅供参考。\n<!--more-->\n### 超看操作日志\n查看当前分支的所有的提交日志\n```sh\ngit log\n```\n查看当前分支最后n次的提交日志\n```sh\ngit log -n\n```\n在一行内显示当前分支的所有提交日志\n```sh\ngit log --oneline\n```\n\n在提交的msg里搜索当前分支的日志\n```sh\ngit log --grep='cps'\n```\n\n根据作者搜索当前分支的日志\n```sh\ngit log --author='suyang'\n```\n\n查看所有的提交日志，包括已经删除的分支的\n```sh\ngit reflog\n```\n`git reflog`与`git log`一样也可以使用`-n, --online,--grep,--author`\n\n### 操作子模块\n\n克隆项目的时候连同子模块一起克隆\n```sh\ngit clone --recursive [url][path]\n```\n如果克隆的时候没有连同子模块一起克隆那么还可以\n```sh\ngit submodule update --init --recursive\n```\n之后想更新子模块的内容\n```sh\ngit submodule update\n```\n如果想修改子模块，操作和正常的git仓库一致。\n\n### 提交\n下面的命令\n```sh\ngit commit -m'提交' -a\n```\n相当于两条命令\n```sh\ngit add .\ngit commit -m'提交'\n```\n\n修改上次提交的message\n```sh\ngit commit --amend\n```\n如果分支已经push了，那么千万不要使用该命令。因为该命令会改变commit的hash值，这样就使当前的分支与远程的分支“开叉”了。\n\n### 分支\n```sh\ngit checkout -b dev origin/dev\n```\n这个命令的初衷是新建本地的dev分支并跟踪远程的dev分支。这个命令的执行前提是本地知道远程有个dev分支，否则会报错。那么怎么才能让本地知道远程的分支呢?使用`git pull`。这个命令不仅能拉取跟踪分支的最新代码，还能拉取分支和标签信息。\n\n如果误删除了分支怎么办？像我这种不想留不再使用的东西的人，已经误删过好几次了，解决办法很简单先试用`git reflog`找到你误删除的分支的最后一次commit的hash值，然后通过下面的命令恢复\n```sh\ngit checkout -b recovery hash值\n```\n\n查看远程和本地的所有分支\n```sh\ngit branch -a\n```\n\n切换到刚才的分支\n```sh\ngit checkout -\n```\n下面说说rebase。\n1. 我的分支a是基于本地的master创建的，我的master跟踪远程的master\n2. 我在分支a上开发，有3个commit\n3. 在我开发的过程中，别人向远程的master提交了新的代码，这次提交总公有2个commit\n\n这个时候我们可以知道本地的master和现在远程最新的master都是基于之前旧版本的master的，如果我现在要向远程推送代码那么我应该\n\n1. 先checkout到我本地的master\n2. 拉取远程最新的master到我的master\n3. 在我本地merge分支a，其实在这个merge的过程就是三方合并，这三方分别是最初的master，现在远程最新的master，我的分支a\n\n上面的这种方式会让提交看起来很难看，因此还有另外一种方法\n\n1. 先checkout到我本地的master\n2. 拉取远程最新的master到我的master\n3. 切换会分支a，然后执行\n```sh\ngit rebase master\n```\n这个命令的意思是，使用现在的master的分支作为基础，重新把我在a分支上的提交依次覆盖到maste分支上作为新的a的分支。变基后a分支就在当前master分支的“直接上游”\n4. 切回master分支然后merge刚才变完基的a分支，这个过程是一个fast-forward\n\n### 撤销命令汇总\n\n撤销最后n次commit，并把撤销出来的更改放到暂存区。工作区不会受影响\n```sh\ngit reset --soft HEAD~n\n```\n\n如果想直接丢弃撤销出来的内容\n```sh\ngit reset --hard HEAD~n\n```\n将fileName从暂存区删除，这不会对此时的工作区有任何的影响，仅仅是从暂存区删除了fileName而已.但是此时git会重新对filename就行评估，如果此时filename与版本库不一致，那么filename还是会出现在工作区，但这与reset命令没有关系\n```sh\ngit reset fileName\n```\n\n用版本库里的代码强行刷新暂存区与工作区\n```sh\ngit checkout -f\n```\n\n拉区版本库的 fileName 同时替换工作区与暂存区的fileName\n```sh\ngit checkout HEAD filename\n```\n\n将工作区的fileName替换为暂存区的fileName，如果暂存区没有，那么会去版本库拉去fileName替换工作区的fileName。之后filename肯定不会出现在工作区\n```sh\ngit checkout filename\n```\n\n最后说一下git revert命令\n```\ngit revert hash值\n```\nrevert命令会撤销某一次的提交，与reset不同的是，当前的版本库不会回退,而是向前一步\n","slug":"git-advance","published":1,"updated":"2020-11-23T15:23:47.776Z","comments":1,"layout":"post","link":"","_id":"ckhupaq9800051no83zyt969a","content":"<p>以下是我在工作中总结的关于git命令的一些使用方法。比较常用的那些我都不说了，主要是一些经常用但是又经常忘的命令，因此在这里总结一下，仅供参考。</p>\n<a id=\"more\"></a>\n<h3 id=\"超看操作日志\"><a href=\"#超看操作日志\" class=\"headerlink\" title=\"超看操作日志\"></a>超看操作日志</h3><p>查看当前分支的所有的提交日志</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">log</span></span><br></pre></td></tr></table></figure>\n\n<p>查看当前分支最后n次的提交日志</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">log</span> -n</span><br></pre></td></tr></table></figure>\n\n<p>在一行内显示当前分支的所有提交日志</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">log</span> --oneline</span><br></pre></td></tr></table></figure>\n\n<p>在提交的msg里搜索当前分支的日志</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">log</span> --grep=<span class=\"string\">'cps'</span></span><br></pre></td></tr></table></figure>\n\n<p>根据作者搜索当前分支的日志</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">log</span> --author=<span class=\"string\">'suyang'</span></span><br></pre></td></tr></table></figure>\n\n<p>查看所有的提交日志，包括已经删除的分支的</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git reflog</span><br></pre></td></tr></table></figure>\n\n<p><code>git reflog</code>与<code>git log</code>一样也可以使用<code>-n, --online,--grep,--author</code></p>\n<h3 id=\"操作子模块\"><a href=\"#操作子模块\" class=\"headerlink\" title=\"操作子模块\"></a>操作子模块</h3><p>克隆项目的时候连同子模块一起克隆</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> --recursive [url][path]</span><br></pre></td></tr></table></figure>\n\n<p>如果克隆的时候没有连同子模块一起克隆那么还可以</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git submodule update --init --recursive</span><br></pre></td></tr></table></figure>\n\n<p>之后想更新子模块的内容</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git submodule update</span><br></pre></td></tr></table></figure>\n\n<p>如果想修改子模块，操作和正常的git仓库一致。</p>\n<h3 id=\"提交\"><a href=\"#提交\" class=\"headerlink\" title=\"提交\"></a>提交</h3><p>下面的命令</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git commit -m<span class=\"string\">'提交'</span> -a</span><br></pre></td></tr></table></figure>\n\n<p>相当于两条命令</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git add .</span><br><span class=\"line\">git commit -m<span class=\"string\">'提交'</span></span><br></pre></td></tr></table></figure>\n\n<p>修改上次提交的message</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git commit --amend</span><br></pre></td></tr></table></figure>\n\n<p>如果分支已经push了，那么千万不要使用该命令。因为该命令会改变commit的hash值，这样就使当前的分支与远程的分支“开叉”了。</p>\n<h3 id=\"分支\"><a href=\"#分支\" class=\"headerlink\" title=\"分支\"></a>分支</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout -b dev origin/dev</span><br></pre></td></tr></table></figure>\n\n<p>这个命令的初衷是新建本地的dev分支并跟踪远程的dev分支。这个命令的执行前提是本地知道远程有个dev分支，否则会报错。那么怎么才能让本地知道远程的分支呢?使用<code>git pull</code>。这个命令不仅能拉取跟踪分支的最新代码，还能拉取分支和标签信息。</p>\n<p>如果误删除了分支怎么办？像我这种不想留不再使用的东西的人，已经误删过好几次了，解决办法很简单先试用<code>git reflog</code>找到你误删除的分支的最后一次commit的hash值，然后通过下面的命令恢复</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout -b recovery <span class=\"built_in\">hash</span>值</span><br></pre></td></tr></table></figure>\n\n<p>查看远程和本地的所有分支</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git branch -a</span><br></pre></td></tr></table></figure>\n\n<p>切换到刚才的分支</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout -</span><br></pre></td></tr></table></figure>\n\n<p>下面说说rebase。</p>\n<ol>\n<li>我的分支a是基于本地的master创建的，我的master跟踪远程的master</li>\n<li>我在分支a上开发，有3个commit</li>\n<li>在我开发的过程中，别人向远程的master提交了新的代码，这次提交总公有2个commit</li>\n</ol>\n<p>这个时候我们可以知道本地的master和现在远程最新的master都是基于之前旧版本的master的，如果我现在要向远程推送代码那么我应该</p>\n<ol>\n<li>先checkout到我本地的master</li>\n<li>拉取远程最新的master到我的master</li>\n<li>在我本地merge分支a，其实在这个merge的过程就是三方合并，这三方分别是最初的master，现在远程最新的master，我的分支a</li>\n</ol>\n<p>上面的这种方式会让提交看起来很难看，因此还有另外一种方法</p>\n<ol>\n<li>先checkout到我本地的master</li>\n<li>拉取远程最新的master到我的master</li>\n<li>切换会分支a，然后执行<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git rebase master</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<p>这个命令的意思是，使用现在的master的分支作为基础，重新把我在a分支上的提交依次覆盖到maste分支上作为新的a的分支。变基后a分支就在当前master分支的“直接上游”<br>4. 切回master分支然后merge刚才变完基的a分支，这个过程是一个fast-forward</p>\n<h3 id=\"撤销命令汇总\"><a href=\"#撤销命令汇总\" class=\"headerlink\" title=\"撤销命令汇总\"></a>撤销命令汇总</h3><p>撤销最后n次commit，并把撤销出来的更改放到暂存区。工作区不会受影响</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git reset --soft HEAD~n</span><br></pre></td></tr></table></figure>\n\n<p>如果想直接丢弃撤销出来的内容</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git reset --hard HEAD~n</span><br></pre></td></tr></table></figure>\n\n<p>将fileName从暂存区删除，这不会对此时的工作区有任何的影响，仅仅是从暂存区删除了fileName而已.但是此时git会重新对filename就行评估，如果此时filename与版本库不一致，那么filename还是会出现在工作区，但这与reset命令没有关系</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git reset fileName</span><br></pre></td></tr></table></figure>\n\n<p>用版本库里的代码强行刷新暂存区与工作区</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout -f</span><br></pre></td></tr></table></figure>\n\n<p>拉区版本库的 fileName 同时替换工作区与暂存区的fileName</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout HEAD filename</span><br></pre></td></tr></table></figure>\n\n<p>将工作区的fileName替换为暂存区的fileName，如果暂存区没有，那么会去版本库拉去fileName替换工作区的fileName。之后filename肯定不会出现在工作区</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout filename</span><br></pre></td></tr></table></figure>\n\n<p>最后说一下git revert命令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git revert hash值</span><br></pre></td></tr></table></figure>\n\n<p>revert命令会撤销某一次的提交，与reset不同的是，当前的版本库不会回退,而是向前一步</p>\n","site":{"data":{}},"excerpt":"<p>以下是我在工作中总结的关于git命令的一些使用方法。比较常用的那些我都不说了，主要是一些经常用但是又经常忘的命令，因此在这里总结一下，仅供参考。</p>","more":"<h3 id=\"超看操作日志\"><a href=\"#超看操作日志\" class=\"headerlink\" title=\"超看操作日志\"></a>超看操作日志</h3><p>查看当前分支的所有的提交日志</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">log</span></span><br></pre></td></tr></table></figure>\n\n<p>查看当前分支最后n次的提交日志</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">log</span> -n</span><br></pre></td></tr></table></figure>\n\n<p>在一行内显示当前分支的所有提交日志</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">log</span> --oneline</span><br></pre></td></tr></table></figure>\n\n<p>在提交的msg里搜索当前分支的日志</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">log</span> --grep=<span class=\"string\">'cps'</span></span><br></pre></td></tr></table></figure>\n\n<p>根据作者搜索当前分支的日志</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">log</span> --author=<span class=\"string\">'suyang'</span></span><br></pre></td></tr></table></figure>\n\n<p>查看所有的提交日志，包括已经删除的分支的</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git reflog</span><br></pre></td></tr></table></figure>\n\n<p><code>git reflog</code>与<code>git log</code>一样也可以使用<code>-n, --online,--grep,--author</code></p>\n<h3 id=\"操作子模块\"><a href=\"#操作子模块\" class=\"headerlink\" title=\"操作子模块\"></a>操作子模块</h3><p>克隆项目的时候连同子模块一起克隆</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> --recursive [url][path]</span><br></pre></td></tr></table></figure>\n\n<p>如果克隆的时候没有连同子模块一起克隆那么还可以</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git submodule update --init --recursive</span><br></pre></td></tr></table></figure>\n\n<p>之后想更新子模块的内容</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git submodule update</span><br></pre></td></tr></table></figure>\n\n<p>如果想修改子模块，操作和正常的git仓库一致。</p>\n<h3 id=\"提交\"><a href=\"#提交\" class=\"headerlink\" title=\"提交\"></a>提交</h3><p>下面的命令</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git commit -m<span class=\"string\">'提交'</span> -a</span><br></pre></td></tr></table></figure>\n\n<p>相当于两条命令</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git add .</span><br><span class=\"line\">git commit -m<span class=\"string\">'提交'</span></span><br></pre></td></tr></table></figure>\n\n<p>修改上次提交的message</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git commit --amend</span><br></pre></td></tr></table></figure>\n\n<p>如果分支已经push了，那么千万不要使用该命令。因为该命令会改变commit的hash值，这样就使当前的分支与远程的分支“开叉”了。</p>\n<h3 id=\"分支\"><a href=\"#分支\" class=\"headerlink\" title=\"分支\"></a>分支</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout -b dev origin/dev</span><br></pre></td></tr></table></figure>\n\n<p>这个命令的初衷是新建本地的dev分支并跟踪远程的dev分支。这个命令的执行前提是本地知道远程有个dev分支，否则会报错。那么怎么才能让本地知道远程的分支呢?使用<code>git pull</code>。这个命令不仅能拉取跟踪分支的最新代码，还能拉取分支和标签信息。</p>\n<p>如果误删除了分支怎么办？像我这种不想留不再使用的东西的人，已经误删过好几次了，解决办法很简单先试用<code>git reflog</code>找到你误删除的分支的最后一次commit的hash值，然后通过下面的命令恢复</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout -b recovery <span class=\"built_in\">hash</span>值</span><br></pre></td></tr></table></figure>\n\n<p>查看远程和本地的所有分支</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git branch -a</span><br></pre></td></tr></table></figure>\n\n<p>切换到刚才的分支</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout -</span><br></pre></td></tr></table></figure>\n\n<p>下面说说rebase。</p>\n<ol>\n<li>我的分支a是基于本地的master创建的，我的master跟踪远程的master</li>\n<li>我在分支a上开发，有3个commit</li>\n<li>在我开发的过程中，别人向远程的master提交了新的代码，这次提交总公有2个commit</li>\n</ol>\n<p>这个时候我们可以知道本地的master和现在远程最新的master都是基于之前旧版本的master的，如果我现在要向远程推送代码那么我应该</p>\n<ol>\n<li>先checkout到我本地的master</li>\n<li>拉取远程最新的master到我的master</li>\n<li>在我本地merge分支a，其实在这个merge的过程就是三方合并，这三方分别是最初的master，现在远程最新的master，我的分支a</li>\n</ol>\n<p>上面的这种方式会让提交看起来很难看，因此还有另外一种方法</p>\n<ol>\n<li>先checkout到我本地的master</li>\n<li>拉取远程最新的master到我的master</li>\n<li>切换会分支a，然后执行<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git rebase master</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<p>这个命令的意思是，使用现在的master的分支作为基础，重新把我在a分支上的提交依次覆盖到maste分支上作为新的a的分支。变基后a分支就在当前master分支的“直接上游”<br>4. 切回master分支然后merge刚才变完基的a分支，这个过程是一个fast-forward</p>\n<h3 id=\"撤销命令汇总\"><a href=\"#撤销命令汇总\" class=\"headerlink\" title=\"撤销命令汇总\"></a>撤销命令汇总</h3><p>撤销最后n次commit，并把撤销出来的更改放到暂存区。工作区不会受影响</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git reset --soft HEAD~n</span><br></pre></td></tr></table></figure>\n\n<p>如果想直接丢弃撤销出来的内容</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git reset --hard HEAD~n</span><br></pre></td></tr></table></figure>\n\n<p>将fileName从暂存区删除，这不会对此时的工作区有任何的影响，仅仅是从暂存区删除了fileName而已.但是此时git会重新对filename就行评估，如果此时filename与版本库不一致，那么filename还是会出现在工作区，但这与reset命令没有关系</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git reset fileName</span><br></pre></td></tr></table></figure>\n\n<p>用版本库里的代码强行刷新暂存区与工作区</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout -f</span><br></pre></td></tr></table></figure>\n\n<p>拉区版本库的 fileName 同时替换工作区与暂存区的fileName</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout HEAD filename</span><br></pre></td></tr></table></figure>\n\n<p>将工作区的fileName替换为暂存区的fileName，如果暂存区没有，那么会去版本库拉去fileName替换工作区的fileName。之后filename肯定不会出现在工作区</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout filename</span><br></pre></td></tr></table></figure>\n\n<p>最后说一下git revert命令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git revert hash值</span><br></pre></td></tr></table></figure>\n\n<p>revert命令会撤销某一次的提交，与reset不同的是，当前的版本库不会回退,而是向前一步</p>"},{"title":"Go语言中的数组、字符串、切片","date":"2019-12-23T04:18:35.000Z","photos":["http://sysummery.top/gocover1.jpeg"],"_content":"之所以把他们三个放一起是因为他们3个的底层的原始数据有着一样的数据结构。\n<!--more-->\n## 数组\n数组是由**固定长度的**特定类型的元素组成的序列。这些元素在内存中的存储是连续的。数组一经定义，他的长度是不能改变的，数组的长度可以是0.\n\n下面几种数组的定义方式都是正确的。在go语言中，数组就是数组，并不是指向首元素的指针。\n```go\n\n//长度为3的数组，数组的每个元素的值都是0\nvar test [3]int\n\n//与上面的一样，加了{}就得用等于号\nvar test = [3]int{}\n\n//长度为3的数组，在定义的时候也初始化了每个元素的值\nvar test = [3]int{1,2,3}\n\n//长度为3的数组，第一个元素的值为1其余的值为0\nvar test = [3]int{1}\n\n//长度为3的数组，下标为1的元素的值是2，下标为0的元素的值是3，其余的值是0\nvar test = [3]int{1:2,0:3}\n\n//长度为3的数组，下标为0的元素值是1，下标为1的元素值是2，下标为2的元素值是3\nvar test = [3]int{1,1:2,2:3}\n```\n\n当一个数组被赋值或者当做函数参数被传递的时候，会复制整个数组，如果此时数组比价大，那么开销也是很大的。可以使用数组指针替代。数组指针在使用上和数组是很相似的\n```go\nfunc main () {\n\tvar test = [3]int{1:2,0:3}\n\n\tp := &test\n\n\tfmt.Println(test[0])\n\tfmt.Println(p[0])\n\n\ttest[0] = 100\n\n\tfmt.Println(test[0])\n\tfmt.Println(p[0])\n}\n```\n结果\n```\n3\n3\n100\n100\n```\n\n空数组时不占内存的，这一点与空结构体是一样的。\n```go\n\nvar times [5][0]int\n\nfor range times {\n    fmt.Println(\"hello\")\n}\n```\n\n## 字符串\n字符串是一个连续的不可改变的字节序列。\n看一下go语言中字符串的定义其实是个结构体\n```go\ntype StringHeader struct {\n    Data uintptr\n    Len int\n}\n```\n可以看出，字符串的底层是一个非负数的字节数组，另外还有一个长度。\n所以当复制一个字符串给一个变量或者作为参数传递的时候只是复制了指向基础数据的指针和字符串的长度，并没有复制底层的数据。\n\n下面先看一段代码\n```go\nfunc main () {\n\tstr := \"Hello 世界\"\n\tfor i:= 0; i < len(str); i++ {\n\t\tch := str[i]\n\t\tfmt.Println(ch)\n\t}\n\n\tfmt.Println(\"-------unicode遍历-------\")\n\tfor _, ch := range str {\n\t\tfmt.Println(ch)\n\t}\n}\n```\n结果为\n72\n101\n108\n108\n111\n32\n228\n184\n150\n231\n149\n140\n-----------unicode遍历-------------\n72\n101\n108\n108\n111\n32\n19990\n30028\n\n从结果我们可以看出\n\n1. 两个循环输出的都是一堆数字，说明go中的字符串是以byte方式存储的\n2. for循环输出的是字节的“数值”，for range输出的是以utf-8为编码方式的unicode字符的“数值”\n\n如果我想直接输出字符而不是字符的“数值”怎么办？很简单，用强制转换就好\n\n```go\nfunc main () {\n\tstr := \"Hello 世界\"\n\tfor i:= 0; i < len(str); i++ {\n\t\tch := str[i]\n\t\tfmt.Println(string(ch))\n\t}\n\n\tfmt.Println(\"------unicode遍历--------\")\n\tfor _, ch := range str {\n\t\tfmt.Println(string(ch))\n\t}\n}\n```\n输出的结果为\nH\ne\nl\nl\no\n \nä\n¸\n\nç\n\n\n-----------unicode遍历-------------\nH\ne\nl\nl\no\n \n世\n界\n\n第一个循环用6个字节“表示”了世界，因为大部分中文字符在utf-8编码方式下使用3个字节。所以在代码中多使用for range来循环字符串\n\n再看一段代码\n```go\nfunc main () {\n\tstr := \"Hello 世界\"\n\tfmt.Println(string(str[6]))\n}\n```\n\n结果\nä\n\n这说明了字符串默认是以byte数组存放的而不是rune数组。如果字符串中包含中文字符并且要读取这个字符的时候要先转成rune类型的数组切片\n```go\nfunc main () {\n\tstr     := \"Hello 世界\"\n\tstrRune := []rune(str)\n\tfmt.Println(string(strRune[6]))\n}\n```\n结果\n世\n\n\ngo中的单引号与双引号是不同的,正常的字符串用双引号表示，单引号内只能是一个字符\n\n```go\nfunc main () {\n\tstr     := '我'\n\tfmt.Println(str)\n}\n```\n结果\n25105\n\nstr存放的其实是一个rune\n\n```go\nfunc main () {\n\tstr     := '我'\n\tfmt.Println(string(str))\n}\n```\n结果\n我\n\n最后说说go语言中的反引号(\\`)。简单地说反引号中的内容不支持任何的转义，所看即所得。\n\n## 切片\n与数组不同的是切片的大小可以变化，并且切边多了一个cap属性，意为最大数量。先看一下切片在go语言中的定义\n```go\ntype SliceHeader struct {\n    Data uintptr\n    Len int\n    Cap int\n}\n```\n这也说明了复制一个切片只是复制了指向底层数据的指针以及len和cap，并不会复制底层的数据。\n\n下面说一下切片的声明和初始化\n```go\n// 不是空切片是nil，这一点与数组是不一样的\nvar a []int\n\n//空切片\nvar b = []int{}\n\n//len和cap都为3\nvar c = []int{1,2,3}\n\n//截取c的第0个和第1个元素生成一个新的切片，len是2，因为从c的0位置开始截取，所以cap与c的cap是一样的3\nvar d = c[:2]\n\n//截取c的第1个元素生成一个新的切片，len是1，cap是2\nvar d = c[1:2]\n\n//截取c的第0个元素和第一个元素生成一个新的切片，len是2，cap是3\nvar e = c[0:2:cap(c)]\n\n//len和cap都是3，每个元素的值是0\nvar f = make([]int, 3)\n\n//len是2cap是3，每个元素都是0\nvar g = make([]int, 2, 3)\n```\n\n切片的追加。如果追加后超过了原始切片的cap，那么追加后切片的cap是追加前的两倍\n```go\nfunc main () {\n\tvar c = []int{1,2,3,4,5,6}\n\n\tfmt.Println(len(c))\n\tfmt.Println(cap(c))\n\n\tc = append(c, 7)\n\n\tfmt.Println(len(c))\n\tfmt.Println(cap(c))\n}\n```\n结果\n```\n6\n6\n7\n12\n```\n删除元素\n```go\nfunc main () {\n\ta = []int{1, 2, 3}\n    // 删除尾部1个元素\n    a = a[:len(a)-1]\n \n    // 删除尾部N个元素\n    a = a[:len(a)-N]\n}\n```\n","source":"_posts/go-array-str-slice.md","raw":"---\ntitle: Go语言中的数组、字符串、切片\ndate: 2019-12-23 12:18:35\ntags:\n    - go\nphotos :\n    - [\"http://sysummery.top/gocover1.jpeg\"]\n---\n之所以把他们三个放一起是因为他们3个的底层的原始数据有着一样的数据结构。\n<!--more-->\n## 数组\n数组是由**固定长度的**特定类型的元素组成的序列。这些元素在内存中的存储是连续的。数组一经定义，他的长度是不能改变的，数组的长度可以是0.\n\n下面几种数组的定义方式都是正确的。在go语言中，数组就是数组，并不是指向首元素的指针。\n```go\n\n//长度为3的数组，数组的每个元素的值都是0\nvar test [3]int\n\n//与上面的一样，加了{}就得用等于号\nvar test = [3]int{}\n\n//长度为3的数组，在定义的时候也初始化了每个元素的值\nvar test = [3]int{1,2,3}\n\n//长度为3的数组，第一个元素的值为1其余的值为0\nvar test = [3]int{1}\n\n//长度为3的数组，下标为1的元素的值是2，下标为0的元素的值是3，其余的值是0\nvar test = [3]int{1:2,0:3}\n\n//长度为3的数组，下标为0的元素值是1，下标为1的元素值是2，下标为2的元素值是3\nvar test = [3]int{1,1:2,2:3}\n```\n\n当一个数组被赋值或者当做函数参数被传递的时候，会复制整个数组，如果此时数组比价大，那么开销也是很大的。可以使用数组指针替代。数组指针在使用上和数组是很相似的\n```go\nfunc main () {\n\tvar test = [3]int{1:2,0:3}\n\n\tp := &test\n\n\tfmt.Println(test[0])\n\tfmt.Println(p[0])\n\n\ttest[0] = 100\n\n\tfmt.Println(test[0])\n\tfmt.Println(p[0])\n}\n```\n结果\n```\n3\n3\n100\n100\n```\n\n空数组时不占内存的，这一点与空结构体是一样的。\n```go\n\nvar times [5][0]int\n\nfor range times {\n    fmt.Println(\"hello\")\n}\n```\n\n## 字符串\n字符串是一个连续的不可改变的字节序列。\n看一下go语言中字符串的定义其实是个结构体\n```go\ntype StringHeader struct {\n    Data uintptr\n    Len int\n}\n```\n可以看出，字符串的底层是一个非负数的字节数组，另外还有一个长度。\n所以当复制一个字符串给一个变量或者作为参数传递的时候只是复制了指向基础数据的指针和字符串的长度，并没有复制底层的数据。\n\n下面先看一段代码\n```go\nfunc main () {\n\tstr := \"Hello 世界\"\n\tfor i:= 0; i < len(str); i++ {\n\t\tch := str[i]\n\t\tfmt.Println(ch)\n\t}\n\n\tfmt.Println(\"-------unicode遍历-------\")\n\tfor _, ch := range str {\n\t\tfmt.Println(ch)\n\t}\n}\n```\n结果为\n72\n101\n108\n108\n111\n32\n228\n184\n150\n231\n149\n140\n-----------unicode遍历-------------\n72\n101\n108\n108\n111\n32\n19990\n30028\n\n从结果我们可以看出\n\n1. 两个循环输出的都是一堆数字，说明go中的字符串是以byte方式存储的\n2. for循环输出的是字节的“数值”，for range输出的是以utf-8为编码方式的unicode字符的“数值”\n\n如果我想直接输出字符而不是字符的“数值”怎么办？很简单，用强制转换就好\n\n```go\nfunc main () {\n\tstr := \"Hello 世界\"\n\tfor i:= 0; i < len(str); i++ {\n\t\tch := str[i]\n\t\tfmt.Println(string(ch))\n\t}\n\n\tfmt.Println(\"------unicode遍历--------\")\n\tfor _, ch := range str {\n\t\tfmt.Println(string(ch))\n\t}\n}\n```\n输出的结果为\nH\ne\nl\nl\no\n \nä\n¸\n\nç\n\n\n-----------unicode遍历-------------\nH\ne\nl\nl\no\n \n世\n界\n\n第一个循环用6个字节“表示”了世界，因为大部分中文字符在utf-8编码方式下使用3个字节。所以在代码中多使用for range来循环字符串\n\n再看一段代码\n```go\nfunc main () {\n\tstr := \"Hello 世界\"\n\tfmt.Println(string(str[6]))\n}\n```\n\n结果\nä\n\n这说明了字符串默认是以byte数组存放的而不是rune数组。如果字符串中包含中文字符并且要读取这个字符的时候要先转成rune类型的数组切片\n```go\nfunc main () {\n\tstr     := \"Hello 世界\"\n\tstrRune := []rune(str)\n\tfmt.Println(string(strRune[6]))\n}\n```\n结果\n世\n\n\ngo中的单引号与双引号是不同的,正常的字符串用双引号表示，单引号内只能是一个字符\n\n```go\nfunc main () {\n\tstr     := '我'\n\tfmt.Println(str)\n}\n```\n结果\n25105\n\nstr存放的其实是一个rune\n\n```go\nfunc main () {\n\tstr     := '我'\n\tfmt.Println(string(str))\n}\n```\n结果\n我\n\n最后说说go语言中的反引号(\\`)。简单地说反引号中的内容不支持任何的转义，所看即所得。\n\n## 切片\n与数组不同的是切片的大小可以变化，并且切边多了一个cap属性，意为最大数量。先看一下切片在go语言中的定义\n```go\ntype SliceHeader struct {\n    Data uintptr\n    Len int\n    Cap int\n}\n```\n这也说明了复制一个切片只是复制了指向底层数据的指针以及len和cap，并不会复制底层的数据。\n\n下面说一下切片的声明和初始化\n```go\n// 不是空切片是nil，这一点与数组是不一样的\nvar a []int\n\n//空切片\nvar b = []int{}\n\n//len和cap都为3\nvar c = []int{1,2,3}\n\n//截取c的第0个和第1个元素生成一个新的切片，len是2，因为从c的0位置开始截取，所以cap与c的cap是一样的3\nvar d = c[:2]\n\n//截取c的第1个元素生成一个新的切片，len是1，cap是2\nvar d = c[1:2]\n\n//截取c的第0个元素和第一个元素生成一个新的切片，len是2，cap是3\nvar e = c[0:2:cap(c)]\n\n//len和cap都是3，每个元素的值是0\nvar f = make([]int, 3)\n\n//len是2cap是3，每个元素都是0\nvar g = make([]int, 2, 3)\n```\n\n切片的追加。如果追加后超过了原始切片的cap，那么追加后切片的cap是追加前的两倍\n```go\nfunc main () {\n\tvar c = []int{1,2,3,4,5,6}\n\n\tfmt.Println(len(c))\n\tfmt.Println(cap(c))\n\n\tc = append(c, 7)\n\n\tfmt.Println(len(c))\n\tfmt.Println(cap(c))\n}\n```\n结果\n```\n6\n6\n7\n12\n```\n删除元素\n```go\nfunc main () {\n\ta = []int{1, 2, 3}\n    // 删除尾部1个元素\n    a = a[:len(a)-1]\n \n    // 删除尾部N个元素\n    a = a[:len(a)-N]\n}\n```\n","slug":"go-array-str-slice","published":1,"updated":"2020-11-23T15:23:47.777Z","comments":1,"layout":"post","link":"","_id":"ckhupaq9b00071no8wjxrb8r5","content":"<p>之所以把他们三个放一起是因为他们3个的底层的原始数据有着一样的数据结构。</p>\n<a id=\"more\"></a>\n<h2 id=\"数组\"><a href=\"#数组\" class=\"headerlink\" title=\"数组\"></a>数组</h2><p>数组是由<strong>固定长度的</strong>特定类型的元素组成的序列。这些元素在内存中的存储是连续的。数组一经定义，他的长度是不能改变的，数组的长度可以是0.</p>\n<p>下面几种数组的定义方式都是正确的。在go语言中，数组就是数组，并不是指向首元素的指针。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//长度为3的数组，数组的每个元素的值都是0</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test [<span class=\"number\">3</span>]<span class=\"keyword\">int</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//与上面的一样，加了&#123;&#125;就得用等于号</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//长度为3的数组，在定义的时候也初始化了每个元素的值</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//长度为3的数组，第一个元素的值为1其余的值为0</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//长度为3的数组，下标为1的元素的值是2，下标为0的元素的值是3，其余的值是0</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>:<span class=\"number\">2</span>,<span class=\"number\">0</span>:<span class=\"number\">3</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//长度为3的数组，下标为0的元素值是1，下标为1的元素值是2，下标为2的元素值是3</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>,<span class=\"number\">1</span>:<span class=\"number\">2</span>,<span class=\"number\">2</span>:<span class=\"number\">3</span>&#125;</span><br></pre></td></tr></table></figure>\n\n<p>当一个数组被赋值或者当做函数参数被传递的时候，会复制整个数组，如果此时数组比价大，那么开销也是很大的。可以使用数组指针替代。数组指针在使用上和数组是很相似的</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>:<span class=\"number\">2</span>,<span class=\"number\">0</span>:<span class=\"number\">3</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tp := &amp;test</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(test[<span class=\"number\">0</span>])</span><br><span class=\"line\">\tfmt.Println(p[<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">\ttest[<span class=\"number\">0</span>] = <span class=\"number\">100</span></span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(test[<span class=\"number\">0</span>])</span><br><span class=\"line\">\tfmt.Println(p[<span class=\"number\">0</span>])</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">3</span><br><span class=\"line\">3</span><br><span class=\"line\">100</span><br><span class=\"line\">100</span><br></pre></td></tr></table></figure>\n\n<p>空数组时不占内存的，这一点与空结构体是一样的。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> times [<span class=\"number\">5</span>][<span class=\"number\">0</span>]<span class=\"keyword\">int</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> <span class=\"keyword\">range</span> times &#123;</span><br><span class=\"line\">    fmt.Println(<span class=\"string\">\"hello\"</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"字符串\"><a href=\"#字符串\" class=\"headerlink\" title=\"字符串\"></a>字符串</h2><p>字符串是一个连续的不可改变的字节序列。<br>看一下go语言中字符串的定义其实是个结构体</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> StringHeader <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">    Data <span class=\"keyword\">uintptr</span></span><br><span class=\"line\">    Len <span class=\"keyword\">int</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>可以看出，字符串的底层是一个非负数的字节数组，另外还有一个长度。<br>所以当复制一个字符串给一个变量或者作为参数传递的时候只是复制了指向基础数据的指针和字符串的长度，并没有复制底层的数据。</p>\n<p>下面先看一段代码</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr := <span class=\"string\">\"Hello 世界\"</span></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i:= <span class=\"number\">0</span>; i &lt; <span class=\"built_in\">len</span>(str); i++ &#123;</span><br><span class=\"line\">\t\tch := str[i]</span><br><span class=\"line\">\t\tfmt.Println(ch)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"-------unicode遍历-------\"</span>)</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> _, ch := <span class=\"keyword\">range</span> str &#123;</span><br><span class=\"line\">\t\tfmt.Println(ch)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果为<br>72<br>101<br>108<br>108<br>111<br>32<br>228<br>184<br>150<br>231<br>149<br>140<br>———–unicode遍历————-<br>72<br>101<br>108<br>108<br>111<br>32<br>19990<br>30028</p>\n<p>从结果我们可以看出</p>\n<ol>\n<li>两个循环输出的都是一堆数字，说明go中的字符串是以byte方式存储的</li>\n<li>for循环输出的是字节的“数值”，for range输出的是以utf-8为编码方式的unicode字符的“数值”</li>\n</ol>\n<p>如果我想直接输出字符而不是字符的“数值”怎么办？很简单，用强制转换就好</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr := <span class=\"string\">\"Hello 世界\"</span></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i:= <span class=\"number\">0</span>; i &lt; <span class=\"built_in\">len</span>(str); i++ &#123;</span><br><span class=\"line\">\t\tch := str[i]</span><br><span class=\"line\">\t\tfmt.Println(<span class=\"keyword\">string</span>(ch))</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"------unicode遍历--------\"</span>)</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> _, ch := <span class=\"keyword\">range</span> str &#123;</span><br><span class=\"line\">\t\tfmt.Println(<span class=\"keyword\">string</span>(ch))</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>输出的结果为<br>H<br>e<br>l<br>l<br>o</p>\n<p>ä<br>¸</p>\n<p>ç</p>\n<p>———–unicode遍历————-<br>H<br>e<br>l<br>l<br>o</p>\n<p>世<br>界</p>\n<p>第一个循环用6个字节“表示”了世界，因为大部分中文字符在utf-8编码方式下使用3个字节。所以在代码中多使用for range来循环字符串</p>\n<p>再看一段代码</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr := <span class=\"string\">\"Hello 世界\"</span></span><br><span class=\"line\">\tfmt.Println(<span class=\"keyword\">string</span>(str[<span class=\"number\">6</span>]))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果<br>ä</p>\n<p>这说明了字符串默认是以byte数组存放的而不是rune数组。如果字符串中包含中文字符并且要读取这个字符的时候要先转成rune类型的数组切片</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr     := <span class=\"string\">\"Hello 世界\"</span></span><br><span class=\"line\">\tstrRune := []<span class=\"keyword\">rune</span>(str)</span><br><span class=\"line\">\tfmt.Println(<span class=\"keyword\">string</span>(strRune[<span class=\"number\">6</span>]))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果<br>世</p>\n<p>go中的单引号与双引号是不同的,正常的字符串用双引号表示，单引号内只能是一个字符</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr     := <span class=\"string\">'我'</span></span><br><span class=\"line\">\tfmt.Println(str)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果<br>25105</p>\n<p>str存放的其实是一个rune</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr     := <span class=\"string\">'我'</span></span><br><span class=\"line\">\tfmt.Println(<span class=\"keyword\">string</span>(str))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果<br>我</p>\n<p>最后说说go语言中的反引号(`)。简单地说反引号中的内容不支持任何的转义，所看即所得。</p>\n<h2 id=\"切片\"><a href=\"#切片\" class=\"headerlink\" title=\"切片\"></a>切片</h2><p>与数组不同的是切片的大小可以变化，并且切边多了一个cap属性，意为最大数量。先看一下切片在go语言中的定义</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> SliceHeader <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">    Data <span class=\"keyword\">uintptr</span></span><br><span class=\"line\">    Len <span class=\"keyword\">int</span></span><br><span class=\"line\">    Cap <span class=\"keyword\">int</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>这也说明了复制一个切片只是复制了指向底层数据的指针以及len和cap，并不会复制底层的数据。</p>\n<p>下面说一下切片的声明和初始化</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 不是空切片是nil，这一点与数组是不一样的</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> a []<span class=\"keyword\">int</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//空切片</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> b = []<span class=\"keyword\">int</span>&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//len和cap都为3</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> c = []<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//截取c的第0个和第1个元素生成一个新的切片，len是2，因为从c的0位置开始截取，所以cap与c的cap是一样的3</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> d = c[:<span class=\"number\">2</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//截取c的第1个元素生成一个新的切片，len是1，cap是2</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> d = c[<span class=\"number\">1</span>:<span class=\"number\">2</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//截取c的第0个元素和第一个元素生成一个新的切片，len是2，cap是3</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> e = c[<span class=\"number\">0</span>:<span class=\"number\">2</span>:<span class=\"built_in\">cap</span>(c)]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//len和cap都是3，每个元素的值是0</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> f = <span class=\"built_in\">make</span>([]<span class=\"keyword\">int</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//len是2cap是3，每个元素都是0</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> g = <span class=\"built_in\">make</span>([]<span class=\"keyword\">int</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br></pre></td></tr></table></figure>\n\n<p>切片的追加。如果追加后超过了原始切片的cap，那么追加后切片的cap是追加前的两倍</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> c = []<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(<span class=\"built_in\">len</span>(c))</span><br><span class=\"line\">\tfmt.Println(<span class=\"built_in\">cap</span>(c))</span><br><span class=\"line\"></span><br><span class=\"line\">\tc = <span class=\"built_in\">append</span>(c, <span class=\"number\">7</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(<span class=\"built_in\">len</span>(c))</span><br><span class=\"line\">\tfmt.Println(<span class=\"built_in\">cap</span>(c))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">6</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">12</span><br></pre></td></tr></table></figure>\n\n<p>删除元素</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\ta = []<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>&#125;</span><br><span class=\"line\">    <span class=\"comment\">// 删除尾部1个元素</span></span><br><span class=\"line\">    a = a[:<span class=\"built_in\">len</span>(a)<span class=\"number\">-1</span>]</span><br><span class=\"line\"> </span><br><span class=\"line\">    <span class=\"comment\">// 删除尾部N个元素</span></span><br><span class=\"line\">    a = a[:<span class=\"built_in\">len</span>(a)-N]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"<p>之所以把他们三个放一起是因为他们3个的底层的原始数据有着一样的数据结构。</p>","more":"<h2 id=\"数组\"><a href=\"#数组\" class=\"headerlink\" title=\"数组\"></a>数组</h2><p>数组是由<strong>固定长度的</strong>特定类型的元素组成的序列。这些元素在内存中的存储是连续的。数组一经定义，他的长度是不能改变的，数组的长度可以是0.</p>\n<p>下面几种数组的定义方式都是正确的。在go语言中，数组就是数组，并不是指向首元素的指针。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//长度为3的数组，数组的每个元素的值都是0</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test [<span class=\"number\">3</span>]<span class=\"keyword\">int</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//与上面的一样，加了&#123;&#125;就得用等于号</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//长度为3的数组，在定义的时候也初始化了每个元素的值</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//长度为3的数组，第一个元素的值为1其余的值为0</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//长度为3的数组，下标为1的元素的值是2，下标为0的元素的值是3，其余的值是0</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>:<span class=\"number\">2</span>,<span class=\"number\">0</span>:<span class=\"number\">3</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//长度为3的数组，下标为0的元素值是1，下标为1的元素值是2，下标为2的元素值是3</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>,<span class=\"number\">1</span>:<span class=\"number\">2</span>,<span class=\"number\">2</span>:<span class=\"number\">3</span>&#125;</span><br></pre></td></tr></table></figure>\n\n<p>当一个数组被赋值或者当做函数参数被传递的时候，会复制整个数组，如果此时数组比价大，那么开销也是很大的。可以使用数组指针替代。数组指针在使用上和数组是很相似的</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> test = [<span class=\"number\">3</span>]<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>:<span class=\"number\">2</span>,<span class=\"number\">0</span>:<span class=\"number\">3</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tp := &amp;test</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(test[<span class=\"number\">0</span>])</span><br><span class=\"line\">\tfmt.Println(p[<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">\ttest[<span class=\"number\">0</span>] = <span class=\"number\">100</span></span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(test[<span class=\"number\">0</span>])</span><br><span class=\"line\">\tfmt.Println(p[<span class=\"number\">0</span>])</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">3</span><br><span class=\"line\">3</span><br><span class=\"line\">100</span><br><span class=\"line\">100</span><br></pre></td></tr></table></figure>\n\n<p>空数组时不占内存的，这一点与空结构体是一样的。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> times [<span class=\"number\">5</span>][<span class=\"number\">0</span>]<span class=\"keyword\">int</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> <span class=\"keyword\">range</span> times &#123;</span><br><span class=\"line\">    fmt.Println(<span class=\"string\">\"hello\"</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"字符串\"><a href=\"#字符串\" class=\"headerlink\" title=\"字符串\"></a>字符串</h2><p>字符串是一个连续的不可改变的字节序列。<br>看一下go语言中字符串的定义其实是个结构体</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> StringHeader <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">    Data <span class=\"keyword\">uintptr</span></span><br><span class=\"line\">    Len <span class=\"keyword\">int</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>可以看出，字符串的底层是一个非负数的字节数组，另外还有一个长度。<br>所以当复制一个字符串给一个变量或者作为参数传递的时候只是复制了指向基础数据的指针和字符串的长度，并没有复制底层的数据。</p>\n<p>下面先看一段代码</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr := <span class=\"string\">\"Hello 世界\"</span></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i:= <span class=\"number\">0</span>; i &lt; <span class=\"built_in\">len</span>(str); i++ &#123;</span><br><span class=\"line\">\t\tch := str[i]</span><br><span class=\"line\">\t\tfmt.Println(ch)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"-------unicode遍历-------\"</span>)</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> _, ch := <span class=\"keyword\">range</span> str &#123;</span><br><span class=\"line\">\t\tfmt.Println(ch)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果为<br>72<br>101<br>108<br>108<br>111<br>32<br>228<br>184<br>150<br>231<br>149<br>140<br>———–unicode遍历————-<br>72<br>101<br>108<br>108<br>111<br>32<br>19990<br>30028</p>\n<p>从结果我们可以看出</p>\n<ol>\n<li>两个循环输出的都是一堆数字，说明go中的字符串是以byte方式存储的</li>\n<li>for循环输出的是字节的“数值”，for range输出的是以utf-8为编码方式的unicode字符的“数值”</li>\n</ol>\n<p>如果我想直接输出字符而不是字符的“数值”怎么办？很简单，用强制转换就好</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr := <span class=\"string\">\"Hello 世界\"</span></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i:= <span class=\"number\">0</span>; i &lt; <span class=\"built_in\">len</span>(str); i++ &#123;</span><br><span class=\"line\">\t\tch := str[i]</span><br><span class=\"line\">\t\tfmt.Println(<span class=\"keyword\">string</span>(ch))</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"------unicode遍历--------\"</span>)</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> _, ch := <span class=\"keyword\">range</span> str &#123;</span><br><span class=\"line\">\t\tfmt.Println(<span class=\"keyword\">string</span>(ch))</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>输出的结果为<br>H<br>e<br>l<br>l<br>o</p>\n<p>ä<br>¸</p>\n<p>ç</p>\n<p>———–unicode遍历————-<br>H<br>e<br>l<br>l<br>o</p>\n<p>世<br>界</p>\n<p>第一个循环用6个字节“表示”了世界，因为大部分中文字符在utf-8编码方式下使用3个字节。所以在代码中多使用for range来循环字符串</p>\n<p>再看一段代码</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr := <span class=\"string\">\"Hello 世界\"</span></span><br><span class=\"line\">\tfmt.Println(<span class=\"keyword\">string</span>(str[<span class=\"number\">6</span>]))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果<br>ä</p>\n<p>这说明了字符串默认是以byte数组存放的而不是rune数组。如果字符串中包含中文字符并且要读取这个字符的时候要先转成rune类型的数组切片</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr     := <span class=\"string\">\"Hello 世界\"</span></span><br><span class=\"line\">\tstrRune := []<span class=\"keyword\">rune</span>(str)</span><br><span class=\"line\">\tfmt.Println(<span class=\"keyword\">string</span>(strRune[<span class=\"number\">6</span>]))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果<br>世</p>\n<p>go中的单引号与双引号是不同的,正常的字符串用双引号表示，单引号内只能是一个字符</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr     := <span class=\"string\">'我'</span></span><br><span class=\"line\">\tfmt.Println(str)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果<br>25105</p>\n<p>str存放的其实是一个rune</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tstr     := <span class=\"string\">'我'</span></span><br><span class=\"line\">\tfmt.Println(<span class=\"keyword\">string</span>(str))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果<br>我</p>\n<p>最后说说go语言中的反引号(`)。简单地说反引号中的内容不支持任何的转义，所看即所得。</p>\n<h2 id=\"切片\"><a href=\"#切片\" class=\"headerlink\" title=\"切片\"></a>切片</h2><p>与数组不同的是切片的大小可以变化，并且切边多了一个cap属性，意为最大数量。先看一下切片在go语言中的定义</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> SliceHeader <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">    Data <span class=\"keyword\">uintptr</span></span><br><span class=\"line\">    Len <span class=\"keyword\">int</span></span><br><span class=\"line\">    Cap <span class=\"keyword\">int</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>这也说明了复制一个切片只是复制了指向底层数据的指针以及len和cap，并不会复制底层的数据。</p>\n<p>下面说一下切片的声明和初始化</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 不是空切片是nil，这一点与数组是不一样的</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> a []<span class=\"keyword\">int</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//空切片</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> b = []<span class=\"keyword\">int</span>&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//len和cap都为3</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> c = []<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//截取c的第0个和第1个元素生成一个新的切片，len是2，因为从c的0位置开始截取，所以cap与c的cap是一样的3</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> d = c[:<span class=\"number\">2</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//截取c的第1个元素生成一个新的切片，len是1，cap是2</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> d = c[<span class=\"number\">1</span>:<span class=\"number\">2</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//截取c的第0个元素和第一个元素生成一个新的切片，len是2，cap是3</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> e = c[<span class=\"number\">0</span>:<span class=\"number\">2</span>:<span class=\"built_in\">cap</span>(c)]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//len和cap都是3，每个元素的值是0</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> f = <span class=\"built_in\">make</span>([]<span class=\"keyword\">int</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//len是2cap是3，每个元素都是0</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> g = <span class=\"built_in\">make</span>([]<span class=\"keyword\">int</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br></pre></td></tr></table></figure>\n\n<p>切片的追加。如果追加后超过了原始切片的cap，那么追加后切片的cap是追加前的两倍</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> c = []<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(<span class=\"built_in\">len</span>(c))</span><br><span class=\"line\">\tfmt.Println(<span class=\"built_in\">cap</span>(c))</span><br><span class=\"line\"></span><br><span class=\"line\">\tc = <span class=\"built_in\">append</span>(c, <span class=\"number\">7</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(<span class=\"built_in\">len</span>(c))</span><br><span class=\"line\">\tfmt.Println(<span class=\"built_in\">cap</span>(c))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">6</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">12</span><br></pre></td></tr></table></figure>\n\n<p>删除元素</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span> <span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\ta = []<span class=\"keyword\">int</span>&#123;<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>&#125;</span><br><span class=\"line\">    <span class=\"comment\">// 删除尾部1个元素</span></span><br><span class=\"line\">    a = a[:<span class=\"built_in\">len</span>(a)<span class=\"number\">-1</span>]</span><br><span class=\"line\"> </span><br><span class=\"line\">    <span class=\"comment\">// 删除尾部N个元素</span></span><br><span class=\"line\">    a = a[:<span class=\"built_in\">len</span>(a)-N]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"Go语言中的垃圾回收","date":"2020-01-01T09:37:50.000Z","photos":["http://sysummery.top/gogc.jpg"],"_content":"垃圾回收（英语：Garbage Collection，缩写为GC），在计算机科学中是一种自动的存储器管理机制。当一个计算机上的动态存储器不再需要时，就应该予以释放，以让出存储器，这种存储器资源管理，称为垃圾回收。垃圾回收器可以让程序员减轻许多负担，也减少程序员犯错的机会。\n<!--more-->\n## 垃圾回收算法\n### 引用计数法\n每个单元维护一个域，保存其他单元对其的引用。当引用为0时就可以回收了。PHP就是使用的这种机制。\n\n引用计数是渐进式的，内存管理与用户程序交织在一起，不会出现STW，但是这种方式解决不了互相引用的问题。比如\n```\na.b = b;\nb.a = a;\n```\na和b二者互相引用，并且没有其他的引用了，引用计数法并不会把他们当做垃圾回收。\n\n### 标记清扫法\n是一种自动内存管理基于追踪的垃圾回收算法。垃圾回收的时候首先会STW。然后从根节点开始追踪每一个可达的对象，标记完之后就去回收没有被标记的几点然后进行回收。\n\n那么标记清扫法能不能解决循环引用的问题呢？是可以的\n![](http://sysummery.top/biaojishanchu.jpg)\n\n虽然object4与object5互相引用，但是从根节点起是没有到达他们的路径的，因此他们两个不会被标记可达，在清扫阶段会被回收。\n\n标记清扫法最大的缺点就是GC的时候会STW。\n\n### 分代收集\n分代垃圾回收算法将对象按生命周期长短存放到堆上的两个（或者更多）区域，这些区域就是分代（generation）。对于新生代的区域的垃圾回收频率要明显高于老年代区域。\n\n分配对象的时候从新生代里面分配，如果后面发现对象的生命周期较长，则将其移到老年代，这个过程叫做 promote。随着不断 promote，最后新生代的大小在整个堆的占用比例不会特别大。收集的时候集中主要精力在新生代就会相对来说效率更高，STW 时间也会更短。\n\njava的GC就是分代收集。\n\n### 三色标记法\n![](http://sysummery.top/sansebiaojifa.gif)\n\n三色标记算法是对标记阶段的改进，原理如下：\n\n1. 起初所有对象都是白色。\n2. 从根出发扫描所有可达对象，标记为灰色，放入待处理队列。\n3. 从队列取出灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色。\n4. 重复 3，直到灰色对象队列为空。此时白色对象即为垃圾，进行回收。\n\n步骤1、2、3的时候需要STW, 不然会出现问题。假如不STW，如下图，灰色的B节点引用了白色的C节点。当C节点还没有变灰的时候，B和C之间的引用断了并且已经变黑的A节点又引用了C。因此C不会变成灰色的，还是白色。等到回收的时候会把C回收了，但是C明明被黑色的A引用着，就出问题。因此三色球算法在标记的过程中必须要STW。\n![](http://sysummery.top/3sbjfqx.jpg)\n\n\n## go语言的垃圾回收算法\ngo原因的垃圾回收算法是基于三色标记法的，并在此基础上加入了写屏障缩短了整个过程的STW时间。\n\n![](http://sysummery.top/gc.png)\n\n具体的过程是\n\n1. 首先从 root 开始遍历，root 包括全局指针和 goroutine 栈上的指针。\n2. 从 root 开始遍历，标记为灰色。遍历灰色队列。\n3. re-scan 全局指针和栈。因为 mark 和用户程序是并行的，所以在过程 1 的时候可能会有新的对象分配，这个时候就需要通过写屏障（write barrier）记录下来。re-scan 再完成检查一下。\n\nSWT的阶段\n\n1. 第一个是 GC 将要开始的时候，这个时候主要是一些准备工作，比如 enable write barrier。\n2. 第二个过程就是上面提到的 re-scan 过程。如果这个时候没有 stw，那么 mark 将无休止。\n\n什么时候触发gc\n\n1. 阈值：默认内存扩大一倍，启动gc\n2. 定期：默认2min触发一次\n3. 手动：runtime.gc()\n","source":"_posts/go-gc.md","raw":"---\ntitle: Go语言中的垃圾回收\ndate: 2020-01-01 17:37:50\ntags:\n    - go\nphotos:\n    - [\"http://sysummery.top/gogc.jpg\"]\n---\n垃圾回收（英语：Garbage Collection，缩写为GC），在计算机科学中是一种自动的存储器管理机制。当一个计算机上的动态存储器不再需要时，就应该予以释放，以让出存储器，这种存储器资源管理，称为垃圾回收。垃圾回收器可以让程序员减轻许多负担，也减少程序员犯错的机会。\n<!--more-->\n## 垃圾回收算法\n### 引用计数法\n每个单元维护一个域，保存其他单元对其的引用。当引用为0时就可以回收了。PHP就是使用的这种机制。\n\n引用计数是渐进式的，内存管理与用户程序交织在一起，不会出现STW，但是这种方式解决不了互相引用的问题。比如\n```\na.b = b;\nb.a = a;\n```\na和b二者互相引用，并且没有其他的引用了，引用计数法并不会把他们当做垃圾回收。\n\n### 标记清扫法\n是一种自动内存管理基于追踪的垃圾回收算法。垃圾回收的时候首先会STW。然后从根节点开始追踪每一个可达的对象，标记完之后就去回收没有被标记的几点然后进行回收。\n\n那么标记清扫法能不能解决循环引用的问题呢？是可以的\n![](http://sysummery.top/biaojishanchu.jpg)\n\n虽然object4与object5互相引用，但是从根节点起是没有到达他们的路径的，因此他们两个不会被标记可达，在清扫阶段会被回收。\n\n标记清扫法最大的缺点就是GC的时候会STW。\n\n### 分代收集\n分代垃圾回收算法将对象按生命周期长短存放到堆上的两个（或者更多）区域，这些区域就是分代（generation）。对于新生代的区域的垃圾回收频率要明显高于老年代区域。\n\n分配对象的时候从新生代里面分配，如果后面发现对象的生命周期较长，则将其移到老年代，这个过程叫做 promote。随着不断 promote，最后新生代的大小在整个堆的占用比例不会特别大。收集的时候集中主要精力在新生代就会相对来说效率更高，STW 时间也会更短。\n\njava的GC就是分代收集。\n\n### 三色标记法\n![](http://sysummery.top/sansebiaojifa.gif)\n\n三色标记算法是对标记阶段的改进，原理如下：\n\n1. 起初所有对象都是白色。\n2. 从根出发扫描所有可达对象，标记为灰色，放入待处理队列。\n3. 从队列取出灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色。\n4. 重复 3，直到灰色对象队列为空。此时白色对象即为垃圾，进行回收。\n\n步骤1、2、3的时候需要STW, 不然会出现问题。假如不STW，如下图，灰色的B节点引用了白色的C节点。当C节点还没有变灰的时候，B和C之间的引用断了并且已经变黑的A节点又引用了C。因此C不会变成灰色的，还是白色。等到回收的时候会把C回收了，但是C明明被黑色的A引用着，就出问题。因此三色球算法在标记的过程中必须要STW。\n![](http://sysummery.top/3sbjfqx.jpg)\n\n\n## go语言的垃圾回收算法\ngo原因的垃圾回收算法是基于三色标记法的，并在此基础上加入了写屏障缩短了整个过程的STW时间。\n\n![](http://sysummery.top/gc.png)\n\n具体的过程是\n\n1. 首先从 root 开始遍历，root 包括全局指针和 goroutine 栈上的指针。\n2. 从 root 开始遍历，标记为灰色。遍历灰色队列。\n3. re-scan 全局指针和栈。因为 mark 和用户程序是并行的，所以在过程 1 的时候可能会有新的对象分配，这个时候就需要通过写屏障（write barrier）记录下来。re-scan 再完成检查一下。\n\nSWT的阶段\n\n1. 第一个是 GC 将要开始的时候，这个时候主要是一些准备工作，比如 enable write barrier。\n2. 第二个过程就是上面提到的 re-scan 过程。如果这个时候没有 stw，那么 mark 将无休止。\n\n什么时候触发gc\n\n1. 阈值：默认内存扩大一倍，启动gc\n2. 定期：默认2min触发一次\n3. 手动：runtime.gc()\n","slug":"go-gc","published":1,"updated":"2020-11-23T15:23:47.777Z","comments":1,"layout":"post","link":"","_id":"ckhupaq9d00091no8dgdl2v8h","content":"<p>垃圾回收（英语：Garbage Collection，缩写为GC），在计算机科学中是一种自动的存储器管理机制。当一个计算机上的动态存储器不再需要时，就应该予以释放，以让出存储器，这种存储器资源管理，称为垃圾回收。垃圾回收器可以让程序员减轻许多负担，也减少程序员犯错的机会。</p>\n<a id=\"more\"></a>\n<h2 id=\"垃圾回收算法\"><a href=\"#垃圾回收算法\" class=\"headerlink\" title=\"垃圾回收算法\"></a>垃圾回收算法</h2><h3 id=\"引用计数法\"><a href=\"#引用计数法\" class=\"headerlink\" title=\"引用计数法\"></a>引用计数法</h3><p>每个单元维护一个域，保存其他单元对其的引用。当引用为0时就可以回收了。PHP就是使用的这种机制。</p>\n<p>引用计数是渐进式的，内存管理与用户程序交织在一起，不会出现STW，但是这种方式解决不了互相引用的问题。比如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a.b = b;</span><br><span class=\"line\">b.a = a;</span><br></pre></td></tr></table></figure>\n\n<p>a和b二者互相引用，并且没有其他的引用了，引用计数法并不会把他们当做垃圾回收。</p>\n<h3 id=\"标记清扫法\"><a href=\"#标记清扫法\" class=\"headerlink\" title=\"标记清扫法\"></a>标记清扫法</h3><p>是一种自动内存管理基于追踪的垃圾回收算法。垃圾回收的时候首先会STW。然后从根节点开始追踪每一个可达的对象，标记完之后就去回收没有被标记的几点然后进行回收。</p>\n<p>那么标记清扫法能不能解决循环引用的问题呢？是可以的<br><img src=\"http://sysummery.top/biaojishanchu.jpg\" alt></p>\n<p>虽然object4与object5互相引用，但是从根节点起是没有到达他们的路径的，因此他们两个不会被标记可达，在清扫阶段会被回收。</p>\n<p>标记清扫法最大的缺点就是GC的时候会STW。</p>\n<h3 id=\"分代收集\"><a href=\"#分代收集\" class=\"headerlink\" title=\"分代收集\"></a>分代收集</h3><p>分代垃圾回收算法将对象按生命周期长短存放到堆上的两个（或者更多）区域，这些区域就是分代（generation）。对于新生代的区域的垃圾回收频率要明显高于老年代区域。</p>\n<p>分配对象的时候从新生代里面分配，如果后面发现对象的生命周期较长，则将其移到老年代，这个过程叫做 promote。随着不断 promote，最后新生代的大小在整个堆的占用比例不会特别大。收集的时候集中主要精力在新生代就会相对来说效率更高，STW 时间也会更短。</p>\n<p>java的GC就是分代收集。</p>\n<h3 id=\"三色标记法\"><a href=\"#三色标记法\" class=\"headerlink\" title=\"三色标记法\"></a>三色标记法</h3><p><img src=\"http://sysummery.top/sansebiaojifa.gif\" alt></p>\n<p>三色标记算法是对标记阶段的改进，原理如下：</p>\n<ol>\n<li>起初所有对象都是白色。</li>\n<li>从根出发扫描所有可达对象，标记为灰色，放入待处理队列。</li>\n<li>从队列取出灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色。</li>\n<li>重复 3，直到灰色对象队列为空。此时白色对象即为垃圾，进行回收。</li>\n</ol>\n<p>步骤1、2、3的时候需要STW, 不然会出现问题。假如不STW，如下图，灰色的B节点引用了白色的C节点。当C节点还没有变灰的时候，B和C之间的引用断了并且已经变黑的A节点又引用了C。因此C不会变成灰色的，还是白色。等到回收的时候会把C回收了，但是C明明被黑色的A引用着，就出问题。因此三色球算法在标记的过程中必须要STW。<br><img src=\"http://sysummery.top/3sbjfqx.jpg\" alt></p>\n<h2 id=\"go语言的垃圾回收算法\"><a href=\"#go语言的垃圾回收算法\" class=\"headerlink\" title=\"go语言的垃圾回收算法\"></a>go语言的垃圾回收算法</h2><p>go原因的垃圾回收算法是基于三色标记法的，并在此基础上加入了写屏障缩短了整个过程的STW时间。</p>\n<p><img src=\"http://sysummery.top/gc.png\" alt></p>\n<p>具体的过程是</p>\n<ol>\n<li>首先从 root 开始遍历，root 包括全局指针和 goroutine 栈上的指针。</li>\n<li>从 root 开始遍历，标记为灰色。遍历灰色队列。</li>\n<li>re-scan 全局指针和栈。因为 mark 和用户程序是并行的，所以在过程 1 的时候可能会有新的对象分配，这个时候就需要通过写屏障（write barrier）记录下来。re-scan 再完成检查一下。</li>\n</ol>\n<p>SWT的阶段</p>\n<ol>\n<li>第一个是 GC 将要开始的时候，这个时候主要是一些准备工作，比如 enable write barrier。</li>\n<li>第二个过程就是上面提到的 re-scan 过程。如果这个时候没有 stw，那么 mark 将无休止。</li>\n</ol>\n<p>什么时候触发gc</p>\n<ol>\n<li>阈值：默认内存扩大一倍，启动gc</li>\n<li>定期：默认2min触发一次</li>\n<li>手动：runtime.gc()</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>垃圾回收（英语：Garbage Collection，缩写为GC），在计算机科学中是一种自动的存储器管理机制。当一个计算机上的动态存储器不再需要时，就应该予以释放，以让出存储器，这种存储器资源管理，称为垃圾回收。垃圾回收器可以让程序员减轻许多负担，也减少程序员犯错的机会。</p>","more":"<h2 id=\"垃圾回收算法\"><a href=\"#垃圾回收算法\" class=\"headerlink\" title=\"垃圾回收算法\"></a>垃圾回收算法</h2><h3 id=\"引用计数法\"><a href=\"#引用计数法\" class=\"headerlink\" title=\"引用计数法\"></a>引用计数法</h3><p>每个单元维护一个域，保存其他单元对其的引用。当引用为0时就可以回收了。PHP就是使用的这种机制。</p>\n<p>引用计数是渐进式的，内存管理与用户程序交织在一起，不会出现STW，但是这种方式解决不了互相引用的问题。比如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a.b = b;</span><br><span class=\"line\">b.a = a;</span><br></pre></td></tr></table></figure>\n\n<p>a和b二者互相引用，并且没有其他的引用了，引用计数法并不会把他们当做垃圾回收。</p>\n<h3 id=\"标记清扫法\"><a href=\"#标记清扫法\" class=\"headerlink\" title=\"标记清扫法\"></a>标记清扫法</h3><p>是一种自动内存管理基于追踪的垃圾回收算法。垃圾回收的时候首先会STW。然后从根节点开始追踪每一个可达的对象，标记完之后就去回收没有被标记的几点然后进行回收。</p>\n<p>那么标记清扫法能不能解决循环引用的问题呢？是可以的<br><img src=\"http://sysummery.top/biaojishanchu.jpg\" alt></p>\n<p>虽然object4与object5互相引用，但是从根节点起是没有到达他们的路径的，因此他们两个不会被标记可达，在清扫阶段会被回收。</p>\n<p>标记清扫法最大的缺点就是GC的时候会STW。</p>\n<h3 id=\"分代收集\"><a href=\"#分代收集\" class=\"headerlink\" title=\"分代收集\"></a>分代收集</h3><p>分代垃圾回收算法将对象按生命周期长短存放到堆上的两个（或者更多）区域，这些区域就是分代（generation）。对于新生代的区域的垃圾回收频率要明显高于老年代区域。</p>\n<p>分配对象的时候从新生代里面分配，如果后面发现对象的生命周期较长，则将其移到老年代，这个过程叫做 promote。随着不断 promote，最后新生代的大小在整个堆的占用比例不会特别大。收集的时候集中主要精力在新生代就会相对来说效率更高，STW 时间也会更短。</p>\n<p>java的GC就是分代收集。</p>\n<h3 id=\"三色标记法\"><a href=\"#三色标记法\" class=\"headerlink\" title=\"三色标记法\"></a>三色标记法</h3><p><img src=\"http://sysummery.top/sansebiaojifa.gif\" alt></p>\n<p>三色标记算法是对标记阶段的改进，原理如下：</p>\n<ol>\n<li>起初所有对象都是白色。</li>\n<li>从根出发扫描所有可达对象，标记为灰色，放入待处理队列。</li>\n<li>从队列取出灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色。</li>\n<li>重复 3，直到灰色对象队列为空。此时白色对象即为垃圾，进行回收。</li>\n</ol>\n<p>步骤1、2、3的时候需要STW, 不然会出现问题。假如不STW，如下图，灰色的B节点引用了白色的C节点。当C节点还没有变灰的时候，B和C之间的引用断了并且已经变黑的A节点又引用了C。因此C不会变成灰色的，还是白色。等到回收的时候会把C回收了，但是C明明被黑色的A引用着，就出问题。因此三色球算法在标记的过程中必须要STW。<br><img src=\"http://sysummery.top/3sbjfqx.jpg\" alt></p>\n<h2 id=\"go语言的垃圾回收算法\"><a href=\"#go语言的垃圾回收算法\" class=\"headerlink\" title=\"go语言的垃圾回收算法\"></a>go语言的垃圾回收算法</h2><p>go原因的垃圾回收算法是基于三色标记法的，并在此基础上加入了写屏障缩短了整个过程的STW时间。</p>\n<p><img src=\"http://sysummery.top/gc.png\" alt></p>\n<p>具体的过程是</p>\n<ol>\n<li>首先从 root 开始遍历，root 包括全局指针和 goroutine 栈上的指针。</li>\n<li>从 root 开始遍历，标记为灰色。遍历灰色队列。</li>\n<li>re-scan 全局指针和栈。因为 mark 和用户程序是并行的，所以在过程 1 的时候可能会有新的对象分配，这个时候就需要通过写屏障（write barrier）记录下来。re-scan 再完成检查一下。</li>\n</ol>\n<p>SWT的阶段</p>\n<ol>\n<li>第一个是 GC 将要开始的时候，这个时候主要是一些准备工作，比如 enable write barrier。</li>\n<li>第二个过程就是上面提到的 re-scan 过程。如果这个时候没有 stw，那么 mark 将无休止。</li>\n</ol>\n<p>什么时候触发gc</p>\n<ol>\n<li>阈值：默认内存扩大一倍，启动gc</li>\n<li>定期：默认2min触发一次</li>\n<li>手动：runtime.gc()</li>\n</ol>"},{"title":"Go语言中的锁","date":"2020-01-15T06:57:01.000Z","photos":["http://sysummery.top/golang2.jpeg"],"_content":"总结一下这段时间学习的有关go语言中的锁的知识。\n<!--more-->\n多线程和多协程编程能够充分利用多核处理器的优势，是系统性能提升。但是有时也会给我们意外的“惊喜”，比如下面的计数器的例子\n```go\nvar count int = 0\nfunc main() {\n\twg := sync.WaitGroup{}\n\twg.Add(5)\n\n\tfor i := 1; i <= 5; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tcount++\n\t\t}()\n\t}\n\n    wg.Wait()\n\tfmt.Println(count)\n}\n```\n我们期待的结果是5，但事实上结果是不确定的。因为5个协程是并发执行的，当每个协程执行到`count += i`的时候count的值是不确定的，因此结果也是不确定的。\n\n向例子中的count变量可以成为临界资源，当多个线程或协程对临界资源进行修改的时候就必须要“上锁”。使用锁可以保证在对临界资源进行修改的这一动作上各个并行的协程是“串行修改的”。\n\n## Mutex 互斥锁\n创建一个互斥锁\n```go\nmx := new(sync.Mutex)\n```\n\n1.mx.Lock()加锁，mx.Unlock()解锁\n2. 锁是针对资源的，不是针对协程的，哪个协程加锁，就得哪个协程解锁。\n3. 一个协程获得锁后其他协程无论读写只能等待，直到占用锁的协程释放锁\n4. Lock()之前Unlock()会导致panic，还未Unlock()之后Lock()会产生死锁\n\n还是上面的例子，我们稍加修改使用互斥锁\n\n```go\nvar count int = 0\nfunc main() {\n    wg := sync.WaitGroup{}\n\twg.Add(5)\n\n\tmx := sync.Mutex{}\n\n\tfor i := 1; i <= 5; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tmx.Lock()\n\t\t\tcount++\n\t\t\tmx.Unlock()\n\t\t}()\n\t}\n\n\twg.Wait()\n\tfmt.Println(count)\n}\n```\n输出的结果恒为5。\n\n## RWMutex 读写锁\n互斥锁的优势是简单，劣势是太粗暴了。假设对于一个临界资源，有的协程想写，有的只想读。如果在某一时刻只能允许一个协程读，其他的协程必须等待的话就显得效率太低了。因此读写锁出现了。\n\n```go\nrwmx := sync.RWMutex{}\n```\n1. rwmx.Lock()加写锁，rwmx.Unlock()解写锁。写锁排斥任何读锁和写锁\n2. rwmx.RLock()加读锁，rwmx.RUnlock()解读锁。读锁排斥写锁但是不排斥读锁\n\n下面的例子，主协程上了读锁，子协程也都可以获取读锁，整个程序和没有加锁是一样的\n```go\nvar count int = 0\nfunc main() {\n\tvar wg sync.WaitGroup\n\tvar mx sync.RWMutex\n\n\tmx.RLock()\n\tfmt.Println(\"主协程获取了读锁\")\n\n\twg.Add(2)\n\n\tfor i := 1; i <= 2; i++ {\n\t\tgo func(x int) {\n\t\t\tdefer wg.Done()\n\t\t\tmx.RLock()\n\t\t\tfmt.Printf(\"协程%d获取了读锁\\n\", x)\n\t\t\tfmt.Println(count)\n\t\t\tmx.RUnlock()\n\t\t\tfmt.Printf(\"协程%d释放了读锁\\n\", x)\n\t\t}(i)\n\t}\n\n\twg.Wait()\n\tmx.RUnlock()\n\tfmt.Println(\"主协程释放了读锁\")\n}\n```\n结果为：\n```\n主协程获取了读锁\n协程2获取了读锁\n0\n协程2释放了读锁\n协程1获取了读锁\n0\n协程1释放了读锁\n主协程释放了读锁\n```\n下面的示例是主协程获取了写锁想修改count的值，子协程想获取读锁读取count的值\n```go\nvar count int = 0\nfunc PracticeCond5() {\n\tvar wg sync.WaitGroup\n\tvar mx sync.RWMutex\n\n\tmx.Lock()\n\tfmt.Println(\"主协程获取了写锁\")\n\n\twg.Add(2)\n\n\tfor i := 1; i <= 2; i++ {\n\t\tgo func(x int) {\n\t\t\tdefer wg.Done()\n\t\t\tmx.RLock()\n\t\t\tfmt.Printf(\"协程%d获取了读锁\\n\", x)\n\t\t\tfmt.Println(count)\n\t\t\tmx.RUnlock()\n\t\t\tfmt.Printf(\"协程%d释放了读锁\\n\", x)\n\t\t}(i)\n\t}\n\n\tcount++\n\tmx.Unlock()\n\tfmt.Println(\"主协程释放了写锁\")\n\twg.Wait()\n}\n```\n结果为\n```\n主协程获取了写锁\n主协程释放了写锁\n协程2获取了读锁\n1\n协程2释放了读锁\n协程1获取了读锁\n1\n协程1释放了读锁\n```\n可以看出子协程都是等到主协程将count值加一然后释放写锁后才获取的读锁。\n\n## Cond 条件变量\n条件变量适用于多个协程等待某一个资源就绪的情况。条件变量依赖于互斥锁或者读写锁。\n\n使用互斥锁创建条件变量\n```go\n    wx   := new(sync.Mutex)\n\tcond := sync.NewCond(wx)\n```\n在使用的过程中有以下几个函数\n\n* cond.Wait() 当前协程等待资源就绪，整个过程会阻塞当前协程，直到被通知资源就绪\n* cond.Signal() 通知1个等待的协程，使其能够继续工作\n* cond.Broadcast() 广播，通知所有的协程继续工作\n\n需要强调以下几点\n\n1. 调用cond.wait()之前一定要先`cond.L.Lock()`因为wait函数是\n```go\nfunc (c *Cond) Wait() {\n\tc.checker.check()\n\tt := runtime_notifyListAdd(&c.notify)\n\tc.L.Unlock()\n\truntime_notifyListWait(&c.notify, t)\n\tc.L.Lock()\n}\n```\n它是先将协程加入到监听队列然后再释放锁。等到资源就绪的时候再尝试获取互斥锁。\n\n来看一个完整的例子\n```go\nfunc main() {\n\tmx   := new(sync.Mutex)\n\tcond := sync.NewCond(mx)\n\twg   := sync.WaitGroup{}\n\twg.Add(4)\n\n\tfor i := 1; i <= 4; i++ {\n\t\tgo func(x int) {\n\t\t\tdefer wg.Done()\n\t\t\tcond.L.Lock()\n\t\t\tcond.Wait()\n\t\t\tfmt.Println(x)\n\t\t\ttime.Sleep(time.Second)\n\t\t\tfmt.Printf(\"%d准备释放锁\\n\", x)\n\t\t\tcond.L.Unlock()\n\t\t}(i)\n\t}\n\n\tfmt.Println(\"start\")\n\ttime.Sleep(time.Second * 3)\n\tfmt.Println(\"下发第一个通知\")\n\tcond.Signal()\n\ttime.Sleep(time.Second * 3)\n\tfmt.Println(\"下发第二个通知\")\n\tcond.Signal()\n\ttime.Sleep(time.Second * 3)\n\tfmt.Println(\"开始广播\")\n\tcond.Broadcast()\n\n\twg.Wait()\n\tfmt.Println(\"退出\")\n}\n```\n结果为\n```\nstart\n下发第一个通知\n1\n1准备释放锁\n下发第二个通知\n2\n2准备释放锁\n开始广播\n3\n3准备释放锁\n4\n4准备释放锁\n退出\n\n```\n","source":"_posts/go-lock.md","raw":"---\ntitle: Go语言中的锁\ndate: 2020-01-15 14:57:01\ntags:\n    - go\nphotos:\n      - [\"http://sysummery.top/golang2.jpeg\"]\n---\n总结一下这段时间学习的有关go语言中的锁的知识。\n<!--more-->\n多线程和多协程编程能够充分利用多核处理器的优势，是系统性能提升。但是有时也会给我们意外的“惊喜”，比如下面的计数器的例子\n```go\nvar count int = 0\nfunc main() {\n\twg := sync.WaitGroup{}\n\twg.Add(5)\n\n\tfor i := 1; i <= 5; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tcount++\n\t\t}()\n\t}\n\n    wg.Wait()\n\tfmt.Println(count)\n}\n```\n我们期待的结果是5，但事实上结果是不确定的。因为5个协程是并发执行的，当每个协程执行到`count += i`的时候count的值是不确定的，因此结果也是不确定的。\n\n向例子中的count变量可以成为临界资源，当多个线程或协程对临界资源进行修改的时候就必须要“上锁”。使用锁可以保证在对临界资源进行修改的这一动作上各个并行的协程是“串行修改的”。\n\n## Mutex 互斥锁\n创建一个互斥锁\n```go\nmx := new(sync.Mutex)\n```\n\n1.mx.Lock()加锁，mx.Unlock()解锁\n2. 锁是针对资源的，不是针对协程的，哪个协程加锁，就得哪个协程解锁。\n3. 一个协程获得锁后其他协程无论读写只能等待，直到占用锁的协程释放锁\n4. Lock()之前Unlock()会导致panic，还未Unlock()之后Lock()会产生死锁\n\n还是上面的例子，我们稍加修改使用互斥锁\n\n```go\nvar count int = 0\nfunc main() {\n    wg := sync.WaitGroup{}\n\twg.Add(5)\n\n\tmx := sync.Mutex{}\n\n\tfor i := 1; i <= 5; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tmx.Lock()\n\t\t\tcount++\n\t\t\tmx.Unlock()\n\t\t}()\n\t}\n\n\twg.Wait()\n\tfmt.Println(count)\n}\n```\n输出的结果恒为5。\n\n## RWMutex 读写锁\n互斥锁的优势是简单，劣势是太粗暴了。假设对于一个临界资源，有的协程想写，有的只想读。如果在某一时刻只能允许一个协程读，其他的协程必须等待的话就显得效率太低了。因此读写锁出现了。\n\n```go\nrwmx := sync.RWMutex{}\n```\n1. rwmx.Lock()加写锁，rwmx.Unlock()解写锁。写锁排斥任何读锁和写锁\n2. rwmx.RLock()加读锁，rwmx.RUnlock()解读锁。读锁排斥写锁但是不排斥读锁\n\n下面的例子，主协程上了读锁，子协程也都可以获取读锁，整个程序和没有加锁是一样的\n```go\nvar count int = 0\nfunc main() {\n\tvar wg sync.WaitGroup\n\tvar mx sync.RWMutex\n\n\tmx.RLock()\n\tfmt.Println(\"主协程获取了读锁\")\n\n\twg.Add(2)\n\n\tfor i := 1; i <= 2; i++ {\n\t\tgo func(x int) {\n\t\t\tdefer wg.Done()\n\t\t\tmx.RLock()\n\t\t\tfmt.Printf(\"协程%d获取了读锁\\n\", x)\n\t\t\tfmt.Println(count)\n\t\t\tmx.RUnlock()\n\t\t\tfmt.Printf(\"协程%d释放了读锁\\n\", x)\n\t\t}(i)\n\t}\n\n\twg.Wait()\n\tmx.RUnlock()\n\tfmt.Println(\"主协程释放了读锁\")\n}\n```\n结果为：\n```\n主协程获取了读锁\n协程2获取了读锁\n0\n协程2释放了读锁\n协程1获取了读锁\n0\n协程1释放了读锁\n主协程释放了读锁\n```\n下面的示例是主协程获取了写锁想修改count的值，子协程想获取读锁读取count的值\n```go\nvar count int = 0\nfunc PracticeCond5() {\n\tvar wg sync.WaitGroup\n\tvar mx sync.RWMutex\n\n\tmx.Lock()\n\tfmt.Println(\"主协程获取了写锁\")\n\n\twg.Add(2)\n\n\tfor i := 1; i <= 2; i++ {\n\t\tgo func(x int) {\n\t\t\tdefer wg.Done()\n\t\t\tmx.RLock()\n\t\t\tfmt.Printf(\"协程%d获取了读锁\\n\", x)\n\t\t\tfmt.Println(count)\n\t\t\tmx.RUnlock()\n\t\t\tfmt.Printf(\"协程%d释放了读锁\\n\", x)\n\t\t}(i)\n\t}\n\n\tcount++\n\tmx.Unlock()\n\tfmt.Println(\"主协程释放了写锁\")\n\twg.Wait()\n}\n```\n结果为\n```\n主协程获取了写锁\n主协程释放了写锁\n协程2获取了读锁\n1\n协程2释放了读锁\n协程1获取了读锁\n1\n协程1释放了读锁\n```\n可以看出子协程都是等到主协程将count值加一然后释放写锁后才获取的读锁。\n\n## Cond 条件变量\n条件变量适用于多个协程等待某一个资源就绪的情况。条件变量依赖于互斥锁或者读写锁。\n\n使用互斥锁创建条件变量\n```go\n    wx   := new(sync.Mutex)\n\tcond := sync.NewCond(wx)\n```\n在使用的过程中有以下几个函数\n\n* cond.Wait() 当前协程等待资源就绪，整个过程会阻塞当前协程，直到被通知资源就绪\n* cond.Signal() 通知1个等待的协程，使其能够继续工作\n* cond.Broadcast() 广播，通知所有的协程继续工作\n\n需要强调以下几点\n\n1. 调用cond.wait()之前一定要先`cond.L.Lock()`因为wait函数是\n```go\nfunc (c *Cond) Wait() {\n\tc.checker.check()\n\tt := runtime_notifyListAdd(&c.notify)\n\tc.L.Unlock()\n\truntime_notifyListWait(&c.notify, t)\n\tc.L.Lock()\n}\n```\n它是先将协程加入到监听队列然后再释放锁。等到资源就绪的时候再尝试获取互斥锁。\n\n来看一个完整的例子\n```go\nfunc main() {\n\tmx   := new(sync.Mutex)\n\tcond := sync.NewCond(mx)\n\twg   := sync.WaitGroup{}\n\twg.Add(4)\n\n\tfor i := 1; i <= 4; i++ {\n\t\tgo func(x int) {\n\t\t\tdefer wg.Done()\n\t\t\tcond.L.Lock()\n\t\t\tcond.Wait()\n\t\t\tfmt.Println(x)\n\t\t\ttime.Sleep(time.Second)\n\t\t\tfmt.Printf(\"%d准备释放锁\\n\", x)\n\t\t\tcond.L.Unlock()\n\t\t}(i)\n\t}\n\n\tfmt.Println(\"start\")\n\ttime.Sleep(time.Second * 3)\n\tfmt.Println(\"下发第一个通知\")\n\tcond.Signal()\n\ttime.Sleep(time.Second * 3)\n\tfmt.Println(\"下发第二个通知\")\n\tcond.Signal()\n\ttime.Sleep(time.Second * 3)\n\tfmt.Println(\"开始广播\")\n\tcond.Broadcast()\n\n\twg.Wait()\n\tfmt.Println(\"退出\")\n}\n```\n结果为\n```\nstart\n下发第一个通知\n1\n1准备释放锁\n下发第二个通知\n2\n2准备释放锁\n开始广播\n3\n3准备释放锁\n4\n4准备释放锁\n退出\n\n```\n","slug":"go-lock","published":1,"updated":"2020-11-23T15:23:47.777Z","comments":1,"layout":"post","link":"","_id":"ckhupaq9g000c1no8tect5gtz","content":"<p>总结一下这段时间学习的有关go语言中的锁的知识。</p>\n<a id=\"more\"></a>\n<p>多线程和多协程编程能够充分利用多核处理器的优势，是系统性能提升。但是有时也会给我们意外的“惊喜”，比如下面的计数器的例子</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> count <span class=\"keyword\">int</span> = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\twg := sync.WaitGroup&#123;&#125;</span><br><span class=\"line\">\twg.Add(<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">1</span>; i &lt;= <span class=\"number\">5</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\tcount++</span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    wg.Wait()</span><br><span class=\"line\">\tfmt.Println(count)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>我们期待的结果是5，但事实上结果是不确定的。因为5个协程是并发执行的，当每个协程执行到<code>count += i</code>的时候count的值是不确定的，因此结果也是不确定的。</p>\n<p>向例子中的count变量可以成为临界资源，当多个线程或协程对临界资源进行修改的时候就必须要“上锁”。使用锁可以保证在对临界资源进行修改的这一动作上各个并行的协程是“串行修改的”。</p>\n<h2 id=\"Mutex-互斥锁\"><a href=\"#Mutex-互斥锁\" class=\"headerlink\" title=\"Mutex 互斥锁\"></a>Mutex 互斥锁</h2><p>创建一个互斥锁</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mx := <span class=\"built_in\">new</span>(sync.Mutex)</span><br></pre></td></tr></table></figure>\n\n<p>1.mx.Lock()加锁，mx.Unlock()解锁<br>2. 锁是针对资源的，不是针对协程的，哪个协程加锁，就得哪个协程解锁。<br>3. 一个协程获得锁后其他协程无论读写只能等待，直到占用锁的协程释放锁<br>4. Lock()之前Unlock()会导致panic，还未Unlock()之后Lock()会产生死锁</p>\n<p>还是上面的例子，我们稍加修改使用互斥锁</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> count <span class=\"keyword\">int</span> = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">    wg := sync.WaitGroup&#123;&#125;</span><br><span class=\"line\">\twg.Add(<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\tmx := sync.Mutex&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">1</span>; i &lt;= <span class=\"number\">5</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\tmx.Lock()</span><br><span class=\"line\">\t\t\tcount++</span><br><span class=\"line\">\t\t\tmx.Unlock()</span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">\tfmt.Println(count)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>输出的结果恒为5。</p>\n<h2 id=\"RWMutex-读写锁\"><a href=\"#RWMutex-读写锁\" class=\"headerlink\" title=\"RWMutex 读写锁\"></a>RWMutex 读写锁</h2><p>互斥锁的优势是简单，劣势是太粗暴了。假设对于一个临界资源，有的协程想写，有的只想读。如果在某一时刻只能允许一个协程读，其他的协程必须等待的话就显得效率太低了。因此读写锁出现了。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rwmx := sync.RWMutex&#123;&#125;</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>rwmx.Lock()加写锁，rwmx.Unlock()解写锁。写锁排斥任何读锁和写锁</li>\n<li>rwmx.RLock()加读锁，rwmx.RUnlock()解读锁。读锁排斥写锁但是不排斥读锁</li>\n</ol>\n<p>下面的例子，主协程上了读锁，子协程也都可以获取读锁，整个程序和没有加锁是一样的</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> count <span class=\"keyword\">int</span> = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> wg sync.WaitGroup</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> mx sync.RWMutex</span><br><span class=\"line\"></span><br><span class=\"line\">\tmx.RLock()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"主协程获取了读锁\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Add(<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">1</span>; i &lt;= <span class=\"number\">2</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(x <span class=\"keyword\">int</span>)</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\tmx.RLock()</span><br><span class=\"line\">\t\t\tfmt.Printf(<span class=\"string\">\"协程%d获取了读锁\\n\"</span>, x)</span><br><span class=\"line\">\t\t\tfmt.Println(count)</span><br><span class=\"line\">\t\t\tmx.RUnlock()</span><br><span class=\"line\">\t\t\tfmt.Printf(<span class=\"string\">\"协程%d释放了读锁\\n\"</span>, x)</span><br><span class=\"line\">\t\t&#125;(i)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">\tmx.RUnlock()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"主协程释放了读锁\"</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果为：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">主协程获取了读锁</span><br><span class=\"line\">协程2获取了读锁</span><br><span class=\"line\">0</span><br><span class=\"line\">协程2释放了读锁</span><br><span class=\"line\">协程1获取了读锁</span><br><span class=\"line\">0</span><br><span class=\"line\">协程1释放了读锁</span><br><span class=\"line\">主协程释放了读锁</span><br></pre></td></tr></table></figure>\n\n<p>下面的示例是主协程获取了写锁想修改count的值，子协程想获取读锁读取count的值</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> count <span class=\"keyword\">int</span> = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">PracticeCond5</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> wg sync.WaitGroup</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> mx sync.RWMutex</span><br><span class=\"line\"></span><br><span class=\"line\">\tmx.Lock()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"主协程获取了写锁\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Add(<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">1</span>; i &lt;= <span class=\"number\">2</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(x <span class=\"keyword\">int</span>)</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\tmx.RLock()</span><br><span class=\"line\">\t\t\tfmt.Printf(<span class=\"string\">\"协程%d获取了读锁\\n\"</span>, x)</span><br><span class=\"line\">\t\t\tfmt.Println(count)</span><br><span class=\"line\">\t\t\tmx.RUnlock()</span><br><span class=\"line\">\t\t\tfmt.Printf(<span class=\"string\">\"协程%d释放了读锁\\n\"</span>, x)</span><br><span class=\"line\">\t\t&#125;(i)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tcount++</span><br><span class=\"line\">\tmx.Unlock()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"主协程释放了写锁\"</span>)</span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">主协程获取了写锁</span><br><span class=\"line\">主协程释放了写锁</span><br><span class=\"line\">协程2获取了读锁</span><br><span class=\"line\">1</span><br><span class=\"line\">协程2释放了读锁</span><br><span class=\"line\">协程1获取了读锁</span><br><span class=\"line\">1</span><br><span class=\"line\">协程1释放了读锁</span><br></pre></td></tr></table></figure>\n\n<p>可以看出子协程都是等到主协程将count值加一然后释放写锁后才获取的读锁。</p>\n<h2 id=\"Cond-条件变量\"><a href=\"#Cond-条件变量\" class=\"headerlink\" title=\"Cond 条件变量\"></a>Cond 条件变量</h2><p>条件变量适用于多个协程等待某一个资源就绪的情况。条件变量依赖于互斥锁或者读写锁。</p>\n<p>使用互斥锁创建条件变量</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">   wx   := <span class=\"built_in\">new</span>(sync.Mutex)</span><br><span class=\"line\">cond := sync.NewCond(wx)</span><br></pre></td></tr></table></figure>\n\n<p>在使用的过程中有以下几个函数</p>\n<ul>\n<li>cond.Wait() 当前协程等待资源就绪，整个过程会阻塞当前协程，直到被通知资源就绪</li>\n<li>cond.Signal() 通知1个等待的协程，使其能够继续工作</li>\n<li>cond.Broadcast() 广播，通知所有的协程继续工作</li>\n</ul>\n<p>需要强调以下几点</p>\n<ol>\n<li>调用cond.wait()之前一定要先<code>cond.L.Lock()</code>因为wait函数是<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(c *Cond)</span> <span class=\"title\">Wait</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tc.checker.check()</span><br><span class=\"line\">\tt := runtime_notifyListAdd(&amp;c.notify)</span><br><span class=\"line\">\tc.L.Unlock()</span><br><span class=\"line\">\truntime_notifyListWait(&amp;c.notify, t)</span><br><span class=\"line\">\tc.L.Lock()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<p>它是先将协程加入到监听队列然后再释放锁。等到资源就绪的时候再尝试获取互斥锁。</p>\n<p>来看一个完整的例子</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tmx   := <span class=\"built_in\">new</span>(sync.Mutex)</span><br><span class=\"line\">\tcond := sync.NewCond(mx)</span><br><span class=\"line\">\twg   := sync.WaitGroup&#123;&#125;</span><br><span class=\"line\">\twg.Add(<span class=\"number\">4</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">1</span>; i &lt;= <span class=\"number\">4</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(x <span class=\"keyword\">int</span>)</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\tcond.L.Lock()</span><br><span class=\"line\">\t\t\tcond.Wait()</span><br><span class=\"line\">\t\t\tfmt.Println(x)</span><br><span class=\"line\">\t\t\ttime.Sleep(time.Second)</span><br><span class=\"line\">\t\t\tfmt.Printf(<span class=\"string\">\"%d准备释放锁\\n\"</span>, x)</span><br><span class=\"line\">\t\t\tcond.L.Unlock()</span><br><span class=\"line\">\t\t&#125;(i)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"start\"</span>)</span><br><span class=\"line\">\ttime.Sleep(time.Second * <span class=\"number\">3</span>)</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"下发第一个通知\"</span>)</span><br><span class=\"line\">\tcond.Signal()</span><br><span class=\"line\">\ttime.Sleep(time.Second * <span class=\"number\">3</span>)</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"下发第二个通知\"</span>)</span><br><span class=\"line\">\tcond.Signal()</span><br><span class=\"line\">\ttime.Sleep(time.Second * <span class=\"number\">3</span>)</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"开始广播\"</span>)</span><br><span class=\"line\">\tcond.Broadcast()</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"退出\"</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">start</span><br><span class=\"line\">下发第一个通知</span><br><span class=\"line\">1</span><br><span class=\"line\">1准备释放锁</span><br><span class=\"line\">下发第二个通知</span><br><span class=\"line\">2</span><br><span class=\"line\">2准备释放锁</span><br><span class=\"line\">开始广播</span><br><span class=\"line\">3</span><br><span class=\"line\">3准备释放锁</span><br><span class=\"line\">4</span><br><span class=\"line\">4准备释放锁</span><br><span class=\"line\">退出</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"<p>总结一下这段时间学习的有关go语言中的锁的知识。</p>","more":"<p>多线程和多协程编程能够充分利用多核处理器的优势，是系统性能提升。但是有时也会给我们意外的“惊喜”，比如下面的计数器的例子</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> count <span class=\"keyword\">int</span> = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\twg := sync.WaitGroup&#123;&#125;</span><br><span class=\"line\">\twg.Add(<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">1</span>; i &lt;= <span class=\"number\">5</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\tcount++</span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    wg.Wait()</span><br><span class=\"line\">\tfmt.Println(count)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>我们期待的结果是5，但事实上结果是不确定的。因为5个协程是并发执行的，当每个协程执行到<code>count += i</code>的时候count的值是不确定的，因此结果也是不确定的。</p>\n<p>向例子中的count变量可以成为临界资源，当多个线程或协程对临界资源进行修改的时候就必须要“上锁”。使用锁可以保证在对临界资源进行修改的这一动作上各个并行的协程是“串行修改的”。</p>\n<h2 id=\"Mutex-互斥锁\"><a href=\"#Mutex-互斥锁\" class=\"headerlink\" title=\"Mutex 互斥锁\"></a>Mutex 互斥锁</h2><p>创建一个互斥锁</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mx := <span class=\"built_in\">new</span>(sync.Mutex)</span><br></pre></td></tr></table></figure>\n\n<p>1.mx.Lock()加锁，mx.Unlock()解锁<br>2. 锁是针对资源的，不是针对协程的，哪个协程加锁，就得哪个协程解锁。<br>3. 一个协程获得锁后其他协程无论读写只能等待，直到占用锁的协程释放锁<br>4. Lock()之前Unlock()会导致panic，还未Unlock()之后Lock()会产生死锁</p>\n<p>还是上面的例子，我们稍加修改使用互斥锁</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> count <span class=\"keyword\">int</span> = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">    wg := sync.WaitGroup&#123;&#125;</span><br><span class=\"line\">\twg.Add(<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\tmx := sync.Mutex&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">1</span>; i &lt;= <span class=\"number\">5</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\tmx.Lock()</span><br><span class=\"line\">\t\t\tcount++</span><br><span class=\"line\">\t\t\tmx.Unlock()</span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">\tfmt.Println(count)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>输出的结果恒为5。</p>\n<h2 id=\"RWMutex-读写锁\"><a href=\"#RWMutex-读写锁\" class=\"headerlink\" title=\"RWMutex 读写锁\"></a>RWMutex 读写锁</h2><p>互斥锁的优势是简单，劣势是太粗暴了。假设对于一个临界资源，有的协程想写，有的只想读。如果在某一时刻只能允许一个协程读，其他的协程必须等待的话就显得效率太低了。因此读写锁出现了。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rwmx := sync.RWMutex&#123;&#125;</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>rwmx.Lock()加写锁，rwmx.Unlock()解写锁。写锁排斥任何读锁和写锁</li>\n<li>rwmx.RLock()加读锁，rwmx.RUnlock()解读锁。读锁排斥写锁但是不排斥读锁</li>\n</ol>\n<p>下面的例子，主协程上了读锁，子协程也都可以获取读锁，整个程序和没有加锁是一样的</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> count <span class=\"keyword\">int</span> = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> wg sync.WaitGroup</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> mx sync.RWMutex</span><br><span class=\"line\"></span><br><span class=\"line\">\tmx.RLock()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"主协程获取了读锁\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Add(<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">1</span>; i &lt;= <span class=\"number\">2</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(x <span class=\"keyword\">int</span>)</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\tmx.RLock()</span><br><span class=\"line\">\t\t\tfmt.Printf(<span class=\"string\">\"协程%d获取了读锁\\n\"</span>, x)</span><br><span class=\"line\">\t\t\tfmt.Println(count)</span><br><span class=\"line\">\t\t\tmx.RUnlock()</span><br><span class=\"line\">\t\t\tfmt.Printf(<span class=\"string\">\"协程%d释放了读锁\\n\"</span>, x)</span><br><span class=\"line\">\t\t&#125;(i)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">\tmx.RUnlock()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"主协程释放了读锁\"</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果为：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">主协程获取了读锁</span><br><span class=\"line\">协程2获取了读锁</span><br><span class=\"line\">0</span><br><span class=\"line\">协程2释放了读锁</span><br><span class=\"line\">协程1获取了读锁</span><br><span class=\"line\">0</span><br><span class=\"line\">协程1释放了读锁</span><br><span class=\"line\">主协程释放了读锁</span><br></pre></td></tr></table></figure>\n\n<p>下面的示例是主协程获取了写锁想修改count的值，子协程想获取读锁读取count的值</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> count <span class=\"keyword\">int</span> = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">PracticeCond5</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> wg sync.WaitGroup</span><br><span class=\"line\">\t<span class=\"keyword\">var</span> mx sync.RWMutex</span><br><span class=\"line\"></span><br><span class=\"line\">\tmx.Lock()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"主协程获取了写锁\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Add(<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">1</span>; i &lt;= <span class=\"number\">2</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(x <span class=\"keyword\">int</span>)</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\tmx.RLock()</span><br><span class=\"line\">\t\t\tfmt.Printf(<span class=\"string\">\"协程%d获取了读锁\\n\"</span>, x)</span><br><span class=\"line\">\t\t\tfmt.Println(count)</span><br><span class=\"line\">\t\t\tmx.RUnlock()</span><br><span class=\"line\">\t\t\tfmt.Printf(<span class=\"string\">\"协程%d释放了读锁\\n\"</span>, x)</span><br><span class=\"line\">\t\t&#125;(i)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tcount++</span><br><span class=\"line\">\tmx.Unlock()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"主协程释放了写锁\"</span>)</span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">主协程获取了写锁</span><br><span class=\"line\">主协程释放了写锁</span><br><span class=\"line\">协程2获取了读锁</span><br><span class=\"line\">1</span><br><span class=\"line\">协程2释放了读锁</span><br><span class=\"line\">协程1获取了读锁</span><br><span class=\"line\">1</span><br><span class=\"line\">协程1释放了读锁</span><br></pre></td></tr></table></figure>\n\n<p>可以看出子协程都是等到主协程将count值加一然后释放写锁后才获取的读锁。</p>\n<h2 id=\"Cond-条件变量\"><a href=\"#Cond-条件变量\" class=\"headerlink\" title=\"Cond 条件变量\"></a>Cond 条件变量</h2><p>条件变量适用于多个协程等待某一个资源就绪的情况。条件变量依赖于互斥锁或者读写锁。</p>\n<p>使用互斥锁创建条件变量</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">   wx   := <span class=\"built_in\">new</span>(sync.Mutex)</span><br><span class=\"line\">cond := sync.NewCond(wx)</span><br></pre></td></tr></table></figure>\n\n<p>在使用的过程中有以下几个函数</p>\n<ul>\n<li>cond.Wait() 当前协程等待资源就绪，整个过程会阻塞当前协程，直到被通知资源就绪</li>\n<li>cond.Signal() 通知1个等待的协程，使其能够继续工作</li>\n<li>cond.Broadcast() 广播，通知所有的协程继续工作</li>\n</ul>\n<p>需要强调以下几点</p>\n<ol>\n<li>调用cond.wait()之前一定要先<code>cond.L.Lock()</code>因为wait函数是<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(c *Cond)</span> <span class=\"title\">Wait</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tc.checker.check()</span><br><span class=\"line\">\tt := runtime_notifyListAdd(&amp;c.notify)</span><br><span class=\"line\">\tc.L.Unlock()</span><br><span class=\"line\">\truntime_notifyListWait(&amp;c.notify, t)</span><br><span class=\"line\">\tc.L.Lock()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<p>它是先将协程加入到监听队列然后再释放锁。等到资源就绪的时候再尝试获取互斥锁。</p>\n<p>来看一个完整的例子</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tmx   := <span class=\"built_in\">new</span>(sync.Mutex)</span><br><span class=\"line\">\tcond := sync.NewCond(mx)</span><br><span class=\"line\">\twg   := sync.WaitGroup&#123;&#125;</span><br><span class=\"line\">\twg.Add(<span class=\"number\">4</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"number\">1</span>; i &lt;= <span class=\"number\">4</span>; i++ &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(x <span class=\"keyword\">int</span>)</span></span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">defer</span> wg.Done()</span><br><span class=\"line\">\t\t\tcond.L.Lock()</span><br><span class=\"line\">\t\t\tcond.Wait()</span><br><span class=\"line\">\t\t\tfmt.Println(x)</span><br><span class=\"line\">\t\t\ttime.Sleep(time.Second)</span><br><span class=\"line\">\t\t\tfmt.Printf(<span class=\"string\">\"%d准备释放锁\\n\"</span>, x)</span><br><span class=\"line\">\t\t\tcond.L.Unlock()</span><br><span class=\"line\">\t\t&#125;(i)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"start\"</span>)</span><br><span class=\"line\">\ttime.Sleep(time.Second * <span class=\"number\">3</span>)</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"下发第一个通知\"</span>)</span><br><span class=\"line\">\tcond.Signal()</span><br><span class=\"line\">\ttime.Sleep(time.Second * <span class=\"number\">3</span>)</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"下发第二个通知\"</span>)</span><br><span class=\"line\">\tcond.Signal()</span><br><span class=\"line\">\ttime.Sleep(time.Second * <span class=\"number\">3</span>)</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"开始广播\"</span>)</span><br><span class=\"line\">\tcond.Broadcast()</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">\"退出\"</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>结果为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">start</span><br><span class=\"line\">下发第一个通知</span><br><span class=\"line\">1</span><br><span class=\"line\">1准备释放锁</span><br><span class=\"line\">下发第二个通知</span><br><span class=\"line\">2</span><br><span class=\"line\">2准备释放锁</span><br><span class=\"line\">开始广播</span><br><span class=\"line\">3</span><br><span class=\"line\">3准备释放锁</span><br><span class=\"line\">4</span><br><span class=\"line\">4准备释放锁</span><br><span class=\"line\">退出</span><br></pre></td></tr></table></figure>"},{"title":"Https","date":"2019-11-15T06:50:20.000Z","photos":["http://sysummery.top/https_cover.jpeg"],"_content":"https是在应用层(http)与传输层之间多了一个SSL(TSL)层。这个层负责先将http要发送的数据使用一个密室加密之后再交给传输层。相应的，接收方的传输层先将加密的数据交给SSL(TLS)层解密后，再发送给应用层(http)。\n<!--more-->\n## 对称加密与非对称加密\n对称加密: 通信双方的密匙是一样的，这个密匙既用于加密有用于解密。\n\n非对称加密：有一对公匙和密匙。公匙加密的内容公匙自己不能解密，必须得私匙解密。同样的，私匙加密的内容私匙自己不能解密，得用公匙解密。\n\n摘要：对一段内用使用hash函数生成一个固定长度的字符串。\n\n数字签名：对摘要使用一个密匙(公匙)加密。\n\n## Https通信过程\n\n![https的简易流程](http://sysummery.top/https.jpg)\n\n上图中还缺少一些步骤，比如通信双方还会对双方密码能力的信息，比如支持的SSL(TSL)版本，加密组件等进行协商约定等。但是本文只想介绍https的原理和关键步骤，所以没有画出。\n\n总的来说，https最开始使用非对称加密在客户端与服务器之间产生一个密匙。之后的数据通信就使用这个密匙进行对称加密。\n\n其中第三步是重点，服务器会给客户端发送一个证书，然后客户端根据验证这个证书的结果来判断是否执行下一步。\n\n### CA颁发的证书\nCA是一个在互联网上权威的第三方机构，我们可以简单的认为所有的网站和用户都信任他。\n\n如果一个网站要支持https协议，那么他就得向CA申请一个证书。假如证书最开始是一张白纸，申请证书的流程如下\n\n1. 网站向CA提供自身的一些信息，如果域名、公匙等，CA验证这些信息没问题后就把这些信息以明文的方式写到证书上。\n2. 生成数字签名。对第一步的明文信息使用hash函数取摘要，然后用CA的密匙(私匙)对这个摘要加密就行程了数字签名。把这个数字签名也放到证书上。\n3. 在证书上附上颁发证书机构的信息，以及证书的有效期等信息。\n\n到此证书的制作就完成了。以后任何一个客户端想和网站发起https协议的时候网站都会先把这个证书给发起端检验。\n\n### 发起端验证证书\n为什么我用发起端这个词而不用客户端呢？因为服务器或网站也可以对客户端进行https校验，过程和原理也是一样的。那么当发起端收到证书后会有以下步骤的校验。\n\n1. 颁发证书的CA机构是否合法，是否仍然有资质。\n2. 验证证书是否在有效期内。\n3. 验证数字签名。我们可以简单的认为，浏览器具有所有CA机构的公钥。浏览器用颁发该证书的CA的公匙，去解密数字签名。如果解密成功说明这个证书是该CA发的，否则证书有问题。解密之后就获得了这个证书明文部分的摘要。\n4. 客户端用同样的hash函数对证书中的明文部分取摘要，如果与第三步中的摘要相同，那么说明证书的内容是准确的，没有被篡改过 。\n5. 对明文部分的信息进行一些校验，比如域名。\n\n此时发起端已经拿到了对方的公匙。\n\n### 发起端与对方交换\"对称加密\"的密匙\n发起端随机生成一个加密字符串，然后使用对方的公匙非对称加密，发送给对方。对方收到后用私匙解密获取这个字符串。然后对方会告诉发起端，我已收到这个加密字符串，以后咱俩再通信的时候咱么都用这个字符串加密通信的内容。\n\n之后双方都是用这个加密字符串对称加密发送的内容。\n","source":"_posts/https.md","raw":"---\ntitle: Https\ndate: 2019-11-15 14:50:20\ntags:\n  - https\nphotos:\n  - [\"http://sysummery.top/https_cover.jpeg\"]\n---\nhttps是在应用层(http)与传输层之间多了一个SSL(TSL)层。这个层负责先将http要发送的数据使用一个密室加密之后再交给传输层。相应的，接收方的传输层先将加密的数据交给SSL(TLS)层解密后，再发送给应用层(http)。\n<!--more-->\n## 对称加密与非对称加密\n对称加密: 通信双方的密匙是一样的，这个密匙既用于加密有用于解密。\n\n非对称加密：有一对公匙和密匙。公匙加密的内容公匙自己不能解密，必须得私匙解密。同样的，私匙加密的内容私匙自己不能解密，得用公匙解密。\n\n摘要：对一段内用使用hash函数生成一个固定长度的字符串。\n\n数字签名：对摘要使用一个密匙(公匙)加密。\n\n## Https通信过程\n\n![https的简易流程](http://sysummery.top/https.jpg)\n\n上图中还缺少一些步骤，比如通信双方还会对双方密码能力的信息，比如支持的SSL(TSL)版本，加密组件等进行协商约定等。但是本文只想介绍https的原理和关键步骤，所以没有画出。\n\n总的来说，https最开始使用非对称加密在客户端与服务器之间产生一个密匙。之后的数据通信就使用这个密匙进行对称加密。\n\n其中第三步是重点，服务器会给客户端发送一个证书，然后客户端根据验证这个证书的结果来判断是否执行下一步。\n\n### CA颁发的证书\nCA是一个在互联网上权威的第三方机构，我们可以简单的认为所有的网站和用户都信任他。\n\n如果一个网站要支持https协议，那么他就得向CA申请一个证书。假如证书最开始是一张白纸，申请证书的流程如下\n\n1. 网站向CA提供自身的一些信息，如果域名、公匙等，CA验证这些信息没问题后就把这些信息以明文的方式写到证书上。\n2. 生成数字签名。对第一步的明文信息使用hash函数取摘要，然后用CA的密匙(私匙)对这个摘要加密就行程了数字签名。把这个数字签名也放到证书上。\n3. 在证书上附上颁发证书机构的信息，以及证书的有效期等信息。\n\n到此证书的制作就完成了。以后任何一个客户端想和网站发起https协议的时候网站都会先把这个证书给发起端检验。\n\n### 发起端验证证书\n为什么我用发起端这个词而不用客户端呢？因为服务器或网站也可以对客户端进行https校验，过程和原理也是一样的。那么当发起端收到证书后会有以下步骤的校验。\n\n1. 颁发证书的CA机构是否合法，是否仍然有资质。\n2. 验证证书是否在有效期内。\n3. 验证数字签名。我们可以简单的认为，浏览器具有所有CA机构的公钥。浏览器用颁发该证书的CA的公匙，去解密数字签名。如果解密成功说明这个证书是该CA发的，否则证书有问题。解密之后就获得了这个证书明文部分的摘要。\n4. 客户端用同样的hash函数对证书中的明文部分取摘要，如果与第三步中的摘要相同，那么说明证书的内容是准确的，没有被篡改过 。\n5. 对明文部分的信息进行一些校验，比如域名。\n\n此时发起端已经拿到了对方的公匙。\n\n### 发起端与对方交换\"对称加密\"的密匙\n发起端随机生成一个加密字符串，然后使用对方的公匙非对称加密，发送给对方。对方收到后用私匙解密获取这个字符串。然后对方会告诉发起端，我已收到这个加密字符串，以后咱俩再通信的时候咱么都用这个字符串加密通信的内容。\n\n之后双方都是用这个加密字符串对称加密发送的内容。\n","slug":"https","published":1,"updated":"2020-11-23T15:23:47.778Z","comments":1,"layout":"post","link":"","_id":"ckhupaq9i000e1no8qqlh35wm","content":"<p>https是在应用层(http)与传输层之间多了一个SSL(TSL)层。这个层负责先将http要发送的数据使用一个密室加密之后再交给传输层。相应的，接收方的传输层先将加密的数据交给SSL(TLS)层解密后，再发送给应用层(http)。</p>\n<a id=\"more\"></a>\n<h2 id=\"对称加密与非对称加密\"><a href=\"#对称加密与非对称加密\" class=\"headerlink\" title=\"对称加密与非对称加密\"></a>对称加密与非对称加密</h2><p>对称加密: 通信双方的密匙是一样的，这个密匙既用于加密有用于解密。</p>\n<p>非对称加密：有一对公匙和密匙。公匙加密的内容公匙自己不能解密，必须得私匙解密。同样的，私匙加密的内容私匙自己不能解密，得用公匙解密。</p>\n<p>摘要：对一段内用使用hash函数生成一个固定长度的字符串。</p>\n<p>数字签名：对摘要使用一个密匙(公匙)加密。</p>\n<h2 id=\"Https通信过程\"><a href=\"#Https通信过程\" class=\"headerlink\" title=\"Https通信过程\"></a>Https通信过程</h2><p><img src=\"http://sysummery.top/https.jpg\" alt=\"https的简易流程\"></p>\n<p>上图中还缺少一些步骤，比如通信双方还会对双方密码能力的信息，比如支持的SSL(TSL)版本，加密组件等进行协商约定等。但是本文只想介绍https的原理和关键步骤，所以没有画出。</p>\n<p>总的来说，https最开始使用非对称加密在客户端与服务器之间产生一个密匙。之后的数据通信就使用这个密匙进行对称加密。</p>\n<p>其中第三步是重点，服务器会给客户端发送一个证书，然后客户端根据验证这个证书的结果来判断是否执行下一步。</p>\n<h3 id=\"CA颁发的证书\"><a href=\"#CA颁发的证书\" class=\"headerlink\" title=\"CA颁发的证书\"></a>CA颁发的证书</h3><p>CA是一个在互联网上权威的第三方机构，我们可以简单的认为所有的网站和用户都信任他。</p>\n<p>如果一个网站要支持https协议，那么他就得向CA申请一个证书。假如证书最开始是一张白纸，申请证书的流程如下</p>\n<ol>\n<li>网站向CA提供自身的一些信息，如果域名、公匙等，CA验证这些信息没问题后就把这些信息以明文的方式写到证书上。</li>\n<li>生成数字签名。对第一步的明文信息使用hash函数取摘要，然后用CA的密匙(私匙)对这个摘要加密就行程了数字签名。把这个数字签名也放到证书上。</li>\n<li>在证书上附上颁发证书机构的信息，以及证书的有效期等信息。</li>\n</ol>\n<p>到此证书的制作就完成了。以后任何一个客户端想和网站发起https协议的时候网站都会先把这个证书给发起端检验。</p>\n<h3 id=\"发起端验证证书\"><a href=\"#发起端验证证书\" class=\"headerlink\" title=\"发起端验证证书\"></a>发起端验证证书</h3><p>为什么我用发起端这个词而不用客户端呢？因为服务器或网站也可以对客户端进行https校验，过程和原理也是一样的。那么当发起端收到证书后会有以下步骤的校验。</p>\n<ol>\n<li>颁发证书的CA机构是否合法，是否仍然有资质。</li>\n<li>验证证书是否在有效期内。</li>\n<li>验证数字签名。我们可以简单的认为，浏览器具有所有CA机构的公钥。浏览器用颁发该证书的CA的公匙，去解密数字签名。如果解密成功说明这个证书是该CA发的，否则证书有问题。解密之后就获得了这个证书明文部分的摘要。</li>\n<li>客户端用同样的hash函数对证书中的明文部分取摘要，如果与第三步中的摘要相同，那么说明证书的内容是准确的，没有被篡改过 。</li>\n<li>对明文部分的信息进行一些校验，比如域名。</li>\n</ol>\n<p>此时发起端已经拿到了对方的公匙。</p>\n<h3 id=\"发起端与对方交换”对称加密”的密匙\"><a href=\"#发起端与对方交换”对称加密”的密匙\" class=\"headerlink\" title=\"发起端与对方交换”对称加密”的密匙\"></a>发起端与对方交换”对称加密”的密匙</h3><p>发起端随机生成一个加密字符串，然后使用对方的公匙非对称加密，发送给对方。对方收到后用私匙解密获取这个字符串。然后对方会告诉发起端，我已收到这个加密字符串，以后咱俩再通信的时候咱么都用这个字符串加密通信的内容。</p>\n<p>之后双方都是用这个加密字符串对称加密发送的内容。</p>\n","site":{"data":{}},"excerpt":"<p>https是在应用层(http)与传输层之间多了一个SSL(TSL)层。这个层负责先将http要发送的数据使用一个密室加密之后再交给传输层。相应的，接收方的传输层先将加密的数据交给SSL(TLS)层解密后，再发送给应用层(http)。</p>","more":"<h2 id=\"对称加密与非对称加密\"><a href=\"#对称加密与非对称加密\" class=\"headerlink\" title=\"对称加密与非对称加密\"></a>对称加密与非对称加密</h2><p>对称加密: 通信双方的密匙是一样的，这个密匙既用于加密有用于解密。</p>\n<p>非对称加密：有一对公匙和密匙。公匙加密的内容公匙自己不能解密，必须得私匙解密。同样的，私匙加密的内容私匙自己不能解密，得用公匙解密。</p>\n<p>摘要：对一段内用使用hash函数生成一个固定长度的字符串。</p>\n<p>数字签名：对摘要使用一个密匙(公匙)加密。</p>\n<h2 id=\"Https通信过程\"><a href=\"#Https通信过程\" class=\"headerlink\" title=\"Https通信过程\"></a>Https通信过程</h2><p><img src=\"http://sysummery.top/https.jpg\" alt=\"https的简易流程\"></p>\n<p>上图中还缺少一些步骤，比如通信双方还会对双方密码能力的信息，比如支持的SSL(TSL)版本，加密组件等进行协商约定等。但是本文只想介绍https的原理和关键步骤，所以没有画出。</p>\n<p>总的来说，https最开始使用非对称加密在客户端与服务器之间产生一个密匙。之后的数据通信就使用这个密匙进行对称加密。</p>\n<p>其中第三步是重点，服务器会给客户端发送一个证书，然后客户端根据验证这个证书的结果来判断是否执行下一步。</p>\n<h3 id=\"CA颁发的证书\"><a href=\"#CA颁发的证书\" class=\"headerlink\" title=\"CA颁发的证书\"></a>CA颁发的证书</h3><p>CA是一个在互联网上权威的第三方机构，我们可以简单的认为所有的网站和用户都信任他。</p>\n<p>如果一个网站要支持https协议，那么他就得向CA申请一个证书。假如证书最开始是一张白纸，申请证书的流程如下</p>\n<ol>\n<li>网站向CA提供自身的一些信息，如果域名、公匙等，CA验证这些信息没问题后就把这些信息以明文的方式写到证书上。</li>\n<li>生成数字签名。对第一步的明文信息使用hash函数取摘要，然后用CA的密匙(私匙)对这个摘要加密就行程了数字签名。把这个数字签名也放到证书上。</li>\n<li>在证书上附上颁发证书机构的信息，以及证书的有效期等信息。</li>\n</ol>\n<p>到此证书的制作就完成了。以后任何一个客户端想和网站发起https协议的时候网站都会先把这个证书给发起端检验。</p>\n<h3 id=\"发起端验证证书\"><a href=\"#发起端验证证书\" class=\"headerlink\" title=\"发起端验证证书\"></a>发起端验证证书</h3><p>为什么我用发起端这个词而不用客户端呢？因为服务器或网站也可以对客户端进行https校验，过程和原理也是一样的。那么当发起端收到证书后会有以下步骤的校验。</p>\n<ol>\n<li>颁发证书的CA机构是否合法，是否仍然有资质。</li>\n<li>验证证书是否在有效期内。</li>\n<li>验证数字签名。我们可以简单的认为，浏览器具有所有CA机构的公钥。浏览器用颁发该证书的CA的公匙，去解密数字签名。如果解密成功说明这个证书是该CA发的，否则证书有问题。解密之后就获得了这个证书明文部分的摘要。</li>\n<li>客户端用同样的hash函数对证书中的明文部分取摘要，如果与第三步中的摘要相同，那么说明证书的内容是准确的，没有被篡改过 。</li>\n<li>对明文部分的信息进行一些校验，比如域名。</li>\n</ol>\n<p>此时发起端已经拿到了对方的公匙。</p>\n<h3 id=\"发起端与对方交换”对称加密”的密匙\"><a href=\"#发起端与对方交换”对称加密”的密匙\" class=\"headerlink\" title=\"发起端与对方交换”对称加密”的密匙\"></a>发起端与对方交换”对称加密”的密匙</h3><p>发起端随机生成一个加密字符串，然后使用对方的公匙非对称加密，发送给对方。对方收到后用私匙解密获取这个字符串。然后对方会告诉发起端，我已收到这个加密字符串，以后咱俩再通信的时候咱么都用这个字符串加密通信的内容。</p>\n<p>之后双方都是用这个加密字符串对称加密发送的内容。</p>"},{"title":"Innodb中的锁","date":"2019-12-07T03:47:11.000Z","photos":["http://sysummery.top/lock_cover.jpg"],"_content":"从粒度上来分可以分为**行锁**、**页锁**、**表锁**; 从“性格”上分可以分为**乐观锁**与**悲观锁**; 从粒度上的分类应该很容易理解，不再敖述。所以是说说锁在性格上的分类。\n<!--more-->\n\n# 1. 锁的分类\n\n## 1.1 乐观锁\n用数据版本记录机制实现，是实现乐观锁的最常用的方式。每次取出一条数据的时候同时也会读取出这行数据的版本version；每次更新数据的时候也会把相应的版本version加一。如果更新的时候发现数据的版本号与第一次取出来的不一样，那么肯定是有别的事务更新了数据，就不更新；如果前后版本号一样，则更新。\n\n## 1.2 悲观锁\n\n### 1.2.1 共享锁\n简称s锁，可以允许用户并发的读取数据。共享锁之间可以兼容，共享锁与排它锁不兼容\n\n```sql\n# 行粒度的共享锁\nselect * from students where id =1 in share mode;\n\n# 表粒度的共享锁\nlock table students read;\n```\n\n### 1.2.2 排它锁\n简称x锁，排它锁之间不兼容，排它锁与共享锁也不兼容\n\n```sql\n# 行粒度的排它锁\nselect * from students where id=1 for update;\n\n# 表粒度的排他锁\nlock table students write;\n```\n**需要注意的是，如果在一个事务里面锁住了一张表，即使事务提交了表锁仍然存在必须手动调用**`unlock tables`**命令释放表锁。**\n\n# 2. innodb中的锁\n根据上面锁的分类，我们可以立马知道innodb里面有**共享行锁**、**共享表锁**、**排他行锁**、**排他表锁**。\n\n## 2.1 innodb中的行锁\n行锁有时候锁住的可能不止是一行而是一个**间隙**。按行锁锁住的范围来说可以分为三种\n\n* Record Lock 单个行记录上的锁，只锁住一行\n* Gap Lock 锁住两个边界值之间的间隙，但是不包括两个边界值\n* Next-Key Lock 锁住一个间隙和间隙的右边界\n\n\n**行锁是通过锁住索引的方式来锁住记录的。**如果在一个事务中使用`select ... for update`或者`select ... in share mode`显示的获取行锁的时候，如果查询没有命中索引，那么会锁住整张表！因此下面我们从索引的角度并且事务的隔离级别为Repeatable Read下的情况来研究行锁是怎么工作的。\n\n### 2.1.1 主键（唯一）索引\n一般在查询的条件使用了主键索引或者唯一索引的值去查询的时候只会为查找到的记录上锁。比如直接用主键去获取一条数据\n```sql\nselect * from students where id=10 for update;\n```\n如果是in查询比如\n```sql\nselect * students where id in (10,20,30) for update;\n```\n也会锁住匹配的行数据不会锁住任何的间隙\n但是如果是主键或唯一索引的范围查询那么不仅会锁住一行数据还会锁住一个间隙，比如我有一张score表\n![](http://sysummery.top/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_c712bf1b-119b-4309-ab36-0251fa0538ae.png)\n里面只有两条数据id分别为35和37\n\n| 事务1 | 事务2 |\n| --- | --- |\n|select * from score where id>=35 and id<37 for update; |  |\n|  | select * from score where id=35 for update;(这条sql语句被阻塞，说明id=35的数据被Record Lock锁住了) |\n| commit；(提交事务释放锁) |  |\n|  | 由于事务1提交了，相应的锁也释放了，事务2阻塞结束 |\n| begin； |  |\n| select * from score where id>=35 and id<37 for update;（与之前的sql是相同的） |  |\n|  | select * from score where id=37 for update;(这条sql语句没有被阻塞，说明id=37的数据没有被Record Lock锁住) |\n|  | insert into score(id,student_id,subject_id,score)value(36,1,1,90);(这条sql语句被阻塞了，因为id=36位于id=35和id=37之间) |\n| commit； |  |\n|  | 阻塞结束，成功插入了语句 |\n|  | commit；|\n\n结论\n\n* 如果只是使用一个或者几个主键（或者唯一索引）获取锁的时候，只会锁住记录不会锁住间隙\n* 如果是使用主键或者唯一索引范围查询，会锁住这两个值之间的间隙（Gap Lock）。锁不锁住边界值取决于查询里面有没有等于边界值\n\n### 2.1.2 普通索引\n现在score表变成了这样\n\n![](http://sysummery.top/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_96c4d877-3f2e-4bd2-a3cd-486e2233b1ea.png)\n\n\n\n| 事务1 | 事务2 |\n| --- | --- |\n| begin; | begin; |\n|select * from score where score=87 for update;||\n|  | insert into score(id,student_id,subject_id,score)value(7,1,7,86);（sql被阻塞） |\n| commit; |  |\n|  | 阻塞结束，成功插入了数据； |\n|  | rollback;（不保存插入的结果） |\n| begin; |  |\n| select * from score where score=87 for update;（与上一条sql一样） |  |\n|  | insert into score(id,student_id,subject_id,score)value(8,1,7,88);（sql被阻塞） |\n| commit; |  |\n|  | 阻塞结束，成功插入了数据； |\n|  | rollback；(不保存插入的结果) |\n| begin; |  |\n| select * from score where score=87 for update;（与上一条sql一样） |  |\n|  | insert into score(id,student_id,subject_id,score)value(10,2,2,89);（没有被阻塞插入成功）|\n|  | insert into score(id,student_id,subject_id,score)value(11,2,2,84);（没有被阻塞插入成功） |\n|  | select * from score where id=2 for update;(sql被阻塞) |\n| commit; |  |\n|  | 阻塞结束 |\n|  | commit; |\n\n结论\n\n* 当使用普通索引（score=87）获取锁的时候首先会在索引值的上区间加上一个Next-Key Lock锁，即锁住(84,87]这个区间，同时会为下区间加上一个Gap Lock，即锁住(84,89)这个区间\n* 使用普通索引，同时会使用Record Lock锁住主键索引。这可能也是因为所有的非主键索引的查询最后都会转化成使用主键索引查询，因为innodb的数据是在主键索引的叶子节点上。\n\n## 2.2 innodb中的表锁\ninnodb除了拥有mysql数据库级别的表锁外，还有另外两个表锁\n\n* 意向共享锁\n* 意向排它锁\n\n这两个表锁有啥作用？设想一下当我想给一张表加一个排他锁的时候，那么我得检查以下三项\n\n1. 该表有没有共享锁\n2. 该表有没有排它锁\n3. 该表的某（几）条记录有没有共享锁\n4. 该表的某（几）条记录有没有排它锁\n\n这其中1和2是比较好确定的，但是3、4怎么确定？锁是属于一个事务的不是属于一张表的，难道一条条数据的检查？显然是不行的，意向锁就应运而生。看一下意向锁与其他锁的兼容情况\n\n|  | 意向共享锁 | 意向排它锁 | 行级共享锁 | 行级排它锁 | 表级共享锁 | 表级排它锁 |\n| --- | --- | --- | --- | --- | --- | --- |\n| 意向共享锁 | 兼容 | 兼容 | 兼容 | 兼容 | 兼容 | 互斥 |\n| 意向排它锁 | 兼容 | 兼容 | 兼容 | 兼容 | 互斥 | 互斥 |\n\n意向锁与意向锁、行级锁都是兼容的。表级锁中只与共享锁兼容。好像意向锁就是为了\"抵抗\"表级锁而生。\n\n意向锁的添加是innodb来完成的，我们没有办法干预。举个例子，事务1想为数据a加了一个排它锁，那么在为这行数据加锁前会为整张表加一张**意向排它锁**，这时事务2想为数据b加一个共享锁，那么会先为表加一个意向共享锁，因为意向锁之间兼容，所以事务2不会阻塞，共享锁也会加到数据b上。这时事务3想为整个数据表加一个表级的排他锁，因为表级排它锁与意向锁相排斥所以事务3会被阻塞，直至事务1和事务2提交或者回滚。\n\n# 3. innodb中的事务与锁\n之前在2.1.1和2.2.2中讨论的内容在事务中同样适用。正式因为Gap Lock和Next-Key Lock的存在才会使innodb在Repeatable Read下能够避免幻读。\n\n## 3.1 一致性非锁定度\n也叫快照读。在一个事务中同一个查询得到的结果总是相同的。这个是因为数据读取的是数据的一个版本。这个版本可能是表中的数据（最新的版本），也可能是undo log中的该行的一个历史版本。读取的时候是不会加任何的锁。比如\n```sql\nselect * from score;\n```\n那么什么时候直接读取表的记录？又什么时候去undo log找历史版本呢？这与最后更改数据的事务id与当前活跃的事务id数组的关系决定的\n\n1. 如果最后修改数据行的事务id比所有的活跃的事务id都小，那么这行数据对当前事务是可见的\n2. 如果最后修改数据行的事务id比所有活跃的事务id大，那么是不可见的要去undo log中找合适的版本\n3. 如果等于当前事务的id，当然是可见的\n4. 如果即不大于也不小于，那么要遍历活跃事务id数组如果最后修改数据行的事务id在这里面就对当前事务不可见，如果不在说明已经commit了就可见\n\n## 3.2 一致性锁定读\n也叫当前读。当事务中执行 select...for update, insert, update, delete操作的时候读取的就是数据表当前的数据（最新的版本）并同时加上行级排它锁。\n\n# 4. 自增锁\n自增锁不是innodb独有的，很多存储引擎都可以为一张表的某一列设置成auto increment，innodb也不例外。因为平时工作中所有表的id都是auto increment的，因此想学习一下自增锁。\n\n一个参数innodb_autoinc_lock_mode控制着在向auto_increment列的表插入数据时，相关的锁行为。\n```sql\nshow  variables like 'innodb_autoinc_lock_mode'\n```\n\n这个参数有三个值\n\n* 0，这个模式下在插入语句开始的时候会得到一个表级别的锁，语句结束则释放。**注意：是语句开始的时候加锁结束的时候释放锁**\n* 1，这个是mysql默认的值，可以理解成插入的时候先锁住这个“自增值”，然后拿到这个自增值作为插入记录的id，然后再把这个自增值的值加一，最后释放锁。\n* 2，没有锁\n","source":"_posts/innodb-locks.md","raw":"---\ntitle: Innodb中的锁\ndate: 2019-12-07 11:47:11\ntags:\n    - mysql\n    - innodb\nphotos:\n    - [\"http://sysummery.top/lock_cover.jpg\"]\n---\n从粒度上来分可以分为**行锁**、**页锁**、**表锁**; 从“性格”上分可以分为**乐观锁**与**悲观锁**; 从粒度上的分类应该很容易理解，不再敖述。所以是说说锁在性格上的分类。\n<!--more-->\n\n# 1. 锁的分类\n\n## 1.1 乐观锁\n用数据版本记录机制实现，是实现乐观锁的最常用的方式。每次取出一条数据的时候同时也会读取出这行数据的版本version；每次更新数据的时候也会把相应的版本version加一。如果更新的时候发现数据的版本号与第一次取出来的不一样，那么肯定是有别的事务更新了数据，就不更新；如果前后版本号一样，则更新。\n\n## 1.2 悲观锁\n\n### 1.2.1 共享锁\n简称s锁，可以允许用户并发的读取数据。共享锁之间可以兼容，共享锁与排它锁不兼容\n\n```sql\n# 行粒度的共享锁\nselect * from students where id =1 in share mode;\n\n# 表粒度的共享锁\nlock table students read;\n```\n\n### 1.2.2 排它锁\n简称x锁，排它锁之间不兼容，排它锁与共享锁也不兼容\n\n```sql\n# 行粒度的排它锁\nselect * from students where id=1 for update;\n\n# 表粒度的排他锁\nlock table students write;\n```\n**需要注意的是，如果在一个事务里面锁住了一张表，即使事务提交了表锁仍然存在必须手动调用**`unlock tables`**命令释放表锁。**\n\n# 2. innodb中的锁\n根据上面锁的分类，我们可以立马知道innodb里面有**共享行锁**、**共享表锁**、**排他行锁**、**排他表锁**。\n\n## 2.1 innodb中的行锁\n行锁有时候锁住的可能不止是一行而是一个**间隙**。按行锁锁住的范围来说可以分为三种\n\n* Record Lock 单个行记录上的锁，只锁住一行\n* Gap Lock 锁住两个边界值之间的间隙，但是不包括两个边界值\n* Next-Key Lock 锁住一个间隙和间隙的右边界\n\n\n**行锁是通过锁住索引的方式来锁住记录的。**如果在一个事务中使用`select ... for update`或者`select ... in share mode`显示的获取行锁的时候，如果查询没有命中索引，那么会锁住整张表！因此下面我们从索引的角度并且事务的隔离级别为Repeatable Read下的情况来研究行锁是怎么工作的。\n\n### 2.1.1 主键（唯一）索引\n一般在查询的条件使用了主键索引或者唯一索引的值去查询的时候只会为查找到的记录上锁。比如直接用主键去获取一条数据\n```sql\nselect * from students where id=10 for update;\n```\n如果是in查询比如\n```sql\nselect * students where id in (10,20,30) for update;\n```\n也会锁住匹配的行数据不会锁住任何的间隙\n但是如果是主键或唯一索引的范围查询那么不仅会锁住一行数据还会锁住一个间隙，比如我有一张score表\n![](http://sysummery.top/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_c712bf1b-119b-4309-ab36-0251fa0538ae.png)\n里面只有两条数据id分别为35和37\n\n| 事务1 | 事务2 |\n| --- | --- |\n|select * from score where id>=35 and id<37 for update; |  |\n|  | select * from score where id=35 for update;(这条sql语句被阻塞，说明id=35的数据被Record Lock锁住了) |\n| commit；(提交事务释放锁) |  |\n|  | 由于事务1提交了，相应的锁也释放了，事务2阻塞结束 |\n| begin； |  |\n| select * from score where id>=35 and id<37 for update;（与之前的sql是相同的） |  |\n|  | select * from score where id=37 for update;(这条sql语句没有被阻塞，说明id=37的数据没有被Record Lock锁住) |\n|  | insert into score(id,student_id,subject_id,score)value(36,1,1,90);(这条sql语句被阻塞了，因为id=36位于id=35和id=37之间) |\n| commit； |  |\n|  | 阻塞结束，成功插入了语句 |\n|  | commit；|\n\n结论\n\n* 如果只是使用一个或者几个主键（或者唯一索引）获取锁的时候，只会锁住记录不会锁住间隙\n* 如果是使用主键或者唯一索引范围查询，会锁住这两个值之间的间隙（Gap Lock）。锁不锁住边界值取决于查询里面有没有等于边界值\n\n### 2.1.2 普通索引\n现在score表变成了这样\n\n![](http://sysummery.top/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_96c4d877-3f2e-4bd2-a3cd-486e2233b1ea.png)\n\n\n\n| 事务1 | 事务2 |\n| --- | --- |\n| begin; | begin; |\n|select * from score where score=87 for update;||\n|  | insert into score(id,student_id,subject_id,score)value(7,1,7,86);（sql被阻塞） |\n| commit; |  |\n|  | 阻塞结束，成功插入了数据； |\n|  | rollback;（不保存插入的结果） |\n| begin; |  |\n| select * from score where score=87 for update;（与上一条sql一样） |  |\n|  | insert into score(id,student_id,subject_id,score)value(8,1,7,88);（sql被阻塞） |\n| commit; |  |\n|  | 阻塞结束，成功插入了数据； |\n|  | rollback；(不保存插入的结果) |\n| begin; |  |\n| select * from score where score=87 for update;（与上一条sql一样） |  |\n|  | insert into score(id,student_id,subject_id,score)value(10,2,2,89);（没有被阻塞插入成功）|\n|  | insert into score(id,student_id,subject_id,score)value(11,2,2,84);（没有被阻塞插入成功） |\n|  | select * from score where id=2 for update;(sql被阻塞) |\n| commit; |  |\n|  | 阻塞结束 |\n|  | commit; |\n\n结论\n\n* 当使用普通索引（score=87）获取锁的时候首先会在索引值的上区间加上一个Next-Key Lock锁，即锁住(84,87]这个区间，同时会为下区间加上一个Gap Lock，即锁住(84,89)这个区间\n* 使用普通索引，同时会使用Record Lock锁住主键索引。这可能也是因为所有的非主键索引的查询最后都会转化成使用主键索引查询，因为innodb的数据是在主键索引的叶子节点上。\n\n## 2.2 innodb中的表锁\ninnodb除了拥有mysql数据库级别的表锁外，还有另外两个表锁\n\n* 意向共享锁\n* 意向排它锁\n\n这两个表锁有啥作用？设想一下当我想给一张表加一个排他锁的时候，那么我得检查以下三项\n\n1. 该表有没有共享锁\n2. 该表有没有排它锁\n3. 该表的某（几）条记录有没有共享锁\n4. 该表的某（几）条记录有没有排它锁\n\n这其中1和2是比较好确定的，但是3、4怎么确定？锁是属于一个事务的不是属于一张表的，难道一条条数据的检查？显然是不行的，意向锁就应运而生。看一下意向锁与其他锁的兼容情况\n\n|  | 意向共享锁 | 意向排它锁 | 行级共享锁 | 行级排它锁 | 表级共享锁 | 表级排它锁 |\n| --- | --- | --- | --- | --- | --- | --- |\n| 意向共享锁 | 兼容 | 兼容 | 兼容 | 兼容 | 兼容 | 互斥 |\n| 意向排它锁 | 兼容 | 兼容 | 兼容 | 兼容 | 互斥 | 互斥 |\n\n意向锁与意向锁、行级锁都是兼容的。表级锁中只与共享锁兼容。好像意向锁就是为了\"抵抗\"表级锁而生。\n\n意向锁的添加是innodb来完成的，我们没有办法干预。举个例子，事务1想为数据a加了一个排它锁，那么在为这行数据加锁前会为整张表加一张**意向排它锁**，这时事务2想为数据b加一个共享锁，那么会先为表加一个意向共享锁，因为意向锁之间兼容，所以事务2不会阻塞，共享锁也会加到数据b上。这时事务3想为整个数据表加一个表级的排他锁，因为表级排它锁与意向锁相排斥所以事务3会被阻塞，直至事务1和事务2提交或者回滚。\n\n# 3. innodb中的事务与锁\n之前在2.1.1和2.2.2中讨论的内容在事务中同样适用。正式因为Gap Lock和Next-Key Lock的存在才会使innodb在Repeatable Read下能够避免幻读。\n\n## 3.1 一致性非锁定度\n也叫快照读。在一个事务中同一个查询得到的结果总是相同的。这个是因为数据读取的是数据的一个版本。这个版本可能是表中的数据（最新的版本），也可能是undo log中的该行的一个历史版本。读取的时候是不会加任何的锁。比如\n```sql\nselect * from score;\n```\n那么什么时候直接读取表的记录？又什么时候去undo log找历史版本呢？这与最后更改数据的事务id与当前活跃的事务id数组的关系决定的\n\n1. 如果最后修改数据行的事务id比所有的活跃的事务id都小，那么这行数据对当前事务是可见的\n2. 如果最后修改数据行的事务id比所有活跃的事务id大，那么是不可见的要去undo log中找合适的版本\n3. 如果等于当前事务的id，当然是可见的\n4. 如果即不大于也不小于，那么要遍历活跃事务id数组如果最后修改数据行的事务id在这里面就对当前事务不可见，如果不在说明已经commit了就可见\n\n## 3.2 一致性锁定读\n也叫当前读。当事务中执行 select...for update, insert, update, delete操作的时候读取的就是数据表当前的数据（最新的版本）并同时加上行级排它锁。\n\n# 4. 自增锁\n自增锁不是innodb独有的，很多存储引擎都可以为一张表的某一列设置成auto increment，innodb也不例外。因为平时工作中所有表的id都是auto increment的，因此想学习一下自增锁。\n\n一个参数innodb_autoinc_lock_mode控制着在向auto_increment列的表插入数据时，相关的锁行为。\n```sql\nshow  variables like 'innodb_autoinc_lock_mode'\n```\n\n这个参数有三个值\n\n* 0，这个模式下在插入语句开始的时候会得到一个表级别的锁，语句结束则释放。**注意：是语句开始的时候加锁结束的时候释放锁**\n* 1，这个是mysql默认的值，可以理解成插入的时候先锁住这个“自增值”，然后拿到这个自增值作为插入记录的id，然后再把这个自增值的值加一，最后释放锁。\n* 2，没有锁\n","slug":"innodb-locks","published":1,"updated":"2020-11-23T15:23:47.778Z","comments":1,"layout":"post","link":"","_id":"ckhupaq9k000h1no8cxi1rxg4","content":"<p>从粒度上来分可以分为<strong>行锁</strong>、<strong>页锁</strong>、<strong>表锁</strong>; 从“性格”上分可以分为<strong>乐观锁</strong>与<strong>悲观锁</strong>; 从粒度上的分类应该很容易理解，不再敖述。所以是说说锁在性格上的分类。</p>\n<a id=\"more\"></a>\n\n<h1 id=\"1-锁的分类\"><a href=\"#1-锁的分类\" class=\"headerlink\" title=\"1. 锁的分类\"></a>1. 锁的分类</h1><h2 id=\"1-1-乐观锁\"><a href=\"#1-1-乐观锁\" class=\"headerlink\" title=\"1.1 乐观锁\"></a>1.1 乐观锁</h2><p>用数据版本记录机制实现，是实现乐观锁的最常用的方式。每次取出一条数据的时候同时也会读取出这行数据的版本version；每次更新数据的时候也会把相应的版本version加一。如果更新的时候发现数据的版本号与第一次取出来的不一样，那么肯定是有别的事务更新了数据，就不更新；如果前后版本号一样，则更新。</p>\n<h2 id=\"1-2-悲观锁\"><a href=\"#1-2-悲观锁\" class=\"headerlink\" title=\"1.2 悲观锁\"></a>1.2 悲观锁</h2><h3 id=\"1-2-1-共享锁\"><a href=\"#1-2-1-共享锁\" class=\"headerlink\" title=\"1.2.1 共享锁\"></a>1.2.1 共享锁</h3><p>简称s锁，可以允许用户并发的读取数据。共享锁之间可以兼容，共享锁与排它锁不兼容</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 行粒度的共享锁</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> students <span class=\"keyword\">where</span> <span class=\"keyword\">id</span> =<span class=\"number\">1</span> <span class=\"keyword\">in</span> <span class=\"keyword\">share</span> <span class=\"keyword\">mode</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 表粒度的共享锁</span></span><br><span class=\"line\"><span class=\"keyword\">lock</span> <span class=\"keyword\">table</span> students <span class=\"keyword\">read</span>;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"1-2-2-排它锁\"><a href=\"#1-2-2-排它锁\" class=\"headerlink\" title=\"1.2.2 排它锁\"></a>1.2.2 排它锁</h3><p>简称x锁，排它锁之间不兼容，排它锁与共享锁也不兼容</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 行粒度的排它锁</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> students <span class=\"keyword\">where</span> <span class=\"keyword\">id</span>=<span class=\"number\">1</span> <span class=\"keyword\">for</span> <span class=\"keyword\">update</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 表粒度的排他锁</span></span><br><span class=\"line\"><span class=\"keyword\">lock</span> <span class=\"keyword\">table</span> students write;</span><br></pre></td></tr></table></figure>\n\n<p><strong>需要注意的是，如果在一个事务里面锁住了一张表，即使事务提交了表锁仍然存在必须手动调用</strong><code>unlock tables</code><strong>命令释放表锁。</strong></p>\n<h1 id=\"2-innodb中的锁\"><a href=\"#2-innodb中的锁\" class=\"headerlink\" title=\"2. innodb中的锁\"></a>2. innodb中的锁</h1><p>根据上面锁的分类，我们可以立马知道innodb里面有<strong>共享行锁</strong>、<strong>共享表锁</strong>、<strong>排他行锁</strong>、<strong>排他表锁</strong>。</p>\n<h2 id=\"2-1-innodb中的行锁\"><a href=\"#2-1-innodb中的行锁\" class=\"headerlink\" title=\"2.1 innodb中的行锁\"></a>2.1 innodb中的行锁</h2><p>行锁有时候锁住的可能不止是一行而是一个<strong>间隙</strong>。按行锁锁住的范围来说可以分为三种</p>\n<ul>\n<li>Record Lock 单个行记录上的锁，只锁住一行</li>\n<li>Gap Lock 锁住两个边界值之间的间隙，但是不包括两个边界值</li>\n<li>Next-Key Lock 锁住一个间隙和间隙的右边界</li>\n</ul>\n<p><strong>行锁是通过锁住索引的方式来锁住记录的。</strong>如果在一个事务中使用<code>select ... for update</code>或者<code>select ... in share mode</code>显示的获取行锁的时候，如果查询没有命中索引，那么会锁住整张表！因此下面我们从索引的角度并且事务的隔离级别为Repeatable Read下的情况来研究行锁是怎么工作的。</p>\n<h3 id=\"2-1-1-主键（唯一）索引\"><a href=\"#2-1-1-主键（唯一）索引\" class=\"headerlink\" title=\"2.1.1 主键（唯一）索引\"></a>2.1.1 主键（唯一）索引</h3><p>一般在查询的条件使用了主键索引或者唯一索引的值去查询的时候只会为查找到的记录上锁。比如直接用主键去获取一条数据</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> students <span class=\"keyword\">where</span> <span class=\"keyword\">id</span>=<span class=\"number\">10</span> <span class=\"keyword\">for</span> <span class=\"keyword\">update</span>;</span><br></pre></td></tr></table></figure>\n\n<p>如果是in查询比如</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">select</span> * students <span class=\"keyword\">where</span> <span class=\"keyword\">id</span> <span class=\"keyword\">in</span> (<span class=\"number\">10</span>,<span class=\"number\">20</span>,<span class=\"number\">30</span>) <span class=\"keyword\">for</span> <span class=\"keyword\">update</span>;</span><br></pre></td></tr></table></figure>\n\n<p>也会锁住匹配的行数据不会锁住任何的间隙<br>但是如果是主键或唯一索引的范围查询那么不仅会锁住一行数据还会锁住一个间隙，比如我有一张score表<br><img src=\"http://sysummery.top/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_c712bf1b-119b-4309-ab36-0251fa0538ae.png\" alt><br>里面只有两条数据id分别为35和37</p>\n<table>\n<thead>\n<tr>\n<th>事务1</th>\n<th>事务2</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>select * from score where id&gt;=35 and id&lt;37 for update;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>select * from score where id=35 for update;(这条sql语句被阻塞，说明id=35的数据被Record Lock锁住了)</td>\n</tr>\n<tr>\n<td>commit；(提交事务释放锁)</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>由于事务1提交了，相应的锁也释放了，事务2阻塞结束</td>\n</tr>\n<tr>\n<td>begin；</td>\n<td></td>\n</tr>\n<tr>\n<td>select * from score where id&gt;=35 and id&lt;37 for update;（与之前的sql是相同的）</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>select * from score where id=37 for update;(这条sql语句没有被阻塞，说明id=37的数据没有被Record Lock锁住)</td>\n</tr>\n<tr>\n<td></td>\n<td>insert into score(id,student_id,subject_id,score)value(36,1,1,90);(这条sql语句被阻塞了，因为id=36位于id=35和id=37之间)</td>\n</tr>\n<tr>\n<td>commit；</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>阻塞结束，成功插入了语句</td>\n</tr>\n<tr>\n<td></td>\n<td>commit；</td>\n</tr>\n</tbody></table>\n<p>结论</p>\n<ul>\n<li>如果只是使用一个或者几个主键（或者唯一索引）获取锁的时候，只会锁住记录不会锁住间隙</li>\n<li>如果是使用主键或者唯一索引范围查询，会锁住这两个值之间的间隙（Gap Lock）。锁不锁住边界值取决于查询里面有没有等于边界值</li>\n</ul>\n<h3 id=\"2-1-2-普通索引\"><a href=\"#2-1-2-普通索引\" class=\"headerlink\" title=\"2.1.2 普通索引\"></a>2.1.2 普通索引</h3><p>现在score表变成了这样</p>\n<p><img src=\"http://sysummery.top/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_96c4d877-3f2e-4bd2-a3cd-486e2233b1ea.png\" alt></p>\n<table>\n<thead>\n<tr>\n<th>事务1</th>\n<th>事务2</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>begin;</td>\n<td>begin;</td>\n</tr>\n<tr>\n<td>select * from score where score=87 for update;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>insert into score(id,student_id,subject_id,score)value(7,1,7,86);（sql被阻塞）</td>\n</tr>\n<tr>\n<td>commit;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>阻塞结束，成功插入了数据；</td>\n</tr>\n<tr>\n<td></td>\n<td>rollback;（不保存插入的结果）</td>\n</tr>\n<tr>\n<td>begin;</td>\n<td></td>\n</tr>\n<tr>\n<td>select * from score where score=87 for update;（与上一条sql一样）</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>insert into score(id,student_id,subject_id,score)value(8,1,7,88);（sql被阻塞）</td>\n</tr>\n<tr>\n<td>commit;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>阻塞结束，成功插入了数据；</td>\n</tr>\n<tr>\n<td></td>\n<td>rollback；(不保存插入的结果)</td>\n</tr>\n<tr>\n<td>begin;</td>\n<td></td>\n</tr>\n<tr>\n<td>select * from score where score=87 for update;（与上一条sql一样）</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>insert into score(id,student_id,subject_id,score)value(10,2,2,89);（没有被阻塞插入成功）</td>\n</tr>\n<tr>\n<td></td>\n<td>insert into score(id,student_id,subject_id,score)value(11,2,2,84);（没有被阻塞插入成功）</td>\n</tr>\n<tr>\n<td></td>\n<td>select * from score where id=2 for update;(sql被阻塞)</td>\n</tr>\n<tr>\n<td>commit;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>阻塞结束</td>\n</tr>\n<tr>\n<td></td>\n<td>commit;</td>\n</tr>\n</tbody></table>\n<p>结论</p>\n<ul>\n<li>当使用普通索引（score=87）获取锁的时候首先会在索引值的上区间加上一个Next-Key Lock锁，即锁住(84,87]这个区间，同时会为下区间加上一个Gap Lock，即锁住(84,89)这个区间</li>\n<li>使用普通索引，同时会使用Record Lock锁住主键索引。这可能也是因为所有的非主键索引的查询最后都会转化成使用主键索引查询，因为innodb的数据是在主键索引的叶子节点上。</li>\n</ul>\n<h2 id=\"2-2-innodb中的表锁\"><a href=\"#2-2-innodb中的表锁\" class=\"headerlink\" title=\"2.2 innodb中的表锁\"></a>2.2 innodb中的表锁</h2><p>innodb除了拥有mysql数据库级别的表锁外，还有另外两个表锁</p>\n<ul>\n<li>意向共享锁</li>\n<li>意向排它锁</li>\n</ul>\n<p>这两个表锁有啥作用？设想一下当我想给一张表加一个排他锁的时候，那么我得检查以下三项</p>\n<ol>\n<li>该表有没有共享锁</li>\n<li>该表有没有排它锁</li>\n<li>该表的某（几）条记录有没有共享锁</li>\n<li>该表的某（几）条记录有没有排它锁</li>\n</ol>\n<p>这其中1和2是比较好确定的，但是3、4怎么确定？锁是属于一个事务的不是属于一张表的，难道一条条数据的检查？显然是不行的，意向锁就应运而生。看一下意向锁与其他锁的兼容情况</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>意向共享锁</th>\n<th>意向排它锁</th>\n<th>行级共享锁</th>\n<th>行级排它锁</th>\n<th>表级共享锁</th>\n<th>表级排它锁</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>意向共享锁</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>互斥</td>\n</tr>\n<tr>\n<td>意向排它锁</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>互斥</td>\n<td>互斥</td>\n</tr>\n</tbody></table>\n<p>意向锁与意向锁、行级锁都是兼容的。表级锁中只与共享锁兼容。好像意向锁就是为了”抵抗”表级锁而生。</p>\n<p>意向锁的添加是innodb来完成的，我们没有办法干预。举个例子，事务1想为数据a加了一个排它锁，那么在为这行数据加锁前会为整张表加一张<strong>意向排它锁</strong>，这时事务2想为数据b加一个共享锁，那么会先为表加一个意向共享锁，因为意向锁之间兼容，所以事务2不会阻塞，共享锁也会加到数据b上。这时事务3想为整个数据表加一个表级的排他锁，因为表级排它锁与意向锁相排斥所以事务3会被阻塞，直至事务1和事务2提交或者回滚。</p>\n<h1 id=\"3-innodb中的事务与锁\"><a href=\"#3-innodb中的事务与锁\" class=\"headerlink\" title=\"3. innodb中的事务与锁\"></a>3. innodb中的事务与锁</h1><p>之前在2.1.1和2.2.2中讨论的内容在事务中同样适用。正式因为Gap Lock和Next-Key Lock的存在才会使innodb在Repeatable Read下能够避免幻读。</p>\n<h2 id=\"3-1-一致性非锁定度\"><a href=\"#3-1-一致性非锁定度\" class=\"headerlink\" title=\"3.1 一致性非锁定度\"></a>3.1 一致性非锁定度</h2><p>也叫快照读。在一个事务中同一个查询得到的结果总是相同的。这个是因为数据读取的是数据的一个版本。这个版本可能是表中的数据（最新的版本），也可能是undo log中的该行的一个历史版本。读取的时候是不会加任何的锁。比如</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> score;</span><br></pre></td></tr></table></figure>\n\n<p>那么什么时候直接读取表的记录？又什么时候去undo log找历史版本呢？这与最后更改数据的事务id与当前活跃的事务id数组的关系决定的</p>\n<ol>\n<li>如果最后修改数据行的事务id比所有的活跃的事务id都小，那么这行数据对当前事务是可见的</li>\n<li>如果最后修改数据行的事务id比所有活跃的事务id大，那么是不可见的要去undo log中找合适的版本</li>\n<li>如果等于当前事务的id，当然是可见的</li>\n<li>如果即不大于也不小于，那么要遍历活跃事务id数组如果最后修改数据行的事务id在这里面就对当前事务不可见，如果不在说明已经commit了就可见</li>\n</ol>\n<h2 id=\"3-2-一致性锁定读\"><a href=\"#3-2-一致性锁定读\" class=\"headerlink\" title=\"3.2 一致性锁定读\"></a>3.2 一致性锁定读</h2><p>也叫当前读。当事务中执行 select…for update, insert, update, delete操作的时候读取的就是数据表当前的数据（最新的版本）并同时加上行级排它锁。</p>\n<h1 id=\"4-自增锁\"><a href=\"#4-自增锁\" class=\"headerlink\" title=\"4. 自增锁\"></a>4. 自增锁</h1><p>自增锁不是innodb独有的，很多存储引擎都可以为一张表的某一列设置成auto increment，innodb也不例外。因为平时工作中所有表的id都是auto increment的，因此想学习一下自增锁。</p>\n<p>一个参数innodb_autoinc_lock_mode控制着在向auto_increment列的表插入数据时，相关的锁行为。</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span>  <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'innodb_autoinc_lock_mode'</span></span><br></pre></td></tr></table></figure>\n\n<p>这个参数有三个值</p>\n<ul>\n<li>0，这个模式下在插入语句开始的时候会得到一个表级别的锁，语句结束则释放。<strong>注意：是语句开始的时候加锁结束的时候释放锁</strong></li>\n<li>1，这个是mysql默认的值，可以理解成插入的时候先锁住这个“自增值”，然后拿到这个自增值作为插入记录的id，然后再把这个自增值的值加一，最后释放锁。</li>\n<li>2，没有锁</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>从粒度上来分可以分为<strong>行锁</strong>、<strong>页锁</strong>、<strong>表锁</strong>; 从“性格”上分可以分为<strong>乐观锁</strong>与<strong>悲观锁</strong>; 从粒度上的分类应该很容易理解，不再敖述。所以是说说锁在性格上的分类。</p>","more":"<h1 id=\"1-锁的分类\"><a href=\"#1-锁的分类\" class=\"headerlink\" title=\"1. 锁的分类\"></a>1. 锁的分类</h1><h2 id=\"1-1-乐观锁\"><a href=\"#1-1-乐观锁\" class=\"headerlink\" title=\"1.1 乐观锁\"></a>1.1 乐观锁</h2><p>用数据版本记录机制实现，是实现乐观锁的最常用的方式。每次取出一条数据的时候同时也会读取出这行数据的版本version；每次更新数据的时候也会把相应的版本version加一。如果更新的时候发现数据的版本号与第一次取出来的不一样，那么肯定是有别的事务更新了数据，就不更新；如果前后版本号一样，则更新。</p>\n<h2 id=\"1-2-悲观锁\"><a href=\"#1-2-悲观锁\" class=\"headerlink\" title=\"1.2 悲观锁\"></a>1.2 悲观锁</h2><h3 id=\"1-2-1-共享锁\"><a href=\"#1-2-1-共享锁\" class=\"headerlink\" title=\"1.2.1 共享锁\"></a>1.2.1 共享锁</h3><p>简称s锁，可以允许用户并发的读取数据。共享锁之间可以兼容，共享锁与排它锁不兼容</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 行粒度的共享锁</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> students <span class=\"keyword\">where</span> <span class=\"keyword\">id</span> =<span class=\"number\">1</span> <span class=\"keyword\">in</span> <span class=\"keyword\">share</span> <span class=\"keyword\">mode</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 表粒度的共享锁</span></span><br><span class=\"line\"><span class=\"keyword\">lock</span> <span class=\"keyword\">table</span> students <span class=\"keyword\">read</span>;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"1-2-2-排它锁\"><a href=\"#1-2-2-排它锁\" class=\"headerlink\" title=\"1.2.2 排它锁\"></a>1.2.2 排它锁</h3><p>简称x锁，排它锁之间不兼容，排它锁与共享锁也不兼容</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 行粒度的排它锁</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> students <span class=\"keyword\">where</span> <span class=\"keyword\">id</span>=<span class=\"number\">1</span> <span class=\"keyword\">for</span> <span class=\"keyword\">update</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 表粒度的排他锁</span></span><br><span class=\"line\"><span class=\"keyword\">lock</span> <span class=\"keyword\">table</span> students write;</span><br></pre></td></tr></table></figure>\n\n<p><strong>需要注意的是，如果在一个事务里面锁住了一张表，即使事务提交了表锁仍然存在必须手动调用</strong><code>unlock tables</code><strong>命令释放表锁。</strong></p>\n<h1 id=\"2-innodb中的锁\"><a href=\"#2-innodb中的锁\" class=\"headerlink\" title=\"2. innodb中的锁\"></a>2. innodb中的锁</h1><p>根据上面锁的分类，我们可以立马知道innodb里面有<strong>共享行锁</strong>、<strong>共享表锁</strong>、<strong>排他行锁</strong>、<strong>排他表锁</strong>。</p>\n<h2 id=\"2-1-innodb中的行锁\"><a href=\"#2-1-innodb中的行锁\" class=\"headerlink\" title=\"2.1 innodb中的行锁\"></a>2.1 innodb中的行锁</h2><p>行锁有时候锁住的可能不止是一行而是一个<strong>间隙</strong>。按行锁锁住的范围来说可以分为三种</p>\n<ul>\n<li>Record Lock 单个行记录上的锁，只锁住一行</li>\n<li>Gap Lock 锁住两个边界值之间的间隙，但是不包括两个边界值</li>\n<li>Next-Key Lock 锁住一个间隙和间隙的右边界</li>\n</ul>\n<p><strong>行锁是通过锁住索引的方式来锁住记录的。</strong>如果在一个事务中使用<code>select ... for update</code>或者<code>select ... in share mode</code>显示的获取行锁的时候，如果查询没有命中索引，那么会锁住整张表！因此下面我们从索引的角度并且事务的隔离级别为Repeatable Read下的情况来研究行锁是怎么工作的。</p>\n<h3 id=\"2-1-1-主键（唯一）索引\"><a href=\"#2-1-1-主键（唯一）索引\" class=\"headerlink\" title=\"2.1.1 主键（唯一）索引\"></a>2.1.1 主键（唯一）索引</h3><p>一般在查询的条件使用了主键索引或者唯一索引的值去查询的时候只会为查找到的记录上锁。比如直接用主键去获取一条数据</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> students <span class=\"keyword\">where</span> <span class=\"keyword\">id</span>=<span class=\"number\">10</span> <span class=\"keyword\">for</span> <span class=\"keyword\">update</span>;</span><br></pre></td></tr></table></figure>\n\n<p>如果是in查询比如</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">select</span> * students <span class=\"keyword\">where</span> <span class=\"keyword\">id</span> <span class=\"keyword\">in</span> (<span class=\"number\">10</span>,<span class=\"number\">20</span>,<span class=\"number\">30</span>) <span class=\"keyword\">for</span> <span class=\"keyword\">update</span>;</span><br></pre></td></tr></table></figure>\n\n<p>也会锁住匹配的行数据不会锁住任何的间隙<br>但是如果是主键或唯一索引的范围查询那么不仅会锁住一行数据还会锁住一个间隙，比如我有一张score表<br><img src=\"http://sysummery.top/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_c712bf1b-119b-4309-ab36-0251fa0538ae.png\" alt><br>里面只有两条数据id分别为35和37</p>\n<table>\n<thead>\n<tr>\n<th>事务1</th>\n<th>事务2</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>select * from score where id&gt;=35 and id&lt;37 for update;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>select * from score where id=35 for update;(这条sql语句被阻塞，说明id=35的数据被Record Lock锁住了)</td>\n</tr>\n<tr>\n<td>commit；(提交事务释放锁)</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>由于事务1提交了，相应的锁也释放了，事务2阻塞结束</td>\n</tr>\n<tr>\n<td>begin；</td>\n<td></td>\n</tr>\n<tr>\n<td>select * from score where id&gt;=35 and id&lt;37 for update;（与之前的sql是相同的）</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>select * from score where id=37 for update;(这条sql语句没有被阻塞，说明id=37的数据没有被Record Lock锁住)</td>\n</tr>\n<tr>\n<td></td>\n<td>insert into score(id,student_id,subject_id,score)value(36,1,1,90);(这条sql语句被阻塞了，因为id=36位于id=35和id=37之间)</td>\n</tr>\n<tr>\n<td>commit；</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>阻塞结束，成功插入了语句</td>\n</tr>\n<tr>\n<td></td>\n<td>commit；</td>\n</tr>\n</tbody></table>\n<p>结论</p>\n<ul>\n<li>如果只是使用一个或者几个主键（或者唯一索引）获取锁的时候，只会锁住记录不会锁住间隙</li>\n<li>如果是使用主键或者唯一索引范围查询，会锁住这两个值之间的间隙（Gap Lock）。锁不锁住边界值取决于查询里面有没有等于边界值</li>\n</ul>\n<h3 id=\"2-1-2-普通索引\"><a href=\"#2-1-2-普通索引\" class=\"headerlink\" title=\"2.1.2 普通索引\"></a>2.1.2 普通索引</h3><p>现在score表变成了这样</p>\n<p><img src=\"http://sysummery.top/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_96c4d877-3f2e-4bd2-a3cd-486e2233b1ea.png\" alt></p>\n<table>\n<thead>\n<tr>\n<th>事务1</th>\n<th>事务2</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>begin;</td>\n<td>begin;</td>\n</tr>\n<tr>\n<td>select * from score where score=87 for update;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>insert into score(id,student_id,subject_id,score)value(7,1,7,86);（sql被阻塞）</td>\n</tr>\n<tr>\n<td>commit;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>阻塞结束，成功插入了数据；</td>\n</tr>\n<tr>\n<td></td>\n<td>rollback;（不保存插入的结果）</td>\n</tr>\n<tr>\n<td>begin;</td>\n<td></td>\n</tr>\n<tr>\n<td>select * from score where score=87 for update;（与上一条sql一样）</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>insert into score(id,student_id,subject_id,score)value(8,1,7,88);（sql被阻塞）</td>\n</tr>\n<tr>\n<td>commit;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>阻塞结束，成功插入了数据；</td>\n</tr>\n<tr>\n<td></td>\n<td>rollback；(不保存插入的结果)</td>\n</tr>\n<tr>\n<td>begin;</td>\n<td></td>\n</tr>\n<tr>\n<td>select * from score where score=87 for update;（与上一条sql一样）</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>insert into score(id,student_id,subject_id,score)value(10,2,2,89);（没有被阻塞插入成功）</td>\n</tr>\n<tr>\n<td></td>\n<td>insert into score(id,student_id,subject_id,score)value(11,2,2,84);（没有被阻塞插入成功）</td>\n</tr>\n<tr>\n<td></td>\n<td>select * from score where id=2 for update;(sql被阻塞)</td>\n</tr>\n<tr>\n<td>commit;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>阻塞结束</td>\n</tr>\n<tr>\n<td></td>\n<td>commit;</td>\n</tr>\n</tbody></table>\n<p>结论</p>\n<ul>\n<li>当使用普通索引（score=87）获取锁的时候首先会在索引值的上区间加上一个Next-Key Lock锁，即锁住(84,87]这个区间，同时会为下区间加上一个Gap Lock，即锁住(84,89)这个区间</li>\n<li>使用普通索引，同时会使用Record Lock锁住主键索引。这可能也是因为所有的非主键索引的查询最后都会转化成使用主键索引查询，因为innodb的数据是在主键索引的叶子节点上。</li>\n</ul>\n<h2 id=\"2-2-innodb中的表锁\"><a href=\"#2-2-innodb中的表锁\" class=\"headerlink\" title=\"2.2 innodb中的表锁\"></a>2.2 innodb中的表锁</h2><p>innodb除了拥有mysql数据库级别的表锁外，还有另外两个表锁</p>\n<ul>\n<li>意向共享锁</li>\n<li>意向排它锁</li>\n</ul>\n<p>这两个表锁有啥作用？设想一下当我想给一张表加一个排他锁的时候，那么我得检查以下三项</p>\n<ol>\n<li>该表有没有共享锁</li>\n<li>该表有没有排它锁</li>\n<li>该表的某（几）条记录有没有共享锁</li>\n<li>该表的某（几）条记录有没有排它锁</li>\n</ol>\n<p>这其中1和2是比较好确定的，但是3、4怎么确定？锁是属于一个事务的不是属于一张表的，难道一条条数据的检查？显然是不行的，意向锁就应运而生。看一下意向锁与其他锁的兼容情况</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>意向共享锁</th>\n<th>意向排它锁</th>\n<th>行级共享锁</th>\n<th>行级排它锁</th>\n<th>表级共享锁</th>\n<th>表级排它锁</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>意向共享锁</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>互斥</td>\n</tr>\n<tr>\n<td>意向排它锁</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>兼容</td>\n<td>互斥</td>\n<td>互斥</td>\n</tr>\n</tbody></table>\n<p>意向锁与意向锁、行级锁都是兼容的。表级锁中只与共享锁兼容。好像意向锁就是为了”抵抗”表级锁而生。</p>\n<p>意向锁的添加是innodb来完成的，我们没有办法干预。举个例子，事务1想为数据a加了一个排它锁，那么在为这行数据加锁前会为整张表加一张<strong>意向排它锁</strong>，这时事务2想为数据b加一个共享锁，那么会先为表加一个意向共享锁，因为意向锁之间兼容，所以事务2不会阻塞，共享锁也会加到数据b上。这时事务3想为整个数据表加一个表级的排他锁，因为表级排它锁与意向锁相排斥所以事务3会被阻塞，直至事务1和事务2提交或者回滚。</p>\n<h1 id=\"3-innodb中的事务与锁\"><a href=\"#3-innodb中的事务与锁\" class=\"headerlink\" title=\"3. innodb中的事务与锁\"></a>3. innodb中的事务与锁</h1><p>之前在2.1.1和2.2.2中讨论的内容在事务中同样适用。正式因为Gap Lock和Next-Key Lock的存在才会使innodb在Repeatable Read下能够避免幻读。</p>\n<h2 id=\"3-1-一致性非锁定度\"><a href=\"#3-1-一致性非锁定度\" class=\"headerlink\" title=\"3.1 一致性非锁定度\"></a>3.1 一致性非锁定度</h2><p>也叫快照读。在一个事务中同一个查询得到的结果总是相同的。这个是因为数据读取的是数据的一个版本。这个版本可能是表中的数据（最新的版本），也可能是undo log中的该行的一个历史版本。读取的时候是不会加任何的锁。比如</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> score;</span><br></pre></td></tr></table></figure>\n\n<p>那么什么时候直接读取表的记录？又什么时候去undo log找历史版本呢？这与最后更改数据的事务id与当前活跃的事务id数组的关系决定的</p>\n<ol>\n<li>如果最后修改数据行的事务id比所有的活跃的事务id都小，那么这行数据对当前事务是可见的</li>\n<li>如果最后修改数据行的事务id比所有活跃的事务id大，那么是不可见的要去undo log中找合适的版本</li>\n<li>如果等于当前事务的id，当然是可见的</li>\n<li>如果即不大于也不小于，那么要遍历活跃事务id数组如果最后修改数据行的事务id在这里面就对当前事务不可见，如果不在说明已经commit了就可见</li>\n</ol>\n<h2 id=\"3-2-一致性锁定读\"><a href=\"#3-2-一致性锁定读\" class=\"headerlink\" title=\"3.2 一致性锁定读\"></a>3.2 一致性锁定读</h2><p>也叫当前读。当事务中执行 select…for update, insert, update, delete操作的时候读取的就是数据表当前的数据（最新的版本）并同时加上行级排它锁。</p>\n<h1 id=\"4-自增锁\"><a href=\"#4-自增锁\" class=\"headerlink\" title=\"4. 自增锁\"></a>4. 自增锁</h1><p>自增锁不是innodb独有的，很多存储引擎都可以为一张表的某一列设置成auto increment，innodb也不例外。因为平时工作中所有表的id都是auto increment的，因此想学习一下自增锁。</p>\n<p>一个参数innodb_autoinc_lock_mode控制着在向auto_increment列的表插入数据时，相关的锁行为。</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span>  <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'innodb_autoinc_lock_mode'</span></span><br></pre></td></tr></table></figure>\n\n<p>这个参数有三个值</p>\n<ul>\n<li>0，这个模式下在插入语句开始的时候会得到一个表级别的锁，语句结束则释放。<strong>注意：是语句开始的时候加锁结束的时候释放锁</strong></li>\n<li>1，这个是mysql默认的值，可以理解成插入的时候先锁住这个“自增值”，然后拿到这个自增值作为插入记录的id，然后再把这个自增值的值加一，最后释放锁。</li>\n<li>2，没有锁</li>\n</ul>"},{"title":"Innodb存储引擎","date":"2019-12-03T04:20:14.000Z","photos":["http://sysummery.top/innodb_cover.jpeg"],"_content":"innodb存储引擎是现在mysql的默认存储引擎，其特点是行锁设计、支持MVCC、支持外键、提供一致性非锁定读、同时被用来最有效的利用以及使用内存和CPU。\n<!--more-->\n## 缓冲池\ninnodb维护了一个内存缓冲池名叫innodb_pool_buffer。当我们读一条数据的时候，先去缓冲池里面找存放改数据的页是不是在这个缓冲池中，如果在直接读取，如果不在那么先从硬盘上读取该页并放到缓冲池中供后续读取使用。写操作也是一样的，先写入缓冲池中的数据页，此时该页也叫脏页，然后再以一定的策略刷新到磁盘。缓冲池中存在的数据大致如下\n![](http://sysummery.top/1.jpg)\n\n缓冲池的大小非常重要。说的极端一点，如果我们可以把数据库的页全部缓存在缓冲池中，那么数据库中的数据就相当于缓存了。可以通过以下命令查看缓冲池的大小\n```sql\nshow variables like 'innodb_buffer_pool_size'\n```\n现在innodb也支持同时启动多个缓冲池，数据页会根据哈希值被分配到不同的实例中去。可以通过以下命令查看缓冲池实例的个数\n```sql\nshow variables like 'innodb_buffer_pool_instance'\n```\n\n缓冲池是一片连续的内存空间，innodb为每一个缓存页都创建了一些所谓的控制信息，这些信息包括该页所属的表空间编号、页号、页在缓冲池中的地址、一些锁信息以及LSN信息等。\n\n每个缓存页的大小是一样的为16k，这个值是可以更改的。每个缓存页对应的控制信息占用的内存大小是相同的，我们就姑且把这些控制信息占用的一块内存称为一个控制块。控制块和缓存页是一对一的，都在缓冲池中。他们之间的关系大致是这样的\n![](http://sysummery.top/2.jpg)\n\n### LRU List、Free List、Flush List\n这三个list结构上很相似，都是双向链表，除了一些元信息之外还有就是指向控制块的指针。以free list为例（这个图是我能找到的最直观的图）\n![](http://sysummery.top/3.jpg)\n\n这三个列表虽然结构类似，但是功能却大不相同。\n\n**LRU List** 是用来管理innodb的缓冲池的。缓冲池的目的就是尽量的把热点数据缓存在内存中，进而保证数据库的性能。LRU list的职责就是尽量把热点的数据页留在内存中，把非热点的数据页从内存中移除。LRU List的前端是最频繁使用的数据页，尾端是最少使用的。当一个数据页从硬盘加载到内存中的时候在LRU List的3/8处会更新一些原信息并将指针指向一个新的**控制块**，而这控制块又指向一个16kb大小的数据页，这个数据页里面存放的就是刚刚从硬盘里面读取出来的数据。这个数据页会在innodb_old_blocks_time之后移动到LRU List的头部。之所以这么做是因为防止类似于扫描全表的操作污染了LRU List。当LRU List的一个节点(比如该节点叫node_lru)将要被移除的时候，Free List中会增加一个节点(比如该节点叫node_free)，node_free指向的控制块其实就是之前node_lru指向的控制块该控制块中所指向的数据页被LRU List认为是非热点数据了，这块地方要“腾出来存放别的热点数据了”\n\n**Free List** 是用来管理空闲的数据页的。当数据库刚刚启动的时候肯定还没有任何的数据页加载到缓冲池中，这个时候Free List的节点的数目应该和**控制块的**的数目相等的。慢慢的当有数据页缓存到缓冲池中的时候Free List这个双向链表的节点数会慢慢变少。当一个从硬盘读取的数据页想要进入缓冲池中的时候是通过Free List来完成的。\n\n**Flush List** 用来管理脏的数据页。写操作和读操作一样，也是先把数据页加载到内存中然后修改内存中的数据。一旦一个数据页变成了脏页那么Flush List这个链表里面就会有一个结点指向这个数据页所对应的**控制块**，意为这个数据页是脏的需要刷新回磁盘。**同时这个数据页也一定会出现在LRU列表中**，如果这个数据页将要从LRU列表中移除时那么肯定会把这个数据页同步到磁盘，这个数据页在Flush列表中的相应的节点也会被删除，这个是我们后面要将的checkpoint的技术。\n\n需要强调的是当数据库实例启动的时候控制块和缓存页就已经初始化好了。就像酒店里的房间，你住不住人房间都在那里。没有人住房间就是空的，同一个房间在不同的时间段内可能是不同的人在居住。而这三个list中的节点是会增加会减少会改变的。\n\n### checkpoint\n把缓冲池中的脏页刷新回磁盘是一件很重要的事情。checkpoint所做的就是这个重要的事情。innodb中的checkpoint如下\n\nSharp Checkpoint 数据库关闭的时候把所有的脏页刷新回磁盘\nFUZZY Checkpoint\n\n* Master Thread Checkpoint 主线程以一个固定的时间间隔异步的刷新脏页回磁盘\n* FLUSH_LRU_LIST Checkpoint 当LRU列表要移除数据页时并且这个数据页还标记在在Flush列表中的时候要强行的刷新这个数据页回磁盘\n* Async/Sync Flush Checkpoint 重做日志文件将要被覆盖的时候\n* Dirty Page too much Checkpoint 脏页的数量太多\n\n## 关键特性\n\n### 插入缓冲\n一般innodb的数据表都会有一个自增的id。因此每次插入一条数据的时候很容易找到待插入的位置，因为数据是存在主键索引的叶子节点上的。但是这有可能导致非主键索引插入的离散性。插入缓冲其实就是解决这个问题的。innodb对于非聚集索引的插入或者更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在则直接插入；若不在先放到一个插入缓冲中，然后再以一定的频率和情况进行插入缓冲和辅助索引页子节点的合并操作，这时通常能将多个插入合并到一个合并操作中，大大的提高了效率。\n### 两次写\n缓冲池中有2MB的内存叫做doublewrite buffer。同样硬盘上也有2M的“二次写”空间。第一次写是将内存的doublewrite buffer里的数据写到硬盘上的“二次写”空间，这个过程是顺序写，开销不大。第二次写是将doublewrite buffer里的数据写到表空间中，这个过程是离散的。如果在第二次写的过程中宕机，那么在“二次写”的硬盘空间中还备份了副本，可以用这个副本恢复数据页。\n![](http://sysummery.top/4.jpg)\n### 自适应哈希索引\nInnodb存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引可以带来速度的提升，则建立哈希索引，成为自适应哈希索引。貌似我们对这个特性什么都做不了，是innodb自己完成的。\n### 异步IO\n脏页刷新回磁盘的操作是异步的，这样不会阻塞用户线程。\n### 刷新邻接页\n如果innodb决定刷新一个脏页回磁盘的时候，会检测该页所在的区的所有页需不需要一起刷新。\n","source":"_posts/innodb.md","raw":"---\ntitle: Innodb存储引擎\ndate: 2019-12-03 12:20:14\ntags:\n    - mysql\n    - innodb\nphotos:\n    - [\"http://sysummery.top/innodb_cover.jpeg\"]\n---\ninnodb存储引擎是现在mysql的默认存储引擎，其特点是行锁设计、支持MVCC、支持外键、提供一致性非锁定读、同时被用来最有效的利用以及使用内存和CPU。\n<!--more-->\n## 缓冲池\ninnodb维护了一个内存缓冲池名叫innodb_pool_buffer。当我们读一条数据的时候，先去缓冲池里面找存放改数据的页是不是在这个缓冲池中，如果在直接读取，如果不在那么先从硬盘上读取该页并放到缓冲池中供后续读取使用。写操作也是一样的，先写入缓冲池中的数据页，此时该页也叫脏页，然后再以一定的策略刷新到磁盘。缓冲池中存在的数据大致如下\n![](http://sysummery.top/1.jpg)\n\n缓冲池的大小非常重要。说的极端一点，如果我们可以把数据库的页全部缓存在缓冲池中，那么数据库中的数据就相当于缓存了。可以通过以下命令查看缓冲池的大小\n```sql\nshow variables like 'innodb_buffer_pool_size'\n```\n现在innodb也支持同时启动多个缓冲池，数据页会根据哈希值被分配到不同的实例中去。可以通过以下命令查看缓冲池实例的个数\n```sql\nshow variables like 'innodb_buffer_pool_instance'\n```\n\n缓冲池是一片连续的内存空间，innodb为每一个缓存页都创建了一些所谓的控制信息，这些信息包括该页所属的表空间编号、页号、页在缓冲池中的地址、一些锁信息以及LSN信息等。\n\n每个缓存页的大小是一样的为16k，这个值是可以更改的。每个缓存页对应的控制信息占用的内存大小是相同的，我们就姑且把这些控制信息占用的一块内存称为一个控制块。控制块和缓存页是一对一的，都在缓冲池中。他们之间的关系大致是这样的\n![](http://sysummery.top/2.jpg)\n\n### LRU List、Free List、Flush List\n这三个list结构上很相似，都是双向链表，除了一些元信息之外还有就是指向控制块的指针。以free list为例（这个图是我能找到的最直观的图）\n![](http://sysummery.top/3.jpg)\n\n这三个列表虽然结构类似，但是功能却大不相同。\n\n**LRU List** 是用来管理innodb的缓冲池的。缓冲池的目的就是尽量的把热点数据缓存在内存中，进而保证数据库的性能。LRU list的职责就是尽量把热点的数据页留在内存中，把非热点的数据页从内存中移除。LRU List的前端是最频繁使用的数据页，尾端是最少使用的。当一个数据页从硬盘加载到内存中的时候在LRU List的3/8处会更新一些原信息并将指针指向一个新的**控制块**，而这控制块又指向一个16kb大小的数据页，这个数据页里面存放的就是刚刚从硬盘里面读取出来的数据。这个数据页会在innodb_old_blocks_time之后移动到LRU List的头部。之所以这么做是因为防止类似于扫描全表的操作污染了LRU List。当LRU List的一个节点(比如该节点叫node_lru)将要被移除的时候，Free List中会增加一个节点(比如该节点叫node_free)，node_free指向的控制块其实就是之前node_lru指向的控制块该控制块中所指向的数据页被LRU List认为是非热点数据了，这块地方要“腾出来存放别的热点数据了”\n\n**Free List** 是用来管理空闲的数据页的。当数据库刚刚启动的时候肯定还没有任何的数据页加载到缓冲池中，这个时候Free List的节点的数目应该和**控制块的**的数目相等的。慢慢的当有数据页缓存到缓冲池中的时候Free List这个双向链表的节点数会慢慢变少。当一个从硬盘读取的数据页想要进入缓冲池中的时候是通过Free List来完成的。\n\n**Flush List** 用来管理脏的数据页。写操作和读操作一样，也是先把数据页加载到内存中然后修改内存中的数据。一旦一个数据页变成了脏页那么Flush List这个链表里面就会有一个结点指向这个数据页所对应的**控制块**，意为这个数据页是脏的需要刷新回磁盘。**同时这个数据页也一定会出现在LRU列表中**，如果这个数据页将要从LRU列表中移除时那么肯定会把这个数据页同步到磁盘，这个数据页在Flush列表中的相应的节点也会被删除，这个是我们后面要将的checkpoint的技术。\n\n需要强调的是当数据库实例启动的时候控制块和缓存页就已经初始化好了。就像酒店里的房间，你住不住人房间都在那里。没有人住房间就是空的，同一个房间在不同的时间段内可能是不同的人在居住。而这三个list中的节点是会增加会减少会改变的。\n\n### checkpoint\n把缓冲池中的脏页刷新回磁盘是一件很重要的事情。checkpoint所做的就是这个重要的事情。innodb中的checkpoint如下\n\nSharp Checkpoint 数据库关闭的时候把所有的脏页刷新回磁盘\nFUZZY Checkpoint\n\n* Master Thread Checkpoint 主线程以一个固定的时间间隔异步的刷新脏页回磁盘\n* FLUSH_LRU_LIST Checkpoint 当LRU列表要移除数据页时并且这个数据页还标记在在Flush列表中的时候要强行的刷新这个数据页回磁盘\n* Async/Sync Flush Checkpoint 重做日志文件将要被覆盖的时候\n* Dirty Page too much Checkpoint 脏页的数量太多\n\n## 关键特性\n\n### 插入缓冲\n一般innodb的数据表都会有一个自增的id。因此每次插入一条数据的时候很容易找到待插入的位置，因为数据是存在主键索引的叶子节点上的。但是这有可能导致非主键索引插入的离散性。插入缓冲其实就是解决这个问题的。innodb对于非聚集索引的插入或者更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在则直接插入；若不在先放到一个插入缓冲中，然后再以一定的频率和情况进行插入缓冲和辅助索引页子节点的合并操作，这时通常能将多个插入合并到一个合并操作中，大大的提高了效率。\n### 两次写\n缓冲池中有2MB的内存叫做doublewrite buffer。同样硬盘上也有2M的“二次写”空间。第一次写是将内存的doublewrite buffer里的数据写到硬盘上的“二次写”空间，这个过程是顺序写，开销不大。第二次写是将doublewrite buffer里的数据写到表空间中，这个过程是离散的。如果在第二次写的过程中宕机，那么在“二次写”的硬盘空间中还备份了副本，可以用这个副本恢复数据页。\n![](http://sysummery.top/4.jpg)\n### 自适应哈希索引\nInnodb存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引可以带来速度的提升，则建立哈希索引，成为自适应哈希索引。貌似我们对这个特性什么都做不了，是innodb自己完成的。\n### 异步IO\n脏页刷新回磁盘的操作是异步的，这样不会阻塞用户线程。\n### 刷新邻接页\n如果innodb决定刷新一个脏页回磁盘的时候，会检测该页所在的区的所有页需不需要一起刷新。\n","slug":"innodb","published":1,"updated":"2020-11-23T15:23:47.778Z","comments":1,"layout":"post","link":"","_id":"ckhupaq9l000k1no8cur1wmpn","content":"<p>innodb存储引擎是现在mysql的默认存储引擎，其特点是行锁设计、支持MVCC、支持外键、提供一致性非锁定读、同时被用来最有效的利用以及使用内存和CPU。</p>\n<a id=\"more\"></a>\n<h2 id=\"缓冲池\"><a href=\"#缓冲池\" class=\"headerlink\" title=\"缓冲池\"></a>缓冲池</h2><p>innodb维护了一个内存缓冲池名叫innodb_pool_buffer。当我们读一条数据的时候，先去缓冲池里面找存放改数据的页是不是在这个缓冲池中，如果在直接读取，如果不在那么先从硬盘上读取该页并放到缓冲池中供后续读取使用。写操作也是一样的，先写入缓冲池中的数据页，此时该页也叫脏页，然后再以一定的策略刷新到磁盘。缓冲池中存在的数据大致如下<br><img src=\"http://sysummery.top/1.jpg\" alt></p>\n<p>缓冲池的大小非常重要。说的极端一点，如果我们可以把数据库的页全部缓存在缓冲池中，那么数据库中的数据就相当于缓存了。可以通过以下命令查看缓冲池的大小</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'innodb_buffer_pool_size'</span></span><br></pre></td></tr></table></figure>\n\n<p>现在innodb也支持同时启动多个缓冲池，数据页会根据哈希值被分配到不同的实例中去。可以通过以下命令查看缓冲池实例的个数</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'innodb_buffer_pool_instance'</span></span><br></pre></td></tr></table></figure>\n\n<p>缓冲池是一片连续的内存空间，innodb为每一个缓存页都创建了一些所谓的控制信息，这些信息包括该页所属的表空间编号、页号、页在缓冲池中的地址、一些锁信息以及LSN信息等。</p>\n<p>每个缓存页的大小是一样的为16k，这个值是可以更改的。每个缓存页对应的控制信息占用的内存大小是相同的，我们就姑且把这些控制信息占用的一块内存称为一个控制块。控制块和缓存页是一对一的，都在缓冲池中。他们之间的关系大致是这样的<br><img src=\"http://sysummery.top/2.jpg\" alt></p>\n<h3 id=\"LRU-List、Free-List、Flush-List\"><a href=\"#LRU-List、Free-List、Flush-List\" class=\"headerlink\" title=\"LRU List、Free List、Flush List\"></a>LRU List、Free List、Flush List</h3><p>这三个list结构上很相似，都是双向链表，除了一些元信息之外还有就是指向控制块的指针。以free list为例（这个图是我能找到的最直观的图）<br><img src=\"http://sysummery.top/3.jpg\" alt></p>\n<p>这三个列表虽然结构类似，但是功能却大不相同。</p>\n<p><strong>LRU List</strong> 是用来管理innodb的缓冲池的。缓冲池的目的就是尽量的把热点数据缓存在内存中，进而保证数据库的性能。LRU list的职责就是尽量把热点的数据页留在内存中，把非热点的数据页从内存中移除。LRU List的前端是最频繁使用的数据页，尾端是最少使用的。当一个数据页从硬盘加载到内存中的时候在LRU List的3/8处会更新一些原信息并将指针指向一个新的<strong>控制块</strong>，而这控制块又指向一个16kb大小的数据页，这个数据页里面存放的就是刚刚从硬盘里面读取出来的数据。这个数据页会在innodb_old_blocks_time之后移动到LRU List的头部。之所以这么做是因为防止类似于扫描全表的操作污染了LRU List。当LRU List的一个节点(比如该节点叫node_lru)将要被移除的时候，Free List中会增加一个节点(比如该节点叫node_free)，node_free指向的控制块其实就是之前node_lru指向的控制块该控制块中所指向的数据页被LRU List认为是非热点数据了，这块地方要“腾出来存放别的热点数据了”</p>\n<p><strong>Free List</strong> 是用来管理空闲的数据页的。当数据库刚刚启动的时候肯定还没有任何的数据页加载到缓冲池中，这个时候Free List的节点的数目应该和<strong>控制块的</strong>的数目相等的。慢慢的当有数据页缓存到缓冲池中的时候Free List这个双向链表的节点数会慢慢变少。当一个从硬盘读取的数据页想要进入缓冲池中的时候是通过Free List来完成的。</p>\n<p><strong>Flush List</strong> 用来管理脏的数据页。写操作和读操作一样，也是先把数据页加载到内存中然后修改内存中的数据。一旦一个数据页变成了脏页那么Flush List这个链表里面就会有一个结点指向这个数据页所对应的<strong>控制块</strong>，意为这个数据页是脏的需要刷新回磁盘。<strong>同时这个数据页也一定会出现在LRU列表中</strong>，如果这个数据页将要从LRU列表中移除时那么肯定会把这个数据页同步到磁盘，这个数据页在Flush列表中的相应的节点也会被删除，这个是我们后面要将的checkpoint的技术。</p>\n<p>需要强调的是当数据库实例启动的时候控制块和缓存页就已经初始化好了。就像酒店里的房间，你住不住人房间都在那里。没有人住房间就是空的，同一个房间在不同的时间段内可能是不同的人在居住。而这三个list中的节点是会增加会减少会改变的。</p>\n<h3 id=\"checkpoint\"><a href=\"#checkpoint\" class=\"headerlink\" title=\"checkpoint\"></a>checkpoint</h3><p>把缓冲池中的脏页刷新回磁盘是一件很重要的事情。checkpoint所做的就是这个重要的事情。innodb中的checkpoint如下</p>\n<p>Sharp Checkpoint 数据库关闭的时候把所有的脏页刷新回磁盘<br>FUZZY Checkpoint</p>\n<ul>\n<li>Master Thread Checkpoint 主线程以一个固定的时间间隔异步的刷新脏页回磁盘</li>\n<li>FLUSH_LRU_LIST Checkpoint 当LRU列表要移除数据页时并且这个数据页还标记在在Flush列表中的时候要强行的刷新这个数据页回磁盘</li>\n<li>Async/Sync Flush Checkpoint 重做日志文件将要被覆盖的时候</li>\n<li>Dirty Page too much Checkpoint 脏页的数量太多</li>\n</ul>\n<h2 id=\"关键特性\"><a href=\"#关键特性\" class=\"headerlink\" title=\"关键特性\"></a>关键特性</h2><h3 id=\"插入缓冲\"><a href=\"#插入缓冲\" class=\"headerlink\" title=\"插入缓冲\"></a>插入缓冲</h3><p>一般innodb的数据表都会有一个自增的id。因此每次插入一条数据的时候很容易找到待插入的位置，因为数据是存在主键索引的叶子节点上的。但是这有可能导致非主键索引插入的离散性。插入缓冲其实就是解决这个问题的。innodb对于非聚集索引的插入或者更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在则直接插入；若不在先放到一个插入缓冲中，然后再以一定的频率和情况进行插入缓冲和辅助索引页子节点的合并操作，这时通常能将多个插入合并到一个合并操作中，大大的提高了效率。</p>\n<h3 id=\"两次写\"><a href=\"#两次写\" class=\"headerlink\" title=\"两次写\"></a>两次写</h3><p>缓冲池中有2MB的内存叫做doublewrite buffer。同样硬盘上也有2M的“二次写”空间。第一次写是将内存的doublewrite buffer里的数据写到硬盘上的“二次写”空间，这个过程是顺序写，开销不大。第二次写是将doublewrite buffer里的数据写到表空间中，这个过程是离散的。如果在第二次写的过程中宕机，那么在“二次写”的硬盘空间中还备份了副本，可以用这个副本恢复数据页。<br><img src=\"http://sysummery.top/4.jpg\" alt></p>\n<h3 id=\"自适应哈希索引\"><a href=\"#自适应哈希索引\" class=\"headerlink\" title=\"自适应哈希索引\"></a>自适应哈希索引</h3><p>Innodb存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引可以带来速度的提升，则建立哈希索引，成为自适应哈希索引。貌似我们对这个特性什么都做不了，是innodb自己完成的。</p>\n<h3 id=\"异步IO\"><a href=\"#异步IO\" class=\"headerlink\" title=\"异步IO\"></a>异步IO</h3><p>脏页刷新回磁盘的操作是异步的，这样不会阻塞用户线程。</p>\n<h3 id=\"刷新邻接页\"><a href=\"#刷新邻接页\" class=\"headerlink\" title=\"刷新邻接页\"></a>刷新邻接页</h3><p>如果innodb决定刷新一个脏页回磁盘的时候，会检测该页所在的区的所有页需不需要一起刷新。</p>\n","site":{"data":{}},"excerpt":"<p>innodb存储引擎是现在mysql的默认存储引擎，其特点是行锁设计、支持MVCC、支持外键、提供一致性非锁定读、同时被用来最有效的利用以及使用内存和CPU。</p>","more":"<h2 id=\"缓冲池\"><a href=\"#缓冲池\" class=\"headerlink\" title=\"缓冲池\"></a>缓冲池</h2><p>innodb维护了一个内存缓冲池名叫innodb_pool_buffer。当我们读一条数据的时候，先去缓冲池里面找存放改数据的页是不是在这个缓冲池中，如果在直接读取，如果不在那么先从硬盘上读取该页并放到缓冲池中供后续读取使用。写操作也是一样的，先写入缓冲池中的数据页，此时该页也叫脏页，然后再以一定的策略刷新到磁盘。缓冲池中存在的数据大致如下<br><img src=\"http://sysummery.top/1.jpg\" alt></p>\n<p>缓冲池的大小非常重要。说的极端一点，如果我们可以把数据库的页全部缓存在缓冲池中，那么数据库中的数据就相当于缓存了。可以通过以下命令查看缓冲池的大小</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'innodb_buffer_pool_size'</span></span><br></pre></td></tr></table></figure>\n\n<p>现在innodb也支持同时启动多个缓冲池，数据页会根据哈希值被分配到不同的实例中去。可以通过以下命令查看缓冲池实例的个数</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'innodb_buffer_pool_instance'</span></span><br></pre></td></tr></table></figure>\n\n<p>缓冲池是一片连续的内存空间，innodb为每一个缓存页都创建了一些所谓的控制信息，这些信息包括该页所属的表空间编号、页号、页在缓冲池中的地址、一些锁信息以及LSN信息等。</p>\n<p>每个缓存页的大小是一样的为16k，这个值是可以更改的。每个缓存页对应的控制信息占用的内存大小是相同的，我们就姑且把这些控制信息占用的一块内存称为一个控制块。控制块和缓存页是一对一的，都在缓冲池中。他们之间的关系大致是这样的<br><img src=\"http://sysummery.top/2.jpg\" alt></p>\n<h3 id=\"LRU-List、Free-List、Flush-List\"><a href=\"#LRU-List、Free-List、Flush-List\" class=\"headerlink\" title=\"LRU List、Free List、Flush List\"></a>LRU List、Free List、Flush List</h3><p>这三个list结构上很相似，都是双向链表，除了一些元信息之外还有就是指向控制块的指针。以free list为例（这个图是我能找到的最直观的图）<br><img src=\"http://sysummery.top/3.jpg\" alt></p>\n<p>这三个列表虽然结构类似，但是功能却大不相同。</p>\n<p><strong>LRU List</strong> 是用来管理innodb的缓冲池的。缓冲池的目的就是尽量的把热点数据缓存在内存中，进而保证数据库的性能。LRU list的职责就是尽量把热点的数据页留在内存中，把非热点的数据页从内存中移除。LRU List的前端是最频繁使用的数据页，尾端是最少使用的。当一个数据页从硬盘加载到内存中的时候在LRU List的3/8处会更新一些原信息并将指针指向一个新的<strong>控制块</strong>，而这控制块又指向一个16kb大小的数据页，这个数据页里面存放的就是刚刚从硬盘里面读取出来的数据。这个数据页会在innodb_old_blocks_time之后移动到LRU List的头部。之所以这么做是因为防止类似于扫描全表的操作污染了LRU List。当LRU List的一个节点(比如该节点叫node_lru)将要被移除的时候，Free List中会增加一个节点(比如该节点叫node_free)，node_free指向的控制块其实就是之前node_lru指向的控制块该控制块中所指向的数据页被LRU List认为是非热点数据了，这块地方要“腾出来存放别的热点数据了”</p>\n<p><strong>Free List</strong> 是用来管理空闲的数据页的。当数据库刚刚启动的时候肯定还没有任何的数据页加载到缓冲池中，这个时候Free List的节点的数目应该和<strong>控制块的</strong>的数目相等的。慢慢的当有数据页缓存到缓冲池中的时候Free List这个双向链表的节点数会慢慢变少。当一个从硬盘读取的数据页想要进入缓冲池中的时候是通过Free List来完成的。</p>\n<p><strong>Flush List</strong> 用来管理脏的数据页。写操作和读操作一样，也是先把数据页加载到内存中然后修改内存中的数据。一旦一个数据页变成了脏页那么Flush List这个链表里面就会有一个结点指向这个数据页所对应的<strong>控制块</strong>，意为这个数据页是脏的需要刷新回磁盘。<strong>同时这个数据页也一定会出现在LRU列表中</strong>，如果这个数据页将要从LRU列表中移除时那么肯定会把这个数据页同步到磁盘，这个数据页在Flush列表中的相应的节点也会被删除，这个是我们后面要将的checkpoint的技术。</p>\n<p>需要强调的是当数据库实例启动的时候控制块和缓存页就已经初始化好了。就像酒店里的房间，你住不住人房间都在那里。没有人住房间就是空的，同一个房间在不同的时间段内可能是不同的人在居住。而这三个list中的节点是会增加会减少会改变的。</p>\n<h3 id=\"checkpoint\"><a href=\"#checkpoint\" class=\"headerlink\" title=\"checkpoint\"></a>checkpoint</h3><p>把缓冲池中的脏页刷新回磁盘是一件很重要的事情。checkpoint所做的就是这个重要的事情。innodb中的checkpoint如下</p>\n<p>Sharp Checkpoint 数据库关闭的时候把所有的脏页刷新回磁盘<br>FUZZY Checkpoint</p>\n<ul>\n<li>Master Thread Checkpoint 主线程以一个固定的时间间隔异步的刷新脏页回磁盘</li>\n<li>FLUSH_LRU_LIST Checkpoint 当LRU列表要移除数据页时并且这个数据页还标记在在Flush列表中的时候要强行的刷新这个数据页回磁盘</li>\n<li>Async/Sync Flush Checkpoint 重做日志文件将要被覆盖的时候</li>\n<li>Dirty Page too much Checkpoint 脏页的数量太多</li>\n</ul>\n<h2 id=\"关键特性\"><a href=\"#关键特性\" class=\"headerlink\" title=\"关键特性\"></a>关键特性</h2><h3 id=\"插入缓冲\"><a href=\"#插入缓冲\" class=\"headerlink\" title=\"插入缓冲\"></a>插入缓冲</h3><p>一般innodb的数据表都会有一个自增的id。因此每次插入一条数据的时候很容易找到待插入的位置，因为数据是存在主键索引的叶子节点上的。但是这有可能导致非主键索引插入的离散性。插入缓冲其实就是解决这个问题的。innodb对于非聚集索引的插入或者更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在则直接插入；若不在先放到一个插入缓冲中，然后再以一定的频率和情况进行插入缓冲和辅助索引页子节点的合并操作，这时通常能将多个插入合并到一个合并操作中，大大的提高了效率。</p>\n<h3 id=\"两次写\"><a href=\"#两次写\" class=\"headerlink\" title=\"两次写\"></a>两次写</h3><p>缓冲池中有2MB的内存叫做doublewrite buffer。同样硬盘上也有2M的“二次写”空间。第一次写是将内存的doublewrite buffer里的数据写到硬盘上的“二次写”空间，这个过程是顺序写，开销不大。第二次写是将doublewrite buffer里的数据写到表空间中，这个过程是离散的。如果在第二次写的过程中宕机，那么在“二次写”的硬盘空间中还备份了副本，可以用这个副本恢复数据页。<br><img src=\"http://sysummery.top/4.jpg\" alt></p>\n<h3 id=\"自适应哈希索引\"><a href=\"#自适应哈希索引\" class=\"headerlink\" title=\"自适应哈希索引\"></a>自适应哈希索引</h3><p>Innodb存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引可以带来速度的提升，则建立哈希索引，成为自适应哈希索引。貌似我们对这个特性什么都做不了，是innodb自己完成的。</p>\n<h3 id=\"异步IO\"><a href=\"#异步IO\" class=\"headerlink\" title=\"异步IO\"></a>异步IO</h3><p>脏页刷新回磁盘的操作是异步的，这样不会阻塞用户线程。</p>\n<h3 id=\"刷新邻接页\"><a href=\"#刷新邻接页\" class=\"headerlink\" title=\"刷新邻接页\"></a>刷新邻接页</h3><p>如果innodb决定刷新一个脏页回磁盘的时候，会检测该页所在的区的所有页需不需要一起刷新。</p>"},{"title":"Nginx学习笔记","date":"2019-08-04T01:04:05.000Z","photos":["http://sysummery.top/nginx_cover.jpeg"],"_content":"Nginx 是一个免费、开源、高性能、轻量级的 HTTP 和反向代理服务器，也是一个电子邮件(IMAP/POP3)代理服务器，其特点是占有内存少，并发能力强。\n<!--more-->\n\n## nginx的架构\nNginx 里有一个 master 进程和多个 worker 进程。master 进程并不处理网络请求，主要负责调度工作进程：加载配置、启动工作进程及非停升级。worker 进程负责处理网络请求与响应。\n\n![](http://sysummery.top/nginx_process.png)\n\nmaster进程主要用来管理worker进程，具体包括如下4个主要功能：\n\n接收来自外界的信号。\n\n向各worker进程发送信号。\n\n监控woker进程的运行状态。\n\n当woker进程退出后（异常情况下），会自动重新启动新的woker进程。\n\nwoker进程主要用来处理基本的网络事件：\n\n多个worker进程之间是对等且相互独立的，他们同等竞争来自客户端的请求。\n\n一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。\n\nworker进程的个数是可以设置的，一般我们会设置与机器cpu核数一致。同时，nginx为了更好的利用多核特性，具有cpu绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。\n## 建立连接的步骤\n\n1. 最开始master进程会建立、绑定、监听一个socket。\n2. 然后fork出多个work进程，work进程共享master监听的文件描述符\n3. 当socket上有数据的时候，work进程会通过锁来竞争资源\n4. 竞争到资源的work进程调用accept方法接收连接，accept方法会返回一个新的socket，之后就是这个新的socket与客户端建立3次握手和数据的交换。需要注意的是新建立的这个socket所监听的端口号还是80或443。唯一确定一个socket（只考虑tcp协议的）是四元组：客户端ip, 客户端端口, 服务器ip, 服务器端口。只要有一个元素不一样，就表示不同的连接。因此一单建立了连接，下次再通信的时候数据就会直接到第一次accept的那个socket，并不会再到达master进程最开始监听的那个socket了。\n\n\n## 处理事件\n每个work进程可以处理两类事件\n\n1. 处理已监听的socket的读或写就绪事件\n2. 处理新的连接\n\n多个进程间通过争夺一块锁来决定谁处理新的连接。同一时刻只能有一个进程获取到锁。也因此不会产生“惊群”现象。\n\n获取到锁的进程调用epoll_wait方法返回的事件列表中既有已监听的socket的读或写就绪事件，也有要处理新的连接事件。新的连接事件的优先级比较高。\n\n没有获取到锁的进程调用epoll_wait方法只会获取到该进程监听的socket上的读或写就绪事件。\n\n每个work进程在启动后都会调用内核的epoll_create方法。该方法返回一个文件描述符，并在内核维护一个epoll模块。之后work进程通过这个文件描述符来实现对自己感兴趣的事件的添加、删除、修改、监听。\n\n当work进程获得一个新的连接的时候，会把这个socket上的读就绪事件通过epoll_ctl函数挂载在epoll模块的红黑树上。\n\nwork进程通过epoll_wait函数获取到了socket上有可读事件后就开始处理该事件，处理的过程很短，就是把该请求根据用户的配置交到下游处理模块中。\n\n## 模块\nNginx 由内核和一系列模块组成，内核提供 Web 服务的基本功能，如启用网络协议，创建运行环境，接收和分配客户端请求，处理模块之间的交互。\n\nNginx 的各种功能和操作都由模块来实现。Nginx 的模块从结构上分为：\n\n* 核心模块：HTTP 模块、EVENT 模块和 MAIL 模块。\n* 基础模块：HTTP Access 模块、HTTP FastCGI 模块、HTTP Proxy 模块和 HTTP Rewrite 模块。\n* 第三方模块：HTTP Upstream Request Hash 模块、Notice 模块和 HTTP Access Key 模块及用户自己开发的模块。\n\n## 配置\nnginx的配置有三大模块\n\n1. 全局块\n2. event块\n3. http块\n\n### 全局块\n全局块负责一些全局的配置，部分配置如下\n\n1. user 规定运行nginx的用户和用户组\n2. worker_processes worker进程的数量\n3. worker_rlimit_nofile 一个worker进程最大的打开文件的数量\n\n### event块\nevent块里的配置是有关事件的，部分配置如下\n\n1. worker_connections 一个work进程能够处理的最大的连接数\n2. accept_mutex 当一个新连接到达时，如果激活了accept_mutex，那么多个Worker将以串行方式来处理，其中有一个Worker会被唤醒，其他的Worker继续保持休眠状态；如果没有激活accept_mutex，那么所有的Worker都会被唤醒，不过只有一个Worker能获取新连接，其它的Worker会重新进入休眠状态\n3. use epoll 使用epoll来管理io事件\n\n### http块\nhttp块中的配置包含两部分，公共部分和server部分。公共部分是所有server都采用的，server部分是每个server单独采用的。\n\n#### 公共配置\n\n1. client_header_buffer_size 请求头缓冲区大小\n2. large_client_header_buffers 当请求头太大的时候client_header_buffer_size放不下了，会向large_client_header_buffers申请一块额外的内存\n3. client_max_body_size 请求body的最大\n4. client_body_timeout 读取请求body的超时时间\n5. client_header_timeout 读取请求header的超时时间\n6. log_format access_log的日志格式\n7. sendfile 支持“零拷贝”\n8. keepalive_timeout 长连接的超时时间。超时后会nginx会释放socket资源。如果客户端再想通信需重新3次握手\n\n#### server配置\nserver配置中一般会有多个location，把不同的url分配给不同的下游服务\n\nnginx中以$开头的都是nginx的变量。nginx在把请求发给fastcgi之前会把nginx的变量转化成fastcgi变量。fastcgi的变量由大写字母和下划线组成。在php的进程中，fastcgi的变量都在SERVERA全局数组中。\n\n##### rewrite\n```sh\nif (!-e $request_filename) {\n    rewrite ^(.*)$ /index.php?_url=$1 last;\n}\n```\n$request_filename是根路径拼接的uri(域名后面的一段)。如果用户请求的不是一个文件那么久将进行重写。重写的规则是请求根域名下的index.php,而uri变成了_url参数\n\nrewrite最后会有一个标识符\n\n* break url重写后，直接使用当前资源，不再执行location里余下的语句，完成本次请求，地址栏url不变 \n* last url重写后，马上发起一个新的请求，再次进入server块，重试location匹配，超过10次匹配不到报500错误，地址栏url不变\n* redirect 返回302临时重定向，地址栏显示重定向后的url，爬虫不会更新url（因为是临时）\n* permanent 返回301永久重定向, 地址栏显示重定向后的url，爬虫更新url\n\n##### location\n在匹配location的时候\n\n* =  精确匹配\n* ~  表示大小写敏感的正则匹配\n* ~* 表示大小写不敏感的正则匹配\n\n以php为例。以.php为结尾的请求都转给fastcgi\n```sh\nlocation ~ \\.php$ {\n    set $real_script_name $fastcgi_script_name;\n    if ($fastcgi_script_name ~ /lianjia(/.*)$) {\n        set $real_script_name $1;\n    }\n    fastcgi_pass    127.0.0.1:18181;\n    fastcgi_index  index.php;\n    fastcgi_param  SCRIPT_FILENAME $document_root$real_script_name;\n    include        tengine.fastcgi_params;\n}\n```\n\n## 负载均衡\nnginx的负载均衡策略有三种\n\n1. 平均分配\n2. 根据权重\n3. 根据客户端的ip\n\n无论哪一种，如果其中的一台机器出问题了，nginx会自动剔除，用起来很方便\n\n### 平均负载\n```sh\nhttp{\n    # 待选服务器列表\n    upstream myproject{\n        server 125.219.42.4;\n        server 172.31.2.183;\n    }\n\n    server{\n        listen 80; \n        location / {            \n            proxy_pass http://myproject;\n        }\n\n   }\n}\n```\n\n### 根据权重负载\n```sh\nhttp{\n    # 待选服务器列表\n    upstream myproject{\n        server 125.219.42.4 weight 1;\n        server 172.31.2.183 weight 2;\n    }\n\n    server{\n        listen 80; \n        location / {            \n            proxy_pass http://myproject;\n        }\n\n   }\n}\n```\n\n### 根据用户ip负载 \n```sh\nhttp{\n    # 待选服务器列表\n    upstream myproject{\n        ip_hash;\n        server 125.219.42.4;\n        server 172.31.2.183;\n    }\n\n    server{\n        listen 80; \n        location / {            \n            proxy_pass http://myproject;\n        }\n\n   }\n}\n```\n","source":"_posts/nginx-notes.md","raw":"---\ntitle: Nginx学习笔记\ndate: 2019-08-04 09:04:05\ntags:\n  - nginx\nphotos:\n  - [\"http://sysummery.top/nginx_cover.jpeg\"]\n---\nNginx 是一个免费、开源、高性能、轻量级的 HTTP 和反向代理服务器，也是一个电子邮件(IMAP/POP3)代理服务器，其特点是占有内存少，并发能力强。\n<!--more-->\n\n## nginx的架构\nNginx 里有一个 master 进程和多个 worker 进程。master 进程并不处理网络请求，主要负责调度工作进程：加载配置、启动工作进程及非停升级。worker 进程负责处理网络请求与响应。\n\n![](http://sysummery.top/nginx_process.png)\n\nmaster进程主要用来管理worker进程，具体包括如下4个主要功能：\n\n接收来自外界的信号。\n\n向各worker进程发送信号。\n\n监控woker进程的运行状态。\n\n当woker进程退出后（异常情况下），会自动重新启动新的woker进程。\n\nwoker进程主要用来处理基本的网络事件：\n\n多个worker进程之间是对等且相互独立的，他们同等竞争来自客户端的请求。\n\n一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。\n\nworker进程的个数是可以设置的，一般我们会设置与机器cpu核数一致。同时，nginx为了更好的利用多核特性，具有cpu绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。\n## 建立连接的步骤\n\n1. 最开始master进程会建立、绑定、监听一个socket。\n2. 然后fork出多个work进程，work进程共享master监听的文件描述符\n3. 当socket上有数据的时候，work进程会通过锁来竞争资源\n4. 竞争到资源的work进程调用accept方法接收连接，accept方法会返回一个新的socket，之后就是这个新的socket与客户端建立3次握手和数据的交换。需要注意的是新建立的这个socket所监听的端口号还是80或443。唯一确定一个socket（只考虑tcp协议的）是四元组：客户端ip, 客户端端口, 服务器ip, 服务器端口。只要有一个元素不一样，就表示不同的连接。因此一单建立了连接，下次再通信的时候数据就会直接到第一次accept的那个socket，并不会再到达master进程最开始监听的那个socket了。\n\n\n## 处理事件\n每个work进程可以处理两类事件\n\n1. 处理已监听的socket的读或写就绪事件\n2. 处理新的连接\n\n多个进程间通过争夺一块锁来决定谁处理新的连接。同一时刻只能有一个进程获取到锁。也因此不会产生“惊群”现象。\n\n获取到锁的进程调用epoll_wait方法返回的事件列表中既有已监听的socket的读或写就绪事件，也有要处理新的连接事件。新的连接事件的优先级比较高。\n\n没有获取到锁的进程调用epoll_wait方法只会获取到该进程监听的socket上的读或写就绪事件。\n\n每个work进程在启动后都会调用内核的epoll_create方法。该方法返回一个文件描述符，并在内核维护一个epoll模块。之后work进程通过这个文件描述符来实现对自己感兴趣的事件的添加、删除、修改、监听。\n\n当work进程获得一个新的连接的时候，会把这个socket上的读就绪事件通过epoll_ctl函数挂载在epoll模块的红黑树上。\n\nwork进程通过epoll_wait函数获取到了socket上有可读事件后就开始处理该事件，处理的过程很短，就是把该请求根据用户的配置交到下游处理模块中。\n\n## 模块\nNginx 由内核和一系列模块组成，内核提供 Web 服务的基本功能，如启用网络协议，创建运行环境，接收和分配客户端请求，处理模块之间的交互。\n\nNginx 的各种功能和操作都由模块来实现。Nginx 的模块从结构上分为：\n\n* 核心模块：HTTP 模块、EVENT 模块和 MAIL 模块。\n* 基础模块：HTTP Access 模块、HTTP FastCGI 模块、HTTP Proxy 模块和 HTTP Rewrite 模块。\n* 第三方模块：HTTP Upstream Request Hash 模块、Notice 模块和 HTTP Access Key 模块及用户自己开发的模块。\n\n## 配置\nnginx的配置有三大模块\n\n1. 全局块\n2. event块\n3. http块\n\n### 全局块\n全局块负责一些全局的配置，部分配置如下\n\n1. user 规定运行nginx的用户和用户组\n2. worker_processes worker进程的数量\n3. worker_rlimit_nofile 一个worker进程最大的打开文件的数量\n\n### event块\nevent块里的配置是有关事件的，部分配置如下\n\n1. worker_connections 一个work进程能够处理的最大的连接数\n2. accept_mutex 当一个新连接到达时，如果激活了accept_mutex，那么多个Worker将以串行方式来处理，其中有一个Worker会被唤醒，其他的Worker继续保持休眠状态；如果没有激活accept_mutex，那么所有的Worker都会被唤醒，不过只有一个Worker能获取新连接，其它的Worker会重新进入休眠状态\n3. use epoll 使用epoll来管理io事件\n\n### http块\nhttp块中的配置包含两部分，公共部分和server部分。公共部分是所有server都采用的，server部分是每个server单独采用的。\n\n#### 公共配置\n\n1. client_header_buffer_size 请求头缓冲区大小\n2. large_client_header_buffers 当请求头太大的时候client_header_buffer_size放不下了，会向large_client_header_buffers申请一块额外的内存\n3. client_max_body_size 请求body的最大\n4. client_body_timeout 读取请求body的超时时间\n5. client_header_timeout 读取请求header的超时时间\n6. log_format access_log的日志格式\n7. sendfile 支持“零拷贝”\n8. keepalive_timeout 长连接的超时时间。超时后会nginx会释放socket资源。如果客户端再想通信需重新3次握手\n\n#### server配置\nserver配置中一般会有多个location，把不同的url分配给不同的下游服务\n\nnginx中以$开头的都是nginx的变量。nginx在把请求发给fastcgi之前会把nginx的变量转化成fastcgi变量。fastcgi的变量由大写字母和下划线组成。在php的进程中，fastcgi的变量都在SERVERA全局数组中。\n\n##### rewrite\n```sh\nif (!-e $request_filename) {\n    rewrite ^(.*)$ /index.php?_url=$1 last;\n}\n```\n$request_filename是根路径拼接的uri(域名后面的一段)。如果用户请求的不是一个文件那么久将进行重写。重写的规则是请求根域名下的index.php,而uri变成了_url参数\n\nrewrite最后会有一个标识符\n\n* break url重写后，直接使用当前资源，不再执行location里余下的语句，完成本次请求，地址栏url不变 \n* last url重写后，马上发起一个新的请求，再次进入server块，重试location匹配，超过10次匹配不到报500错误，地址栏url不变\n* redirect 返回302临时重定向，地址栏显示重定向后的url，爬虫不会更新url（因为是临时）\n* permanent 返回301永久重定向, 地址栏显示重定向后的url，爬虫更新url\n\n##### location\n在匹配location的时候\n\n* =  精确匹配\n* ~  表示大小写敏感的正则匹配\n* ~* 表示大小写不敏感的正则匹配\n\n以php为例。以.php为结尾的请求都转给fastcgi\n```sh\nlocation ~ \\.php$ {\n    set $real_script_name $fastcgi_script_name;\n    if ($fastcgi_script_name ~ /lianjia(/.*)$) {\n        set $real_script_name $1;\n    }\n    fastcgi_pass    127.0.0.1:18181;\n    fastcgi_index  index.php;\n    fastcgi_param  SCRIPT_FILENAME $document_root$real_script_name;\n    include        tengine.fastcgi_params;\n}\n```\n\n## 负载均衡\nnginx的负载均衡策略有三种\n\n1. 平均分配\n2. 根据权重\n3. 根据客户端的ip\n\n无论哪一种，如果其中的一台机器出问题了，nginx会自动剔除，用起来很方便\n\n### 平均负载\n```sh\nhttp{\n    # 待选服务器列表\n    upstream myproject{\n        server 125.219.42.4;\n        server 172.31.2.183;\n    }\n\n    server{\n        listen 80; \n        location / {            \n            proxy_pass http://myproject;\n        }\n\n   }\n}\n```\n\n### 根据权重负载\n```sh\nhttp{\n    # 待选服务器列表\n    upstream myproject{\n        server 125.219.42.4 weight 1;\n        server 172.31.2.183 weight 2;\n    }\n\n    server{\n        listen 80; \n        location / {            \n            proxy_pass http://myproject;\n        }\n\n   }\n}\n```\n\n### 根据用户ip负载 \n```sh\nhttp{\n    # 待选服务器列表\n    upstream myproject{\n        ip_hash;\n        server 125.219.42.4;\n        server 172.31.2.183;\n    }\n\n    server{\n        listen 80; \n        location / {            \n            proxy_pass http://myproject;\n        }\n\n   }\n}\n```\n","slug":"nginx-notes","published":1,"updated":"2020-11-23T15:23:47.779Z","comments":1,"layout":"post","link":"","_id":"ckhupaq9n000o1no8t1xfmp73","content":"<p>Nginx 是一个免费、开源、高性能、轻量级的 HTTP 和反向代理服务器，也是一个电子邮件(IMAP/POP3)代理服务器，其特点是占有内存少，并发能力强。</p>\n<a id=\"more\"></a>\n\n<h2 id=\"nginx的架构\"><a href=\"#nginx的架构\" class=\"headerlink\" title=\"nginx的架构\"></a>nginx的架构</h2><p>Nginx 里有一个 master 进程和多个 worker 进程。master 进程并不处理网络请求，主要负责调度工作进程：加载配置、启动工作进程及非停升级。worker 进程负责处理网络请求与响应。</p>\n<p><img src=\"http://sysummery.top/nginx_process.png\" alt></p>\n<p>master进程主要用来管理worker进程，具体包括如下4个主要功能：</p>\n<p>接收来自外界的信号。</p>\n<p>向各worker进程发送信号。</p>\n<p>监控woker进程的运行状态。</p>\n<p>当woker进程退出后（异常情况下），会自动重新启动新的woker进程。</p>\n<p>woker进程主要用来处理基本的网络事件：</p>\n<p>多个worker进程之间是对等且相互独立的，他们同等竞争来自客户端的请求。</p>\n<p>一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。</p>\n<p>worker进程的个数是可以设置的，一般我们会设置与机器cpu核数一致。同时，nginx为了更好的利用多核特性，具有cpu绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。</p>\n<h2 id=\"建立连接的步骤\"><a href=\"#建立连接的步骤\" class=\"headerlink\" title=\"建立连接的步骤\"></a>建立连接的步骤</h2><ol>\n<li>最开始master进程会建立、绑定、监听一个socket。</li>\n<li>然后fork出多个work进程，work进程共享master监听的文件描述符</li>\n<li>当socket上有数据的时候，work进程会通过锁来竞争资源</li>\n<li>竞争到资源的work进程调用accept方法接收连接，accept方法会返回一个新的socket，之后就是这个新的socket与客户端建立3次握手和数据的交换。需要注意的是新建立的这个socket所监听的端口号还是80或443。唯一确定一个socket（只考虑tcp协议的）是四元组：客户端ip, 客户端端口, 服务器ip, 服务器端口。只要有一个元素不一样，就表示不同的连接。因此一单建立了连接，下次再通信的时候数据就会直接到第一次accept的那个socket，并不会再到达master进程最开始监听的那个socket了。</li>\n</ol>\n<h2 id=\"处理事件\"><a href=\"#处理事件\" class=\"headerlink\" title=\"处理事件\"></a>处理事件</h2><p>每个work进程可以处理两类事件</p>\n<ol>\n<li>处理已监听的socket的读或写就绪事件</li>\n<li>处理新的连接</li>\n</ol>\n<p>多个进程间通过争夺一块锁来决定谁处理新的连接。同一时刻只能有一个进程获取到锁。也因此不会产生“惊群”现象。</p>\n<p>获取到锁的进程调用epoll_wait方法返回的事件列表中既有已监听的socket的读或写就绪事件，也有要处理新的连接事件。新的连接事件的优先级比较高。</p>\n<p>没有获取到锁的进程调用epoll_wait方法只会获取到该进程监听的socket上的读或写就绪事件。</p>\n<p>每个work进程在启动后都会调用内核的epoll_create方法。该方法返回一个文件描述符，并在内核维护一个epoll模块。之后work进程通过这个文件描述符来实现对自己感兴趣的事件的添加、删除、修改、监听。</p>\n<p>当work进程获得一个新的连接的时候，会把这个socket上的读就绪事件通过epoll_ctl函数挂载在epoll模块的红黑树上。</p>\n<p>work进程通过epoll_wait函数获取到了socket上有可读事件后就开始处理该事件，处理的过程很短，就是把该请求根据用户的配置交到下游处理模块中。</p>\n<h2 id=\"模块\"><a href=\"#模块\" class=\"headerlink\" title=\"模块\"></a>模块</h2><p>Nginx 由内核和一系列模块组成，内核提供 Web 服务的基本功能，如启用网络协议，创建运行环境，接收和分配客户端请求，处理模块之间的交互。</p>\n<p>Nginx 的各种功能和操作都由模块来实现。Nginx 的模块从结构上分为：</p>\n<ul>\n<li>核心模块：HTTP 模块、EVENT 模块和 MAIL 模块。</li>\n<li>基础模块：HTTP Access 模块、HTTP FastCGI 模块、HTTP Proxy 模块和 HTTP Rewrite 模块。</li>\n<li>第三方模块：HTTP Upstream Request Hash 模块、Notice 模块和 HTTP Access Key 模块及用户自己开发的模块。</li>\n</ul>\n<h2 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h2><p>nginx的配置有三大模块</p>\n<ol>\n<li>全局块</li>\n<li>event块</li>\n<li>http块</li>\n</ol>\n<h3 id=\"全局块\"><a href=\"#全局块\" class=\"headerlink\" title=\"全局块\"></a>全局块</h3><p>全局块负责一些全局的配置，部分配置如下</p>\n<ol>\n<li>user 规定运行nginx的用户和用户组</li>\n<li>worker_processes worker进程的数量</li>\n<li>worker_rlimit_nofile 一个worker进程最大的打开文件的数量</li>\n</ol>\n<h3 id=\"event块\"><a href=\"#event块\" class=\"headerlink\" title=\"event块\"></a>event块</h3><p>event块里的配置是有关事件的，部分配置如下</p>\n<ol>\n<li>worker_connections 一个work进程能够处理的最大的连接数</li>\n<li>accept_mutex 当一个新连接到达时，如果激活了accept_mutex，那么多个Worker将以串行方式来处理，其中有一个Worker会被唤醒，其他的Worker继续保持休眠状态；如果没有激活accept_mutex，那么所有的Worker都会被唤醒，不过只有一个Worker能获取新连接，其它的Worker会重新进入休眠状态</li>\n<li>use epoll 使用epoll来管理io事件</li>\n</ol>\n<h3 id=\"http块\"><a href=\"#http块\" class=\"headerlink\" title=\"http块\"></a>http块</h3><p>http块中的配置包含两部分，公共部分和server部分。公共部分是所有server都采用的，server部分是每个server单独采用的。</p>\n<h4 id=\"公共配置\"><a href=\"#公共配置\" class=\"headerlink\" title=\"公共配置\"></a>公共配置</h4><ol>\n<li>client_header_buffer_size 请求头缓冲区大小</li>\n<li>large_client_header_buffers 当请求头太大的时候client_header_buffer_size放不下了，会向large_client_header_buffers申请一块额外的内存</li>\n<li>client_max_body_size 请求body的最大</li>\n<li>client_body_timeout 读取请求body的超时时间</li>\n<li>client_header_timeout 读取请求header的超时时间</li>\n<li>log_format access_log的日志格式</li>\n<li>sendfile 支持“零拷贝”</li>\n<li>keepalive_timeout 长连接的超时时间。超时后会nginx会释放socket资源。如果客户端再想通信需重新3次握手</li>\n</ol>\n<h4 id=\"server配置\"><a href=\"#server配置\" class=\"headerlink\" title=\"server配置\"></a>server配置</h4><p>server配置中一般会有多个location，把不同的url分配给不同的下游服务</p>\n<p>nginx中以$开头的都是nginx的变量。nginx在把请求发给fastcgi之前会把nginx的变量转化成fastcgi变量。fastcgi的变量由大写字母和下划线组成。在php的进程中，fastcgi的变量都在SERVERA全局数组中。</p>\n<h5 id=\"rewrite\"><a href=\"#rewrite\" class=\"headerlink\" title=\"rewrite\"></a>rewrite</h5><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (!-e <span class=\"variable\">$request_filename</span>) &#123;</span><br><span class=\"line\">    rewrite ^(.*)$ /index.php?_url=<span class=\"variable\">$1</span> last;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>$request_filename是根路径拼接的uri(域名后面的一段)。如果用户请求的不是一个文件那么久将进行重写。重写的规则是请求根域名下的index.php,而uri变成了_url参数</p>\n<p>rewrite最后会有一个标识符</p>\n<ul>\n<li>break url重写后，直接使用当前资源，不再执行location里余下的语句，完成本次请求，地址栏url不变 </li>\n<li>last url重写后，马上发起一个新的请求，再次进入server块，重试location匹配，超过10次匹配不到报500错误，地址栏url不变</li>\n<li>redirect 返回302临时重定向，地址栏显示重定向后的url，爬虫不会更新url（因为是临时）</li>\n<li>permanent 返回301永久重定向, 地址栏显示重定向后的url，爬虫更新url</li>\n</ul>\n<h5 id=\"location\"><a href=\"#location\" class=\"headerlink\" title=\"location\"></a>location</h5><p>在匹配location的时候</p>\n<ul>\n<li>=  精确匹配</li>\n<li>~  表示大小写敏感的正则匹配</li>\n<li>~* 表示大小写不敏感的正则匹配</li>\n</ul>\n<p>以php为例。以.php为结尾的请求都转给fastcgi</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location ~ \\.php$ &#123;</span><br><span class=\"line\">    <span class=\"built_in\">set</span> <span class=\"variable\">$real_script_name</span> <span class=\"variable\">$fastcgi_script_name</span>;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"variable\">$fastcgi_script_name</span> ~ /lianjia(/.*)$) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">set</span> <span class=\"variable\">$real_script_name</span> <span class=\"variable\">$1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    fastcgi_pass    127.0.0.1:18181;</span><br><span class=\"line\">    fastcgi_index  index.php;</span><br><span class=\"line\">    fastcgi_param  SCRIPT_FILENAME <span class=\"variable\">$document_root</span><span class=\"variable\">$real_script_name</span>;</span><br><span class=\"line\">    include        tengine.fastcgi_params;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"负载均衡\"><a href=\"#负载均衡\" class=\"headerlink\" title=\"负载均衡\"></a>负载均衡</h2><p>nginx的负载均衡策略有三种</p>\n<ol>\n<li>平均分配</li>\n<li>根据权重</li>\n<li>根据客户端的ip</li>\n</ol>\n<p>无论哪一种，如果其中的一台机器出问题了，nginx会自动剔除，用起来很方便</p>\n<h3 id=\"平均负载\"><a href=\"#平均负载\" class=\"headerlink\" title=\"平均负载\"></a>平均负载</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http&#123;</span><br><span class=\"line\">    <span class=\"comment\"># 待选服务器列表</span></span><br><span class=\"line\">    upstream myproject&#123;</span><br><span class=\"line\">        server 125.219.42.4;</span><br><span class=\"line\">        server 172.31.2.183;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    server&#123;</span><br><span class=\"line\">        listen 80; </span><br><span class=\"line\">        location / &#123;            </span><br><span class=\"line\">            proxy_pass http://myproject;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"根据权重负载\"><a href=\"#根据权重负载\" class=\"headerlink\" title=\"根据权重负载\"></a>根据权重负载</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http&#123;</span><br><span class=\"line\">    <span class=\"comment\"># 待选服务器列表</span></span><br><span class=\"line\">    upstream myproject&#123;</span><br><span class=\"line\">        server 125.219.42.4 weight 1;</span><br><span class=\"line\">        server 172.31.2.183 weight 2;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    server&#123;</span><br><span class=\"line\">        listen 80; </span><br><span class=\"line\">        location / &#123;            </span><br><span class=\"line\">            proxy_pass http://myproject;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"根据用户ip负载\"><a href=\"#根据用户ip负载\" class=\"headerlink\" title=\"根据用户ip负载\"></a>根据用户ip负载</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http&#123;</span><br><span class=\"line\">    <span class=\"comment\"># 待选服务器列表</span></span><br><span class=\"line\">    upstream myproject&#123;</span><br><span class=\"line\">        ip_hash;</span><br><span class=\"line\">        server 125.219.42.4;</span><br><span class=\"line\">        server 172.31.2.183;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    server&#123;</span><br><span class=\"line\">        listen 80; </span><br><span class=\"line\">        location / &#123;            </span><br><span class=\"line\">            proxy_pass http://myproject;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"<p>Nginx 是一个免费、开源、高性能、轻量级的 HTTP 和反向代理服务器，也是一个电子邮件(IMAP/POP3)代理服务器，其特点是占有内存少，并发能力强。</p>","more":"<h2 id=\"nginx的架构\"><a href=\"#nginx的架构\" class=\"headerlink\" title=\"nginx的架构\"></a>nginx的架构</h2><p>Nginx 里有一个 master 进程和多个 worker 进程。master 进程并不处理网络请求，主要负责调度工作进程：加载配置、启动工作进程及非停升级。worker 进程负责处理网络请求与响应。</p>\n<p><img src=\"http://sysummery.top/nginx_process.png\" alt></p>\n<p>master进程主要用来管理worker进程，具体包括如下4个主要功能：</p>\n<p>接收来自外界的信号。</p>\n<p>向各worker进程发送信号。</p>\n<p>监控woker进程的运行状态。</p>\n<p>当woker进程退出后（异常情况下），会自动重新启动新的woker进程。</p>\n<p>woker进程主要用来处理基本的网络事件：</p>\n<p>多个worker进程之间是对等且相互独立的，他们同等竞争来自客户端的请求。</p>\n<p>一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。</p>\n<p>worker进程的个数是可以设置的，一般我们会设置与机器cpu核数一致。同时，nginx为了更好的利用多核特性，具有cpu绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。</p>\n<h2 id=\"建立连接的步骤\"><a href=\"#建立连接的步骤\" class=\"headerlink\" title=\"建立连接的步骤\"></a>建立连接的步骤</h2><ol>\n<li>最开始master进程会建立、绑定、监听一个socket。</li>\n<li>然后fork出多个work进程，work进程共享master监听的文件描述符</li>\n<li>当socket上有数据的时候，work进程会通过锁来竞争资源</li>\n<li>竞争到资源的work进程调用accept方法接收连接，accept方法会返回一个新的socket，之后就是这个新的socket与客户端建立3次握手和数据的交换。需要注意的是新建立的这个socket所监听的端口号还是80或443。唯一确定一个socket（只考虑tcp协议的）是四元组：客户端ip, 客户端端口, 服务器ip, 服务器端口。只要有一个元素不一样，就表示不同的连接。因此一单建立了连接，下次再通信的时候数据就会直接到第一次accept的那个socket，并不会再到达master进程最开始监听的那个socket了。</li>\n</ol>\n<h2 id=\"处理事件\"><a href=\"#处理事件\" class=\"headerlink\" title=\"处理事件\"></a>处理事件</h2><p>每个work进程可以处理两类事件</p>\n<ol>\n<li>处理已监听的socket的读或写就绪事件</li>\n<li>处理新的连接</li>\n</ol>\n<p>多个进程间通过争夺一块锁来决定谁处理新的连接。同一时刻只能有一个进程获取到锁。也因此不会产生“惊群”现象。</p>\n<p>获取到锁的进程调用epoll_wait方法返回的事件列表中既有已监听的socket的读或写就绪事件，也有要处理新的连接事件。新的连接事件的优先级比较高。</p>\n<p>没有获取到锁的进程调用epoll_wait方法只会获取到该进程监听的socket上的读或写就绪事件。</p>\n<p>每个work进程在启动后都会调用内核的epoll_create方法。该方法返回一个文件描述符，并在内核维护一个epoll模块。之后work进程通过这个文件描述符来实现对自己感兴趣的事件的添加、删除、修改、监听。</p>\n<p>当work进程获得一个新的连接的时候，会把这个socket上的读就绪事件通过epoll_ctl函数挂载在epoll模块的红黑树上。</p>\n<p>work进程通过epoll_wait函数获取到了socket上有可读事件后就开始处理该事件，处理的过程很短，就是把该请求根据用户的配置交到下游处理模块中。</p>\n<h2 id=\"模块\"><a href=\"#模块\" class=\"headerlink\" title=\"模块\"></a>模块</h2><p>Nginx 由内核和一系列模块组成，内核提供 Web 服务的基本功能，如启用网络协议，创建运行环境，接收和分配客户端请求，处理模块之间的交互。</p>\n<p>Nginx 的各种功能和操作都由模块来实现。Nginx 的模块从结构上分为：</p>\n<ul>\n<li>核心模块：HTTP 模块、EVENT 模块和 MAIL 模块。</li>\n<li>基础模块：HTTP Access 模块、HTTP FastCGI 模块、HTTP Proxy 模块和 HTTP Rewrite 模块。</li>\n<li>第三方模块：HTTP Upstream Request Hash 模块、Notice 模块和 HTTP Access Key 模块及用户自己开发的模块。</li>\n</ul>\n<h2 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h2><p>nginx的配置有三大模块</p>\n<ol>\n<li>全局块</li>\n<li>event块</li>\n<li>http块</li>\n</ol>\n<h3 id=\"全局块\"><a href=\"#全局块\" class=\"headerlink\" title=\"全局块\"></a>全局块</h3><p>全局块负责一些全局的配置，部分配置如下</p>\n<ol>\n<li>user 规定运行nginx的用户和用户组</li>\n<li>worker_processes worker进程的数量</li>\n<li>worker_rlimit_nofile 一个worker进程最大的打开文件的数量</li>\n</ol>\n<h3 id=\"event块\"><a href=\"#event块\" class=\"headerlink\" title=\"event块\"></a>event块</h3><p>event块里的配置是有关事件的，部分配置如下</p>\n<ol>\n<li>worker_connections 一个work进程能够处理的最大的连接数</li>\n<li>accept_mutex 当一个新连接到达时，如果激活了accept_mutex，那么多个Worker将以串行方式来处理，其中有一个Worker会被唤醒，其他的Worker继续保持休眠状态；如果没有激活accept_mutex，那么所有的Worker都会被唤醒，不过只有一个Worker能获取新连接，其它的Worker会重新进入休眠状态</li>\n<li>use epoll 使用epoll来管理io事件</li>\n</ol>\n<h3 id=\"http块\"><a href=\"#http块\" class=\"headerlink\" title=\"http块\"></a>http块</h3><p>http块中的配置包含两部分，公共部分和server部分。公共部分是所有server都采用的，server部分是每个server单独采用的。</p>\n<h4 id=\"公共配置\"><a href=\"#公共配置\" class=\"headerlink\" title=\"公共配置\"></a>公共配置</h4><ol>\n<li>client_header_buffer_size 请求头缓冲区大小</li>\n<li>large_client_header_buffers 当请求头太大的时候client_header_buffer_size放不下了，会向large_client_header_buffers申请一块额外的内存</li>\n<li>client_max_body_size 请求body的最大</li>\n<li>client_body_timeout 读取请求body的超时时间</li>\n<li>client_header_timeout 读取请求header的超时时间</li>\n<li>log_format access_log的日志格式</li>\n<li>sendfile 支持“零拷贝”</li>\n<li>keepalive_timeout 长连接的超时时间。超时后会nginx会释放socket资源。如果客户端再想通信需重新3次握手</li>\n</ol>\n<h4 id=\"server配置\"><a href=\"#server配置\" class=\"headerlink\" title=\"server配置\"></a>server配置</h4><p>server配置中一般会有多个location，把不同的url分配给不同的下游服务</p>\n<p>nginx中以$开头的都是nginx的变量。nginx在把请求发给fastcgi之前会把nginx的变量转化成fastcgi变量。fastcgi的变量由大写字母和下划线组成。在php的进程中，fastcgi的变量都在SERVERA全局数组中。</p>\n<h5 id=\"rewrite\"><a href=\"#rewrite\" class=\"headerlink\" title=\"rewrite\"></a>rewrite</h5><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (!-e <span class=\"variable\">$request_filename</span>) &#123;</span><br><span class=\"line\">    rewrite ^(.*)$ /index.php?_url=<span class=\"variable\">$1</span> last;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>$request_filename是根路径拼接的uri(域名后面的一段)。如果用户请求的不是一个文件那么久将进行重写。重写的规则是请求根域名下的index.php,而uri变成了_url参数</p>\n<p>rewrite最后会有一个标识符</p>\n<ul>\n<li>break url重写后，直接使用当前资源，不再执行location里余下的语句，完成本次请求，地址栏url不变 </li>\n<li>last url重写后，马上发起一个新的请求，再次进入server块，重试location匹配，超过10次匹配不到报500错误，地址栏url不变</li>\n<li>redirect 返回302临时重定向，地址栏显示重定向后的url，爬虫不会更新url（因为是临时）</li>\n<li>permanent 返回301永久重定向, 地址栏显示重定向后的url，爬虫更新url</li>\n</ul>\n<h5 id=\"location\"><a href=\"#location\" class=\"headerlink\" title=\"location\"></a>location</h5><p>在匹配location的时候</p>\n<ul>\n<li>=  精确匹配</li>\n<li>~  表示大小写敏感的正则匹配</li>\n<li>~* 表示大小写不敏感的正则匹配</li>\n</ul>\n<p>以php为例。以.php为结尾的请求都转给fastcgi</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">location ~ \\.php$ &#123;</span><br><span class=\"line\">    <span class=\"built_in\">set</span> <span class=\"variable\">$real_script_name</span> <span class=\"variable\">$fastcgi_script_name</span>;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"variable\">$fastcgi_script_name</span> ~ /lianjia(/.*)$) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">set</span> <span class=\"variable\">$real_script_name</span> <span class=\"variable\">$1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    fastcgi_pass    127.0.0.1:18181;</span><br><span class=\"line\">    fastcgi_index  index.php;</span><br><span class=\"line\">    fastcgi_param  SCRIPT_FILENAME <span class=\"variable\">$document_root</span><span class=\"variable\">$real_script_name</span>;</span><br><span class=\"line\">    include        tengine.fastcgi_params;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"负载均衡\"><a href=\"#负载均衡\" class=\"headerlink\" title=\"负载均衡\"></a>负载均衡</h2><p>nginx的负载均衡策略有三种</p>\n<ol>\n<li>平均分配</li>\n<li>根据权重</li>\n<li>根据客户端的ip</li>\n</ol>\n<p>无论哪一种，如果其中的一台机器出问题了，nginx会自动剔除，用起来很方便</p>\n<h3 id=\"平均负载\"><a href=\"#平均负载\" class=\"headerlink\" title=\"平均负载\"></a>平均负载</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http&#123;</span><br><span class=\"line\">    <span class=\"comment\"># 待选服务器列表</span></span><br><span class=\"line\">    upstream myproject&#123;</span><br><span class=\"line\">        server 125.219.42.4;</span><br><span class=\"line\">        server 172.31.2.183;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    server&#123;</span><br><span class=\"line\">        listen 80; </span><br><span class=\"line\">        location / &#123;            </span><br><span class=\"line\">            proxy_pass http://myproject;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"根据权重负载\"><a href=\"#根据权重负载\" class=\"headerlink\" title=\"根据权重负载\"></a>根据权重负载</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http&#123;</span><br><span class=\"line\">    <span class=\"comment\"># 待选服务器列表</span></span><br><span class=\"line\">    upstream myproject&#123;</span><br><span class=\"line\">        server 125.219.42.4 weight 1;</span><br><span class=\"line\">        server 172.31.2.183 weight 2;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    server&#123;</span><br><span class=\"line\">        listen 80; </span><br><span class=\"line\">        location / &#123;            </span><br><span class=\"line\">            proxy_pass http://myproject;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"根据用户ip负载\"><a href=\"#根据用户ip负载\" class=\"headerlink\" title=\"根据用户ip负载\"></a>根据用户ip负载</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http&#123;</span><br><span class=\"line\">    <span class=\"comment\"># 待选服务器列表</span></span><br><span class=\"line\">    upstream myproject&#123;</span><br><span class=\"line\">        ip_hash;</span><br><span class=\"line\">        server 125.219.42.4;</span><br><span class=\"line\">        server 172.31.2.183;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    server&#123;</span><br><span class=\"line\">        listen 80; </span><br><span class=\"line\">        location / &#123;            </span><br><span class=\"line\">            proxy_pass http://myproject;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"Basic Paxos 与 Multi Paxos","date":"2020-03-14T14:25:13.000Z","photos":["http://sysummery.top/yizhi.jpg"],"_content":"Paxos算法是Leslie Lamport于1990年提出的一种基于消息传递且具有高度容错特性的一致性算法，是目前公认的解决分布式一致性问题最有效的算法之一。\n<!--more-->\n这篇文章是基于[Paxos算法详解](http://zhuanlan.zhihu.com/p/31780743)加上自己的理解和总结完成的。\n## Basic Paxos\n### 角色\n![](http://sysummery.top/paxosjuese.jpg)\n1. proposer，负责接收客户端的请求并向acceptor提prepare请求和accept请求。\n2. acceptor，接受proposer的请求并在特定情况下给与回复。\n3. learner，不参与决策，学习最终达成一致的提案，一旦有多数acceptor对值达成了共识那么就写入值。\n\n### 流程\n![](http://sysummery.top/paxos%E6%B5%81%E7%A8%8B.jpg)\n在说流程前先确定几个名词的意义\n* max_proposal_id acceptor目前通过prepare请求收到的最大的proposal的id\n* accept_id acceptor目前决定要accept的proposal的id\n\n下面是流程：\n1. 一个客户端请求将一个字段值变成value。proposer为每一个客户端的请求封装成一个proposal，并为这个proposal生成一个去全局唯一的proposal_id。\n2. proposal向所有的acceptor发送prepare请求，请求中包含proposal_id，可以不包含value。\n3. acceptor对prepare请求进行处理。如果请求中的proposal_id大于max_proposal_id，那么acceptor是接受这个proposal的，会把自己的max_proposal_id更新成proposal_id同时会返回给proposer当前自己已经accept的proposal的value，如果自己之前没有accept任何proposal则会返回空（让proposer自己去决定下一步accept的时候使用哪个value）。如果请求中的proposal_id小于max_proposal_id，则不做回应。\n4. 如果proposer收到了多一半的acceptor的回应时，会挑出最大的value，如果所有的value都为空就用自己的value。\n5. proposer用第4步获得的value和自己的proposal_id发起accept请求。\n6. acceptor处理accept请求。如果请求中的proposal_id大于等于acceptor的max_proposal_id，那么会更新自己的accept_id、max_proposal_id，同时accept这个proposal。如果请求中的proposal_id小于acceptor的max_proposal_id那么会直接返回max_proposal_id。\n7. proposal收到了多一半acceptor的结果后，如果发现有结果大于自己的proposal_id的则说明accept了别的proposal，会从步骤1开始重新执行。\n\n下面想做几点说明\n\n1. prepare返回的结果中是acceptor希望尽快达成共识的value（也就是一个acceptor已经accept的value），所以一个proposer发起accept的value不一定使自己的value。\n2. prepare通俗点来说的话就是acceptor“决定”讨论哪个proposal，决定的尺度很简单就是要大于acceptor之前已经决定讨论过的proposal_id的最大值。accept通俗来讲就是决定接受一个value。当多一半acceptor接受一个value后整个流程也就结束了。\n3. basic paxos有局限性。他必须走完一轮流程后才能走下一轮流程，因为它没有日志的概念。\n4. basic paxos会有活锁的可能。\n\n下面是几个案例。s1提出把值更新为x，s5提出把值更新成y。P代表prepare阶段，A代表accept阶段。s1的proposal_id是3.1，s5的proposal_id是4.5。\n![](http://sysummery.top/paxos%E6%A1%88%E4%BE%8B1.jpg)\n\ns1的proposal已经被大多数accept了，此时s5的prepare发出后，如果有大多数acceptor返回那么返回的结果中要不是x要不是空而且x一定存在。所以s5的accept请求中的value是想而不是自己的y。最终的结果是x被写入。s5的y只能走下一轮的流程。\n\n![](http://sysummery.top/paxos%E7%A4%BA%E4%BE%8B2.jpg)\n\n如果s1的proposal只被一个acceptor请求，即s3，同时s5的prepare请求收到了s3的回应，那么s5的accept请求中的值还是x\n\n![](http://sysummery.top/paxos%E7%A4%BA%E4%BE%8B3.jpg)\n这个案例的情况与上面的正好相反，s1的proposal只被s1自己accept了，而s5的prepare返回的结果中不包含s1的结果，此时s5就会用自己的值y来发起accept请求。\n\n## Multi Paxos\nmulti paxos算法中在所有proposers中选举一个leader，由leader唯一地提交proposal给acceptors进行表决。这样没有proposer竞争，解决了活锁问题。在系统中仅有一个leader进行value提交的情况下，prepare阶段就可以跳过，从而将两阶段变为一阶段，提高效率。\n\n既然所有的选举都走leader，那么leader就负责为每一个proposal生成一个全局唯一的proposal_id。leader的选举算法可以使用basic paxos,需要两段请求，而且有活锁的可能。一单选出leader就不用再经历prepare阶段了。\n\n## 总结\n上面的两个算法是强一致性的。虽然这两个算法中也有“大多数”的概念，但是这个大多数与raft和zab中的又不大一样。paxos中的大多数的作用是决定写入哪个值，一单给客户端返回结果那么各个节点的值一定是最新的，即强一致性。raft与zba中只要大多数节点的值写入就返回，是最终一致性，他们的“大多数”是为了高可用。\n\n","source":"_posts/paxos.md","raw":"---\ntitle: Basic Paxos 与 Multi Paxos\ndate: 2020-03-14 22:25:13\ntags:\n   - 分布式\nphotos:\n   - [\"http://sysummery.top/yizhi.jpg\"]\n---\nPaxos算法是Leslie Lamport于1990年提出的一种基于消息传递且具有高度容错特性的一致性算法，是目前公认的解决分布式一致性问题最有效的算法之一。\n<!--more-->\n这篇文章是基于[Paxos算法详解](http://zhuanlan.zhihu.com/p/31780743)加上自己的理解和总结完成的。\n## Basic Paxos\n### 角色\n![](http://sysummery.top/paxosjuese.jpg)\n1. proposer，负责接收客户端的请求并向acceptor提prepare请求和accept请求。\n2. acceptor，接受proposer的请求并在特定情况下给与回复。\n3. learner，不参与决策，学习最终达成一致的提案，一旦有多数acceptor对值达成了共识那么就写入值。\n\n### 流程\n![](http://sysummery.top/paxos%E6%B5%81%E7%A8%8B.jpg)\n在说流程前先确定几个名词的意义\n* max_proposal_id acceptor目前通过prepare请求收到的最大的proposal的id\n* accept_id acceptor目前决定要accept的proposal的id\n\n下面是流程：\n1. 一个客户端请求将一个字段值变成value。proposer为每一个客户端的请求封装成一个proposal，并为这个proposal生成一个去全局唯一的proposal_id。\n2. proposal向所有的acceptor发送prepare请求，请求中包含proposal_id，可以不包含value。\n3. acceptor对prepare请求进行处理。如果请求中的proposal_id大于max_proposal_id，那么acceptor是接受这个proposal的，会把自己的max_proposal_id更新成proposal_id同时会返回给proposer当前自己已经accept的proposal的value，如果自己之前没有accept任何proposal则会返回空（让proposer自己去决定下一步accept的时候使用哪个value）。如果请求中的proposal_id小于max_proposal_id，则不做回应。\n4. 如果proposer收到了多一半的acceptor的回应时，会挑出最大的value，如果所有的value都为空就用自己的value。\n5. proposer用第4步获得的value和自己的proposal_id发起accept请求。\n6. acceptor处理accept请求。如果请求中的proposal_id大于等于acceptor的max_proposal_id，那么会更新自己的accept_id、max_proposal_id，同时accept这个proposal。如果请求中的proposal_id小于acceptor的max_proposal_id那么会直接返回max_proposal_id。\n7. proposal收到了多一半acceptor的结果后，如果发现有结果大于自己的proposal_id的则说明accept了别的proposal，会从步骤1开始重新执行。\n\n下面想做几点说明\n\n1. prepare返回的结果中是acceptor希望尽快达成共识的value（也就是一个acceptor已经accept的value），所以一个proposer发起accept的value不一定使自己的value。\n2. prepare通俗点来说的话就是acceptor“决定”讨论哪个proposal，决定的尺度很简单就是要大于acceptor之前已经决定讨论过的proposal_id的最大值。accept通俗来讲就是决定接受一个value。当多一半acceptor接受一个value后整个流程也就结束了。\n3. basic paxos有局限性。他必须走完一轮流程后才能走下一轮流程，因为它没有日志的概念。\n4. basic paxos会有活锁的可能。\n\n下面是几个案例。s1提出把值更新为x，s5提出把值更新成y。P代表prepare阶段，A代表accept阶段。s1的proposal_id是3.1，s5的proposal_id是4.5。\n![](http://sysummery.top/paxos%E6%A1%88%E4%BE%8B1.jpg)\n\ns1的proposal已经被大多数accept了，此时s5的prepare发出后，如果有大多数acceptor返回那么返回的结果中要不是x要不是空而且x一定存在。所以s5的accept请求中的value是想而不是自己的y。最终的结果是x被写入。s5的y只能走下一轮的流程。\n\n![](http://sysummery.top/paxos%E7%A4%BA%E4%BE%8B2.jpg)\n\n如果s1的proposal只被一个acceptor请求，即s3，同时s5的prepare请求收到了s3的回应，那么s5的accept请求中的值还是x\n\n![](http://sysummery.top/paxos%E7%A4%BA%E4%BE%8B3.jpg)\n这个案例的情况与上面的正好相反，s1的proposal只被s1自己accept了，而s5的prepare返回的结果中不包含s1的结果，此时s5就会用自己的值y来发起accept请求。\n\n## Multi Paxos\nmulti paxos算法中在所有proposers中选举一个leader，由leader唯一地提交proposal给acceptors进行表决。这样没有proposer竞争，解决了活锁问题。在系统中仅有一个leader进行value提交的情况下，prepare阶段就可以跳过，从而将两阶段变为一阶段，提高效率。\n\n既然所有的选举都走leader，那么leader就负责为每一个proposal生成一个全局唯一的proposal_id。leader的选举算法可以使用basic paxos,需要两段请求，而且有活锁的可能。一单选出leader就不用再经历prepare阶段了。\n\n## 总结\n上面的两个算法是强一致性的。虽然这两个算法中也有“大多数”的概念，但是这个大多数与raft和zab中的又不大一样。paxos中的大多数的作用是决定写入哪个值，一单给客户端返回结果那么各个节点的值一定是最新的，即强一致性。raft与zba中只要大多数节点的值写入就返回，是最终一致性，他们的“大多数”是为了高可用。\n\n","slug":"paxos","published":1,"updated":"2020-11-23T15:23:47.779Z","comments":1,"layout":"post","link":"","_id":"ckhupaq9q000r1no8k21og357","content":"<p>Paxos算法是Leslie Lamport于1990年提出的一种基于消息传递且具有高度容错特性的一致性算法，是目前公认的解决分布式一致性问题最有效的算法之一。</p>\n<a id=\"more\"></a>\n<p>这篇文章是基于<a href=\"http://zhuanlan.zhihu.com/p/31780743\" target=\"_blank\" rel=\"noopener\">Paxos算法详解</a>加上自己的理解和总结完成的。</p>\n<h2 id=\"Basic-Paxos\"><a href=\"#Basic-Paxos\" class=\"headerlink\" title=\"Basic Paxos\"></a>Basic Paxos</h2><h3 id=\"角色\"><a href=\"#角色\" class=\"headerlink\" title=\"角色\"></a>角色</h3><p><img src=\"http://sysummery.top/paxosjuese.jpg\" alt></p>\n<ol>\n<li>proposer，负责接收客户端的请求并向acceptor提prepare请求和accept请求。</li>\n<li>acceptor，接受proposer的请求并在特定情况下给与回复。</li>\n<li>learner，不参与决策，学习最终达成一致的提案，一旦有多数acceptor对值达成了共识那么就写入值。</li>\n</ol>\n<h3 id=\"流程\"><a href=\"#流程\" class=\"headerlink\" title=\"流程\"></a>流程</h3><p><img src=\"http://sysummery.top/paxos%E6%B5%81%E7%A8%8B.jpg\" alt><br>在说流程前先确定几个名词的意义</p>\n<ul>\n<li>max_proposal_id acceptor目前通过prepare请求收到的最大的proposal的id</li>\n<li>accept_id acceptor目前决定要accept的proposal的id</li>\n</ul>\n<p>下面是流程：</p>\n<ol>\n<li>一个客户端请求将一个字段值变成value。proposer为每一个客户端的请求封装成一个proposal，并为这个proposal生成一个去全局唯一的proposal_id。</li>\n<li>proposal向所有的acceptor发送prepare请求，请求中包含proposal_id，可以不包含value。</li>\n<li>acceptor对prepare请求进行处理。如果请求中的proposal_id大于max_proposal_id，那么acceptor是接受这个proposal的，会把自己的max_proposal_id更新成proposal_id同时会返回给proposer当前自己已经accept的proposal的value，如果自己之前没有accept任何proposal则会返回空（让proposer自己去决定下一步accept的时候使用哪个value）。如果请求中的proposal_id小于max_proposal_id，则不做回应。</li>\n<li>如果proposer收到了多一半的acceptor的回应时，会挑出最大的value，如果所有的value都为空就用自己的value。</li>\n<li>proposer用第4步获得的value和自己的proposal_id发起accept请求。</li>\n<li>acceptor处理accept请求。如果请求中的proposal_id大于等于acceptor的max_proposal_id，那么会更新自己的accept_id、max_proposal_id，同时accept这个proposal。如果请求中的proposal_id小于acceptor的max_proposal_id那么会直接返回max_proposal_id。</li>\n<li>proposal收到了多一半acceptor的结果后，如果发现有结果大于自己的proposal_id的则说明accept了别的proposal，会从步骤1开始重新执行。</li>\n</ol>\n<p>下面想做几点说明</p>\n<ol>\n<li>prepare返回的结果中是acceptor希望尽快达成共识的value（也就是一个acceptor已经accept的value），所以一个proposer发起accept的value不一定使自己的value。</li>\n<li>prepare通俗点来说的话就是acceptor“决定”讨论哪个proposal，决定的尺度很简单就是要大于acceptor之前已经决定讨论过的proposal_id的最大值。accept通俗来讲就是决定接受一个value。当多一半acceptor接受一个value后整个流程也就结束了。</li>\n<li>basic paxos有局限性。他必须走完一轮流程后才能走下一轮流程，因为它没有日志的概念。</li>\n<li>basic paxos会有活锁的可能。</li>\n</ol>\n<p>下面是几个案例。s1提出把值更新为x，s5提出把值更新成y。P代表prepare阶段，A代表accept阶段。s1的proposal_id是3.1，s5的proposal_id是4.5。<br><img src=\"http://sysummery.top/paxos%E6%A1%88%E4%BE%8B1.jpg\" alt></p>\n<p>s1的proposal已经被大多数accept了，此时s5的prepare发出后，如果有大多数acceptor返回那么返回的结果中要不是x要不是空而且x一定存在。所以s5的accept请求中的value是想而不是自己的y。最终的结果是x被写入。s5的y只能走下一轮的流程。</p>\n<p><img src=\"http://sysummery.top/paxos%E7%A4%BA%E4%BE%8B2.jpg\" alt></p>\n<p>如果s1的proposal只被一个acceptor请求，即s3，同时s5的prepare请求收到了s3的回应，那么s5的accept请求中的值还是x</p>\n<p><img src=\"http://sysummery.top/paxos%E7%A4%BA%E4%BE%8B3.jpg\" alt><br>这个案例的情况与上面的正好相反，s1的proposal只被s1自己accept了，而s5的prepare返回的结果中不包含s1的结果，此时s5就会用自己的值y来发起accept请求。</p>\n<h2 id=\"Multi-Paxos\"><a href=\"#Multi-Paxos\" class=\"headerlink\" title=\"Multi Paxos\"></a>Multi Paxos</h2><p>multi paxos算法中在所有proposers中选举一个leader，由leader唯一地提交proposal给acceptors进行表决。这样没有proposer竞争，解决了活锁问题。在系统中仅有一个leader进行value提交的情况下，prepare阶段就可以跳过，从而将两阶段变为一阶段，提高效率。</p>\n<p>既然所有的选举都走leader，那么leader就负责为每一个proposal生成一个全局唯一的proposal_id。leader的选举算法可以使用basic paxos,需要两段请求，而且有活锁的可能。一单选出leader就不用再经历prepare阶段了。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>上面的两个算法是强一致性的。虽然这两个算法中也有“大多数”的概念，但是这个大多数与raft和zab中的又不大一样。paxos中的大多数的作用是决定写入哪个值，一单给客户端返回结果那么各个节点的值一定是最新的，即强一致性。raft与zba中只要大多数节点的值写入就返回，是最终一致性，他们的“大多数”是为了高可用。</p>\n","site":{"data":{}},"excerpt":"<p>Paxos算法是Leslie Lamport于1990年提出的一种基于消息传递且具有高度容错特性的一致性算法，是目前公认的解决分布式一致性问题最有效的算法之一。</p>","more":"<p>这篇文章是基于<a href=\"http://zhuanlan.zhihu.com/p/31780743\" target=\"_blank\" rel=\"noopener\">Paxos算法详解</a>加上自己的理解和总结完成的。</p>\n<h2 id=\"Basic-Paxos\"><a href=\"#Basic-Paxos\" class=\"headerlink\" title=\"Basic Paxos\"></a>Basic Paxos</h2><h3 id=\"角色\"><a href=\"#角色\" class=\"headerlink\" title=\"角色\"></a>角色</h3><p><img src=\"http://sysummery.top/paxosjuese.jpg\" alt></p>\n<ol>\n<li>proposer，负责接收客户端的请求并向acceptor提prepare请求和accept请求。</li>\n<li>acceptor，接受proposer的请求并在特定情况下给与回复。</li>\n<li>learner，不参与决策，学习最终达成一致的提案，一旦有多数acceptor对值达成了共识那么就写入值。</li>\n</ol>\n<h3 id=\"流程\"><a href=\"#流程\" class=\"headerlink\" title=\"流程\"></a>流程</h3><p><img src=\"http://sysummery.top/paxos%E6%B5%81%E7%A8%8B.jpg\" alt><br>在说流程前先确定几个名词的意义</p>\n<ul>\n<li>max_proposal_id acceptor目前通过prepare请求收到的最大的proposal的id</li>\n<li>accept_id acceptor目前决定要accept的proposal的id</li>\n</ul>\n<p>下面是流程：</p>\n<ol>\n<li>一个客户端请求将一个字段值变成value。proposer为每一个客户端的请求封装成一个proposal，并为这个proposal生成一个去全局唯一的proposal_id。</li>\n<li>proposal向所有的acceptor发送prepare请求，请求中包含proposal_id，可以不包含value。</li>\n<li>acceptor对prepare请求进行处理。如果请求中的proposal_id大于max_proposal_id，那么acceptor是接受这个proposal的，会把自己的max_proposal_id更新成proposal_id同时会返回给proposer当前自己已经accept的proposal的value，如果自己之前没有accept任何proposal则会返回空（让proposer自己去决定下一步accept的时候使用哪个value）。如果请求中的proposal_id小于max_proposal_id，则不做回应。</li>\n<li>如果proposer收到了多一半的acceptor的回应时，会挑出最大的value，如果所有的value都为空就用自己的value。</li>\n<li>proposer用第4步获得的value和自己的proposal_id发起accept请求。</li>\n<li>acceptor处理accept请求。如果请求中的proposal_id大于等于acceptor的max_proposal_id，那么会更新自己的accept_id、max_proposal_id，同时accept这个proposal。如果请求中的proposal_id小于acceptor的max_proposal_id那么会直接返回max_proposal_id。</li>\n<li>proposal收到了多一半acceptor的结果后，如果发现有结果大于自己的proposal_id的则说明accept了别的proposal，会从步骤1开始重新执行。</li>\n</ol>\n<p>下面想做几点说明</p>\n<ol>\n<li>prepare返回的结果中是acceptor希望尽快达成共识的value（也就是一个acceptor已经accept的value），所以一个proposer发起accept的value不一定使自己的value。</li>\n<li>prepare通俗点来说的话就是acceptor“决定”讨论哪个proposal，决定的尺度很简单就是要大于acceptor之前已经决定讨论过的proposal_id的最大值。accept通俗来讲就是决定接受一个value。当多一半acceptor接受一个value后整个流程也就结束了。</li>\n<li>basic paxos有局限性。他必须走完一轮流程后才能走下一轮流程，因为它没有日志的概念。</li>\n<li>basic paxos会有活锁的可能。</li>\n</ol>\n<p>下面是几个案例。s1提出把值更新为x，s5提出把值更新成y。P代表prepare阶段，A代表accept阶段。s1的proposal_id是3.1，s5的proposal_id是4.5。<br><img src=\"http://sysummery.top/paxos%E6%A1%88%E4%BE%8B1.jpg\" alt></p>\n<p>s1的proposal已经被大多数accept了，此时s5的prepare发出后，如果有大多数acceptor返回那么返回的结果中要不是x要不是空而且x一定存在。所以s5的accept请求中的value是想而不是自己的y。最终的结果是x被写入。s5的y只能走下一轮的流程。</p>\n<p><img src=\"http://sysummery.top/paxos%E7%A4%BA%E4%BE%8B2.jpg\" alt></p>\n<p>如果s1的proposal只被一个acceptor请求，即s3，同时s5的prepare请求收到了s3的回应，那么s5的accept请求中的值还是x</p>\n<p><img src=\"http://sysummery.top/paxos%E7%A4%BA%E4%BE%8B3.jpg\" alt><br>这个案例的情况与上面的正好相反，s1的proposal只被s1自己accept了，而s5的prepare返回的结果中不包含s1的结果，此时s5就会用自己的值y来发起accept请求。</p>\n<h2 id=\"Multi-Paxos\"><a href=\"#Multi-Paxos\" class=\"headerlink\" title=\"Multi Paxos\"></a>Multi Paxos</h2><p>multi paxos算法中在所有proposers中选举一个leader，由leader唯一地提交proposal给acceptors进行表决。这样没有proposer竞争，解决了活锁问题。在系统中仅有一个leader进行value提交的情况下，prepare阶段就可以跳过，从而将两阶段变为一阶段，提高效率。</p>\n<p>既然所有的选举都走leader，那么leader就负责为每一个proposal生成一个全局唯一的proposal_id。leader的选举算法可以使用basic paxos,需要两段请求，而且有活锁的可能。一单选出leader就不用再经历prepare阶段了。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>上面的两个算法是强一致性的。虽然这两个算法中也有“大多数”的概念，但是这个大多数与raft和zab中的又不大一样。paxos中的大多数的作用是决定写入哪个值，一单给客户端返回结果那么各个节点的值一定是最新的，即强一致性。raft与zba中只要大多数节点的值写入就返回，是最终一致性，他们的“大多数”是为了高可用。</p>"},{"title":"Raft协议学习笔记","date":"2020-03-15T13:03:50.000Z","photos":["http://sysummery.top/raft.jpg"],"_content":"raft也是分布式系统的一个共识算法，号称比paxos更容易理解。\n<!--more-->\n## 状态机\nraft中有一个状态机的概念。如果多个节点的初始状态相同，所经历的操作（日志中记录的command）以及这些操作的顺序一致，那么每个节点最终的状态是一致的。\n\n## 节点的角色\nraft协议里面的角色有三类\n\n* leader 领导者\n* follower 追随者\n* candidate 候选者\n\n每一个节点一开始都是follower, 每个folloewr都会一个随机的“超时时间”，一但超时时间到了之后follower没有接收到leader的心跳自己就会变成candidate,然后发起一轮竞选，如果能收到大多数的票数就是竞选成功称为leader。因此raft中哪个节点的随机超时时间短，最开始就哪个节点有可能成为leader。\n\n## leader的选举\n1. leader节点维护着自己与follower的心跳。一但follower在自己的超时时间内没有收到leader的心跳，就变成candidate并发起选举并投自己一票。\n2. 给其他节点发送vote rpc请求\n3. 等待结果，如果收到大多数的票数，那么自己就是leader，此时会给其他的节点发送rpc消息告诉他们“我是leader”；如果被告知别人当选就变成follower。如果票数被瓜分，那么等到超时时间过了以后再次发起选举。\n\n当一个节点收到别人的选票的时候怎么判断是“投他还是投自己”？方法是比较term和entry log id。term可以理解为leader的任期，每个节点发起一轮选举的时候都会将自己的本地term_id自增，如果收到的投票的term比自己的小那么不会回复，如果比自己的大则投票给对方，如果一样就比较entry log id如果entry  log id大就投票给对方否则不投。entry log id是该节点在该term下的最大的entry log id。\n\n所以raft中因为随机超时时间的存在，极大地避免了同一时刻多个节点同时竞选的情形。能不能当leader取决于你现在的数据”够不够新“。\n\n### 怎么确保只有一个leader\n1. 在一个选举周期里（一个term内），一个节点只能投一票。\n2. 获得大半数票的节点才能成为leader。\n3. 获得leader的节点的term以及entry log id不能落后于其他的节点。\n4. 每个结点的“超时时间”是随机的，可以认为每个节点都不相同，同时竞选的可能性比较小。\n5. 如果一个leader 的term比另一个节点的term小，那么会自动变成follower\n\n## 数据的同步\n和zk的zab协议一样，raft也是先在大多数的节点上写入entry  log后，然后通知各个节点提交。但是在描述上二者有区别，raft第一阶段叫commit，第二阶段叫apply。log entry的示意图如下\n![](http://sysummery.top/raftlogentry.jpg)\n\nraft的每一个entry log都有一个entry log id，因此可以保证消息的顺序。\n\n### 正常的同步\n有了leader之后，集群的读写请求都要经过leader，follower只做备份。\n\n当leader收到一个写请求后会记录一个entry log，然后把这个entry发送给集群中的follower，其他的follower收到entry之后会发送确认信息给leader，如果leader收到超过一半的follower的确认信息之后就会把数据写进去（前面记录entry并不会apply数据），并通知其他follower写数据。\n\n任何一个follower重启后都会接收到leader的心跳，日志的内容也会与leader变成一致。\n\n如果是leader挂了，那么肯定是team和team index最大的那个称为新的leader\n\n### 重新选举leader后的数据同步\n这个我想说的通俗点，就是leader与follower比较各自已经commit的entrty log id。直至找到二者的第一个”共同点“。之后leader就会把”共同点“后面的entrty log同步给follower。\n\n下图是一个leader节点对应的follower的状态\n![](http://sysummery.top/raftlandf.png)\n\n如果follower是b,那么leader与follower会先找到term为4 entrty log id为4的日志的位置作为”共同点“，之后leader会把”共同点“后面的日志同步给follower。\n\n### State Machine Safety\n如果一个节点在某一个log entry的位置apply了这条log里面的command，那么其他节点也必须在这个log entry的位置apply这条log。\n","source":"_posts/raft-note.md","raw":"---\ntitle: Raft协议学习笔记\ndate: 2020-03-15 21:03:50\ntags:\n   - 分布式\nphotos:\n   - [\"http://sysummery.top/raft.jpg\"]\n---\nraft也是分布式系统的一个共识算法，号称比paxos更容易理解。\n<!--more-->\n## 状态机\nraft中有一个状态机的概念。如果多个节点的初始状态相同，所经历的操作（日志中记录的command）以及这些操作的顺序一致，那么每个节点最终的状态是一致的。\n\n## 节点的角色\nraft协议里面的角色有三类\n\n* leader 领导者\n* follower 追随者\n* candidate 候选者\n\n每一个节点一开始都是follower, 每个folloewr都会一个随机的“超时时间”，一但超时时间到了之后follower没有接收到leader的心跳自己就会变成candidate,然后发起一轮竞选，如果能收到大多数的票数就是竞选成功称为leader。因此raft中哪个节点的随机超时时间短，最开始就哪个节点有可能成为leader。\n\n## leader的选举\n1. leader节点维护着自己与follower的心跳。一但follower在自己的超时时间内没有收到leader的心跳，就变成candidate并发起选举并投自己一票。\n2. 给其他节点发送vote rpc请求\n3. 等待结果，如果收到大多数的票数，那么自己就是leader，此时会给其他的节点发送rpc消息告诉他们“我是leader”；如果被告知别人当选就变成follower。如果票数被瓜分，那么等到超时时间过了以后再次发起选举。\n\n当一个节点收到别人的选票的时候怎么判断是“投他还是投自己”？方法是比较term和entry log id。term可以理解为leader的任期，每个节点发起一轮选举的时候都会将自己的本地term_id自增，如果收到的投票的term比自己的小那么不会回复，如果比自己的大则投票给对方，如果一样就比较entry log id如果entry  log id大就投票给对方否则不投。entry log id是该节点在该term下的最大的entry log id。\n\n所以raft中因为随机超时时间的存在，极大地避免了同一时刻多个节点同时竞选的情形。能不能当leader取决于你现在的数据”够不够新“。\n\n### 怎么确保只有一个leader\n1. 在一个选举周期里（一个term内），一个节点只能投一票。\n2. 获得大半数票的节点才能成为leader。\n3. 获得leader的节点的term以及entry log id不能落后于其他的节点。\n4. 每个结点的“超时时间”是随机的，可以认为每个节点都不相同，同时竞选的可能性比较小。\n5. 如果一个leader 的term比另一个节点的term小，那么会自动变成follower\n\n## 数据的同步\n和zk的zab协议一样，raft也是先在大多数的节点上写入entry  log后，然后通知各个节点提交。但是在描述上二者有区别，raft第一阶段叫commit，第二阶段叫apply。log entry的示意图如下\n![](http://sysummery.top/raftlogentry.jpg)\n\nraft的每一个entry log都有一个entry log id，因此可以保证消息的顺序。\n\n### 正常的同步\n有了leader之后，集群的读写请求都要经过leader，follower只做备份。\n\n当leader收到一个写请求后会记录一个entry log，然后把这个entry发送给集群中的follower，其他的follower收到entry之后会发送确认信息给leader，如果leader收到超过一半的follower的确认信息之后就会把数据写进去（前面记录entry并不会apply数据），并通知其他follower写数据。\n\n任何一个follower重启后都会接收到leader的心跳，日志的内容也会与leader变成一致。\n\n如果是leader挂了，那么肯定是team和team index最大的那个称为新的leader\n\n### 重新选举leader后的数据同步\n这个我想说的通俗点，就是leader与follower比较各自已经commit的entrty log id。直至找到二者的第一个”共同点“。之后leader就会把”共同点“后面的entrty log同步给follower。\n\n下图是一个leader节点对应的follower的状态\n![](http://sysummery.top/raftlandf.png)\n\n如果follower是b,那么leader与follower会先找到term为4 entrty log id为4的日志的位置作为”共同点“，之后leader会把”共同点“后面的日志同步给follower。\n\n### State Machine Safety\n如果一个节点在某一个log entry的位置apply了这条log里面的command，那么其他节点也必须在这个log entry的位置apply这条log。\n","slug":"raft-note","published":1,"updated":"2020-11-23T15:23:47.779Z","comments":1,"layout":"post","link":"","_id":"ckhupaq9t000v1no8tf8i1gb5","content":"<p>raft也是分布式系统的一个共识算法，号称比paxos更容易理解。</p>\n<a id=\"more\"></a>\n<h2 id=\"状态机\"><a href=\"#状态机\" class=\"headerlink\" title=\"状态机\"></a>状态机</h2><p>raft中有一个状态机的概念。如果多个节点的初始状态相同，所经历的操作（日志中记录的command）以及这些操作的顺序一致，那么每个节点最终的状态是一致的。</p>\n<h2 id=\"节点的角色\"><a href=\"#节点的角色\" class=\"headerlink\" title=\"节点的角色\"></a>节点的角色</h2><p>raft协议里面的角色有三类</p>\n<ul>\n<li>leader 领导者</li>\n<li>follower 追随者</li>\n<li>candidate 候选者</li>\n</ul>\n<p>每一个节点一开始都是follower, 每个folloewr都会一个随机的“超时时间”，一但超时时间到了之后follower没有接收到leader的心跳自己就会变成candidate,然后发起一轮竞选，如果能收到大多数的票数就是竞选成功称为leader。因此raft中哪个节点的随机超时时间短，最开始就哪个节点有可能成为leader。</p>\n<h2 id=\"leader的选举\"><a href=\"#leader的选举\" class=\"headerlink\" title=\"leader的选举\"></a>leader的选举</h2><ol>\n<li>leader节点维护着自己与follower的心跳。一但follower在自己的超时时间内没有收到leader的心跳，就变成candidate并发起选举并投自己一票。</li>\n<li>给其他节点发送vote rpc请求</li>\n<li>等待结果，如果收到大多数的票数，那么自己就是leader，此时会给其他的节点发送rpc消息告诉他们“我是leader”；如果被告知别人当选就变成follower。如果票数被瓜分，那么等到超时时间过了以后再次发起选举。</li>\n</ol>\n<p>当一个节点收到别人的选票的时候怎么判断是“投他还是投自己”？方法是比较term和entry log id。term可以理解为leader的任期，每个节点发起一轮选举的时候都会将自己的本地term_id自增，如果收到的投票的term比自己的小那么不会回复，如果比自己的大则投票给对方，如果一样就比较entry log id如果entry  log id大就投票给对方否则不投。entry log id是该节点在该term下的最大的entry log id。</p>\n<p>所以raft中因为随机超时时间的存在，极大地避免了同一时刻多个节点同时竞选的情形。能不能当leader取决于你现在的数据”够不够新“。</p>\n<h3 id=\"怎么确保只有一个leader\"><a href=\"#怎么确保只有一个leader\" class=\"headerlink\" title=\"怎么确保只有一个leader\"></a>怎么确保只有一个leader</h3><ol>\n<li>在一个选举周期里（一个term内），一个节点只能投一票。</li>\n<li>获得大半数票的节点才能成为leader。</li>\n<li>获得leader的节点的term以及entry log id不能落后于其他的节点。</li>\n<li>每个结点的“超时时间”是随机的，可以认为每个节点都不相同，同时竞选的可能性比较小。</li>\n<li>如果一个leader 的term比另一个节点的term小，那么会自动变成follower</li>\n</ol>\n<h2 id=\"数据的同步\"><a href=\"#数据的同步\" class=\"headerlink\" title=\"数据的同步\"></a>数据的同步</h2><p>和zk的zab协议一样，raft也是先在大多数的节点上写入entry  log后，然后通知各个节点提交。但是在描述上二者有区别，raft第一阶段叫commit，第二阶段叫apply。log entry的示意图如下<br><img src=\"http://sysummery.top/raftlogentry.jpg\" alt></p>\n<p>raft的每一个entry log都有一个entry log id，因此可以保证消息的顺序。</p>\n<h3 id=\"正常的同步\"><a href=\"#正常的同步\" class=\"headerlink\" title=\"正常的同步\"></a>正常的同步</h3><p>有了leader之后，集群的读写请求都要经过leader，follower只做备份。</p>\n<p>当leader收到一个写请求后会记录一个entry log，然后把这个entry发送给集群中的follower，其他的follower收到entry之后会发送确认信息给leader，如果leader收到超过一半的follower的确认信息之后就会把数据写进去（前面记录entry并不会apply数据），并通知其他follower写数据。</p>\n<p>任何一个follower重启后都会接收到leader的心跳，日志的内容也会与leader变成一致。</p>\n<p>如果是leader挂了，那么肯定是team和team index最大的那个称为新的leader</p>\n<h3 id=\"重新选举leader后的数据同步\"><a href=\"#重新选举leader后的数据同步\" class=\"headerlink\" title=\"重新选举leader后的数据同步\"></a>重新选举leader后的数据同步</h3><p>这个我想说的通俗点，就是leader与follower比较各自已经commit的entrty log id。直至找到二者的第一个”共同点“。之后leader就会把”共同点“后面的entrty log同步给follower。</p>\n<p>下图是一个leader节点对应的follower的状态<br><img src=\"http://sysummery.top/raftlandf.png\" alt></p>\n<p>如果follower是b,那么leader与follower会先找到term为4 entrty log id为4的日志的位置作为”共同点“，之后leader会把”共同点“后面的日志同步给follower。</p>\n<h3 id=\"State-Machine-Safety\"><a href=\"#State-Machine-Safety\" class=\"headerlink\" title=\"State Machine Safety\"></a>State Machine Safety</h3><p>如果一个节点在某一个log entry的位置apply了这条log里面的command，那么其他节点也必须在这个log entry的位置apply这条log。</p>\n","site":{"data":{}},"excerpt":"<p>raft也是分布式系统的一个共识算法，号称比paxos更容易理解。</p>","more":"<h2 id=\"状态机\"><a href=\"#状态机\" class=\"headerlink\" title=\"状态机\"></a>状态机</h2><p>raft中有一个状态机的概念。如果多个节点的初始状态相同，所经历的操作（日志中记录的command）以及这些操作的顺序一致，那么每个节点最终的状态是一致的。</p>\n<h2 id=\"节点的角色\"><a href=\"#节点的角色\" class=\"headerlink\" title=\"节点的角色\"></a>节点的角色</h2><p>raft协议里面的角色有三类</p>\n<ul>\n<li>leader 领导者</li>\n<li>follower 追随者</li>\n<li>candidate 候选者</li>\n</ul>\n<p>每一个节点一开始都是follower, 每个folloewr都会一个随机的“超时时间”，一但超时时间到了之后follower没有接收到leader的心跳自己就会变成candidate,然后发起一轮竞选，如果能收到大多数的票数就是竞选成功称为leader。因此raft中哪个节点的随机超时时间短，最开始就哪个节点有可能成为leader。</p>\n<h2 id=\"leader的选举\"><a href=\"#leader的选举\" class=\"headerlink\" title=\"leader的选举\"></a>leader的选举</h2><ol>\n<li>leader节点维护着自己与follower的心跳。一但follower在自己的超时时间内没有收到leader的心跳，就变成candidate并发起选举并投自己一票。</li>\n<li>给其他节点发送vote rpc请求</li>\n<li>等待结果，如果收到大多数的票数，那么自己就是leader，此时会给其他的节点发送rpc消息告诉他们“我是leader”；如果被告知别人当选就变成follower。如果票数被瓜分，那么等到超时时间过了以后再次发起选举。</li>\n</ol>\n<p>当一个节点收到别人的选票的时候怎么判断是“投他还是投自己”？方法是比较term和entry log id。term可以理解为leader的任期，每个节点发起一轮选举的时候都会将自己的本地term_id自增，如果收到的投票的term比自己的小那么不会回复，如果比自己的大则投票给对方，如果一样就比较entry log id如果entry  log id大就投票给对方否则不投。entry log id是该节点在该term下的最大的entry log id。</p>\n<p>所以raft中因为随机超时时间的存在，极大地避免了同一时刻多个节点同时竞选的情形。能不能当leader取决于你现在的数据”够不够新“。</p>\n<h3 id=\"怎么确保只有一个leader\"><a href=\"#怎么确保只有一个leader\" class=\"headerlink\" title=\"怎么确保只有一个leader\"></a>怎么确保只有一个leader</h3><ol>\n<li>在一个选举周期里（一个term内），一个节点只能投一票。</li>\n<li>获得大半数票的节点才能成为leader。</li>\n<li>获得leader的节点的term以及entry log id不能落后于其他的节点。</li>\n<li>每个结点的“超时时间”是随机的，可以认为每个节点都不相同，同时竞选的可能性比较小。</li>\n<li>如果一个leader 的term比另一个节点的term小，那么会自动变成follower</li>\n</ol>\n<h2 id=\"数据的同步\"><a href=\"#数据的同步\" class=\"headerlink\" title=\"数据的同步\"></a>数据的同步</h2><p>和zk的zab协议一样，raft也是先在大多数的节点上写入entry  log后，然后通知各个节点提交。但是在描述上二者有区别，raft第一阶段叫commit，第二阶段叫apply。log entry的示意图如下<br><img src=\"http://sysummery.top/raftlogentry.jpg\" alt></p>\n<p>raft的每一个entry log都有一个entry log id，因此可以保证消息的顺序。</p>\n<h3 id=\"正常的同步\"><a href=\"#正常的同步\" class=\"headerlink\" title=\"正常的同步\"></a>正常的同步</h3><p>有了leader之后，集群的读写请求都要经过leader，follower只做备份。</p>\n<p>当leader收到一个写请求后会记录一个entry log，然后把这个entry发送给集群中的follower，其他的follower收到entry之后会发送确认信息给leader，如果leader收到超过一半的follower的确认信息之后就会把数据写进去（前面记录entry并不会apply数据），并通知其他follower写数据。</p>\n<p>任何一个follower重启后都会接收到leader的心跳，日志的内容也会与leader变成一致。</p>\n<p>如果是leader挂了，那么肯定是team和team index最大的那个称为新的leader</p>\n<h3 id=\"重新选举leader后的数据同步\"><a href=\"#重新选举leader后的数据同步\" class=\"headerlink\" title=\"重新选举leader后的数据同步\"></a>重新选举leader后的数据同步</h3><p>这个我想说的通俗点，就是leader与follower比较各自已经commit的entrty log id。直至找到二者的第一个”共同点“。之后leader就会把”共同点“后面的entrty log同步给follower。</p>\n<p>下图是一个leader节点对应的follower的状态<br><img src=\"http://sysummery.top/raftlandf.png\" alt></p>\n<p>如果follower是b,那么leader与follower会先找到term为4 entrty log id为4的日志的位置作为”共同点“，之后leader会把”共同点“后面的日志同步给follower。</p>\n<h3 id=\"State-Machine-Safety\"><a href=\"#State-Machine-Safety\" class=\"headerlink\" title=\"State Machine Safety\"></a>State Machine Safety</h3><p>如果一个节点在某一个log entry的位置apply了这条log里面的command，那么其他节点也必须在这个log entry的位置apply这条log。</p>"},{"title":"Mysql中的日志文件","date":"2019-11-17T00:52:53.000Z","photos":["http://sysummery.top/mysql_cover.jpg"],"_content":"mysql中有很多重要的日志文件，这些日志文件主要可以分为两大类：服务器的日志文件以及存储引擎的日志文件。平时我们用的存储引擎都是innodb，因此今天介绍的存储引擎的日志文件也是innodb的日志文件。\n<!--more-->\n## 服务器日志文件\n* error log 错误日志\n* slow query log 慢查询日志\n* bin log 二进制日志\n* relay log 中继日志\n\n\n## innodb存储引擎的日志\n\n* redo log 重做日志\n* undo log 撤回日志\n\n### 1.1 error log\nerror log存在于数据库的数据根目录下。用于记录mysql的启动、运行、关闭的过程中出现的错误和警告。在mysql启动异常的时候尤其有用。可以通过以下的命令来查看error log的具体的位置\n\n```sql\n show variables like 'log_error'\\G\n```\n### 1.2 slow query log\nslow query log 记录了所有查询时间大于(不包括等于)查询阈值的sql语句。可以通过以下命令获取查询阈值\n\n```sql\nshow variables like 'long_query_time'\\G\n```\n另一个和慢查询日志有关的参数是`log_queries_not_using_indexes`,表示如果查询没有用到索引也会被记录到慢查询日志当中去，无论有没有超过查询阈值。\n\n### 1.3 bin log\nbin log记录的mysql所有数据库的所有数据表的更改的所有操作，无论使用的是什么存储引擎。他也是唯一一个使用二进制记录的日志。如果在更新一条记录的一个字段的时候是用原值更新的那么这条记录并没有改变但是还是会写入bin log。\n\nbin log主要用来复制，在主库上源源不断的产生bin log并同步给各个从库来保证主从之间的数据一致。\n\nbin log也可以以支持point-in-time的数据恢复。\n\nbin log 的格式主要有三种\n1. row 基于每一行\n2. statement 基于sql语句\n3. mixed 既有row形式的又有statement形式的\n\n### 1.4 relay log\n在从库中会有一个专门的IO线程不断的从主库中读取bin log并把读取的内容写入relay log中。然后会有另外的线程会将新产生的relay log重放到从库中。主从复制的流程大致为\n\n![](http://sysummery.top/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_cde5d8b5-3035-4efa-bb0b-367394045f75.png)\n### 2.1 redo log\n存在于共享表空间中，是**物理日志**，记录的是一个事务中数据页的变化信息，不是某行的数据的变化信息。\n\n用于保证事务的持久性。在使用innodb存储引擎的时候，当一页数据被更新时首先在innodb的缓冲池中进行更新，然后才会根据一定的策略异步刷新回磁盘。那么问题来了，如果缓冲池中的数据页还未来的急刷新回磁盘服务器就宕机了怎么办？innodb是采用的日志先于数据刷新到磁盘的策略。\n\n每当一个事务写入数据的时候，innodb会向redo log缓存里写入**数据页**的物理变化信息，并以一定的策略更新到硬盘上。等到事务提交的时候强制redo log把数据页信息的更改更新到磁盘上。也就是说，当事务提交成功后相应的数据页可能还没更新到磁盘上，但是redo log一定更新到了磁盘上。如果此时宕机，那么innodb在重启时可以根据redo log来更新数据。\n\n如果缓冲池中的脏页都已经刷新到磁盘了，那么redo log就相当于完成了他的使命。\n\nredo log每次更新到磁盘的数据大小都是512kb，正好是一个扇区的大小，因此这个过程是原子性的。\n\nredo log刷新回磁盘的策略\n\n1. 主线程每秒刷新一次\n2. 每次事务提交时\n3. 当redo log的可用空间少于一半的时候\n\n因此，redo log写入磁盘不是在事务提交的那一刹那完成的，是在提交之前就已经开始“运动”了。所以即使一个大的事务提交，redo log的写入磁盘都会很快，不会成为事务提交慢的原因。\n\n### 2.2 undo log\n存在于共享表空间里，5.7可以存放在单独的表空间里。是存放在一个叫做undo log segment里面。undo log不像redo log那样有缓冲池，是顺序的往物理页上面写的。\n\nundo log记录的是一个事务中数据的逻辑改变。如果你删除一条数据那么他就增加一条数据，如果你更改一条数据那么他就反向更改一条数据。\n\nundo log的作用主要有两点\n\n1. 用于事务的回滚\n2. 用于MVCC\n\n每当一个事务开启的时候，当要更新一条数据的时候会先写undo log，只有undo log成功的写入了，整个事务才会有“后路”，才能回滚。之后才是写数据写redo log。特别需要注意的是，undo log 也是 redo log的保护对象，每一条undo log的写入都会有redo log的写入。\n\n当一条数据被事务T1修改中，此时T2事务中想要读取此数据，那么T2读取的永远是T1还未修改的那个版本，这就能保证在T2中不会出现幻读的情况。\n\n当一条数据更新时先写undo log，再写数据，再写redo log。\n\nundo log是数据库并发(MVCC)的关关键。innodb为每一行的数据都分配了两个隐藏的列：**事务id和回滚指针**。事务id能代表当前哪个事务正在写这行数据。回滚指针指向undo log中的这条数据的“上一个版本”，一单回滚就使用undo log中的日志恢复数据。undo log与read view一起工作实现了innodb的MVCC。\n","source":"_posts/the-log-files-in-mysql.md","raw":"---\ntitle: Mysql中的日志文件\ndate: 2019-11-17 08:52:53\ntags:\n    - mysql\n    - innodb\nphotos:\n    - [\"http://sysummery.top/mysql_cover.jpg\"]\n---\nmysql中有很多重要的日志文件，这些日志文件主要可以分为两大类：服务器的日志文件以及存储引擎的日志文件。平时我们用的存储引擎都是innodb，因此今天介绍的存储引擎的日志文件也是innodb的日志文件。\n<!--more-->\n## 服务器日志文件\n* error log 错误日志\n* slow query log 慢查询日志\n* bin log 二进制日志\n* relay log 中继日志\n\n\n## innodb存储引擎的日志\n\n* redo log 重做日志\n* undo log 撤回日志\n\n### 1.1 error log\nerror log存在于数据库的数据根目录下。用于记录mysql的启动、运行、关闭的过程中出现的错误和警告。在mysql启动异常的时候尤其有用。可以通过以下的命令来查看error log的具体的位置\n\n```sql\n show variables like 'log_error'\\G\n```\n### 1.2 slow query log\nslow query log 记录了所有查询时间大于(不包括等于)查询阈值的sql语句。可以通过以下命令获取查询阈值\n\n```sql\nshow variables like 'long_query_time'\\G\n```\n另一个和慢查询日志有关的参数是`log_queries_not_using_indexes`,表示如果查询没有用到索引也会被记录到慢查询日志当中去，无论有没有超过查询阈值。\n\n### 1.3 bin log\nbin log记录的mysql所有数据库的所有数据表的更改的所有操作，无论使用的是什么存储引擎。他也是唯一一个使用二进制记录的日志。如果在更新一条记录的一个字段的时候是用原值更新的那么这条记录并没有改变但是还是会写入bin log。\n\nbin log主要用来复制，在主库上源源不断的产生bin log并同步给各个从库来保证主从之间的数据一致。\n\nbin log也可以以支持point-in-time的数据恢复。\n\nbin log 的格式主要有三种\n1. row 基于每一行\n2. statement 基于sql语句\n3. mixed 既有row形式的又有statement形式的\n\n### 1.4 relay log\n在从库中会有一个专门的IO线程不断的从主库中读取bin log并把读取的内容写入relay log中。然后会有另外的线程会将新产生的relay log重放到从库中。主从复制的流程大致为\n\n![](http://sysummery.top/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_cde5d8b5-3035-4efa-bb0b-367394045f75.png)\n### 2.1 redo log\n存在于共享表空间中，是**物理日志**，记录的是一个事务中数据页的变化信息，不是某行的数据的变化信息。\n\n用于保证事务的持久性。在使用innodb存储引擎的时候，当一页数据被更新时首先在innodb的缓冲池中进行更新，然后才会根据一定的策略异步刷新回磁盘。那么问题来了，如果缓冲池中的数据页还未来的急刷新回磁盘服务器就宕机了怎么办？innodb是采用的日志先于数据刷新到磁盘的策略。\n\n每当一个事务写入数据的时候，innodb会向redo log缓存里写入**数据页**的物理变化信息，并以一定的策略更新到硬盘上。等到事务提交的时候强制redo log把数据页信息的更改更新到磁盘上。也就是说，当事务提交成功后相应的数据页可能还没更新到磁盘上，但是redo log一定更新到了磁盘上。如果此时宕机，那么innodb在重启时可以根据redo log来更新数据。\n\n如果缓冲池中的脏页都已经刷新到磁盘了，那么redo log就相当于完成了他的使命。\n\nredo log每次更新到磁盘的数据大小都是512kb，正好是一个扇区的大小，因此这个过程是原子性的。\n\nredo log刷新回磁盘的策略\n\n1. 主线程每秒刷新一次\n2. 每次事务提交时\n3. 当redo log的可用空间少于一半的时候\n\n因此，redo log写入磁盘不是在事务提交的那一刹那完成的，是在提交之前就已经开始“运动”了。所以即使一个大的事务提交，redo log的写入磁盘都会很快，不会成为事务提交慢的原因。\n\n### 2.2 undo log\n存在于共享表空间里，5.7可以存放在单独的表空间里。是存放在一个叫做undo log segment里面。undo log不像redo log那样有缓冲池，是顺序的往物理页上面写的。\n\nundo log记录的是一个事务中数据的逻辑改变。如果你删除一条数据那么他就增加一条数据，如果你更改一条数据那么他就反向更改一条数据。\n\nundo log的作用主要有两点\n\n1. 用于事务的回滚\n2. 用于MVCC\n\n每当一个事务开启的时候，当要更新一条数据的时候会先写undo log，只有undo log成功的写入了，整个事务才会有“后路”，才能回滚。之后才是写数据写redo log。特别需要注意的是，undo log 也是 redo log的保护对象，每一条undo log的写入都会有redo log的写入。\n\n当一条数据被事务T1修改中，此时T2事务中想要读取此数据，那么T2读取的永远是T1还未修改的那个版本，这就能保证在T2中不会出现幻读的情况。\n\n当一条数据更新时先写undo log，再写数据，再写redo log。\n\nundo log是数据库并发(MVCC)的关关键。innodb为每一行的数据都分配了两个隐藏的列：**事务id和回滚指针**。事务id能代表当前哪个事务正在写这行数据。回滚指针指向undo log中的这条数据的“上一个版本”，一单回滚就使用undo log中的日志恢复数据。undo log与read view一起工作实现了innodb的MVCC。\n","slug":"the-log-files-in-mysql","published":1,"updated":"2020-11-23T15:23:47.780Z","comments":1,"layout":"post","link":"","_id":"ckhupaq9v000y1no8wau7mebv","content":"<p>mysql中有很多重要的日志文件，这些日志文件主要可以分为两大类：服务器的日志文件以及存储引擎的日志文件。平时我们用的存储引擎都是innodb，因此今天介绍的存储引擎的日志文件也是innodb的日志文件。</p>\n<a id=\"more\"></a>\n<h2 id=\"服务器日志文件\"><a href=\"#服务器日志文件\" class=\"headerlink\" title=\"服务器日志文件\"></a>服务器日志文件</h2><ul>\n<li>error log 错误日志</li>\n<li>slow query log 慢查询日志</li>\n<li>bin log 二进制日志</li>\n<li>relay log 中继日志</li>\n</ul>\n<h2 id=\"innodb存储引擎的日志\"><a href=\"#innodb存储引擎的日志\" class=\"headerlink\" title=\"innodb存储引擎的日志\"></a>innodb存储引擎的日志</h2><ul>\n<li>redo log 重做日志</li>\n<li>undo log 撤回日志</li>\n</ul>\n<h3 id=\"1-1-error-log\"><a href=\"#1-1-error-log\" class=\"headerlink\" title=\"1.1 error log\"></a>1.1 error log</h3><p>error log存在于数据库的数据根目录下。用于记录mysql的启动、运行、关闭的过程中出现的错误和警告。在mysql启动异常的时候尤其有用。可以通过以下的命令来查看error log的具体的位置</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'log_error'</span>\\G</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"1-2-slow-query-log\"><a href=\"#1-2-slow-query-log\" class=\"headerlink\" title=\"1.2 slow query log\"></a>1.2 slow query log</h3><p>slow query log 记录了所有查询时间大于(不包括等于)查询阈值的sql语句。可以通过以下命令获取查询阈值</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'long_query_time'</span>\\G</span><br></pre></td></tr></table></figure>\n\n<p>另一个和慢查询日志有关的参数是<code>log_queries_not_using_indexes</code>,表示如果查询没有用到索引也会被记录到慢查询日志当中去，无论有没有超过查询阈值。</p>\n<h3 id=\"1-3-bin-log\"><a href=\"#1-3-bin-log\" class=\"headerlink\" title=\"1.3 bin log\"></a>1.3 bin log</h3><p>bin log记录的mysql所有数据库的所有数据表的更改的所有操作，无论使用的是什么存储引擎。他也是唯一一个使用二进制记录的日志。如果在更新一条记录的一个字段的时候是用原值更新的那么这条记录并没有改变但是还是会写入bin log。</p>\n<p>bin log主要用来复制，在主库上源源不断的产生bin log并同步给各个从库来保证主从之间的数据一致。</p>\n<p>bin log也可以以支持point-in-time的数据恢复。</p>\n<p>bin log 的格式主要有三种</p>\n<ol>\n<li>row 基于每一行</li>\n<li>statement 基于sql语句</li>\n<li>mixed 既有row形式的又有statement形式的</li>\n</ol>\n<h3 id=\"1-4-relay-log\"><a href=\"#1-4-relay-log\" class=\"headerlink\" title=\"1.4 relay log\"></a>1.4 relay log</h3><p>在从库中会有一个专门的IO线程不断的从主库中读取bin log并把读取的内容写入relay log中。然后会有另外的线程会将新产生的relay log重放到从库中。主从复制的流程大致为</p>\n<p><img src=\"http://sysummery.top/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_cde5d8b5-3035-4efa-bb0b-367394045f75.png\" alt></p>\n<h3 id=\"2-1-redo-log\"><a href=\"#2-1-redo-log\" class=\"headerlink\" title=\"2.1 redo log\"></a>2.1 redo log</h3><p>存在于共享表空间中，是<strong>物理日志</strong>，记录的是一个事务中数据页的变化信息，不是某行的数据的变化信息。</p>\n<p>用于保证事务的持久性。在使用innodb存储引擎的时候，当一页数据被更新时首先在innodb的缓冲池中进行更新，然后才会根据一定的策略异步刷新回磁盘。那么问题来了，如果缓冲池中的数据页还未来的急刷新回磁盘服务器就宕机了怎么办？innodb是采用的日志先于数据刷新到磁盘的策略。</p>\n<p>每当一个事务写入数据的时候，innodb会向redo log缓存里写入<strong>数据页</strong>的物理变化信息，并以一定的策略更新到硬盘上。等到事务提交的时候强制redo log把数据页信息的更改更新到磁盘上。也就是说，当事务提交成功后相应的数据页可能还没更新到磁盘上，但是redo log一定更新到了磁盘上。如果此时宕机，那么innodb在重启时可以根据redo log来更新数据。</p>\n<p>如果缓冲池中的脏页都已经刷新到磁盘了，那么redo log就相当于完成了他的使命。</p>\n<p>redo log每次更新到磁盘的数据大小都是512kb，正好是一个扇区的大小，因此这个过程是原子性的。</p>\n<p>redo log刷新回磁盘的策略</p>\n<ol>\n<li>主线程每秒刷新一次</li>\n<li>每次事务提交时</li>\n<li>当redo log的可用空间少于一半的时候</li>\n</ol>\n<p>因此，redo log写入磁盘不是在事务提交的那一刹那完成的，是在提交之前就已经开始“运动”了。所以即使一个大的事务提交，redo log的写入磁盘都会很快，不会成为事务提交慢的原因。</p>\n<h3 id=\"2-2-undo-log\"><a href=\"#2-2-undo-log\" class=\"headerlink\" title=\"2.2 undo log\"></a>2.2 undo log</h3><p>存在于共享表空间里，5.7可以存放在单独的表空间里。是存放在一个叫做undo log segment里面。undo log不像redo log那样有缓冲池，是顺序的往物理页上面写的。</p>\n<p>undo log记录的是一个事务中数据的逻辑改变。如果你删除一条数据那么他就增加一条数据，如果你更改一条数据那么他就反向更改一条数据。</p>\n<p>undo log的作用主要有两点</p>\n<ol>\n<li>用于事务的回滚</li>\n<li>用于MVCC</li>\n</ol>\n<p>每当一个事务开启的时候，当要更新一条数据的时候会先写undo log，只有undo log成功的写入了，整个事务才会有“后路”，才能回滚。之后才是写数据写redo log。特别需要注意的是，undo log 也是 redo log的保护对象，每一条undo log的写入都会有redo log的写入。</p>\n<p>当一条数据被事务T1修改中，此时T2事务中想要读取此数据，那么T2读取的永远是T1还未修改的那个版本，这就能保证在T2中不会出现幻读的情况。</p>\n<p>当一条数据更新时先写undo log，再写数据，再写redo log。</p>\n<p>undo log是数据库并发(MVCC)的关关键。innodb为每一行的数据都分配了两个隐藏的列：<strong>事务id和回滚指针</strong>。事务id能代表当前哪个事务正在写这行数据。回滚指针指向undo log中的这条数据的“上一个版本”，一单回滚就使用undo log中的日志恢复数据。undo log与read view一起工作实现了innodb的MVCC。</p>\n","site":{"data":{}},"excerpt":"<p>mysql中有很多重要的日志文件，这些日志文件主要可以分为两大类：服务器的日志文件以及存储引擎的日志文件。平时我们用的存储引擎都是innodb，因此今天介绍的存储引擎的日志文件也是innodb的日志文件。</p>","more":"<h2 id=\"服务器日志文件\"><a href=\"#服务器日志文件\" class=\"headerlink\" title=\"服务器日志文件\"></a>服务器日志文件</h2><ul>\n<li>error log 错误日志</li>\n<li>slow query log 慢查询日志</li>\n<li>bin log 二进制日志</li>\n<li>relay log 中继日志</li>\n</ul>\n<h2 id=\"innodb存储引擎的日志\"><a href=\"#innodb存储引擎的日志\" class=\"headerlink\" title=\"innodb存储引擎的日志\"></a>innodb存储引擎的日志</h2><ul>\n<li>redo log 重做日志</li>\n<li>undo log 撤回日志</li>\n</ul>\n<h3 id=\"1-1-error-log\"><a href=\"#1-1-error-log\" class=\"headerlink\" title=\"1.1 error log\"></a>1.1 error log</h3><p>error log存在于数据库的数据根目录下。用于记录mysql的启动、运行、关闭的过程中出现的错误和警告。在mysql启动异常的时候尤其有用。可以通过以下的命令来查看error log的具体的位置</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'log_error'</span>\\G</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"1-2-slow-query-log\"><a href=\"#1-2-slow-query-log\" class=\"headerlink\" title=\"1.2 slow query log\"></a>1.2 slow query log</h3><p>slow query log 记录了所有查询时间大于(不包括等于)查询阈值的sql语句。可以通过以下命令获取查询阈值</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">show</span> <span class=\"keyword\">variables</span> <span class=\"keyword\">like</span> <span class=\"string\">'long_query_time'</span>\\G</span><br></pre></td></tr></table></figure>\n\n<p>另一个和慢查询日志有关的参数是<code>log_queries_not_using_indexes</code>,表示如果查询没有用到索引也会被记录到慢查询日志当中去，无论有没有超过查询阈值。</p>\n<h3 id=\"1-3-bin-log\"><a href=\"#1-3-bin-log\" class=\"headerlink\" title=\"1.3 bin log\"></a>1.3 bin log</h3><p>bin log记录的mysql所有数据库的所有数据表的更改的所有操作，无论使用的是什么存储引擎。他也是唯一一个使用二进制记录的日志。如果在更新一条记录的一个字段的时候是用原值更新的那么这条记录并没有改变但是还是会写入bin log。</p>\n<p>bin log主要用来复制，在主库上源源不断的产生bin log并同步给各个从库来保证主从之间的数据一致。</p>\n<p>bin log也可以以支持point-in-time的数据恢复。</p>\n<p>bin log 的格式主要有三种</p>\n<ol>\n<li>row 基于每一行</li>\n<li>statement 基于sql语句</li>\n<li>mixed 既有row形式的又有statement形式的</li>\n</ol>\n<h3 id=\"1-4-relay-log\"><a href=\"#1-4-relay-log\" class=\"headerlink\" title=\"1.4 relay log\"></a>1.4 relay log</h3><p>在从库中会有一个专门的IO线程不断的从主库中读取bin log并把读取的内容写入relay log中。然后会有另外的线程会将新产生的relay log重放到从库中。主从复制的流程大致为</p>\n<p><img src=\"http://sysummery.top/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_cde5d8b5-3035-4efa-bb0b-367394045f75.png\" alt></p>\n<h3 id=\"2-1-redo-log\"><a href=\"#2-1-redo-log\" class=\"headerlink\" title=\"2.1 redo log\"></a>2.1 redo log</h3><p>存在于共享表空间中，是<strong>物理日志</strong>，记录的是一个事务中数据页的变化信息，不是某行的数据的变化信息。</p>\n<p>用于保证事务的持久性。在使用innodb存储引擎的时候，当一页数据被更新时首先在innodb的缓冲池中进行更新，然后才会根据一定的策略异步刷新回磁盘。那么问题来了，如果缓冲池中的数据页还未来的急刷新回磁盘服务器就宕机了怎么办？innodb是采用的日志先于数据刷新到磁盘的策略。</p>\n<p>每当一个事务写入数据的时候，innodb会向redo log缓存里写入<strong>数据页</strong>的物理变化信息，并以一定的策略更新到硬盘上。等到事务提交的时候强制redo log把数据页信息的更改更新到磁盘上。也就是说，当事务提交成功后相应的数据页可能还没更新到磁盘上，但是redo log一定更新到了磁盘上。如果此时宕机，那么innodb在重启时可以根据redo log来更新数据。</p>\n<p>如果缓冲池中的脏页都已经刷新到磁盘了，那么redo log就相当于完成了他的使命。</p>\n<p>redo log每次更新到磁盘的数据大小都是512kb，正好是一个扇区的大小，因此这个过程是原子性的。</p>\n<p>redo log刷新回磁盘的策略</p>\n<ol>\n<li>主线程每秒刷新一次</li>\n<li>每次事务提交时</li>\n<li>当redo log的可用空间少于一半的时候</li>\n</ol>\n<p>因此，redo log写入磁盘不是在事务提交的那一刹那完成的，是在提交之前就已经开始“运动”了。所以即使一个大的事务提交，redo log的写入磁盘都会很快，不会成为事务提交慢的原因。</p>\n<h3 id=\"2-2-undo-log\"><a href=\"#2-2-undo-log\" class=\"headerlink\" title=\"2.2 undo log\"></a>2.2 undo log</h3><p>存在于共享表空间里，5.7可以存放在单独的表空间里。是存放在一个叫做undo log segment里面。undo log不像redo log那样有缓冲池，是顺序的往物理页上面写的。</p>\n<p>undo log记录的是一个事务中数据的逻辑改变。如果你删除一条数据那么他就增加一条数据，如果你更改一条数据那么他就反向更改一条数据。</p>\n<p>undo log的作用主要有两点</p>\n<ol>\n<li>用于事务的回滚</li>\n<li>用于MVCC</li>\n</ol>\n<p>每当一个事务开启的时候，当要更新一条数据的时候会先写undo log，只有undo log成功的写入了，整个事务才会有“后路”，才能回滚。之后才是写数据写redo log。特别需要注意的是，undo log 也是 redo log的保护对象，每一条undo log的写入都会有redo log的写入。</p>\n<p>当一条数据被事务T1修改中，此时T2事务中想要读取此数据，那么T2读取的永远是T1还未修改的那个版本，这就能保证在T2中不会出现幻读的情况。</p>\n<p>当一条数据更新时先写undo log，再写数据，再写redo log。</p>\n<p>undo log是数据库并发(MVCC)的关关键。innodb为每一行的数据都分配了两个隐藏的列：<strong>事务id和回滚指针</strong>。事务id能代表当前哪个事务正在写这行数据。回滚指针指向undo log中的这条数据的“上一个版本”，一单回滚就使用undo log中的日志恢复数据。undo log与read view一起工作实现了innodb的MVCC。</p>"},{"title":"ZooKeeper总结","date":"2020-03-17T05:17:11.000Z","_content":"ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。\n<!--more-->\n## zookeeper所能提供的功能\n\n### 命名服务\n在zk下创建一个节点作为服务，然后节点下面的子节点中存放该服务的各个机器的ip\n\n### 配置管理\n在zk下存放一个节点，当节点的数据发生变化的时候通知watch这个节点的client\n\n### 集群管理\n当一个服务的集群增加或者减少机器的时候会在相应的服务节点上增加或删除子节点并通知watch这个服务节点的的所有的client。如果子节点是顺序节点，那么可以顺理成章的把编号最小的那个作为master\n\n### 选举算法\n所有的节点都向zk的一个路径下面创建临时有序节点,序号最小的那个就是leader。\n\n### 锁定和同步\n保持独占：各个client在zk上创建一个相同的znode，创建成功的client就相当于获取到了锁。保持独占这个方法实现比较简单，但是zk是leader负责写入的，如果很多个客户端同时写的话会有问题。\n控制时序：各个client往一个znode下面创建临时有序节点，创建的节点的编号最小的client获取到了锁。没获取到锁的client开始watch这个znode下面的节点。获取到锁的client执行完后删除这个锁节点，其他watch的client会受到通知然后看谁的编号最小谁就获取到了这个锁\n\n获取锁的时候，创建的节点都是暂时的，如果获得锁的进程意外退出，那么这个暂时的节点会立马被删除。\n\n### 高度可靠地数据注册表\n\n![](http://sysummery.top/zkc.jpg)\n## znode\nZooKeeper命名空间内部拥有一个树状的内存模型，其中各节点被称为znode。每个znode包含一个路径和与之相关的元数据，以及该znode下关联的子节点列表。\n![](http://sysummery.top/znode.png)\n\n### znode节点类型\n\n1. 持久节点\n2. 持久顺序节点\n3. 临时节点\n4. 临时顺序节点\n\nznode可以存储一些数据外还有一些元数据\n\n* czxid 创建节点的事务id\n* ctime 创建时间\n* mzxid 最后一次更新节点的事务id\n* mtime 最后一次更新时间\n* dataLength 数据长度\n* numChildren 子节点数\n\n## 会话\n一个客户端与zookeeper连接后就形成了一个会话，客户端通过心跳与zookeeper保持联系。一单在超时时间内zookeeper没有收到心跳，就认为客户端已经“失联”，该客户端创建的所有临时znode都会被删除。\n\n## 监视\n客户端在读取特定的znode时可以设置监视这个znode，一单这个znode发生白变化客户端就会收到通知。\n\n## 节点的角色\n\n1. leader\n2. follower\n3. observer\n\n这3中角色的节点都能接受客户端的连接，都能响应读请求。如果follower或者observer收到了写请求会把这个请求转发给leader。\n\nobserver节点不会参与leader的选举。\n\n为什么有observer？如果连接的客户端很多，那么就要扩充zk的节点数量。扩充了之后在选举的时候就会”变慢“，因此引入observer，扩充了节点数量但是参与投票的节点还没有那么多。\n\n## 节点的状态\n1. leading 该节点目前是leader\n2. following 该节点目前是follower\n3. looking 该节点找不到leader，正在“寻找”leader\n4. observering 该节点是observer\n\n## 选举\n选举出现在三种情况\n\n1. 集群启动的时候。\n2. leader出问题了，需要重新选举。\n3. zxid的高位或者低位用尽。\n\n在选取leader的过程中zookeeper集群是不可用的。\nleaer通过心跳与follower和observer通信。当follower失去与leader的联系后会进入looking状态并“投自己一票”然后向集群内的其他节点广播。\n\n选举的核心逻辑就是比较。比较什么呢？比较logicClock、zxid和serverid。 \n\n* logicClock是投票的轮数，每个节点发起投票的时候会将自己的logicClock加1。如果一个节点收到其他节点的投票的时候发现对方的logicClock比自己的小那么会直接忽略该投票。如果发现比自己的大，那么会更新自己的logicClock并重新广播自己的投票（自己的投票之前可能已经被别的节点忽略了）。如果logicClock一样大就去比较zxid。\n* zxid是一个64位的数字，类似于事务id。前32位是epoch，有点类似于raft中的term, 每一次新leader的产生都会使前32位加1。后32位是此次“epoch”周期内的单调递增id。如果zxid一样就去比较serverid。\n* serverid是集群内每个机器的id，一个zk集群在启动的时候就已经确认好了这个集群有几个节点。每一个节点的配置文件里都有这个集群每一个节点的信息。\n\n**一但zxid的高位或者低位用尽则会重新强制重新选举。**\n\n每次选举的时候各个节点首先都是“先投自己一票”然后广播。每一个follower收到“其他节点的投票”的时候都会与自己刚刚投的票相比较（logicClock、zxid和server id），如果自己被pk下去了那么就更新自己本地的投票然后广播，如果不需要修改就什么都不做。\n\n因为每一个节点的投票信息其他的节点都会通过广播收到，因此每一个节点都有当前整个集群中所有节点的投票信息。一但有一个节点获取到了大多数票那么投票就结束了。\n\n如果一个节点新加入或者宕机后新加入，首先会发起选举，但是其他的节点会告诉他我们已经有leader了，然后此节点会自动变成follower。\n\n如果集群刚启动或者leader出现了问题，那么集群会进入崩溃恢复模式选举产生新的leader。新的leader出现后，**有超过半数的follower已经与leader同步过数据后集群就进入了消息广播模式，即正常工作模式**\n\n## 数据同步\n### 正常的同步\nzookeepe使用自己的zab协议实现数据同步。\n写请求都会转发到leader上，随后leader会发出一个proposal，**leader与follower之间的通信是通过队列来实现的并且每个proposal都有一个唯一的zxid**，因此保证了follower中数据写入的顺序。当follower收到proposal后会写入本地日志到磁盘，并返回ack给leader。leader收到大多数的follower的ack后自己commit然后通知各个follower也commit同时返回客户端结果。\n\n### 重新选举出leader后的同步\n新leader先判断自己的未被commit的proposa是否能够commit（依据是此时整个集群额大多数节点都有这个proposal），如果可以就commit，如果不可以就不commit。因此最开始是先搞好leader的数据，之后leader会告诉follower增减数据。\n\n### 如果leader刚发出proposal就宕机了，follower都没有收到\n\n那么新产生的leader将不知道有这个proposal，也就相当于这个proposal被废掉了，即使之前的leader加入集群，这个proposal也会被新的leader废掉。\n\n### 如果leader收到大多数的ack，但是还没有commit\n收到的这些follower中肯定会有一个是新的leader。在其成为leader后会“领导大家”commit这个proposal\n\n## zk保证了一致性和分区可用性，在选举leader的时候集群不可用，牺牲了可用性\n","source":"_posts/zk-first-exploration.md","raw":"---\ntitle: ZooKeeper总结\ndate: 2020-03-17 13:17:11\ntags:\n   - 分布式\nphoto:\n   - [http://sysummery.top/zk.png]\n---\nZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。\n<!--more-->\n## zookeeper所能提供的功能\n\n### 命名服务\n在zk下创建一个节点作为服务，然后节点下面的子节点中存放该服务的各个机器的ip\n\n### 配置管理\n在zk下存放一个节点，当节点的数据发生变化的时候通知watch这个节点的client\n\n### 集群管理\n当一个服务的集群增加或者减少机器的时候会在相应的服务节点上增加或删除子节点并通知watch这个服务节点的的所有的client。如果子节点是顺序节点，那么可以顺理成章的把编号最小的那个作为master\n\n### 选举算法\n所有的节点都向zk的一个路径下面创建临时有序节点,序号最小的那个就是leader。\n\n### 锁定和同步\n保持独占：各个client在zk上创建一个相同的znode，创建成功的client就相当于获取到了锁。保持独占这个方法实现比较简单，但是zk是leader负责写入的，如果很多个客户端同时写的话会有问题。\n控制时序：各个client往一个znode下面创建临时有序节点，创建的节点的编号最小的client获取到了锁。没获取到锁的client开始watch这个znode下面的节点。获取到锁的client执行完后删除这个锁节点，其他watch的client会受到通知然后看谁的编号最小谁就获取到了这个锁\n\n获取锁的时候，创建的节点都是暂时的，如果获得锁的进程意外退出，那么这个暂时的节点会立马被删除。\n\n### 高度可靠地数据注册表\n\n![](http://sysummery.top/zkc.jpg)\n## znode\nZooKeeper命名空间内部拥有一个树状的内存模型，其中各节点被称为znode。每个znode包含一个路径和与之相关的元数据，以及该znode下关联的子节点列表。\n![](http://sysummery.top/znode.png)\n\n### znode节点类型\n\n1. 持久节点\n2. 持久顺序节点\n3. 临时节点\n4. 临时顺序节点\n\nznode可以存储一些数据外还有一些元数据\n\n* czxid 创建节点的事务id\n* ctime 创建时间\n* mzxid 最后一次更新节点的事务id\n* mtime 最后一次更新时间\n* dataLength 数据长度\n* numChildren 子节点数\n\n## 会话\n一个客户端与zookeeper连接后就形成了一个会话，客户端通过心跳与zookeeper保持联系。一单在超时时间内zookeeper没有收到心跳，就认为客户端已经“失联”，该客户端创建的所有临时znode都会被删除。\n\n## 监视\n客户端在读取特定的znode时可以设置监视这个znode，一单这个znode发生白变化客户端就会收到通知。\n\n## 节点的角色\n\n1. leader\n2. follower\n3. observer\n\n这3中角色的节点都能接受客户端的连接，都能响应读请求。如果follower或者observer收到了写请求会把这个请求转发给leader。\n\nobserver节点不会参与leader的选举。\n\n为什么有observer？如果连接的客户端很多，那么就要扩充zk的节点数量。扩充了之后在选举的时候就会”变慢“，因此引入observer，扩充了节点数量但是参与投票的节点还没有那么多。\n\n## 节点的状态\n1. leading 该节点目前是leader\n2. following 该节点目前是follower\n3. looking 该节点找不到leader，正在“寻找”leader\n4. observering 该节点是observer\n\n## 选举\n选举出现在三种情况\n\n1. 集群启动的时候。\n2. leader出问题了，需要重新选举。\n3. zxid的高位或者低位用尽。\n\n在选取leader的过程中zookeeper集群是不可用的。\nleaer通过心跳与follower和observer通信。当follower失去与leader的联系后会进入looking状态并“投自己一票”然后向集群内的其他节点广播。\n\n选举的核心逻辑就是比较。比较什么呢？比较logicClock、zxid和serverid。 \n\n* logicClock是投票的轮数，每个节点发起投票的时候会将自己的logicClock加1。如果一个节点收到其他节点的投票的时候发现对方的logicClock比自己的小那么会直接忽略该投票。如果发现比自己的大，那么会更新自己的logicClock并重新广播自己的投票（自己的投票之前可能已经被别的节点忽略了）。如果logicClock一样大就去比较zxid。\n* zxid是一个64位的数字，类似于事务id。前32位是epoch，有点类似于raft中的term, 每一次新leader的产生都会使前32位加1。后32位是此次“epoch”周期内的单调递增id。如果zxid一样就去比较serverid。\n* serverid是集群内每个机器的id，一个zk集群在启动的时候就已经确认好了这个集群有几个节点。每一个节点的配置文件里都有这个集群每一个节点的信息。\n\n**一但zxid的高位或者低位用尽则会重新强制重新选举。**\n\n每次选举的时候各个节点首先都是“先投自己一票”然后广播。每一个follower收到“其他节点的投票”的时候都会与自己刚刚投的票相比较（logicClock、zxid和server id），如果自己被pk下去了那么就更新自己本地的投票然后广播，如果不需要修改就什么都不做。\n\n因为每一个节点的投票信息其他的节点都会通过广播收到，因此每一个节点都有当前整个集群中所有节点的投票信息。一但有一个节点获取到了大多数票那么投票就结束了。\n\n如果一个节点新加入或者宕机后新加入，首先会发起选举，但是其他的节点会告诉他我们已经有leader了，然后此节点会自动变成follower。\n\n如果集群刚启动或者leader出现了问题，那么集群会进入崩溃恢复模式选举产生新的leader。新的leader出现后，**有超过半数的follower已经与leader同步过数据后集群就进入了消息广播模式，即正常工作模式**\n\n## 数据同步\n### 正常的同步\nzookeepe使用自己的zab协议实现数据同步。\n写请求都会转发到leader上，随后leader会发出一个proposal，**leader与follower之间的通信是通过队列来实现的并且每个proposal都有一个唯一的zxid**，因此保证了follower中数据写入的顺序。当follower收到proposal后会写入本地日志到磁盘，并返回ack给leader。leader收到大多数的follower的ack后自己commit然后通知各个follower也commit同时返回客户端结果。\n\n### 重新选举出leader后的同步\n新leader先判断自己的未被commit的proposa是否能够commit（依据是此时整个集群额大多数节点都有这个proposal），如果可以就commit，如果不可以就不commit。因此最开始是先搞好leader的数据，之后leader会告诉follower增减数据。\n\n### 如果leader刚发出proposal就宕机了，follower都没有收到\n\n那么新产生的leader将不知道有这个proposal，也就相当于这个proposal被废掉了，即使之前的leader加入集群，这个proposal也会被新的leader废掉。\n\n### 如果leader收到大多数的ack，但是还没有commit\n收到的这些follower中肯定会有一个是新的leader。在其成为leader后会“领导大家”commit这个proposal\n\n## zk保证了一致性和分区可用性，在选举leader的时候集群不可用，牺牲了可用性\n","slug":"zk-first-exploration","published":1,"updated":"2020-11-23T15:23:47.780Z","photos":["http://sysummery.top/zk.png"],"comments":1,"layout":"post","link":"","_id":"ckhupaq9x00111no8u4z0p16m","content":"<p>ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。</p>\n<a id=\"more\"></a>\n<h2 id=\"zookeeper所能提供的功能\"><a href=\"#zookeeper所能提供的功能\" class=\"headerlink\" title=\"zookeeper所能提供的功能\"></a>zookeeper所能提供的功能</h2><h3 id=\"命名服务\"><a href=\"#命名服务\" class=\"headerlink\" title=\"命名服务\"></a>命名服务</h3><p>在zk下创建一个节点作为服务，然后节点下面的子节点中存放该服务的各个机器的ip</p>\n<h3 id=\"配置管理\"><a href=\"#配置管理\" class=\"headerlink\" title=\"配置管理\"></a>配置管理</h3><p>在zk下存放一个节点，当节点的数据发生变化的时候通知watch这个节点的client</p>\n<h3 id=\"集群管理\"><a href=\"#集群管理\" class=\"headerlink\" title=\"集群管理\"></a>集群管理</h3><p>当一个服务的集群增加或者减少机器的时候会在相应的服务节点上增加或删除子节点并通知watch这个服务节点的的所有的client。如果子节点是顺序节点，那么可以顺理成章的把编号最小的那个作为master</p>\n<h3 id=\"选举算法\"><a href=\"#选举算法\" class=\"headerlink\" title=\"选举算法\"></a>选举算法</h3><p>所有的节点都向zk的一个路径下面创建临时有序节点,序号最小的那个就是leader。</p>\n<h3 id=\"锁定和同步\"><a href=\"#锁定和同步\" class=\"headerlink\" title=\"锁定和同步\"></a>锁定和同步</h3><p>保持独占：各个client在zk上创建一个相同的znode，创建成功的client就相当于获取到了锁。保持独占这个方法实现比较简单，但是zk是leader负责写入的，如果很多个客户端同时写的话会有问题。<br>控制时序：各个client往一个znode下面创建临时有序节点，创建的节点的编号最小的client获取到了锁。没获取到锁的client开始watch这个znode下面的节点。获取到锁的client执行完后删除这个锁节点，其他watch的client会受到通知然后看谁的编号最小谁就获取到了这个锁</p>\n<p>获取锁的时候，创建的节点都是暂时的，如果获得锁的进程意外退出，那么这个暂时的节点会立马被删除。</p>\n<h3 id=\"高度可靠地数据注册表\"><a href=\"#高度可靠地数据注册表\" class=\"headerlink\" title=\"高度可靠地数据注册表\"></a>高度可靠地数据注册表</h3><p><img src=\"http://sysummery.top/zkc.jpg\" alt></p>\n<h2 id=\"znode\"><a href=\"#znode\" class=\"headerlink\" title=\"znode\"></a>znode</h2><p>ZooKeeper命名空间内部拥有一个树状的内存模型，其中各节点被称为znode。每个znode包含一个路径和与之相关的元数据，以及该znode下关联的子节点列表。<br><img src=\"http://sysummery.top/znode.png\" alt></p>\n<h3 id=\"znode节点类型\"><a href=\"#znode节点类型\" class=\"headerlink\" title=\"znode节点类型\"></a>znode节点类型</h3><ol>\n<li>持久节点</li>\n<li>持久顺序节点</li>\n<li>临时节点</li>\n<li>临时顺序节点</li>\n</ol>\n<p>znode可以存储一些数据外还有一些元数据</p>\n<ul>\n<li>czxid 创建节点的事务id</li>\n<li>ctime 创建时间</li>\n<li>mzxid 最后一次更新节点的事务id</li>\n<li>mtime 最后一次更新时间</li>\n<li>dataLength 数据长度</li>\n<li>numChildren 子节点数</li>\n</ul>\n<h2 id=\"会话\"><a href=\"#会话\" class=\"headerlink\" title=\"会话\"></a>会话</h2><p>一个客户端与zookeeper连接后就形成了一个会话，客户端通过心跳与zookeeper保持联系。一单在超时时间内zookeeper没有收到心跳，就认为客户端已经“失联”，该客户端创建的所有临时znode都会被删除。</p>\n<h2 id=\"监视\"><a href=\"#监视\" class=\"headerlink\" title=\"监视\"></a>监视</h2><p>客户端在读取特定的znode时可以设置监视这个znode，一单这个znode发生白变化客户端就会收到通知。</p>\n<h2 id=\"节点的角色\"><a href=\"#节点的角色\" class=\"headerlink\" title=\"节点的角色\"></a>节点的角色</h2><ol>\n<li>leader</li>\n<li>follower</li>\n<li>observer</li>\n</ol>\n<p>这3中角色的节点都能接受客户端的连接，都能响应读请求。如果follower或者observer收到了写请求会把这个请求转发给leader。</p>\n<p>observer节点不会参与leader的选举。</p>\n<p>为什么有observer？如果连接的客户端很多，那么就要扩充zk的节点数量。扩充了之后在选举的时候就会”变慢“，因此引入observer，扩充了节点数量但是参与投票的节点还没有那么多。</p>\n<h2 id=\"节点的状态\"><a href=\"#节点的状态\" class=\"headerlink\" title=\"节点的状态\"></a>节点的状态</h2><ol>\n<li>leading 该节点目前是leader</li>\n<li>following 该节点目前是follower</li>\n<li>looking 该节点找不到leader，正在“寻找”leader</li>\n<li>observering 该节点是observer</li>\n</ol>\n<h2 id=\"选举\"><a href=\"#选举\" class=\"headerlink\" title=\"选举\"></a>选举</h2><p>选举出现在三种情况</p>\n<ol>\n<li>集群启动的时候。</li>\n<li>leader出问题了，需要重新选举。</li>\n<li>zxid的高位或者低位用尽。</li>\n</ol>\n<p>在选取leader的过程中zookeeper集群是不可用的。<br>leaer通过心跳与follower和observer通信。当follower失去与leader的联系后会进入looking状态并“投自己一票”然后向集群内的其他节点广播。</p>\n<p>选举的核心逻辑就是比较。比较什么呢？比较logicClock、zxid和serverid。 </p>\n<ul>\n<li>logicClock是投票的轮数，每个节点发起投票的时候会将自己的logicClock加1。如果一个节点收到其他节点的投票的时候发现对方的logicClock比自己的小那么会直接忽略该投票。如果发现比自己的大，那么会更新自己的logicClock并重新广播自己的投票（自己的投票之前可能已经被别的节点忽略了）。如果logicClock一样大就去比较zxid。</li>\n<li>zxid是一个64位的数字，类似于事务id。前32位是epoch，有点类似于raft中的term, 每一次新leader的产生都会使前32位加1。后32位是此次“epoch”周期内的单调递增id。如果zxid一样就去比较serverid。</li>\n<li>serverid是集群内每个机器的id，一个zk集群在启动的时候就已经确认好了这个集群有几个节点。每一个节点的配置文件里都有这个集群每一个节点的信息。</li>\n</ul>\n<p><strong>一但zxid的高位或者低位用尽则会重新强制重新选举。</strong></p>\n<p>每次选举的时候各个节点首先都是“先投自己一票”然后广播。每一个follower收到“其他节点的投票”的时候都会与自己刚刚投的票相比较（logicClock、zxid和server id），如果自己被pk下去了那么就更新自己本地的投票然后广播，如果不需要修改就什么都不做。</p>\n<p>因为每一个节点的投票信息其他的节点都会通过广播收到，因此每一个节点都有当前整个集群中所有节点的投票信息。一但有一个节点获取到了大多数票那么投票就结束了。</p>\n<p>如果一个节点新加入或者宕机后新加入，首先会发起选举，但是其他的节点会告诉他我们已经有leader了，然后此节点会自动变成follower。</p>\n<p>如果集群刚启动或者leader出现了问题，那么集群会进入崩溃恢复模式选举产生新的leader。新的leader出现后，<strong>有超过半数的follower已经与leader同步过数据后集群就进入了消息广播模式，即正常工作模式</strong></p>\n<h2 id=\"数据同步\"><a href=\"#数据同步\" class=\"headerlink\" title=\"数据同步\"></a>数据同步</h2><h3 id=\"正常的同步\"><a href=\"#正常的同步\" class=\"headerlink\" title=\"正常的同步\"></a>正常的同步</h3><p>zookeepe使用自己的zab协议实现数据同步。<br>写请求都会转发到leader上，随后leader会发出一个proposal，<strong>leader与follower之间的通信是通过队列来实现的并且每个proposal都有一个唯一的zxid</strong>，因此保证了follower中数据写入的顺序。当follower收到proposal后会写入本地日志到磁盘，并返回ack给leader。leader收到大多数的follower的ack后自己commit然后通知各个follower也commit同时返回客户端结果。</p>\n<h3 id=\"重新选举出leader后的同步\"><a href=\"#重新选举出leader后的同步\" class=\"headerlink\" title=\"重新选举出leader后的同步\"></a>重新选举出leader后的同步</h3><p>新leader先判断自己的未被commit的proposa是否能够commit（依据是此时整个集群额大多数节点都有这个proposal），如果可以就commit，如果不可以就不commit。因此最开始是先搞好leader的数据，之后leader会告诉follower增减数据。</p>\n<h3 id=\"如果leader刚发出proposal就宕机了，follower都没有收到\"><a href=\"#如果leader刚发出proposal就宕机了，follower都没有收到\" class=\"headerlink\" title=\"如果leader刚发出proposal就宕机了，follower都没有收到\"></a>如果leader刚发出proposal就宕机了，follower都没有收到</h3><p>那么新产生的leader将不知道有这个proposal，也就相当于这个proposal被废掉了，即使之前的leader加入集群，这个proposal也会被新的leader废掉。</p>\n<h3 id=\"如果leader收到大多数的ack，但是还没有commit\"><a href=\"#如果leader收到大多数的ack，但是还没有commit\" class=\"headerlink\" title=\"如果leader收到大多数的ack，但是还没有commit\"></a>如果leader收到大多数的ack，但是还没有commit</h3><p>收到的这些follower中肯定会有一个是新的leader。在其成为leader后会“领导大家”commit这个proposal</p>\n<h2 id=\"zk保证了一致性和分区可用性，在选举leader的时候集群不可用，牺牲了可用性\"><a href=\"#zk保证了一致性和分区可用性，在选举leader的时候集群不可用，牺牲了可用性\" class=\"headerlink\" title=\"zk保证了一致性和分区可用性，在选举leader的时候集群不可用，牺牲了可用性\"></a>zk保证了一致性和分区可用性，在选举leader的时候集群不可用，牺牲了可用性</h2>","site":{"data":{}},"excerpt":"<p>ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。</p>","more":"<h2 id=\"zookeeper所能提供的功能\"><a href=\"#zookeeper所能提供的功能\" class=\"headerlink\" title=\"zookeeper所能提供的功能\"></a>zookeeper所能提供的功能</h2><h3 id=\"命名服务\"><a href=\"#命名服务\" class=\"headerlink\" title=\"命名服务\"></a>命名服务</h3><p>在zk下创建一个节点作为服务，然后节点下面的子节点中存放该服务的各个机器的ip</p>\n<h3 id=\"配置管理\"><a href=\"#配置管理\" class=\"headerlink\" title=\"配置管理\"></a>配置管理</h3><p>在zk下存放一个节点，当节点的数据发生变化的时候通知watch这个节点的client</p>\n<h3 id=\"集群管理\"><a href=\"#集群管理\" class=\"headerlink\" title=\"集群管理\"></a>集群管理</h3><p>当一个服务的集群增加或者减少机器的时候会在相应的服务节点上增加或删除子节点并通知watch这个服务节点的的所有的client。如果子节点是顺序节点，那么可以顺理成章的把编号最小的那个作为master</p>\n<h3 id=\"选举算法\"><a href=\"#选举算法\" class=\"headerlink\" title=\"选举算法\"></a>选举算法</h3><p>所有的节点都向zk的一个路径下面创建临时有序节点,序号最小的那个就是leader。</p>\n<h3 id=\"锁定和同步\"><a href=\"#锁定和同步\" class=\"headerlink\" title=\"锁定和同步\"></a>锁定和同步</h3><p>保持独占：各个client在zk上创建一个相同的znode，创建成功的client就相当于获取到了锁。保持独占这个方法实现比较简单，但是zk是leader负责写入的，如果很多个客户端同时写的话会有问题。<br>控制时序：各个client往一个znode下面创建临时有序节点，创建的节点的编号最小的client获取到了锁。没获取到锁的client开始watch这个znode下面的节点。获取到锁的client执行完后删除这个锁节点，其他watch的client会受到通知然后看谁的编号最小谁就获取到了这个锁</p>\n<p>获取锁的时候，创建的节点都是暂时的，如果获得锁的进程意外退出，那么这个暂时的节点会立马被删除。</p>\n<h3 id=\"高度可靠地数据注册表\"><a href=\"#高度可靠地数据注册表\" class=\"headerlink\" title=\"高度可靠地数据注册表\"></a>高度可靠地数据注册表</h3><p><img src=\"http://sysummery.top/zkc.jpg\" alt></p>\n<h2 id=\"znode\"><a href=\"#znode\" class=\"headerlink\" title=\"znode\"></a>znode</h2><p>ZooKeeper命名空间内部拥有一个树状的内存模型，其中各节点被称为znode。每个znode包含一个路径和与之相关的元数据，以及该znode下关联的子节点列表。<br><img src=\"http://sysummery.top/znode.png\" alt></p>\n<h3 id=\"znode节点类型\"><a href=\"#znode节点类型\" class=\"headerlink\" title=\"znode节点类型\"></a>znode节点类型</h3><ol>\n<li>持久节点</li>\n<li>持久顺序节点</li>\n<li>临时节点</li>\n<li>临时顺序节点</li>\n</ol>\n<p>znode可以存储一些数据外还有一些元数据</p>\n<ul>\n<li>czxid 创建节点的事务id</li>\n<li>ctime 创建时间</li>\n<li>mzxid 最后一次更新节点的事务id</li>\n<li>mtime 最后一次更新时间</li>\n<li>dataLength 数据长度</li>\n<li>numChildren 子节点数</li>\n</ul>\n<h2 id=\"会话\"><a href=\"#会话\" class=\"headerlink\" title=\"会话\"></a>会话</h2><p>一个客户端与zookeeper连接后就形成了一个会话，客户端通过心跳与zookeeper保持联系。一单在超时时间内zookeeper没有收到心跳，就认为客户端已经“失联”，该客户端创建的所有临时znode都会被删除。</p>\n<h2 id=\"监视\"><a href=\"#监视\" class=\"headerlink\" title=\"监视\"></a>监视</h2><p>客户端在读取特定的znode时可以设置监视这个znode，一单这个znode发生白变化客户端就会收到通知。</p>\n<h2 id=\"节点的角色\"><a href=\"#节点的角色\" class=\"headerlink\" title=\"节点的角色\"></a>节点的角色</h2><ol>\n<li>leader</li>\n<li>follower</li>\n<li>observer</li>\n</ol>\n<p>这3中角色的节点都能接受客户端的连接，都能响应读请求。如果follower或者observer收到了写请求会把这个请求转发给leader。</p>\n<p>observer节点不会参与leader的选举。</p>\n<p>为什么有observer？如果连接的客户端很多，那么就要扩充zk的节点数量。扩充了之后在选举的时候就会”变慢“，因此引入observer，扩充了节点数量但是参与投票的节点还没有那么多。</p>\n<h2 id=\"节点的状态\"><a href=\"#节点的状态\" class=\"headerlink\" title=\"节点的状态\"></a>节点的状态</h2><ol>\n<li>leading 该节点目前是leader</li>\n<li>following 该节点目前是follower</li>\n<li>looking 该节点找不到leader，正在“寻找”leader</li>\n<li>observering 该节点是observer</li>\n</ol>\n<h2 id=\"选举\"><a href=\"#选举\" class=\"headerlink\" title=\"选举\"></a>选举</h2><p>选举出现在三种情况</p>\n<ol>\n<li>集群启动的时候。</li>\n<li>leader出问题了，需要重新选举。</li>\n<li>zxid的高位或者低位用尽。</li>\n</ol>\n<p>在选取leader的过程中zookeeper集群是不可用的。<br>leaer通过心跳与follower和observer通信。当follower失去与leader的联系后会进入looking状态并“投自己一票”然后向集群内的其他节点广播。</p>\n<p>选举的核心逻辑就是比较。比较什么呢？比较logicClock、zxid和serverid。 </p>\n<ul>\n<li>logicClock是投票的轮数，每个节点发起投票的时候会将自己的logicClock加1。如果一个节点收到其他节点的投票的时候发现对方的logicClock比自己的小那么会直接忽略该投票。如果发现比自己的大，那么会更新自己的logicClock并重新广播自己的投票（自己的投票之前可能已经被别的节点忽略了）。如果logicClock一样大就去比较zxid。</li>\n<li>zxid是一个64位的数字，类似于事务id。前32位是epoch，有点类似于raft中的term, 每一次新leader的产生都会使前32位加1。后32位是此次“epoch”周期内的单调递增id。如果zxid一样就去比较serverid。</li>\n<li>serverid是集群内每个机器的id，一个zk集群在启动的时候就已经确认好了这个集群有几个节点。每一个节点的配置文件里都有这个集群每一个节点的信息。</li>\n</ul>\n<p><strong>一但zxid的高位或者低位用尽则会重新强制重新选举。</strong></p>\n<p>每次选举的时候各个节点首先都是“先投自己一票”然后广播。每一个follower收到“其他节点的投票”的时候都会与自己刚刚投的票相比较（logicClock、zxid和server id），如果自己被pk下去了那么就更新自己本地的投票然后广播，如果不需要修改就什么都不做。</p>\n<p>因为每一个节点的投票信息其他的节点都会通过广播收到，因此每一个节点都有当前整个集群中所有节点的投票信息。一但有一个节点获取到了大多数票那么投票就结束了。</p>\n<p>如果一个节点新加入或者宕机后新加入，首先会发起选举，但是其他的节点会告诉他我们已经有leader了，然后此节点会自动变成follower。</p>\n<p>如果集群刚启动或者leader出现了问题，那么集群会进入崩溃恢复模式选举产生新的leader。新的leader出现后，<strong>有超过半数的follower已经与leader同步过数据后集群就进入了消息广播模式，即正常工作模式</strong></p>\n<h2 id=\"数据同步\"><a href=\"#数据同步\" class=\"headerlink\" title=\"数据同步\"></a>数据同步</h2><h3 id=\"正常的同步\"><a href=\"#正常的同步\" class=\"headerlink\" title=\"正常的同步\"></a>正常的同步</h3><p>zookeepe使用自己的zab协议实现数据同步。<br>写请求都会转发到leader上，随后leader会发出一个proposal，<strong>leader与follower之间的通信是通过队列来实现的并且每个proposal都有一个唯一的zxid</strong>，因此保证了follower中数据写入的顺序。当follower收到proposal后会写入本地日志到磁盘，并返回ack给leader。leader收到大多数的follower的ack后自己commit然后通知各个follower也commit同时返回客户端结果。</p>\n<h3 id=\"重新选举出leader后的同步\"><a href=\"#重新选举出leader后的同步\" class=\"headerlink\" title=\"重新选举出leader后的同步\"></a>重新选举出leader后的同步</h3><p>新leader先判断自己的未被commit的proposa是否能够commit（依据是此时整个集群额大多数节点都有这个proposal），如果可以就commit，如果不可以就不commit。因此最开始是先搞好leader的数据，之后leader会告诉follower增减数据。</p>\n<h3 id=\"如果leader刚发出proposal就宕机了，follower都没有收到\"><a href=\"#如果leader刚发出proposal就宕机了，follower都没有收到\" class=\"headerlink\" title=\"如果leader刚发出proposal就宕机了，follower都没有收到\"></a>如果leader刚发出proposal就宕机了，follower都没有收到</h3><p>那么新产生的leader将不知道有这个proposal，也就相当于这个proposal被废掉了，即使之前的leader加入集群，这个proposal也会被新的leader废掉。</p>\n<h3 id=\"如果leader收到大多数的ack，但是还没有commit\"><a href=\"#如果leader收到大多数的ack，但是还没有commit\" class=\"headerlink\" title=\"如果leader收到大多数的ack，但是还没有commit\"></a>如果leader收到大多数的ack，但是还没有commit</h3><p>收到的这些follower中肯定会有一个是新的leader。在其成为leader后会“领导大家”commit这个proposal</p>\n<h2 id=\"zk保证了一致性和分区可用性，在选举leader的时候集群不可用，牺牲了可用性\"><a href=\"#zk保证了一致性和分区可用性，在选举leader的时候集群不可用，牺牲了可用性\" class=\"headerlink\" title=\"zk保证了一致性和分区可用性，在选举leader的时候集群不可用，牺牲了可用性\"></a>zk保证了一致性和分区可用性，在选举leader的时候集群不可用，牺牲了可用性</h2>"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"ckhupaq8z00001no8mjznkcgi","tag_id":"ckhupaq9600041no8xfvz9xy7","_id":"ckhupaq9k000i1no86gnkr1qq"},{"post_id":"ckhupaq8z00001no8mjznkcgi","tag_id":"ckhupaq9f000a1no8qtep06mx","_id":"ckhupaq9m000l1no8y4wx5jpt"},{"post_id":"ckhupaq9k000h1no8cxi1rxg4","tag_id":"ckhupaq9600041no8xfvz9xy7","_id":"ckhupaq9o000p1no88e43ap4s"},{"post_id":"ckhupaq9k000h1no8cxi1rxg4","tag_id":"ckhupaq9f000a1no8qtep06mx","_id":"ckhupaq9r000s1no85kw0phlh"},{"post_id":"ckhupaq9l000k1no8cur1wmpn","tag_id":"ckhupaq9600041no8xfvz9xy7","_id":"ckhupaq9u000w1no8va34pu28"},{"post_id":"ckhupaq9l000k1no8cur1wmpn","tag_id":"ckhupaq9f000a1no8qtep06mx","_id":"ckhupaq9w000z1no80shxv6qv"},{"post_id":"ckhupaq9v000y1no8wau7mebv","tag_id":"ckhupaq9600041no8xfvz9xy7","_id":"ckhupaq9z00141no892p1mu46"},{"post_id":"ckhupaq9v000y1no8wau7mebv","tag_id":"ckhupaq9f000a1no8qtep06mx","_id":"ckhupaqa000161no84bmhc45w"},{"post_id":"ckhupaq9400021no8eawhmatt","tag_id":"ckhupaq9j000g1no89izfiyok","_id":"ckhupaqa100191no8njo1n56x"},{"post_id":"ckhupaq9400021no8eawhmatt","tag_id":"ckhupaq9n000n1no8wwwr4mxv","_id":"ckhupaqa1001a1no8kjtvc8gn"},{"post_id":"ckhupaq9400021no8eawhmatt","tag_id":"ckhupaq9t000u1no8emgl3lnj","_id":"ckhupaqa1001c1no8kca8c5nn"},{"post_id":"ckhupaq9800051no83zyt969a","tag_id":"ckhupaq9x00121no8e50hc4t6","_id":"ckhupaqa2001d1no8xy6fkfvs"},{"post_id":"ckhupaq9b00071no8wjxrb8r5","tag_id":"ckhupaqa000181no808j1symp","_id":"ckhupaqa3001f1no80p3x555i"},{"post_id":"ckhupaq9d00091no8dgdl2v8h","tag_id":"ckhupaqa000181no808j1symp","_id":"ckhupaqa3001g1no8egp0v4if"},{"post_id":"ckhupaq9g000c1no8tect5gtz","tag_id":"ckhupaqa000181no808j1symp","_id":"ckhupaqa4001i1no8cfwwd1q9"},{"post_id":"ckhupaq9i000e1no8qqlh35wm","tag_id":"ckhupaqa4001h1no8t4buivc7","_id":"ckhupaqa5001k1no8ftj7vksb"},{"post_id":"ckhupaq9n000o1no8t1xfmp73","tag_id":"ckhupaqa4001j1no8gc2vp5pd","_id":"ckhupaqa5001m1no8i0zmzcm2"},{"post_id":"ckhupaq9q000r1no8k21og357","tag_id":"ckhupaqa5001l1no8h14j54mn","_id":"ckhupaqa6001o1no8glaoq93m"},{"post_id":"ckhupaq9t000v1no8tf8i1gb5","tag_id":"ckhupaqa5001l1no8h14j54mn","_id":"ckhupaqa7001q1no8i6gdupiu"},{"post_id":"ckhupaq9x00111no8u4z0p16m","tag_id":"ckhupaqa5001l1no8h14j54mn","_id":"ckhupaqa7001r1no8y3dlg2av"}],"Tag":[{"name":"mysql","_id":"ckhupaq9600041no8xfvz9xy7"},{"name":"innodb","_id":"ckhupaq9f000a1no8qtep06mx"},{"name":"cookie","_id":"ckhupaq9j000g1no89izfiyok"},{"name":"oauth2","_id":"ckhupaq9n000n1no8wwwr4mxv"},{"name":"jwt","_id":"ckhupaq9t000u1no8emgl3lnj"},{"name":"git","_id":"ckhupaq9x00121no8e50hc4t6"},{"name":"go","_id":"ckhupaqa000181no808j1symp"},{"name":"https","_id":"ckhupaqa4001h1no8t4buivc7"},{"name":"nginx","_id":"ckhupaqa4001j1no8gc2vp5pd"},{"name":"分布式","_id":"ckhupaqa5001l1no8h14j54mn"}]}}